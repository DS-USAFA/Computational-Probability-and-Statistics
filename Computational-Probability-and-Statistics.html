<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Computational Probability and Statistics</title>

    <meta name="author" content="Matthew Davis" />
    <meta name="author" content="Brianna Hitt" />
    <meta name="author" content="Ken Horton" />
    <meta name="author" content="Bradley Warner" />
  
   <meta name="description" content="This is a set of notes used for Math 377 starting in the fall of 2020 that has been compiled into a book." />
   <meta name="generator" content="placeholder" />
  <meta property="og:title" content="Computational Probability and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/figures/Cover.png" />
  <meta property="og:description" content="This is a set of notes used for Math 377 starting in the fall of 2020 that has been compiled into a book." />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Computational Probability and Statistics" />
  
  <meta name="twitter:description" content="This is a set of notes used for Math 377 starting in the fall of 2020 that has been compiled into a book." />
  <meta name="twitter:image" content="/figures/Cover.png" />
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
    <script src="libs/bs3compat-0.3.1/transition.js"></script>
    <script src="libs/bs3compat-0.3.1/tabs.js"></script>
    <script src="libs/bs3compat-0.3.1/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script>

  <!-- CSS -->
  <style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
    <style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
      <link rel="stylesheet" href="style.css" />
  
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<!--bookdown:title:start-->
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Computational Probability and Statistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>

      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book source <i class="fab fa-github"></i></a></li></p>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="preface" class="section level1 unnumbered">
<h1 class="unnumbered">Preface</h1>
<p><img src="figures/Cover.png" width="705" /></p>
<p>This book is based on the notes we created for our students as part of a one semester course on probability and statistics. We developed these notes from three primary resources. The most important is the Openintro Introductory Statistics with Randomization and Simulation <span class="citation">(<a href="#ref-ointrorand" role="doc-biblioref">Diez, Barr, and Çetinkaya-Rundel 2014</a>)</span> book. In parts, we have used their notes and homework problems. However, in most cases we have altered their work to fit our needs. The second most important book for our work is Introduction to Probability and Statistics Using R <span class="citation">(<a href="#ref-ipsur" role="doc-biblioref">Kerns 2010</a>)</span>. Finally, we have used some examples, code, and ideas from the first addition of Prium’s book Foundations and Applications of Statistics: An Introduction Using R <span class="citation">(<a href="#ref-pruim2011foundations" role="doc-biblioref">R. J. Pruim 2011</a>)</span>.</p>
<div id="who-is-this-book-for" class="section level2" number="0.1">
<h2><span class="header-section-number">0.1</span> Who is this book for?</h2>
<p>We designed this book for study of statistics that maximizes computational ideas while minimizing algebraic symbol manipulation. Although we do discuss traditional small-sample, normal-based inference and some of the classical probability distributions, we rely heavily on ideas such as simulation, permutations, and bootstrap. This means that students with a background in differential and integral calculus will be successful with this book.</p>
<p>The book makes extensive using of the <code>R</code> programming language. In particular we focus both on the <strong>tidyverse</strong> and <strong>mosaic</strong> packages. We include a significant amount of code in our notes and frequently demonstrate multiple ways of completing a task. We have used this book for juniors and sophomores.</p>
</div>
<div id="book-structure-and-how-to-use-it" class="section level2" number="0.2">
<h2><span class="header-section-number">0.2</span> Book structure and how to use it</h2>
<p>This book is divided into 4 parts. Each part starts with a case study that introduces many of the main ideas of each part. Each chapter is designed to be a standalone 50 minute lesson. Within each lesson, we give exercises that can be worked in class and we provide learning objectives.</p>
<p>This book assumes students have access to <code>R</code>. Finally, we keep the number of homework problems to a reasonable level and assign all problems.</p>
<p>The four parts of the book are:</p>
<ol style="list-style-type: decimal">
<li><p>Descriptive Statistical Modeling: This part introduces the student to data collection methods, summary statistics, visual summaries, and exploratory data analysis.</p></li>
<li><p>Probability: We discuss the foundational ideas of probability, counting methods, and common distributions. We use both calculus and simulation to find moments and probabilities. We introduce basic ideas of multivariate probability. We include method of moments and maximum likelihood estimators.</p></li>
<li><p>Statistical Inference: We discuss many of the basic inference ideas found in a traditional introductory statistics class but we add ideas of bootstrap and permutation methods.</p></li>
<li><p>Statistical Prediction: The final part introduces prediction methods mainly in the form of linear regression. This part also includes inference for regression.</p></li>
</ol>
<p>The learning outcomes for this course are to use computational and mathematical statistical/probabilistic concepts for:</p>
<ol style="list-style-type: lower-alpha">
<li>Developing probabilistic models</li>
<li>Developing statistical models for description, inference, and prediction<br />
</li>
<li>Advancing practical and theoretical analytic experience and skills</li>
</ol>
</div>
<div id="prerequisites" class="section level2" number="0.3">
<h2><span class="header-section-number">0.3</span> Prerequisites</h2>
<p>To take this course, students are expected to have completed calculus up through and including integral calculus. We do have multivariate ideas in the course but they are easily taught and don’t require calculus III. We don’t assume the students have any programming experience and thus, we include a great deal of code. We have historically supplemented the course with <a href="http://datacamp.com/">Data Camp</a> courses. We have also used <a href="http://rstudio.cloud">RStudio Cloud</a> to help students get started without the burden of loading and maintaining software.</p>
</div>
<div id="packages" class="section level2" number="0.4">
<h2><span class="header-section-number">0.4</span> Packages</h2>
<p>These notes make use of the following packages in <code>R</code>: <strong>knitr</strong> <span class="citation">(<a href="#ref-R-knitr" role="doc-biblioref">Xie 2022b</a>)</span>, <strong>rmarkdown</strong> <span class="citation">(<a href="#ref-R-rmarkdown" role="doc-biblioref">Allaire et al. 2022</a>)</span>, <strong>mosaic</strong> <span class="citation">(<a href="#ref-R-mosaic" role="doc-biblioref">R. Pruim, Kaplan, and Horton 2021</a>)</span>, <strong>mosaicCalc</strong> <span class="citation">(<a href="#ref-R-mosaicCalc" role="doc-biblioref">Kaplan, Pruim, and Horton 2020</a>)</span>, <strong>tidyverse</strong> <span class="citation">(<a href="#ref-R-tidyverse" role="doc-biblioref">Wickham 2021</a>)</span>, <strong>ISLR</strong> <span class="citation">(<a href="#ref-R-ISLR" role="doc-biblioref">James et al. 2021</a>)</span>, <strong>vcd</strong> <span class="citation">(<a href="#ref-R-vcd" role="doc-biblioref">Meyer, Zeileis, and Hornik 2022</a>)</span>, <strong>ggplot2</strong> <span class="citation">(<a href="#ref-R-ggplot2" role="doc-biblioref">Wickham et al. 2021</a>)</span>, <strong>MASS</strong> <span class="citation">(<a href="#ref-R-MASS" role="doc-biblioref">Ripley 2022</a>)</span>, <strong>openintro</strong> <span class="citation">(<a href="#ref-R-openintro" role="doc-biblioref">Çetinkaya-Rundel et al. 2022</a>)</span>, <strong>broom</strong> <span class="citation">(<a href="#ref-R-broom" role="doc-biblioref">Robinson, Hayes, and Couch 2022</a>)</span>, <strong>infer</strong> <span class="citation">(<a href="#ref-R-infer" role="doc-biblioref">Bray et al. 2021</a>)</span>, <strong>kableExtra</strong> <span class="citation">(<a href="#ref-R-kableExtra" role="doc-biblioref">Zhu 2021</a>)</span>, and <strong>DT</strong> <span class="citation">(<a href="#ref-R-DT" role="doc-biblioref">Xie, Cheng, and Tan 2022</a>)</span>.</p>
</div>
<div id="acknowledgements" class="section level2" number="0.5">
<h2><span class="header-section-number">0.5</span> Acknowledgements</h2>
<p>We have been lucky to have numerous open sources to help facilitate this work. Thank you to those who helped to correct mistakes to include Skyler Royse.</p>
<p>This book was written using the <strong>bookdown</strong> package <span class="citation">(<a href="#ref-R-bookdown" role="doc-biblioref">Xie 2022a</a>)</span>.</p>
<p><img src="figures/by-nc-sa.png" width="44" /></p>
<p>This book is licensed under the <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
</div>
<div id="file-creation-information" class="section level2" number="0.6">
<h2><span class="header-section-number">0.6</span> File Creation Information</h2>
<ul>
<li>File creation date: 2022-06-14</li>
<li>R version 4.1.3 (2022-03-10)</li>
</ul>
<!--chapter:end:index.Rmd-->
</div>
</div>
<div id="part-descriptive-statistical-modeling" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Descriptive Statistical Modeling</h1>
</div>
<div id="CS1" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Case Study</h1>
<div id="objectives" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Use R for basic analysis and visualization.<br />
</li>
<li>Compile a report using <code>knitr</code>.</li>
</ol>
</div>
<div id="introduction-to-descriptive-statistical-modeling" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Introduction to descriptive statistical modeling</h2>
<p>In this first block of material, we will focus on data types, collection methods, summaries, and visualizations. We also intend to introduce computing via the <code>R</code> package. Programming in <code>R</code> requires some focus early in the course and we will supplement with some online courses. There is relatively little mathematics in this first block.</p>
</div>
<div id="the-data-analytic-process" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> The data analytic process</h2>
<p>Scientists seek to answer questions using rigorous methods and careful observations. These observations – collected from the likes of field notes, surveys, and experiments – form the backbone of a statistical investigation and are called <strong>data</strong>. Statistics is the study of how best to collect, analyze, and draw conclusions from data. It is helpful to put statistics in the context of a general process of investigation:</p>
<ol style="list-style-type: decimal">
<li><p>Identify a question or problem.</p></li>
<li><p>Collect relevant data on the topic.</p></li>
<li><p>Explore and understand the data.</p></li>
<li><p>Analyze the data.</p></li>
<li><p>Form a conclusion.</p></li>
<li><p>Make decisions based on the conclusion.</p></li>
</ol>
<p>This is typical of an explanatory process because it starts with a research question and proceeds. However, sometimes an analysis is exploratory in nature. There is data but not necessarily a research question. The purpose of the analysis is to find interesting features in the data and sometimes generate hypotheses. In this course we focus on the explanatory aspects of analysis.</p>
<p>Statistics as a subject focuses on making stages 2-5 objective, rigorous, and efficient. That is, statistics has three primary components:</p>
<ul>
<li>How best can we collect data?<br />
</li>
<li>How should it be analyzed?<br />
</li>
<li>And what can we infer from the analysis?</li>
</ul>
<p>The topics scientists investigate are as diverse as the questions they ask. However, many of these investigations can be addressed with a small number of data collection techniques, analytic tools, and fundamental concepts in statistical inference. This lesson provides a glimpse into these and other themes we will encounter throughout the rest of the course.</p>
</div>
<div id="case-study" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Case study</h2>
<p>In this lesson we will consider an experiment that studies effectiveness of stents in treating patients at risk of stroke. <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> <a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Stents are small mesh tubes that are placed inside narrow or weak arteries to assist in patient recovery after cardiac events and reduce the risk of an additional heart attack or death. Many doctors have hoped that there would be similar benefits for patients at risk of stroke. We start by writing the principal question the researchers hope to answer:</p>
<div id="research-question" class="section level3" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Research question</h3>
<blockquote>
<p>Does the use of stents reduce the risk of stroke?</p>
</blockquote>
</div>
<div id="collect-the-relevant-data" class="section level3" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Collect the relevant data</h3>
<p>The researchers who asked this question collected data on 451 at-risk patients. Each volunteer patient was randomly assigned to one of two groups:</p>
<p><strong>Treatment group</strong>. Patients in the treatment group received a stent and medical management. The medical management included medications, management of risk factors, and help in lifestyle modification.</p>
<p><strong>Control group</strong>. Patients in the control group received the same medical management as the treatment group but did not receive stents.</p>
<p>Researchers randomly assigned 224 patients to the treatment group and 227 to the control group. In this study, the control group provides a reference point against which we can measure the medical impact of stents in the treatment group.</p>
<p>This is an experiment and not an observational study. We will learn more about these ideas in this block.</p>
<p>Researchers studied the effect of stents at two time points: 30 days after enrollment and 365 days after enrollment.</p>
</div>
<div id="import-data" class="section level3" number="1.4.3">
<h3><span class="header-section-number">1.4.3</span> Import data</h3>
<p>We begin our first use of <code>R</code>.</p>
<p>If you need to install a package, most likely it will be on CRAN, the Comprehensive R Archive Network. Before
a package can be used, it must be installed on the computer (once per computer or account) and loaded into a session (once per <code>R</code> session). When you exit <code>R</code>, the package stays installed on the computer but will not be reloaded when <code>R</code> is started again.</p>
<p>In summary, <code>R</code> has packages that can be downloaded and installed from online repositories such as CRAN. When you install a package, which only needs to be done once per computer or account, in <code>R</code> all it is doing is placing the source code in a library folder designated during the installation of <code>R</code>. Packages are typically collections of functions and variables that are specific to a certain task or subject matter.</p>
<p>For example, to install the <strong>mosaic</strong> package, enter:</p>
<pre><code>install.packages(&quot;mosaic&quot;) # fetch package from CRAN</code></pre>
<p>In RStudio, there is a <em>Packages</em> tab that makes it easy to add and maintain packages.</p>
<p>To use a package in a session, we must load it. This makes it available to the current session only. When you start <code>R</code> again, you will have to load packages again. The command <code>library()</code> with the package name supplied as the argument is all that is needed. For this session, we will load <strong>tidyverse</strong> and <strong>mosaic</strong>. Note: the box below is executing the <code>R</code> commands, this is known as reproducible research since you can see the code and then you can run or modify as you need.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mosaic)</span></code></pre></div>
<p>Next read in the data into the working environment.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>stent_study <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/stent_study.csv&quot;</span>)</span></code></pre></div>
<p>Let’s break this code down. We are reading from a .csv file and assigning the results into an object called <code>stent_study</code>. The assignment arrow <code>&lt;-</code> means we assign what is on the right to what is on the left. The <code>R</code> function we use in this case is <code>read_csv()</code>. When using <code>R</code> functions, you should ask yourself:</p>
<ol style="list-style-type: decimal">
<li><p>What do I want <code>R</code> to do?</p></li>
<li><p>What information must I provide for <code>R</code> to do this?</p></li>
</ol>
<p>We want <code>R</code> to read in a .csv file. We can get help on this function by typing <code>?read_csv</code> or <code>help(read_csv)</code> at the prompt. The only required input to <code>read_csv()</code> is the file location. We have our data stored in a folder called “data” under the working directory. We can determine the working directory by typing <code>getwd()</code> at the prompt.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getwd</span>()</span></code></pre></div>
<p>Similarly, if we wish to change the working directory, we can do so by using the <code>setwd()</code> function:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&#39;C:/Users/Brad.Warner/Documents/Classes/Prob Stat/Another Folder&#39;</span>)</span></code></pre></div>
<p>In <code>R</code> if you use the <code>view()</code>, you will see the data in what looks like a standard spreadsheet.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">view</span>(stent_study)</span></code></pre></div>
</div>
<div id="explore-data" class="section level3" number="1.4.4">
<h3><span class="header-section-number">1.4.4</span> Explore data</h3>
<p>Before we attempt to answer the research question, let’s look at the data. We want <code>R</code> to print out the first 10 rows of the data. The appropriate function is <code>head()</code> and it needs the data object. By default, <code>R</code> will output the first 6 rows. By using the <code>n =</code> argument, we can specify how many rows we want to view.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(stent_study, <span class="at">n =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 3
##    group   outcome30 outcome365
##    &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;     
##  1 control no_event  no_event  
##  2 trmt    no_event  no_event  
##  3 control no_event  no_event  
##  4 trmt    no_event  no_event  
##  5 trmt    no_event  no_event  
##  6 control no_event  no_event  
##  7 trmt    no_event  no_event  
##  8 control no_event  no_event  
##  9 control no_event  no_event  
## 10 control no_event  no_event</code></pre>
<p>We also want to “inspect” the data. The function is <code>inspect()</code> and <code>R</code> needs the data object <code>stent_study</code>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(stent_study)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##         name     class levels   n missing
## 1      group character      2 451       0
## 2  outcome30 character      2 451       0
## 3 outcome365 character      2 451       0
##                                    distribution
## 1 control (50.3%), trmt (49.7%)                
## 2 no_event (89.8%), stroke (10.2%)             
## 3 no_event (83.8%), stroke (16.2%)</code></pre>
<p>To keep things simple, we will only look at the <code>outcome30</code> variable in this case study. We will summarize the data in a table. Later in the course, we will learn to do this using the <strong>tidy</strong> package; for now we use the <strong>mosaic</strong> package. This package makes use of the modeling formula that you will use extensively later in this course. The modeling formula is also used in Math 378.</p>
<p>We want to summarize the data by making a table. From <code>mosaic</code>, we use the <code>tally()</code> function. Before using this function, we have to understand the basic formula notation that <code>mosaic</code> uses. The basic format is:</p>
<pre><code>goal(y ~ x, data = MyData, ...) # pseudo-code for the formula template</code></pre>
<p>We read <code>y ~ x</code> as “y tilde x” and interpret it in the equivalent forms: “y broken down by x”; “y modeled by x”; “y explained by x”; “y depends on x”; or “y accounted for by x.” For graphics, it’s reasonable to read the formula as “y vs. x”, which is exactly the convention used for coordinate axes.</p>
<p>For this exercise, we want to apply <code>tally()</code> to the variables <code>group</code> and <code>outcome30</code>. In this case it does not matter which we call <code>y</code> and <code>x</code>; however, it is more natural to think of <code>outcome30</code> as a dependent variable.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(outcome30 <span class="sc">~</span> group, <span class="at">data =</span> stent_study, <span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##           group
## outcome30  control trmt
##   no_event     214  191
##   stroke        13   33
##   Total        227  224</code></pre>
<p>The <code>margins</code> option totals the columns.</p>
<p>Of the 224 patients in the treatment group, 33 had a stroke by the end of the first month. Using these two numbers, we can use <code>R</code> to compute the proportion of patients in the treatment group who had a stroke by the end of their first month.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="dv">33</span> <span class="sc">/</span> (<span class="dv">33</span> <span class="sc">+</span> <span class="dv">191</span>)</span></code></pre></div>
<pre><code>## [1] 0.1473214</code></pre>
<blockquote>
<p><strong>Exercise</strong>:<br />
What proportion of the control group had a stroke by the end of the first month? And why is this answer different from what <code>inspect()</code> reports?</p>
</blockquote>
<p>Let’s have <code>R</code> calculate proportions for us. Use <code>?</code> or <code>help()</code> to look at the help menu for <code>tally()</code>. Note that one of the option arguments of the <code>tally()</code> function is <code>format =</code>. Setting this equal to <code>proportion</code> will output the proportions instead of the counts.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(outcome30 <span class="sc">~</span> group, <span class="at">data =</span> stent_study, <span class="at">format =</span> <span class="st">&#39;proportion&#39;</span>, <span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##           group
## outcome30     control       trmt
##   no_event 0.94273128 0.85267857
##   stroke   0.05726872 0.14732143
##   Total    1.00000000 1.00000000</code></pre>
<p>We can compute summary statistics from the table. A <strong>summary statistic</strong> is a single number summarizing a large amount of data.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> For instance, the primary results of the study after 1 month could be described by two summary statistics: the proportion of people who had a stroke in the treatment group and the proportion of people who had a stroke in the control group.</p>
<ul>
<li><p>Proportion who had a stroke in the treatment (stent) group: <span class="math inline">\(33/224 = 0.15 = 15\%\)</span></p></li>
<li><p>Proportion who had a stroke in the control group: <span class="math inline">\(13/227 = 0.06 = 6\%\)</span></p></li>
</ul>
</div>
<div id="visualize-the-data" class="section level3" number="1.4.5">
<h3><span class="header-section-number">1.4.5</span> Visualize the data</h3>
<p>It is often important to visualize the data. The table is a type of visualization, but in this section we will introduce a graphical method called bar charts.</p>
<p>We will use the <a href="https://cran.r-project.org/web/packages/ggformula/vignettes/ggformula-blog.html"><strong>ggformula</strong></a> package to visualize the data. It is a wrapper to the <strong>ggplot2</strong> package which is becoming the industry standard for generating professional graphics. However, the interface for <strong>ggplot2</strong> can be difficult to learn and we will ease into it by using <code>ggformula</code>, which makes use of the formula notation introduced above. The <strong>ggformula</strong> package was loaded when we loaded <code>mosaic</code>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p>To generate a basic graphic, we need to ask ourselves what information we are trying to see, what particular type of graph is best, what corresponding <code>R</code> function to use, and what information that <code>R</code> function needs in order to build a plot. For categorical data, we want a bar chart and the <code>R</code> function <code>gf_bar()</code> needs the data object and the variable(s) of interest.</p>
<p>Here is our first attempt. In Figure @ref(fig:first-fig), we leave the <code>y</code> portion of our formula blank. Doing this implies that we simply want to view the number/count of <code>outcome30</code> by type. We will see the two levels of <code>outcome30</code> on the x-axis and counts on the y-axis.</p>
<p>(ref:ggfbold) Using <strong>ggformula</strong> to create a bar chart.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_bar</span>(<span class="sc">~</span> outcome30, <span class="at">data =</span> stent_study)</span></code></pre></div>
<div class="figure">
<img src="01-Data-Case-Study_files/figure-html/first-fig-1.png" alt="(ref:ggfbold)" width="672" />
<p class="caption">
(#fig:first-fig)(ref:ggfbold)
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Explain Figure @ref(fig:first-fig).</p>
</blockquote>
<p>This plot graphically shows us the total number of “stroke” and the total number of “no_event”. However, this is not what we want. We want to compare the 30-day outcomes for both treatment groups. So, we need to break the data into different groups based on treatment type. In the formula notation, we now update it to the form:</p>
<pre><code>goal(y ~ x|z, data = MyData, ...) # pseudo-code for the formula template</code></pre>
<p>We read <code>y ~ x|z</code> as “y tilde x by z” and interpret it in the equivalent forms: “y modeled by x for each z”; “y explained by x within each z”; or “y accounted for by x within z.” For graphics, it’s reasonable to read the formula as “y vs. x for each z”. Figure @ref(fig:split-fig) shows the results.</p>
<p>(ref:groupvar) Bar charts conditioned on the <code>group</code> variable.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_bar</span>(<span class="sc">~</span> outcome30 <span class="sc">|</span> group, <span class="at">data =</span> stent_study) </span></code></pre></div>
<div class="figure">
<img src="01-Data-Case-Study_files/figure-html/split-fig-1.png" alt="(ref:groupvar)" width="672" />
<p class="caption">
(#fig:split-fig)(ref:groupvar)
</p>
</div>
<div id="more-advanced-graphics" class="section level4" number="1.4.5.1">
<h4><span class="header-section-number">1.4.5.1</span> More advanced graphics</h4>
<p>As a prelude for things to come, the above graphic needs work. The labels don’t help and there is no title. We could add color. Does it make more sense to use proportions? Here is the code and results for a better graph, see Figure @ref(fig:cs1-fig). Don’t worry if this seems a bit advanced, but feel free to examine each new component of this code.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>stent_study <span class="sc">%&gt;%</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_props</span>(<span class="sc">~</span> group, <span class="at">fill =</span> <span class="sc">~</span> outcome30, <span class="at">position =</span> <span class="st">&#39;fill&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title =</span> <span class="st">&quot;Impact of Stents of Stroke&quot;</span>,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">subtitle =</span> <span class="st">&#39;Experiment with 451 Patients&#39;</span>,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">x =</span> <span class="st">&quot;Experimental Group&quot;</span>,</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">y =</span> <span class="st">&quot;Number of Events&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="01-Data-Case-Study_files/figure-html/cs1-fig-1.png" alt="Better graph." width="672" />
<p class="caption">
(#fig:cs1-fig)Better graph.
</p>
</div>
<p>Notice that we used the pipe operator, <code>%&gt;%</code>. This operator allows us to string functions together in a manner that makes it easier to read the code. In the above code, we are sending the data object <code>stent_study</code> into the function <code>gf_props()</code> to use as data, so we don’t need the <code>data =</code> argument. In math, this is a composition of functions. Instead of <code>f(g(x))</code> we could use a pipe <code>f(g(x)) = g(x) %&gt;% f()</code>.</p>
</div>
</div>
<div id="conclusion" class="section level3" number="1.4.6">
<h3><span class="header-section-number">1.4.6</span> Conclusion</h3>
<p>These two summary statistics (the proportions of people who had a stroke) are useful in looking for differences in the groups, and we are in for a surprise: an additional 9% of patients in the treatment group had a stroke! This is important for two reasons. First, it is contrary to what doctors expected, which was that stents would <em>reduce</em> the rate of strokes. Second, it leads to a statistical question: do the data show a <strong>real</strong> difference due to the treatment?</p>
<p>This second question is subtle. Suppose you flip a coin 100 times. While the chance a coin lands heads in any given coin flip is 50%, we probably won’t observe exactly 50 heads. This type of fluctuation is part of almost any type of data generating process. It is possible that the 9% difference in the stent study is due to this natural variation. However, the larger the difference we observe (for a particular sample size), the less believable it is that the difference is due to chance. So what we are really asking is the following: is the difference so large that we should reject the notion that it was due to chance?</p>
<p>This is a preview of step 4, analyze the data, and step 5, form a conclusion, of the analysis cycle. While we haven’t yet covered statistical tools to fully address these steps, we can comprehend the conclusions of the published analysis: there was compelling evidence of harm by stents in this study of stroke patients.</p>
<p><strong>Be careful:</strong> do not generalize the results of this study to all patients and all stents. This study looked at patients with very specific characteristics who volunteered to be a part of this study and who may not be representative of all stroke patients. In addition, there are many types of stents and this study only considered the self-expanding Wingspan stent (Boston Scientific). However, this study does leave us with an important lesson: we should keep our eyes open for surprises.</p>
</div>
</div>
<div id="homework-problems" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Homework Problems</h2>
<p>Create an Rmd file <code>01 Data Case Study Application.Rmd</code> in R (it may be provided), and start by inserting your name in the header. Code blocks below can be inserted and then you can complete the code and answer the questions. When you are done, <code>knit</code> it into a pdf file.</p>
<p>To create an <code>R</code> code chunk, use CTRL-ALT-I or on the <code>insert</code> tab of the window, use the drop down to select <code>R</code>. Anything between the dashes is interpreted as <code>R</code> code.</p>
<p>For more on RMarkdown, see the following video: <a href="https://www.youtube.com/watch?v=DNS7i2m4sB0" class="uri">https://www.youtube.com/watch?v=DNS7i2m4sB0</a>. This video assumes you are using <code>R</code> on your computer, but we are using RStudio Cloud. Thus we can <code>knit</code> to a pdf since it is setup for us. You can also take the first chapter of the Data Camp course, <em>Reporting with R Markdown</em>, to learn more.</p>
<ol style="list-style-type: decimal">
<li><strong>Stent study continued</strong>. Complete a similar analysis for the stent data, but this time use the one year outcome. In particular,</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Read the data into your working directory.</li>
</ol>
<pre><code>stent_study &lt;- read_csv(___)</code></pre>
<ol start="2" style="list-style-type: lower-alpha">
<li>Complete similar steps as in the class notes. The start of code is provided below.<br />
i. Use <code>inspect</code> on the data.<br />
ii. Create a table of <code>outcome365</code> and <code>group</code>. Comment on the results.<br />
iii. Create a barchart of the data.</li>
</ol>
<p>Using <code>inspect</code>:</p>
<pre><code>inspect(___)</code></pre>
<p>The table:</p>
<pre><code>tally(outcome365 ~ ___, data = stent_study, format = ___, margins = TRUE)</code></pre>
<p>Barchart:</p>
<pre><code>stent_study %&gt;%
  gf_props(~ ___, fill = ~ ___, position = &#39;fill&#39;) %&gt;%
  gf_labs(title = ___,
          subtitle = ___,
          x = ___,
          y = ___)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><strong>Migraine and acupuncture</strong>. A migraine is a particularly painful type of headache, which patients sometimes wish to treat with acupuncture. To determine whether acupuncture relieves migraine pain, researchers conducted a randomized controlled study where 89 females diagnosed with migraine headaches were randomly assigned to one of two groups: treatment or control. 43 patients in the treatment group received acupuncture that is specifically designed to treat migraines. 46 patients in the control group received placebo acupuncture (needle insertion at nonacupoint locations). 24 hours after patients received acupuncture, they were asked if they were pain free.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></li>
</ol>
<p>The data is in the file <code>migraine_study.csv</code> in the <code>data</code> folder.</p>
<p>Complete the following work:</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into an object called <code>migraine_study</code>.</li>
</ol>
<pre><code>migraine_study &lt;- read_csv(&quot;data/___&quot;)</code></pre>
<pre><code>head(migraine_study)</code></pre>
<ol start="2" style="list-style-type: lower-alpha">
<li>Create a table of the data.</li>
</ol>
<pre><code>tally(___)</code></pre>
<ol start="3" style="list-style-type: lower-alpha">
<li>Report the percent of patients in the treatment group who were pain free 24 hours after receiving acupuncture.<br />
</li>
<li>Repeat for the control group.<br />
</li>
<li>At first glance, does acupuncture appear to be an effective treatment for migraines? Explain your reasoning.<br />
</li>
<li>Do the data provide convincing evidence that there is a real pain reduction for those patients in the treatment group? Or do you think that the observed difference might just be due to chance?</li>
</ol>
<p>Compile, <code>knit</code>, this report into an html and a pdf. In order to <code>knit</code> the report into a pdf, you may need to install the <code>knitr</code> and <code>tinytex</code> packages in <code>R</code>.</p>
<!--chapter:end:01-Data-Case-Study.Rmd-->
</div>
</div>
<div id="DB" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Data Basics</h1>
<div id="objectives-1" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and use properly in context all new terminology to include, but not limited to, case, observational unit, variables, data frame, associated variables, independent, and discrete and continuous variables.<br />
</li>
<li>Identify and define the different types of variables.<br />
</li>
<li>Given a study description, explain the research question.<br />
</li>
<li>Create a scatterplot in <code>R</code> and determine the association of two numerical variables from the plot.</li>
</ol>
</div>
<div id="data-basics" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Data basics</h2>
<p>Effective presentation and description of data is a first step in most analyses. This lesson introduces one structure for organizing data, as well as some terminology that will be used throughout this course.</p>
<div id="observations-variables-and-data-matrices" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Observations, variables, and data matrices</h3>
<p>For reference we will be using a data set concerning 50 emails received in 2012. These observations will be referred to as the <code>email50</code> data set, and they are a random sample from a larger data set. This data is in the <strong>openintro</strong> package so let’s install and then load this package.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;openintro&quot;</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(openintro)</span></code></pre></div>
<p>Table @ref(tab:db1-tab) shows 4 rows of the <code>email50</code> data set and we have elected to only list 5 variables for ease of observation.</p>
<p>Each row in the table represents a single email or <strong>case</strong>.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> The columns represent characteristics, called <strong>variables</strong>, for each of the emails. For example, the first row represents email 1, which is not spam, contains 21,705 characters, 551 line breaks, is written in HTML format, and contains only small numbers.</p>
<table>
<caption>
(#tab:db1-tab)First 5 rows of email data frame
</caption>
<thead>
<tr>
<th style="text-align:left;">
spam
</th>
<th style="text-align:right;">
num_char
</th>
<th style="text-align:right;">
line_breaks
</th>
<th style="text-align:left;">
format
</th>
<th style="text-align:left;">
number
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
0
</td>
<td style="text-align:right;">
21.705
</td>
<td style="text-align:right;">
551
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
small
</td>
</tr>
<tr>
<td style="text-align:left;">
0
</td>
<td style="text-align:right;">
7.011
</td>
<td style="text-align:right;">
183
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
big
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
0.631
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
none
</td>
</tr>
<tr>
<td style="text-align:left;">
0
</td>
<td style="text-align:right;">
15.829
</td>
<td style="text-align:right;">
242
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
small
</td>
</tr>
</tbody>
</table>
<p>Let’s look at the first 10 rows of data from <code>email50</code> using <code>R</code>. Remember to ask the two questions:</p>
<p><em>What do we want <code>R</code> to do?</em> and</p>
<p><em>What must we give <code>R</code> for it to do this?</em></p>
<p>We want the first 10 rows so we use <code>head()</code> and <code>R</code> needs the data object and the number of rows. The data object is called <code>email50</code> and is accessible once the <strong>openintro</strong> package is loaded.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(email50, <span class="at">n =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 21
##    spam  to_multiple from     cc sent_email time                image attach
##    &lt;fct&gt; &lt;fct&gt;       &lt;fct&gt; &lt;int&gt; &lt;fct&gt;      &lt;dttm&gt;              &lt;dbl&gt;  &lt;dbl&gt;
##  1 0     0           1         0 1          2012-01-04 06:19:16     0      0
##  2 0     0           1         0 0          2012-02-16 13:10:06     0      0
##  3 1     0           1         4 0          2012-01-04 08:36:23     0      2
##  4 0     0           1         0 0          2012-01-04 10:49:52     0      0
##  5 0     0           1         0 0          2012-01-27 02:34:45     0      0
##  6 0     0           1         0 0          2012-01-17 10:31:57     0      0
##  7 0     0           1         0 0          2012-03-17 22:18:55     0      0
##  8 0     0           1         0 1          2012-03-31 07:58:56     0      0
##  9 0     0           1         1 1          2012-01-10 18:57:54     0      0
## 10 0     0           1         0 0          2012-01-07 12:29:16     0      0
## # ... with 13 more variables: dollar &lt;dbl&gt;, winner &lt;fct&gt;, inherit &lt;dbl&gt;,
## #   viagra &lt;dbl&gt;, password &lt;dbl&gt;, num_char &lt;dbl&gt;, line_breaks &lt;int&gt;,
## #   format &lt;fct&gt;, re_subj &lt;fct&gt;, exclaim_subj &lt;dbl&gt;, urgent_subj &lt;fct&gt;,
## #   exclaim_mess &lt;dbl&gt;, number &lt;fct&gt;</code></pre>
<p>In practice, it is especially important to ask clarifying questions to ensure important aspects of the data are understood. For instance, it is always important to be sure we know what each variable means and the units of measurement. Descriptions of all variables in the <code>email50</code> data set are given in its documentation which can be accessed in <code>R</code> by using the <code>?</code> command:</p>
<pre><code>?email50</code></pre>
<p>(Note that not all data sets will have associated documentation; the authors of <strong>openintro</strong> package included this documentation with the <code>email50</code> data set contained in the package.)</p>
<p>The data in <code>email50</code> represent a <strong>data matrix</strong>, or in <code>R</code> terminology a <strong>data frame</strong> or <strong>tibble</strong> <a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>, which is a common way to organize data. Each row of a data matrix corresponds to a unique case, and each column corresponds to a variable. This is called <strong>tidy data</strong>.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> The data frame for the stroke study introduced in the previous lesson had patients as the cases and there were three variables recorded for each patient. If we are thinking of patients as the unit of observation, then this data is tidy.</p>
<pre><code>## # A tibble: 10 x 3
##    group   outcome30 outcome365
##    &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;     
##  1 control no_event  no_event  
##  2 trmt    no_event  no_event  
##  3 control no_event  no_event  
##  4 trmt    no_event  no_event  
##  5 trmt    no_event  no_event  
##  6 control no_event  no_event  
##  7 trmt    no_event  no_event  
##  8 control no_event  no_event  
##  9 control no_event  no_event  
## 10 control no_event  no_event</code></pre>
<p>If we think of an outcome as a unit of observation, then it is not tidy since the two outcome columns are variable values (month or year). The tidy data for this case would be:</p>
<pre><code>## # A tibble: 10 x 4
##    patient_id group   time  result  
##         &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   
##  1          1 control month no_event
##  2          1 control year  no_event
##  3          2 trmt    month no_event
##  4          2 trmt    year  no_event
##  5          3 control month no_event
##  6          3 control year  no_event
##  7          4 trmt    month no_event
##  8          4 trmt    year  no_event
##  9          5 trmt    month no_event
## 10          5 trmt    year  no_event</code></pre>
<p>There are three interrelated rules which make a data set tidy:</p>
<ol style="list-style-type: decimal">
<li>Each variable must have its own column.<br />
</li>
<li>Each observation must have its own row.<br />
</li>
<li>Each value must have its own cell.</li>
</ol>
<p>Why ensure that your data is tidy? There are two main advantages:</p>
<ol style="list-style-type: decimal">
<li><p>There’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity.</p></li>
<li><p>There’s a specific advantage to placing variables in columns because it allows <code>R</code>’s vectorized nature to shine. This will be more clear as we progress in our studies. Since most built-in <code>R</code> functions work with vectors of values, it makes transforming tidy data feel particularly natural.</p></li>
</ol>
<p>Data frames are a convenient way to record and store data. If another individual or case is added to the data set, an additional row can be easily added. Similarly, another column can be added for a new variable.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
We consider a publicly available data set that summarizes information about the 3,142 counties in the United States, and we create a data set called <code>county_subset</code> data set. This data set will include information about each county: its name, the state where it resides, its population in 2000 and 2010, per capita federal spending, poverty rate, and four additional characteristics. We create this data object in the code following this description. The parent data set is part of the <code>usdata</code> library and is called <code>county_complete</code>. The variables are summarized in the help menu built into the <strong>usdata</strong> package<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>. How might these data be organized in a data matrix? <a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
</blockquote>
<p>Using <code>R</code> we will create our data object. First we load the library <code>usdata</code>.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(usdata)</span></code></pre></div>
<p>We only want a subset of the columns and we will use the <code>select</code> verb in <code>dplyr</code> to select and rename columns. We also create a new variable which is federal spending per capita using the <code>mutate</code> function.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>county_subset <span class="ot">&lt;-</span> county_complete <span class="sc">%&gt;%</span> </span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(name, state, pop2000, pop2010, <span class="at">fed_spend =</span> fed_spending_2009, </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">poverty =</span> poverty_2010, <span class="at">homeownership =</span> homeownership_2010, </span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">multi_unit =</span> housing_multi_unit_2010, <span class="at">income =</span> per_capita_income_2010, </span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">med_income =</span> median_household_income_2010) <span class="sc">%&gt;%</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">fed_spend =</span> fed_spend <span class="sc">/</span> pop2010)</span></code></pre></div>
<p>Using <code>R</code>, we will display seven rows of the <code>county_subset</code> data frame.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(county_subset, <span class="at">n =</span> <span class="dv">7</span>)</span></code></pre></div>
<pre><code>##             name   state pop2000 pop2010 fed_spend poverty homeownership
## 1 Autauga County Alabama   43671   54571  6.068095    10.6          77.5
## 2 Baldwin County Alabama  140415  182265  6.139862    12.2          76.7
## 3 Barbour County Alabama   29038   27457  8.752158    25.0          68.0
## 4    Bibb County Alabama   20826   22915  7.122016    12.6          82.9
## 5  Blount County Alabama   51024   57322  5.130910    13.4          82.0
## 6 Bullock County Alabama   11714   10914  9.973062    25.3          76.9
## 7  Butler County Alabama   21399   20947  9.311835    25.0          69.0
##   multi_unit income med_income
## 1        7.2  24568      53255
## 2       22.6  26469      50147
## 3       11.1  15875      33219
## 4        6.6  19918      41770
## 5        3.7  21070      45549
## 6        9.9  20289      31602
## 7       13.7  16916      30659</code></pre>
</div>
<div id="types-of-variables" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Types of variables</h3>
<p>Examine the <code>fed_spend</code>, <code>pop2010</code>, and <code>state</code> variables in the <code>county</code> data set. Each of these variables is inherently different from the others, yet many of them share certain characteristics.</p>
<p>First consider <code>fed_spend</code>. It is said to be a <strong>numerical variable</strong> since it can take a wide range of numerical values, and it is sensible to add, subtract, or take averages with those values. On the other hand, we would not classify a variable reporting telephone area codes as numerical; even though area codes are made up of numerical digits, their average, sum, and difference have no clear meaning.</p>
<p>The <code>pop2010</code> variable is also numerical; it is sensible to add, subtract, or take averages with those values, although it seems to be a little different than <code>fed_spend</code>. This variable of the population count can only be a whole non-negative number (<span class="math inline">\(0\)</span>, <span class="math inline">\(1\)</span>, <span class="math inline">\(2\)</span>, <span class="math inline">\(...\)</span>). For this reason, the population variable is said to be <strong>discrete</strong> since it can only take specific numerical values. On the other hand, the federal spending variable is said to be <strong>continuous</strong>. Now technically, there are no truly continuous numerical variables since all measurements are finite up to some level of accuracy or measurement precision. However, in this course we will treat both types of numerical variables the same, that is as continuous variables for statistical modeling. The only place this will be different in this course is in probability models, which we see in the probability modeling section.</p>
<p>The variable <strong>state</strong> can take up to 51 values, after accounting for Washington, DC, and are summarized as: <em>Alabama</em>, <em>Alaska</em>, …, and <em>Wyoming</em>. Because the responses themselves are categories, <code>state</code> is called a <strong>categorical</strong> variable,<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> and the possible values are called the variable’s <strong>levels</strong>.</p>
<div class="figure">
<img src="02-Data-Basics_files/figure-html/tax-fig-1.png" alt="Taxonomy of Variables." width="672" />
<p class="caption">
(#fig:tax-fig)Taxonomy of Variables.
</p>
</div>
<p>Finally, consider a hypothetical variable on education, which describes the highest level of education completed and takes on one of the values <em>noHS</em>, <em>HS</em>, <em>College</em> or <em>Graduate_school</em>. This variable seems to be a hybrid: it is a categorical variable but the levels have a natural ordering. A variable with these properties is called an <strong>ordinal</strong> variable. A categorical variable with levels that do not have a natural ordering is called a <strong>nominal</strong> variable. To simplify analyses, any ordinal variables in this course will be treated as nominal categorical variables. In <code>R</code>, categorical variables can be treated in different ways; one of the key differences is that we can leave them as character values or as factors. When <code>R</code> handles factors, it is only concerned about the <em>levels</em> of values of the factors. We will learn more about this as we progress.</p>
<p>Figure @ref(fig:tax-fig) captures this classification of variables we have described.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Data were collected about students in a statistics course. Three variables were recorded for each student: number of siblings, student height, and whether the student had previously taken a statistics course. Classify each of the variables as continuous numerical, discrete numerical, or categorical.</p>
</blockquote>
<p>The number of siblings and student height represent numerical variables. Because the number of siblings is a count, it is discrete. Height varies continuously, so it is a continuous numerical variable. The last variable classifies students into two categories – those who have and those who have not taken a statistics course – which makes this variable categorical.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Consider the variables <code>group</code> and <code>outcome30</code> from the stent study in the case study lesson. Are these numerical or categorical variables? <a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
</blockquote>
</div>
<div id="relationships-between-variables" class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Relationships between variables</h3>
<p>Many analyses are motivated by a researcher looking for a relationship between two or more variables. This is the heart of statistical modeling. A social scientist may like to answer some of the following questions:</p>
<ol style="list-style-type: decimal">
<li>Is federal spending, on average, higher or lower in counties with high rates of poverty?<br />
</li>
<li>If homeownership is lower than the national average in one county, will the percent of multi-unit structures in that county likely be above or below the national average?</li>
</ol>
<p>To answer these questions, data must be collected, such as the <code>county_complete</code> data set. Examining summary statistics could provide insights for each of the two questions about counties. Graphs can be used to visually summarize data and are useful for answering such questions as well.</p>
<p>Scatterplots are one type of graph used to study the relationship between two numerical variables. Figure @ref(fig:pov1-fig) compares the variables <code>fed_spend</code> and <code>poverty</code>. Each point on the plot represents a single county. For instance, the highlighted dot corresponds to County 1088 in the <code>county_subset</code> data set: Owsley County, Kentucky, which had a poverty rate of 41.5% and federal spending of $21.50 per capita. The dense cloud in the scatterplot suggests a relationship between the two variables: counties with a high poverty rate also tend to have slightly more federal spending. We might brainstorm as to why this relationship exists and investigate each idea to determine which is the most reasonable explanation.</p>
<div class="figure">
<img src="02-Data-Basics_files/figure-html/pov1-fig-1.png" alt="A scatterplot showing fed_spend against poverty. Owsley County of Kentucky, with a poverty rate of 41.5% and federal spending of $21.50 per capita, is highlighted." width="672" />
<p class="caption">
(#fig:pov1-fig)A scatterplot showing fed_spend against poverty. Owsley County of Kentucky, with a poverty rate of 41.5% and federal spending of $21.50 per capita, is highlighted.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Examine the variables in the <code>email50</code> data set. Create two research questions about the relationships between these variables that are of interest to you.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
</blockquote>
<p>The <code>fed_spend</code> and <code>poverty</code> variables are said to be associated because the plot shows a discernible pattern. When two variables show some connection with one another, they are called <strong>associated variables</strong>. Associated variables can also be called <strong>dependent</strong> variables and vice-versa.</p>
<blockquote>
<p><em>Example</em>:<br />
The relationship between the homeownership rate and the percent of units in multi-unit structures (e.g. apartments, condos) is visualized using a scatterplot in Figure @ref(fig:homeown-fig). Are these variables associated?</p>
</blockquote>
<p>It appears that the larger the fraction of units in multi-unit structures, the lower the homeownership rate. Since there is some relationship between the variables, they are associated.</p>
<div class="figure">
<img src="02-Data-Basics_files/figure-html/homeown-fig-1.png" alt="A scatterplot of the homeownership rate versus the percent of units that are in multi-unit structures for all 3,143 counties." width="672" />
<p class="caption">
(#fig:homeown-fig)A scatterplot of the homeownership rate versus the percent of units that are in multi-unit structures for all 3,143 counties.
</p>
</div>
<p>Because there is a downward trend in Figure @ref(fig:homeown-fig) – counties with more units in multi-unit structures are associated with lower homeownership – these variables are said to be <strong>negatively associated</strong>. A <strong>positive association</strong> is shown in the relationship between the <code>poverty</code> and <code>fed_spend</code> variables represented in Figure @ref(fig:pov1-fig), where counties with higher poverty rates tend to receive more federal spending per capita.</p>
<p>If two variables are not associated, then they are said to be <strong>independent</strong>. That is, two variables are independent if there is no evident relationship between the two.</p>
<blockquote>
<p>A pair of variables are either related in some way (associated) or not (independent). No pair of variables is both associated and independent.</p>
</blockquote>
</div>
<div id="creating-a-scatterplot" class="section level3" number="2.2.4">
<h3><span class="header-section-number">2.2.4</span> Creating a scatterplot</h3>
<p>In this section, we will create a simple scatterplot and then ask you to create one on your own. First, we will recreate the scatterplot seen in Figure @ref(fig:pov1-fig). This figure uses the <code>county_subset</code> data set.</p>
<p>Here are two questions:</p>
<p><em>What do we want <code>R</code> to do?</em> and</p>
<p><em>What must we give <code>R</code> for it to do this?</em></p>
<p>We want <code>R</code> to create a scatterplot and to do this it needs, at a minimum, the data object, what we want on the <span class="math inline">\(x\)</span>-axis, and what we want on the <span class="math inline">\(y\)</span>-axis. More information on <a href="https://cran.r-project.org/web/packages/ggformula/vignettes/ggformula-blog.html"><strong>ggformula</strong></a> can be found by clicking on the link.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<p>(ref:ggfbold2) Scatterplot with <strong>ggformula</strong>.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>county_subset <span class="sc">%&gt;%</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(fed_spend <span class="sc">~</span> poverty)</span></code></pre></div>
<div class="figure">
<img src="02-Data-Basics_files/figure-html/pov2-fig-1.png" alt="(ref:ggfbold2)" width="672" />
<p class="caption">
(#fig:pov2-fig)(ref:ggfbold2)
</p>
</div>
<p>Figure @ref(fig:pov2-fig) is bad. There are poor axis labels, no title, dense clustering of points, and the <span class="math inline">\(y\)</span>-axis is being driven by a couple of extreme points. We will need to clear this up. Again, try to read the code and use <code>help()</code> or <code>?</code> to determine the purpose of each command in Figure @ref(fig:pov3-fig).</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>county_subset <span class="sc">%&gt;%</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(fed_spend <span class="sc">&lt;</span> <span class="dv">32</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(fed_spend <span class="sc">~</span> poverty,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">xlab =</span> <span class="st">&quot;Poverty Rate (Percent)&quot;</span>, </span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">ylab =</span> <span class="st">&quot;Federal Spending Per Capita&quot;</span>,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">title =</span> <span class="st">&quot;A scatterplot showing fed_spend against poverty&quot;</span>, </span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">cex =</span> <span class="dv">1</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>())</span></code></pre></div>
<div class="figure">
<img src="02-Data-Basics_files/figure-html/pov3-fig-1.png" alt="Better example of a scatterplot." width="672" />
<p class="caption">
(#fig:pov3-fig)Better example of a scatterplot.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Create the scatterplot in Figure @ref(fig:homeown-fig).</p>
</blockquote>
</div>
</div>
<div id="homework-problems-1" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Homework Problems</h2>
<p><strong>Identify study components</strong></p>
<p>Identify (i) the cases, (ii) the variables and their types, and (iii) the main research question in the studies described below.</p>
<ol style="list-style-type: decimal">
<li><p>Researchers collected data to examine the relationship between pollutants and preterm births in Southern California. During the study, air pollution levels were measured by air quality monitoring stations. Specifically, levels of carbon monoxide were recorded in parts per million, nitrogen dioxide and ozone in parts per hundred million, and coarse particulate matter (PM<span class="math inline">\(_{10}\)</span>) in <span class="math inline">\(\mu g/m^3\)</span>. Length of gestation data were collected on 143,196 births between the years 1989 and 1993, and air pollution exposure during gestation was calculated for each birth. The analysis suggested that increased ambient PM<span class="math inline">\(_{10}\)</span> and, to a lesser degree, CO concentrations may be associated with the occurrence of preterm births.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p></li>
<li><p>The Buteyko method is a shallow breathing technique developed by Konstantin Buteyko, a Russian doctor, in 1952. Anecdotal evidence suggests that the Buteyko method can reduce asthma symptoms and improve quality of life. In a scientific study to determine the effectiveness of this method, researchers recruited 600 asthma patients aged 18-69 who relied on medication for asthma treatment. These patients were split into two research groups: one practiced the Buteyko method and the other did not. Patients were scored on quality of life, activity, asthma symptoms, and medication reduction on a scale from 0 to 10. On average, the participants in the Buteyko group experienced a significant reduction in asthma symptoms and an improvement in quality of life.<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p></li>
<li><p>In the package <strong>Stat2Data</strong> is a data set called <code>Election16</code>. Create a scatterplot for the percent of advanced degree versus per capita income in the state. Describe the relationship between these two variables. Note: you may have to load the library.</p></li>
</ol>
<!--chapter:end:02-Data-Basics.Rmd-->
</div>
</div>
<div id="ODCP" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Overview of Data Collection Principles</h1>
<div id="objectives-2" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and use properly in context all new terminology.<br />
</li>
<li>From a description of a research project, at a minimum be able to describe the population of interest, the generalizability of the study, the response and predictor variables, differentiate whether it is observational or experimental, and determine the type of sample.<br />
</li>
<li>Explain in the context of a problem how to conduct a sample for the different types of sampling procedures.</li>
</ol>
</div>
<div id="overview-of-data-collection-principles" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Overview of data collection principles</h2>
<p>The first step in conducting research is to identify topics or questions that are to be investigated. A clearly laid out research question is helpful in identifying what subjects or cases should be studied and what variables are important. It is also important to consider <em>how</em> data are collected so that they are reliable and help achieve the research goals.</p>
<div id="populations-and-samples" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Populations and samples</h3>
<p>Consider the following three research questions:</p>
<ol style="list-style-type: decimal">
<li>What is the average mercury content in swordfish in the Atlantic Ocean?<br />
</li>
<li>Over the last 5 years, what is the average time to complete a degree for Duke undergraduate students?<br />
</li>
<li>Does a new drug reduce the number of deaths in patients with severe heart disease?</li>
</ol>
<p>Each research question refers to a target <strong>population</strong>. In the first question, the target population is all swordfish in the Atlantic Ocean, and each fish represents a case. It is usually too expensive to collect data for every case in a population. Instead, a sample is taken. A <strong>sample</strong> represents a subset of the cases and is often a small fraction of the population. For instance, 60 swordfish (or some other number) in the population might be selected, and this sample data may be used to provide an estimate of the population average and answer the research question.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
For the second and third questions above, identify the target population and what represents an individual case.<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a></p>
</blockquote>
</div>
<div id="anecdotal-evidence" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Anecdotal evidence</h3>
<p>Consider the following possible responses to the three research questions:</p>
<ol style="list-style-type: decimal">
<li>A man on the news got mercury poisoning from eating swordfish, so the average mercury concentration in swordfish must be dangerously high.</li>
<li>I met two students who took more than 7 years to graduate from Duke, so it must take longer to graduate at Duke than at many other colleges.</li>
<li>My friend’s dad had a heart attack and died after they gave him a new heart disease drug, so the drug must not work.</li>
</ol>
<p>Each conclusion is based on data. However, there are two problems. First, the data only represent one or two cases. Second, and more importantly, it is unclear whether these cases are actually representative of the population. Data collected in this haphazard fashion are called <strong>anecdotal evidence</strong>.</p>
<p>(ref:quote1) In February 2010, some media pundits cited one large snow storm as evidence against global warming. As comedian Jon Stewart pointed out, <em>‘It’s one storm, in one region, of one country.’</em></p>
<div class="figure" style="text-align: center">
<img src="figures/mnWinter.JPG" alt="(ref:quote1)" width="400" />
<p class="caption">
(#fig:unnamed-chunk-1)(ref:quote1)
</p>
</div>
<blockquote>
<p><strong>Anecdotal evidence</strong>:
Be careful of data collected haphazardly. Such evidence may be true and verifiable, but it may only represent extraordinary cases.</p>
</blockquote>
<p>Anecdotal evidence typically is composed of unusual cases that we recall based on their striking characteristics. For instance, we are more likely to remember the two people we met who took 7 years to graduate than the six others who graduated in four years. Instead of looking at the most unusual cases, we should examine a sample of many cases that represent the population.</p>
</div>
<div id="sampling-from-a-population" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Sampling from a population</h3>
<p>We might try to estimate the time to graduation for Duke undergraduates in the last 5 years by collecting a sample of students. All graduates in the last 5 years represent the <em>population</em>, and graduates who are selected for review are collectively called the <em>sample</em>. In general, we always seek to <em>randomly</em> select a sample from a population. The most basic type of random selection is equivalent to how raffles are conducted. For example, in selecting graduates, we could write each graduate’s name on a raffle ticket and draw 100 tickets. The selected names would represent a random sample of 100 graduates. This is illustrated in Figure @ref(fig:randsamp-fig).</p>
<div class="figure">
<img src="03-Overview-of-Data-Collection-Principles_files/figure-html/randsamp-fig-1.png" alt="In this graphic, five graduates are randomly selected from the population to be included in the sample." width="672" />
<p class="caption">
(#fig:randsamp-fig)In this graphic, five graduates are randomly selected from the population to be included in the sample.
</p>
</div>
<p>Why pick a sample randomly? Why not just pick a sample by hand? Consider the following scenario.</p>
<blockquote>
<p><strong>Example</strong>:<br />
Suppose we ask a student who happens to be majoring in nutrition to select several graduates for the study. What kind of students do you think she might collect? Do you think her sample would be representative of all graduates?
<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a></p>
</blockquote>
<div class="figure">
<img src="03-Overview-of-Data-Collection-Principles_files/figure-html/biased-fig-1.png" alt="Instead of sampling from all graduates equally, a nutrition major might inadvertently pick graduates with health-related majors disproportionately often." width="672" />
<p class="caption">
(#fig:biased-fig)Instead of sampling from all graduates equally, a nutrition major might inadvertently pick graduates with health-related majors disproportionately often.
</p>
</div>
<p>If someone was permitted to pick and choose exactly which graduates were included in the sample, it is entirely possible that the sample could be skewed to that person’s interests, which may be entirely unintentional. This introduces <strong>bias</strong> into a sample, see Figure @ref(fig:biased-fig). Sampling randomly helps resolve this problem. The most basic random sample is called a <strong>simple random sample</strong>, which is equivalent to using a raffle to select cases. This means that each case in the population has an equal chance of being included and there is no implied connection between the cases in the sample.</p>
<p>Sometimes a simple random sample is difficult to implement and an alternative method is helpful. One such substitute is a <strong>systematic sample</strong>, where one case is sampled after letting a fixed number of others, say 10 other cases, pass by. Since this approach uses a mechanism that is not easily subject to personal biases, it often yields a reasonably representative sample. This course will focus on simple random samples since the use of systematic samples is uncommon and requires additional considerations of the context.</p>
<p>The act of taking a simple random sample helps minimize bias. However, bias can crop up in other ways. Even when people are picked at random, e.g. for surveys, caution must be exercised if the <strong>non-response</strong> is high. For instance, if only 30% of the people randomly sampled for a survey actually respond, and it is unclear whether the respondents are <strong>representative</strong> of the entire population, the survey might suffer from <strong>non-response bias</strong>.</p>
<div class="figure">
<img src="03-Overview-of-Data-Collection-Principles_files/figure-html/convsamp-fig-1.png" alt="Due to the possibility of non-response, surveys studies may only reach a certain group within the population. It is difficult, and often impossible, to completely fix this problem" width="672" />
<p class="caption">
(#fig:convsamp-fig)Due to the possibility of non-response, surveys studies may only reach a certain group within the population. It is difficult, and often impossible, to completely fix this problem
</p>
</div>
<p>Another common pitfall is a <strong>convenience sample</strong>, where individuals who are easily accessible are more likely to be included in the sample, see Figure @ref(fig:convsamp-fig) . For instance, if a political survey is done by stopping people walking in the Bronx, it will not represent all of New York City. It is often difficult to discern what sub-population a convenience sample represents.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
We can easily access ratings for products, sellers, and companies through websites. These ratings are based only on those people who go out of their way to provide a rating. If 50% of online reviews for a product are negative, do you think this means that 50% of buyers are dissatisfied with the product?<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></p>
</blockquote>
</div>
<div id="explanatory-and-response-variables" class="section level3" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Explanatory and response variables</h3>
<p>Consider the following question for the <code>county</code> data set:</p>
<p>Is federal spending, on average, higher or lower in counties with high rates of poverty?</p>
<p>If we suspect poverty might affect spending in a county, then poverty is the <strong>explanatory</strong> variable and federal spending is the <strong>response</strong> variable in the relationship.<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> If there are many variables, it may be possible to consider a number of them as explanatory variables.</p>
<blockquote>
<p><strong>Explanatory</strong> and <strong>response</strong> variables<br />
To identify the explanatory variable in a pair of variables, identify which of the two is suspected of affecting the other.</p>
</blockquote>
<blockquote>
<p><strong>Caution</strong>:
Association does not imply causation. Labeling variables as <em>explanatory</em> and <em>response</em> does not guarantee the relationship between the two is actually causal, even if there is an association identified between the two variables. We use these labels only to keep track of which variable we suspect affects the other. We also use this language to help in our use of <code>R</code> and the formula notation.</p>
</blockquote>
<p>In some cases, there is no explanatory or response variable. Consider the following question:</p>
<p>If homeownership in a particular county is lower than the national average, will the percent of multi-unit structures in that county likely be above or below the national average?</p>
<p>It is difficult to decide which of these variables should be considered the explanatory and response variable; i.e. the direction is ambiguous, so no explanatory or response labels are suggested here.</p>
</div>
<div id="introducing-observational-studies-and-experiments" class="section level3" number="3.2.5">
<h3><span class="header-section-number">3.2.5</span> Introducing observational studies and experiments</h3>
<p>There are two primary types of data collection: observational studies and experiments.</p>
<p>Researchers perform an <strong>observational study</strong> when they collect data in a way that does not directly interfere with how the data arise. For instance, researchers may collect information via surveys, review medical or company records, or follow a <strong>cohort</strong> of many similar individuals to study why certain diseases might develop. In each of these situations, researchers merely observe what happens. In general, observational studies can provide evidence of a naturally occurring association between variables, but by themselves, they cannot show a causal connection.</p>
<p>When researchers want to investigate the possibility of a causal connection, they conduct an <strong>experiment</strong>. Usually there will be both an explanatory and a response variable. For instance, we may suspect administering a drug will reduce mortality in heart attack patients over the following year. To check if there really is a causal connection between the explanatory variable and the response, researchers will collect a sample of individuals and split them into groups. The individuals in each group are <em>assigned</em> a treatment. When individuals are randomly assigned to a treatment group, the experiment is called a <strong>randomized experiment</strong>. For example, each heart attack patient in the drug trial could be randomly assigned, perhaps by flipping a coin, into one of two groups: the first group receives a <strong>placebo</strong> (fake treatment) and the second group receives the drug. The case study at the beginning of the semester is another example of an experiment, though that study did not employ a placebo. Math 359 is a course on the design and analysis of experimental data, DOE. In the Air Force these types of experiments are an important part of test and evaluation. Many Air Force analysts are expert practitioners of DOE. In this course we will minimize our discussion of DOE.</p>
<blockquote>
<p>Association <span class="math inline">\(\neq\)</span> Causation<br />
Again, association does not imply causation. In a data analysis, association does not imply causation, and causation can only be inferred from a randomized experiment. Although, a hot field is the analysis of causal relationships in observational data. This is important because consider cigarette smoking, how do we know it causes lung cancer? We only have observational data and clearly cannot do an experiment. We think analysts will be charged in the near future with using causal reasoning on observational data.</p>
</blockquote>
</div>
</div>
<div id="homework-problems-2" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li><strong>Generalizability and causality</strong>. Identify the population of interest and the sample in the studies described below. These are the same studies from the previous lesson. Also comment on whether or not the results of the study can be generalized to the population and if the findings of the study can be used to establish causal relationships.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Researchers collected data to examine the relationship between pollutants and preterm births in Southern California. During the study air pollution levels were measured by air quality monitoring stations. Specifically, levels of carbon monoxide were recorded in parts per million, nitrogen dioxide and ozone in parts per hundred million, and coarse particulate matter (PM<span class="math inline">\(_{10}\)</span>) in <span class="math inline">\(\mu g/m^3\)</span>. Length of gestation data were collected on 143,196 births between the years 1989 and 1993, and air pollution exposure during gestation was calculated for each birth. The analysis suggested that increased ambient PM<span class="math inline">\(_{10}\)</span> and, to a lesser degree, CO concentrations may be associated with the occurrence of preterm births.<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a><br />
</li>
<li>The Buteyko method is a shallow breathing technique developed by Konstantin Buteyko, a Russian doctor, in 1952. Anecdotal evidence suggests that the Buteyko method can reduce asthma symptoms and improve quality of life. In a scientific study to determine the effectiveness of this method, researchers recruited 600 asthma patients aged 18-69 who relied on medication for asthma treatment. These patients were split into two research groups: one practiced the Buteyko method and the other did not. Patients were scored on quality of life, activity, asthma symptoms, and medication reduction on a scale from 0 to 10. On average, the participants in the Buteyko group experienced a significant reduction in asthma symptoms and an improvement in quality of life.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a></li>
</ol>
<div style="page-break-after: always;"></div>
<ol start="2" style="list-style-type: decimal">
<li><strong>GPA and study time</strong>. A survey was conducted on 55 undergraduates from Duke University who took an introductory statistics course in Spring 2012. Among many other questions, this survey asked them about their GPA and the number of hours they spent studying per week. The scatterplot below displays the relationship between these two variables.</li>
</ol>
<p><img src="03-Overview-of-Data-Collection-Principles_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<ol style="list-style-type: lower-alpha">
<li>What is the explanatory variable and what is the response variable?</li>
<li>Describe the relationship between the two variables. Make sure to discuss unusual observations, if any.</li>
<li>Is this an experiment or an observational study?</li>
<li>Can we conclude that studying longer hours leads to higher GPAs?</li>
</ol>
<div style="page-break-after: always;"></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>Income and education</strong> The scatterplot below shows the relationship between per capita income (in thousands of dollars) and percent of population with a bachelor’s degree in 3,143 counties in the US in 2010.</li>
</ol>
<p><img src="03-Overview-of-Data-Collection-Principles_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<ol style="list-style-type: lower-alpha">
<li>What are the explanatory and response variables?<br />
</li>
<li>Describe the relationship between the two variables. Make sure to discuss unusual observations, if any.<br />
</li>
<li>Can we conclude that having a bachelor’s degree increases one’s income?</li>
</ol>
<!--chapter:end:03-Overview-of-Data-Collection-Principles.Rmd-->
</div>
</div>
<div id="STUDY" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Studies</h1>
<div id="objectives-3" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and use properly in context all new terminology.<br />
</li>
<li>Given a study description, be able to identify and explain the study using correct terms.<br />
</li>
<li>Given a scenario, describe flaws in reasoning and propose study and sampling designs.</li>
</ol>
</div>
<div id="observation-studies-sampling-strategies-and-experiments" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Observation studies, sampling strategies, and experiments</h2>
<div id="observational-studies" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Observational studies</h3>
<p>Generally, data in observational studies are collected only by monitoring what occurs, while experiments require the primary explanatory variable in a study be assigned for each subject by the researchers.</p>
<p>Making causal conclusions based on experiments is often reasonable. However, making the same causal conclusions based on observational data can be treacherous and is not recommended. Thus, observational studies are generally only sufficient to show associations.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Suppose an observational study tracked sunscreen use and skin cancer, and it was found that the more sunscreen someone used, the more likely the person was to have skin cancer. Does this mean sunscreen <em>causes</em> skin cancer?<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a></p>
</blockquote>
<p>Some previous research<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> tells us that using sunscreen actually reduces skin cancer risk, so maybe there is another variable that can explain this hypothetical association between sunscreen usage and skin cancer. One important piece of information that is absent is sun exposure. If someone is out in the sun all day, she is more likely to use sunscreen <em>and</em> more likely to get skin cancer. Exposure to the sun is unaccounted for in the simple investigation.</p>
<div class="figure">
<img src="04-Studies_files/figure-html/confound-fig-1.png" alt="Sun exposure is a confounding variable because it is related to both response and explanatory variables." width="480" />
<p class="caption">
(#fig:confound-fig)Sun exposure is a confounding variable because it is related to both response and explanatory variables.
</p>
</div>
<p>Sun exposure is what is called a <strong>confounding variable</strong>,<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> which is a variable that is correlated with both the explanatory and response variables, see Figure @ref(fig:confound-fig) . While one method to justify making causal conclusions from observational studies is to exhaust the search for confounding variables, there is no guarantee that all confounding variables can be examined or measured.</p>
<p>Let’s look at an example of confounding visually. Using the <code>SAT</code> data from the <strong>mosaic</strong> package let’s look at expenditure per pupil versus SAT scores. Figure @ref(fig:confound2-fig) is a plot of the data.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
What conclusion to you reach from the plot in Figure @ref(fig:confound2-fig)?<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a></p>
</blockquote>
<div class="figure">
<img src="04-Studies_files/figure-html/confound2-fig-1.png" alt="Average SAT score versus expenditure per pupil; reminder: each observation represents an individual state." width="672" />
<p class="caption">
(#fig:confound2-fig)Average SAT score versus expenditure per pupil; reminder: each observation represents an individual state.
</p>
</div>
<p>The implication that spending less might give better results is not justified. Expenditures are confounded with the proportion of students who take the exam, and scores are higher in states where fewer students take the exam.</p>
<p>It is interesting to look at the original plot if we place the states into two groups depending on whether more or
fewer than 40% of students take the SAT. Figure @ref(fig:conditional-fig) is a plot of the data broken down into the 2 groups.</p>
<div class="figure">
<img src="04-Studies_files/figure-html/conditional-fig-1.png" alt="Average SAT score versus expenditure per pupil; broken down by level of participation." width="672" />
<p class="caption">
(#fig:conditional-fig)Average SAT score versus expenditure per pupil; broken down by level of participation.
</p>
</div>
<p>Once we account for the fraction of students taking the SAT, the relationship between expenditures and SAT scores changes.</p>
<p>In the same way, the <code>county</code> data set is an observational study with confounding variables, and its data cannot easily be used to make causal conclusions.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Figure @ref(fig:homeown2-fig) shows a negative association between the homeownership rate and the percentage of multi-unit structures in a county. However, it is unreasonable to conclude that there is a causal relationship between the two variables. Suggest one or more other variables that might explain the relationship in the Figure @ref(fig:homeown2-fig).<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></p>
</blockquote>
<div class="figure">
<img src="04-Studies_files/figure-html/homeown2-fig-1.png" alt="A scatterplot of the homeownership rate versus the percent of units that are in multi-unit structures for all 3,143 counties." width="672" />
<p class="caption">
(#fig:homeown2-fig)A scatterplot of the homeownership rate versus the percent of units that are in multi-unit structures for all 3,143 counties.
</p>
</div>
<p>Observational studies come in two forms: prospective and retrospective studies. A <strong>prospective study</strong> identifies individuals and collects information as events unfold. For instance, medical researchers may identify and follow a group of similar individuals over many years to assess the possible influences of behavior on cancer risk. One example of such a study is The Nurses Health Study, started in 1976 and expanded in 1989.<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> This prospective study recruits registered nurses and then collects data from them using questionnaires.</p>
<p><strong>Retrospective studies</strong> collect data after events have taken place; e.g. researchers may review past events in medical records. Some data sets, such as <code>county</code>, may contain both prospectively- and retrospectively-collected variables. Local governments prospectively collect some variables as events unfolded (e.g. retail sales) while the federal government retrospectively collected others during the 2010 census (e.g. county population).</p>
</div>
<div id="three-sampling-methods" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Three sampling methods</h3>
<p>Almost all statistical methods are based on the notion of implied randomness. If observational data are not collected in a random framework from a population, results from these statistical methods are not reliable. Here we consider three random sampling techniques: simple, stratified, and cluster sampling. Figures @ref(fig:simprand-fig) , @ref(fig:stratsamp2-fig) , and @ref(fig:clussamp4-fig) provides a graphical representation of these techniques.</p>
<div class="figure">
<img src="04-Studies_files/figure-html/simprand-fig-1.png" alt="Examples of simple random sampling. In this figure, simple random sampling was used to randomly select the 18 cases." width="672" />
<p class="caption">
(#fig:simprand-fig)Examples of simple random sampling. In this figure, simple random sampling was used to randomly select the 18 cases.
</p>
</div>
<div class="figure">
<img src="04-Studies_files/figure-html/stratsamp2-fig-1.png" alt="In this figure, stratified sampling was used: cases were grouped into strata, and then simple random sampling was employed within each stratum." width="672" />
<p class="caption">
(#fig:stratsamp2-fig)In this figure, stratified sampling was used: cases were grouped into strata, and then simple random sampling was employed within each stratum.
</p>
</div>
<div class="figure">
<img src="04-Studies_files/figure-html/clussamp4-fig-1.png" alt="In this figure, cluster sampling was used, where data were binned into nine clusters, and three of the clusters were randomly selected." width="672" />
<p class="caption">
(#fig:clussamp4-fig)In this figure, cluster sampling was used, where data were binned into nine clusters, and three of the clusters were randomly selected.
</p>
</div>
<p><strong>Simple random sampling</strong> is probably the most intuitive form of random sampling. Consider the salaries of Major League Baseball (MLB) players, where each player is a member of one of the league’s 30 teams. To take a simple random sample of 120 baseball players and their salaries from the 2010 season, we could write the names of that season’s 828 players onto slips of paper, drop the slips into a bucket, shake the bucket around until we are sure the names are all mixed up, then draw out slips until we have the sample of 120 players. In general, a sample is referred to as ``simple random’’ if each case in the population has an equal chance of being included in the final sample <em>and</em> knowing that a case is included in a sample does not provide useful information about which other cases are included.</p>
<p><strong>Stratified sampling</strong> is a divide-and-conquer sampling strategy. The population is divided into groups called <strong>strata</strong>. The strata are chosen so that similar cases are grouped together, then a second sampling method, usually simple random sampling, is employed within each stratum. In the baseball salary example, the teams could represent the strata; some teams have a lot more money (we’re looking at you, Yankees). Then we might randomly sample 4 players from each team for a total of 120 players.</p>
<p>Stratified sampling is especially useful when the cases in each stratum are very similar with respect to the outcome of interest. The downside is that analyzing data from a stratified sample is a more complex task than analyzing data from a simple random sample. The analysis methods introduced in this course would need to be extended to analyze data collected using stratified sampling.</p>
<blockquote>
<p><strong>Example</strong>:<br />
Why would it be good for cases within each stratum to be very similar?<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a></p>
</blockquote>
<p>In <strong>cluster sampling</strong>, we group observations into clusters, then randomly sample some of the clusters. Sometimes cluster sampling can be a more economical technique than the alternatives. Also, unlike stratified sampling, cluster sampling is most helpful when there is a lot of case-to-case variability within a cluster but the clusters themselves don’t look very different from one another. For example, if neighborhoods represented clusters, then this sampling method works best when the neighborhoods are very diverse. A downside of cluster sampling is that more advanced analysis techniques are typically required, though the methods in this course can be extended to handle such data.</p>
<blockquote>
<p><strong>Example</strong>:<br />
Suppose we are interested in estimating the malaria rate in a densely tropical portion of rural Indonesia. We learn that there are 30 villages in that part of the Indonesian jungle, each more or less similar to the next. What sampling method should be employed?<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a></p>
</blockquote>
<p>Another technique called <strong>multistage sampling</strong> is similar to cluster sampling, except that we take a simple random sample within each selected cluster. For instance, if we sampled neighborhoods using cluster sampling, we would next sample a subset of homes within each selected neighborhood if we were using multistage sampling.</p>
</div>
<div id="experiments" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Experiments</h3>
<p>Studies where the researchers assign treatments to cases are called <strong>experiments</strong>. When this assignment includes randomization, e.g. using a coin flip to decide which treatment a patient receives, it is called a <strong>randomized experiment</strong>. Randomized experiments are fundamentally important when trying to show a causal connection between two variables.</p>
<div id="principles-of-experimental-design" class="section level4" number="4.2.3.1">
<h4><span class="header-section-number">4.2.3.1</span> Principles of experimental design</h4>
<p>Randomized experiments are generally built on four principles.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Controlling</strong>. Researchers assign treatments to cases, and they do their best to <strong>control</strong> any other differences in the groups. For example, when patients take a drug in pill form, some patients take the pill with only a sip of water while others may have it with an entire glass of water. To control for the effect of water consumption, a doctor may ask all patients to drink a 12 ounce glass of water with the pill.</p></li>
<li><p><strong>Randomization</strong>. Researchers randomize patients into treatment groups to account for variables that cannot be controlled. For example, some patients may be more susceptible to a disease than others due to their dietary habits. Randomizing patients into the treatment or control group helps even out such differences, and it also prevents accidental bias from entering the study.</p></li>
<li><p><strong>Replication</strong>. The more cases researchers observe, the more accurately they can estimate the effect of the explanatory variable on the response. In a single study, we <strong>replicate</strong> by collecting a sufficiently large sample. Additionally, a group of scientists may replicate an entire study to verify an earlier finding. You replicate to the level of variability you want to estimate. For example, in flight test, we can run the same flight conditions again to get a replicate; however, if the same plane and pilot are being used, the replicate is not getting the pilot-to-pilot or the plane-to-plane variability.</p></li>
<li><p><strong>Blocking</strong>. Researchers sometimes know or suspect that variables, other than the treatment, influence the response. Under these circumstances, they may first group individuals based on this variable and then randomize cases within each block to the treatment groups. This strategy is often referred to as <strong>blocking</strong>. For instance, if we are looking at the effect of a drug on heart attacks, we might first split patients into low-risk and high-risk <strong>blocks</strong>, then randomly assign half the patients from each block to the control group and the other half to the treatment group, as shown in Figure @ref(fig:exp4-fig). This strategy ensures each treatment group has an equal number of low-risk and high-risk patients.</p></li>
</ol>
<div class="figure">
<img src="04-Studies_files/figure-html/exp4-fig-1.png" alt="Blocking using a variable depicting patient risk. Patients are first divided into low-risk and high-risk blocks, then each block is evenly divided into the treatment groups using randomization. This strategy ensures an equal representation of patients in each treatment group from both the low-risk and high-risk categories." width="480" />
<p class="caption">
(#fig:exp4-fig)Blocking using a variable depicting patient risk. Patients are first divided into low-risk and high-risk blocks, then each block is evenly divided into the treatment groups using randomization. This strategy ensures an equal representation of patients in each treatment group from both the low-risk and high-risk categories.
</p>
</div>
<p>It is important to incorporate the first three experimental design principles into any study, and this course describes methods for analyzing data from such experiments. Blocking is a slightly more advanced technique, and statistical methods in this course may be extended to analyze data collected using blocking. Math 359 is an entire course devoted to the design and analysis of experiments.</p>
</div>
<div id="reducing-bias-in-human-experiments" class="section level4" number="4.2.3.2">
<h4><span class="header-section-number">4.2.3.2</span> Reducing bias in human experiments</h4>
<p>Randomized experiments are the gold standard for data collection, but they do not ensure an unbiased perspective into the cause and effect relationships in all cases. Human studies are perfect examples where bias can unintentionally arise. Here we reconsider a study where a new drug was used to treat heart attack patients.<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a> In particular, researchers wanted to know if the drug reduced deaths in patients.</p>
<p>These researchers designed a randomized experiment because they wanted to draw causal conclusions about the drug’s effect. Study volunteers<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a> were randomly placed into two study groups. One group, the <strong>treatment group</strong>, received the drug. The other group, called the <strong>control group</strong>, did not receive any drug treatment.</p>
<p>Put yourself in the place of a person in the study. If you are in the treatment group, you are given a fancy new drug that you anticipate will help you. On the other hand, a person in the other group doesn’t receive the drug and sits idly, hoping her participation doesn’t increase her risk of death. These perspectives suggest there are actually two effects: the one of interest is the effectiveness of the drug, and the second is an emotional effect that is difficult to quantify.</p>
<p>Researchers aren’t usually interested in the emotional effect, which might bias the study. To circumvent this problem, researchers do not want patients to know which group they are in. When researchers keep the patients uninformed about their treatment, the study is said to be <strong>blind</strong>. But there is one problem: if a patient doesn’t receive a treatment, she will know she is in the control group. The solution to this problem is to give fake treatments to patients in the control group. A fake treatment is called a <strong>placebo</strong>, and an effective placebo is the key to making a study truly blind. A classic example of a placebo is a sugar pill that is made to look like the actual treatment pill. Often times, a placebo results in a slight but real improvement in patients. This effect has been dubbed the <strong>placebo effect</strong>.</p>
<p>The patients are not the only ones who should be blinded: doctors and researchers can accidentally bias a study. When a doctor knows a patient has been given the real treatment, she might inadvertently give that patient more attention or care than a patient that she knows is on the placebo. To guard against this bias, which again has been found to have a measurable effect in some instances, most modern studies employ a <strong>double-blind</strong> setup where doctors or researchers who interact with patients are, just like the patients, unaware of who is or is not receiving the treatment.<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a></p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Look back to the stent study in the first lesson where researchers were testing whether stents were effective at reducing strokes in at-risk patients. Is this an experiment? Was the study blinded? Was it double-blinded?<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a></p>
</blockquote>
</div>
</div>
</div>
<div id="homework-problems-3" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li><strong>Propose a sampling strategy</strong>. A large college class has 160 students. All 160 students attend the lectures together, but the students are divided into 4 groups, each of 40 students, for lab sections administered by different teaching assistants. The professor wants to conduct a survey about how satisfied the students are with the course, and he believes that the lab section a student is in might affect the student’s overall satisfaction with the course.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>What type of study is this?<br />
</li>
<li>Suggest a sampling strategy for carrying out this study.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><strong>Flawed reasoning</strong>. Identify the flaw in reasoning in the following scenarios. Explain what the individuals in the study should have done differently if they wanted to make such strong conclusions.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Students at an elementary school are given a questionnaire that they are required to return after their parents have completed it. One of the questions asked is, <em>Do you find that your work schedule makes it difficult for you to spend time with your kids after school?</em> Of the parents who replied, 85% said <em>no</em>. Based on these results, the school officials conclude that a great majority of the parents have no difficulty spending time with their kids after school.<br />
</li>
<li>A survey is conducted on a simple random sample of 1,000 women who recently gave birth, asking them about whether or not they smoked during pregnancy. A follow-up survey asking if the children have respiratory problems is conducted 3 years later, however, only 567 of these women are reached at the same address. The researcher reports that these 567 women are representative of all mothers.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li><strong>Sampling strategies</strong>. A statistics student who is curious about the relationship between the amount of time students spend on social networking sites and their performance at school decides to conduct a survey. Four research strategies for collecting data are described below. In each, name the sampling method proposed and any bias you might expect.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>He randomly samples 40 students from the study’s population, gives them the survey, asks them to fill it out and bring it back the next day.<br />
</li>
<li>He gives out the survey only to his friends, and makes sure each one of them fills out the survey.<br />
</li>
<li>He posts a link to an online survey on his Facebook wall and asks his friends to fill out the survey.<br />
</li>
<li>He stands outside the QRC and asks every third person that walks out the door to fill out the survey.</li>
</ol>
<div style="page-break-after: always;"></div>
<ol start="4" style="list-style-type: decimal">
<li><strong>Vitamin supplements</strong>. In order to assess the effectiveness of taking large doses of vitamin C in reducing the duration of the common cold, researchers recruited 400 healthy volunteers from staff and students at a university. A quarter of the patients were assigned a placebo, and the rest were evenly divided between 1g Vitamin C, 3g Vitamin C, or 3g Vitamin C plus additives to be taken at onset of a cold for the following two days. All tablets had identical appearance and packaging. The nurses who handed the prescribed pills to the patients knew which patient received which treatment, but the researchers assessing the patients when they were sick did not. No significant differences were observed in any measure of cold duration or severity between the four medication groups, and the placebo group had the shortest duration of symptoms.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Was this an experiment or an observational study? Why?<br />
</li>
<li>What are the explanatory and response variables in this study?<br />
</li>
<li>Were the patients blinded to their treatment?<br />
</li>
<li>Was this study double-blind?<br />
</li>
<li>Participants are ultimately able to choose whether or not to use the pills prescribed to them. We might expect that not all of them will adhere and take their pills. Does this introduce a confounding variable to the study? Explain your reasoning.</li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li><strong>Exercise and mental health</strong>. A researcher is interested in the effects of exercise on mental health and she proposes the following study: Use stratified random sampling to ensure representative proportions of 18-30, 31-40 and 41-55 year olds from the population. Next, randomly assign half the subjects from each age group to exercise twice a week, and instruct the rest not to exercise. Conduct a mental health exam at the beginning and at the end of the study, and compare the results.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>What type of study is this?<br />
</li>
<li>What are the treatment and control groups in this study?<br />
</li>
<li>Does this study make use of blocking? If so, what is the blocking variable?<br />
</li>
<li>Does this study make use of blinding?<br />
</li>
<li>Comment on whether or not the results of the study can be used to establish a causal relationship between exercise and mental health, and indicate whether or not the conclusions can be generalized to the population at large.<br />
</li>
<li>Suppose you are given the task of determining if this proposed study should get funding. Would you have any reservations about the study proposal?</li>
</ol>
<!--chapter:end:04-Studies.Rmd-->
</div>
</div>
<div id="NUMDATA" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Numerical Data</h1>
<div id="objectives-4" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and use properly in context all new terminology.<br />
</li>
<li>Generate in <code>R</code> summary statistics for a numeric variable including breaking down by cases.<br />
</li>
<li>Generate in <code>R</code> appropriate graphical summaries of numerical variables.<br />
</li>
<li>Be able to interpret and explain output both graphically and numerically.</li>
</ol>
</div>
<div id="numerical-data" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Numerical Data</h2>
<p>This lesson introduces techniques for exploring and summarizing numerical variables, and the <code>email50</code> and <code>mlb</code> data sets from the <strong>openintro</strong> package and a subset of <code>county_complete</code> from <code>usdata</code> provide rich opportunities for examples. Recall that outcomes of numerical variables are numbers on which it is reasonable to perform basic arithmetic operations. For example, the <code>pop2010</code> variable, which represents the populations of counties in 2010, is numerical since we can sensibly discuss the difference or ratio of the populations in two counties. On the other hand, area codes and zip codes are not numerical.</p>
<div id="scatterplots-for-paired-data" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Scatterplots for paired data</h3>
<p>A <strong>scatterplot</strong> provides a case-by-case view of data for two numerical variables. In Figure @ref(fig:scat5-fig), we again present a scatterplot used to examine how federal spending and poverty were related in the <code>county</code> data set.</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/scat5-fig-1.png" alt="A scatterplot showing fed_spend against poverty. Owsley County of Kentucky, with a poverty rate of 41.5% and federal spending of $21.50 per capita, is highlighted." width="672" />
<p class="caption">
(#fig:scat5-fig)A scatterplot showing fed_spend against poverty. Owsley County of Kentucky, with a poverty rate of 41.5% and federal spending of $21.50 per capita, is highlighted.
</p>
</div>
<p>Another scatterplot is shown in Figure @ref(fig:scat52-fig), comparing the number of line breaks <code>line_breaks</code> and number of characters <code>num_char</code> in emails for the <code>email50</code> data set. In any scatterplot, each point represents a single case. Since there are 50 cases in <code>email50</code>, there are 50 points in Figure @ref(fig:scat52-fig).</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/scat52-fig-1.png" alt="A scatterplot of `line_breaks` versus `num_char` for the `email50` data." width="672" />
<p class="caption">
(#fig:scat52-fig)A scatterplot of <code>line_breaks</code> versus <code>num_char</code> for the <code>email50</code> data.
</p>
</div>
<p>To put the number of characters in perspective, this paragraph has 357 characters. Looking at Figure @ref(fig:scat52-fig), it seems that some emails are incredibly long! Upon further investigation, we would actually find that most of the long emails use the HTML format, which means most of the characters in those emails are used to format the email rather than provide text.</p>
<div style="page-break-after: always;"></div>
<blockquote>
<p><strong>Exercise</strong>:<br />
What do scatterplots reveal about the data, and how might they be useful?<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a></p>
</blockquote>
<blockquote>
<p><em>Example</em>:<br />
Consider a new data set of 54 cars with two variables: vehicle price and weight.<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a> A scatterplot of vehicle price versus weight is shown in Figure @ref(fig:scat53-fig). What can be said about the relationship between these variables?</p>
</blockquote>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/scat53-fig-1.png" alt="A scatterplot of *price* versus *weight* for 54 cars." width="672" />
<p class="caption">
(#fig:scat53-fig)A scatterplot of <em>price</em> versus <em>weight</em> for 54 cars.
</p>
</div>
<p>The relationship is evidently nonlinear, as highlighted by the dashed line. This is different from previous scatterplots we’ve seen which show relationships that are very linear.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Describe two variables that would have a horseshoe shaped association in a scatterplot.<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a></p>
</blockquote>
</div>
<div id="dot-plots-and-the-mean" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Dot plots and the mean</h3>
<p>Sometimes two variables are one too many: only one variable may be of interest. In these cases, a dot plot provides the most basic of displays. A <strong>dot plot</strong> is a one-variable scatterplot; an example using the number of characters from 50 emails is shown in Figure @ref(fig:dot5-fig).</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/dot5-fig-1.png" alt="A dot plot of `num_char` for the `email50` data set." width="672" />
<p class="caption">
(#fig:dot5-fig)A dot plot of <code>num_char</code> for the <code>email50</code> data set.
</p>
</div>
<p>The <strong>mean</strong>, sometimes called the average, is a common way to measure the center of a <strong>distribution</strong> of data. To find the mean number of characters in the 50 emails, we add up all the character counts and divide by the number of emails. For computational convenience, the number of characters is listed in the thousands and rounded to the first decimal.</p>
<p><span class="math display">\[\bar{x} = \frac{21.7 + 7.0 + \cdots + 15.8}{50} = 11.6\]</span></p>
<p>The sample mean is often labeled <span class="math inline">\(\bar{x}\)</span>, a bar over the letter, and the letter <span class="math inline">\(x\)</span> is being used as a generic placeholder for the variable of interest, <code>num_char</code>.</p>
<blockquote>
<p><strong>Mean</strong><br />
The sample mean of a numerical variable is the sum of all of the observations divided by the number of observations, Equation @ref(eq:mean5).</p>
</blockquote>
<p><span class="math display">\[\begin{equation}
  \bar{x} = \frac{x_1+x_2+\cdots+x_n}{n}
  (\#eq:mean5)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(x_1, x_2, \dots, x_n\)</span> represent the <span class="math inline">\(n\)</span> observed values.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Examine the two equations above. What does <span class="math inline">\(x_1\)</span> correspond to? And <span class="math inline">\(x_2\)</span>? Can you infer a general meaning to what <span class="math inline">\(x_i\)</span> might represent?<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
What was <span class="math inline">\(n\)</span> in this sample of emails?<a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a></p>
</blockquote>
<p>The <code>email50</code> data set is a sample from a larger population of emails that were received in January and March. We could compute a mean for this population in the same way as the sample mean. However, there is a difference in notation: the population mean has a special label: <span class="math inline">\(\mu\)</span>. The symbol <span class="math inline">\(\mu\)</span> is the Greek letter <em>mu</em> and represents the average of all observations in the population. Sometimes a subscript, such as <span class="math inline">\(_x\)</span>, is used to represent which variable the population mean refers to, e.g. <span class="math inline">\(\mu_x\)</span>.</p>
<blockquote>
<p><em>Example</em>:
The average number of characters across all emails can be estimated using the sample data. Based on the sample of 50 emails, what would be a reasonable estimate of <span class="math inline">\(\mu_x\)</span>, the mean number of characters in all emails in the <code>email</code> data set? (Recall that <code>email50</code> is a sample from <code>email</code>.)</p>
</blockquote>
<p>The sample mean, 11.6, may provide a reasonable estimate of <span class="math inline">\(\mu_x\)</span>. While this number will not be perfect, it provides a <strong>point estimate</strong> of the population mean. Later in the text, we will develop tools to characterize the accuracy of point estimates, and we will find that point estimates based on larger samples tend to be more accurate than those based on smaller samples.</p>
<blockquote>
<p><em>Example</em>:<br />
We might like to compute the average income per person in the US. To do so, we might first think to take the mean of the per capita incomes from the 3,143 counties in the <code>county</code> data set. What would be a better approach?</p>
</blockquote>
<p>The <code>county</code> data set is special in that each county actually represents many individual people. If we were to simply average across the <code>income</code> variable, we would be treating counties with 5,000 and 5,000,000 residents equally in the calculations. Instead, we should compute the total income for each county, add up all the counties’ totals, and then divide by the number of people in all the counties. If we completed these steps with the <code>county</code> data, we would find that the per capita income for the US is $27,348.43. Had we computed the <em>simple</em> mean of per capita income across counties, the result would have been just $22,504.70!</p>
<p>This previous example used what is called a <strong>weighted mean</strong>, which will be a key topic in the probability section. As a look ahead, the probability mass function gives the population proportions of each value and thus to find the population mean <span class="math inline">\(\mu\)</span>, we will use a weighted mean.</p>
</div>
<div id="histograms-and-shape" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Histograms and shape</h3>
<p>Dot plots show the exact value of each observation. This is useful for small data sets, but they can become hard to read with larger samples. Rather than showing the value of each observation, think of the value as belonging to a <em>bin</em>. For example, in the <code>email50</code> data set, we create a table of counts for the number of cases with character counts between 0 and 5,000, then the number of cases between 5,000 and 10,000, and so on. Observations that fall on the boundary of a bin (e.g. 5,000) are allocated to the lower bin. This tabulation is shown below.</p>
<pre><code>## 
##   (0,5]  (5,10] (10,15] (15,20] (20,25] (25,30] (30,35] (35,40] (40,45] (45,50] 
##      19      12       6       2       3       5       0       0       2       0 
## (50,55] (55,60] (60,65] 
##       0       0       1</code></pre>
<p>These binned counts are plotted as bars in Figure @ref(fig:hist5-fig) into what is called a <strong>histogram</strong>.</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/hist5-fig-1.png" alt="A histogram of `num_char`. This distribution is very strongly skewed to the right." width="672" />
<p class="caption">
(#fig:hist5-fig)A histogram of <code>num_char</code>. This distribution is very strongly skewed to the right.
</p>
</div>
<p>Histograms provide a view of the <strong>data density</strong>. Higher bars represent where the data are relatively more dense. For instance, there are many more emails between 0 and 10,000 characters than emails between 10,000 and 20,000 characters in the data set. The bars make it easy to see how the density of the data changes relative to the number of characters.</p>
<p>Histograms are especially convenient for describing the shape of the data distribution. Figure @ref(fig:hist5-fig) shows that most emails have a relatively small number of characters, while fewer emails have a very large number of characters. When data trail off to the right in this way and have a longer right <strong>tail</strong>, the shape is said to be <strong>right skewed</strong>.<a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a></p>
<p>Data sets with the reverse characteristic – a long, thin tail to the left – are said to be <strong>left skewed</strong>. We also say that such a distribution has a long left tail. Data sets that show roughly equal trailing off in both directions are called <strong>symmetric</strong>.</p>
<blockquote>
<p><strong>Long tails to identify skew</strong><br />
When data trail off in one direction, the distribution has a <strong>long tail</strong>. If a distribution has a long left tail, it is left skewed. If a distribution has a long right tail, it is right skewed.</p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
Take a look at the dot plot above, Figure @ref(fig:dot5-fig). Can you see the skew in the data? Is it easier to see the skew in this histogram or the dot plots?<a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
Besides the mean, what can you see in the dot plot that you cannot see in the histogram?<a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a></p>
</blockquote>
<div id="making-our-own-histogram" class="section level4" number="5.2.3.1">
<h4><span class="header-section-number">5.2.3.1</span> Making our own histogram</h4>
<p>Let’s take some time to make a simple histogram. We will use the <strong>ggformula</strong> package which is a wrapper for the <strong>ggplot</strong> package.</p>
<p>Here are two questions:<br />
<em>What do we want <code>R</code> to do?</em> and<br />
<em>What must we give <code>R</code> for it to do this?</em></p>
<p>We want <code>R</code> to make a histogram. In <code>ggformula</code> the plots have the form <code>gf_XXXX</code> so we will use the <code>gf_histogram</code>. To find options and more information type:</p>
<pre><code>?gf_histogram</code></pre>
<p>To start we just have to give the formulas and data to <code>R</code>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_histogram</span>(<span class="sc">~</span>num_char,<span class="at">data=</span>email50,<span class="at">color=</span><span class="st">&quot;black&quot;</span>,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>)</span></code></pre></div>
<p><img src="05-Numerical-Data_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Look at the help menu for <code>gf_histogram</code> and change the x-axis label, change the bin width to 5, and have the left bin start at 0.</p>
</blockquote>
<p>Here is the code for the exercise</p>
<pre><code>email50 %&gt;%
   gf_histogram(~num_char,binwidth = 5,boundary=0,
   xlab=&quot;The Number of Characters (in thousands)&quot;
   ,color=&quot;black&quot;,fill=&quot;cyan&quot;) %&gt;%
   gf_theme(theme_classic())</code></pre>
<p>In addition to looking at whether a distribution is skewed or symmetric, histograms can be used to identify modes. A <strong>mode</strong> is represented by a prominent peak in the distribution.<a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a> There is only one prominent peak in the histogram of <code>num_char</code>.</p>
<p>Figure @ref(fig:histmulti-fig) show histograms that have one, two, or three prominent peaks. Such distributions are called <strong>unimodal</strong>, <strong>bimodal</strong>, and <strong>multimodal</strong>, respectively. Any distribution with more than 2 prominent peaks is called multimodal. Notice that there was one prominent peak in the unimodal distribution with a second less prominent peak that was not counted since it only differs from its neighboring bins by a few observations.</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/histmulti-fig-1.png" alt="Histograms that demonstrate unimodal, bimodal, and multimodal data." width="33%" /><img src="05-Numerical-Data_files/figure-html/histmulti-fig-2.png" alt="Histograms that demonstrate unimodal, bimodal, and multimodal data." width="33%" /><img src="05-Numerical-Data_files/figure-html/histmulti-fig-3.png" alt="Histograms that demonstrate unimodal, bimodal, and multimodal data." width="33%" />
<p class="caption">
(#fig:histmulti-fig)Histograms that demonstrate unimodal, bimodal, and multimodal data.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Height measurements of young students and adult teachers at a K-3 elementary school were taken. How many modes would you anticipate in this height data set?<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Looking for modes</strong><br />
Looking for modes isn’t about finding a clear and correct answer about the number of modes in a distribution, which is why <strong>prominent</strong> is not rigorously defined in these notes. The important part of this examination is to better understand your data and how it might be structured.</p>
</blockquote>
</div>
</div>
<div id="variance-and-standard-deviation" class="section level3" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Variance and standard deviation</h3>
<p>The mean is used to describe the center of a data set, but the <em>variability</em> in the data is also important. Here, we introduce two measures of variability: the <strong>variance</strong> and the <strong>standard deviation</strong>. Both of these are very useful in data analysis, even though the formulas are a bit tedious to calculate by hand. The standard deviation is the easier of the two to conceptually understand, and it roughly describes how far away the typical observation is from the mean. Equation @ref(eq:var5) is the equation for sample variance. We will demonstrate it with data so that the notation is easier to understand.</p>
<p><span class="math display">\[\begin{equation}
  s^2 = \sum_{i=1}^{n}\frac{(x_i-\bar{x})^2}{n-1}=\frac{(x_1-\bar{x})^2 + (x_2-\bar{x})^2 + (x_3-\bar{x})^2 + \cdots + (x_n-\bar{x})^2}{n-1}
  (\#eq:var5)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(x_1, x_2, \dots, x_n\)</span> represent the <span class="math inline">\(n\)</span> observed values.</p>
<p>We call the distance of an observation from its mean its <strong>deviation</strong>. Below are the deviations for the <span class="math inline">\(1^{st}\)</span>, <span class="math inline">\(2^{nd}\)</span>, <span class="math inline">\(3^{rd}\)</span>, and <span class="math inline">\(50^{th}\)</span> observations in the <code>num_char</code> variable. For computational convenience, the number of characters is listed in the thousands and rounded to the first decimal.</p>
<p><span class="math display">\[
\begin{aligned}
x_1^{}-\bar{x} &amp;= 21.7 - 11.6 = 10.1 \hspace{5mm}\text{ } \\
x_2^{}-\bar{x} &amp;= 7.0 - 11.6 = -4.6 \\
x_3^{}-\bar{x} &amp;= 0.6 - 11.6 = -11.0 \\
            &amp;\ \vdots \\
x_{50}^{}-\bar{x} &amp;= 15.8 - 11.6 = 4.2
\end{aligned}
\]</span></p>
<p>If we square these deviations and then take an average, the result is equal to the <strong>sample variance</strong>, denoted by <span class="math inline">\(s_{}^2\)</span>:
<span class="math display">\[
\begin{aligned}
s_{}^2 &amp;= \frac{10.1_{}^2 + (-4.6)_{}^2 + (-11.0)_{}^2 + \cdots + 4.2_{}^2}{50-1} \\
    &amp;= \frac{102.01 + 21.16 + 121.00 + \cdots + 17.64}{49} \\
    &amp;= 172.44
\end{aligned}
\]</span></p>
<p>We divide by <span class="math inline">\(n-1\)</span>, rather than dividing by <span class="math inline">\(n\)</span>, when computing the variance; you need not worry about this mathematical nuance yet. Notice that squaring the deviations does two things. First, it makes large values much larger, seen by comparing <span class="math inline">\(10.1^2\)</span>, <span class="math inline">\((-4.6)^2\)</span>, <span class="math inline">\((-11.0)^2\)</span>, and <span class="math inline">\(4.2^2\)</span>. Second, it gets rid of any negative signs.</p>
<p>The sample <strong>standard deviation</strong> <span class="math inline">\(s\)</span> is the square root of the variance:
<span class="math display">\[s=\sqrt{172.44} = 13.13\]</span>
The sample standard deviation of the number of characters in an email is 13.13 thousand. A subscript of <span class="math inline">\(_x\)</span> may be added to the variance and standard deviation, i.e. <span class="math inline">\(s_x^2\)</span> and <span class="math inline">\(s_x^{}\)</span>, as a reminder that these are the variance and standard deviation of the observations represented by <span class="math inline">\(x_1^{}\)</span>, <span class="math inline">\(x_2^{}\)</span>, …, <span class="math inline">\(x_n^{}\)</span>. The <span class="math inline">\(_{x}\)</span> subscript is usually omitted when it is clear which data the variance or standard deviation is referencing.</p>
<blockquote>
<p><strong>Variance and standard deviation</strong><br />
The variance is roughly the average squared distance from the mean. The standard deviation is the square root of the variance and describes how close the data are to the mean.</p>
</blockquote>
<p>Formulas and methods used to compute the variance and standard deviation for a population are similar to those used for a sample.<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a> However, like the mean, the population values have special symbols: <span class="math inline">\(\sigma_{}^2\)</span> for the variance and <span class="math inline">\(\sigma\)</span> for the standard deviation. The symbol <span class="math inline">\(\sigma\)</span> is the Greek letter <em>sigma</em>.</p>
<blockquote>
<p><strong>Tip: standard deviation describes variability</strong><br />
Focus on the conceptual meaning of the standard deviation as a descriptor of variability rather than the formulas. Usually 70% of the data will be within one standard deviation of the mean and about 95% will be within two standard deviations. However, as we have seen, these percentages are not strict rules.</p>
</blockquote>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/hist53-fig-1.png" alt="The first of three very different population distributions with the same mean, 0, and standard deviation, 1." width="672" />
<p class="caption">
(#fig:hist53-fig)The first of three very different population distributions with the same mean, 0, and standard deviation, 1.
</p>
</div>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/hist54-fig-1.png" alt="The second plot with mean 0 and standard deviation 1." width="672" />
<p class="caption">
(#fig:hist54-fig)The second plot with mean 0 and standard deviation 1.
</p>
</div>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/hist55-fig-1.png" alt="The final plot with mean 0 and standard deviation 1." width="672" />
<p class="caption">
(#fig:hist55-fig)The final plot with mean 0 and standard deviation 1.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Earlier the concept of shape of a distribution was introduced. A good description of the shape of a distribution should include modality and whether the distribution is symmetric or skewed to one side. Using the three figures, Figures @ref(fig:hist53-fig), @ref(fig:hist54-fig), and @ref(fig:hist55-fig) as an example, explain why such a description is important.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a></p>
</blockquote>
<blockquote>
<p><em>Example</em>:<br />
Describe the distribution of the <code>num_char</code> variable using the histogram in Figure @ref(fig:hist5-fig). The description should incorporate the center, variability, and shape of the distribution, and it should also be placed in context: the number of characters in emails. Also note any especially unusual cases.<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a></p>
</blockquote>
<p>In practice, the variance and standard deviation are sometimes used as a means to an end, where the <em>end</em> is being able to accurately estimate the uncertainty associated with a sample statistic. For example, later in the course we will use the variance and standard deviation to assess how close the sample mean is to the population mean.</p>
</div>
<div id="box-plots-quartiles-and-the-median" class="section level3" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> Box plots, quartiles, and the median</h3>
<p>A <strong>box plot</strong> summarizes a data set using five statistics while also plotting unusual observations. Figure @ref(fig:box-fig) provides a vertical dot plot alongside a box plot of the <code>num_char</code> variable from the <code>email50</code> data set.</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/box-fig-1.png" alt="A vertical dot plot next to a labeled box plot for the number of characters in 50 emails. The median (6,890), splits the data into the bottom 50% and the top 50%, marked in the dot plot by horizontal dashes and open circles, respectively." width="672" />
<p class="caption">
(#fig:box-fig)A vertical dot plot next to a labeled box plot for the number of characters in 50 emails. The median (6,890), splits the data into the bottom 50% and the top 50%, marked in the dot plot by horizontal dashes and open circles, respectively.
</p>
</div>
<p>The first step in building a box plot is drawing a dark line denoting the <strong>median</strong>, which splits the data in half. Figure @ref(fig:box-fig) shows 50% of the data falling below the median (red dashes) and the other 50% falling above the median (blue open circles). There are 50 character counts in the data set (an even number) so the data are perfectly split into two groups of 25. We take the median in this case to be the average of the two observations closest to the <span class="math inline">\(50^{th}\)</span> percentile: <span class="math inline">\((\text{6,768} + \text{7,012}) / 2 = \text{6,890}\)</span>. When there are an odd number of observations, there will be exactly one observation that splits the data into two halves, and in this case that observation is the median (no average needed).</p>
<blockquote>
<p><strong>Median: the number in the middle</strong><br />
If the data are ordered from smallest to largest, the <strong>median</strong> is the observation right in the middle. If there are an even number of observations, there will be two values in the middle, and the median is taken as their average.</p>
</blockquote>
<p>The second step in building a box plot is drawing a rectangle to represent the middle 50% of the data. The total length of the box, shown vertically in Figure @ref(fig:box-fig), is called the <strong>interquartile range</strong> (IQR, for short). It, like the standard deviation, is a measure of variability in data. The more variable the data, the larger the standard deviation and IQR. The two boundaries of the box are called the <strong>first quartile</strong> (the <span class="math inline">\(25^{th}\)</span> percentile, i.e. 25% of the data fall below this value) and the <strong>third quartile</strong> (the <span class="math inline">\(75^{th}\)</span> percentile), and these are often labeled <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_3\)</span>, respectively.</p>
<blockquote>
<p><strong>Interquartile range (IQR)</strong><br />
The IQR is the length of the box in a box plot. It is computed as
<span class="math display">\[ IQR = Q_3 - Q_1 \]</span>
where <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_3\)</span> are the <span class="math inline">\(25^{th}\)</span> and <span class="math inline">\(75^{th}\)</span> percentiles.</p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
What percent of the data fall between <span class="math inline">\(Q_1\)</span> and the median? What percent is between the median and <span class="math inline">\(Q_3\)</span>?<a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a></p>
</blockquote>
<p>Extending out from the box, the <strong>whiskers</strong> attempt to capture the data outside of the box, however, their reach is never allowed to be more than <span class="math inline">\(1.5\times IQR\)</span>.<a href="#fn49" class="footnote-ref" id="fnref49"><sup>49</sup></a> They capture everything within this reach. In Figure @ref(fig:box-fig), the upper whisker does not extend to the last three points, which are beyond <span class="math inline">\(Q_3 + 1.5\times IQR\)</span>, and so it extends only to the last point below this limit. The lower whisker stops at the lowest value, 33, since there is no additional data to reach; the lower whisker’s limit is not shown in the figure because the plot does not extend down to <span class="math inline">\(Q_1 - 1.5\times IQR\)</span>. In a sense, the box is like the body of the box plot and the whiskers are like its arms trying to reach the rest of the data.</p>
<p>Any observation that lies beyond the whiskers is labeled with a dot. The purpose of labeling these points – instead of just extending the whiskers to the minimum and maximum observed values – is to help identify any observations that appear to be unusually distant from the rest of the data. Unusually distant observations are called <strong>outliers</strong>. In this case, it would be reasonable to classify the emails with character counts of 41,623, 42,793, and 64,401 as outliers since they are numerically distant from most of the data.</p>
<blockquote>
<p><strong>Outliers are extreme</strong><br />
An <strong>outlier</strong> is an observation that is extreme relative to the rest of the data.</p>
</blockquote>
<blockquote>
<p><strong>Why it is important to look for outliers</strong><br />
Examination of data for possible outliers serves many useful purposes, including<br />
1. Identifying <strong>strong skew</strong> in the distribution.<br />
2. Identifying data collection or entry errors. For instance, we re-examined the email purported to have 64,401 characters to ensure this value was accurate.<br />
3. Providing insight into interesting properties of the data.</p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
The observation with value 64,401, an outlier, was found to be an accurate observation. What would such an observation suggest about the nature of character counts in emails?<a href="#fn50" class="footnote-ref" id="fnref50"><sup>50</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
Using Figure @ref(fig:box-fig), estimate the following values for <code>num_char</code> in the <code>email50</code> data set:<br />
(a) <span class="math inline">\(Q_1\)</span>,<br />
(b) <span class="math inline">\(Q_3\)</span>, and<br />
(c) IQR.<a href="#fn51" class="footnote-ref" id="fnref51"><sup>51</sup></a></p>
</blockquote>
<p>Of course <code>R</code> can calculate these summary statistics for us. First we will do these calculations individually and then in one function call. Remember to ask what you want <code>R</code> to do and what it needs.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="sc">~</span>num_char,<span class="at">data=</span>email50)</span></code></pre></div>
<pre><code>## [1] 11.59822</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(<span class="sc">~</span>num_char,<span class="at">data=</span>email50)</span></code></pre></div>
<pre><code>## [1] 13.12526</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(<span class="sc">~</span>num_char,<span class="at">data=</span>email50)</span></code></pre></div>
<pre><code>##       0%      25%      50%      75%     100% 
##  0.05700  2.53550  6.88950 15.41075 64.40100</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">iqr</span>(<span class="sc">~</span>num_char,<span class="at">data=</span>email50)</span></code></pre></div>
<pre><code>## [1] 12.87525</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(<span class="sc">~</span>num_char,<span class="at">data=</span>email50)</span></code></pre></div>
<pre><code>##    min     Q1 median       Q3    max     mean       sd  n missing
##  0.057 2.5355 6.8895 15.41075 64.401 11.59822 13.12526 50       0</code></pre>
</div>
<div id="robust-statistics" class="section level3" number="5.2.6">
<h3><span class="header-section-number">5.2.6</span> Robust statistics</h3>
<p>How are the <em>sample statistics</em> of the <code>num_char</code> data set affected by the observation with value 64,401? What would have happened if this email wasn’t observed? What would happen to these <em>summary statistics</em> if the observation at 64,401 had been even larger, say 150,000? These scenarios are plotted alongside the original data in Figure @ref(fig:box2-fig), and sample statistics are computed in <code>R</code>.</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/box2-fig-1.png" alt="Box plots of the original character count data and two modified data sets." width="672" />
<p class="caption">
(#fig:box2-fig)Box plots of the original character count data and two modified data sets.
</p>
</div>
<pre><code>##       group   min     Q1 median       Q3     max     mean       sd  n missing
## 1   Dropped 0.057 2.4540 6.7680 14.15600  42.793 10.52061 10.79768 49       0
## 2 Increased 0.057 2.5355 6.8895 15.41075 150.000 13.31020 22.43436 50       0
## 3  Original 0.057 2.5355 6.8895 15.41075  64.401 11.59822 13.12526 50       0</code></pre>
<p>The code used to generate this table is</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> email50<span class="sc">$</span>num_char</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p1[<span class="sc">-</span><span class="fu">which.max</span>(p1)]</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> p1</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>p3[<span class="fu">which.max</span>(p1)] <span class="ot">&lt;-</span> <span class="dv">150</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>robust <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">value=</span> <span class="fu">c</span>(p1,p2,p3),<span class="at">group=</span><span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;Original&quot;</span>,<span class="dv">50</span>),<span class="fu">rep</span>(<span class="st">&quot;Dropped&quot;</span>,<span class="dv">49</span>),<span class="fu">rep</span>(<span class="st">&quot;Increased&quot;</span>,<span class="dv">50</span>)))</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(value<span class="sc">~</span>group,<span class="at">data=</span>robust)</span></code></pre></div>
<p>Notice by using the formula notation, we were able to calculate the summary statistics for each group.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
(a) Which is more affected by extreme observations, the mean or median? The data summary may be helpful.<br />
(b) Is the standard deviation or IQR more affected by extreme observations?<a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a></p>
</blockquote>
<p>The median and IQR are called <strong>robust estimates</strong> because extreme observations have little effect on their values. The mean and standard deviation are much more affected by changes in extreme observations.</p>
<blockquote>
<p><em>Example</em>:<br />
The median and IQR do not change much under the three scenarios above. Why might this be the case?<a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
The distribution of vehicle prices tends to be right skewed, with a few luxury and sports cars lingering out into the right tail. If you were searching for a new car and cared about price, should you be more interested in the mean or median price of vehicles sold, assuming you are in the market for a regular car?<a href="#fn54" class="footnote-ref" id="fnref54"><sup>54</sup></a></p>
</blockquote>
</div>
<div id="transforming-data" class="section level3" number="5.2.7">
<h3><span class="header-section-number">5.2.7</span> Transforming data</h3>
<p>When data are very strongly skewed, we sometimes transform them so they are easier to model. Consider the histogram of salaries for Major League Baseball players’ salaries from 2010, which is shown in Figure @ref(fig:hist510-fig).</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/hist510-fig-1.png" alt="Histogram of MLB player salaries for 2010, in millions of dollars." width="672" />
<p class="caption">
(#fig:hist510-fig)Histogram of MLB player salaries for 2010, in millions of dollars.
</p>
</div>
<blockquote>
<p><em>Example</em>:<br />
The histogram of MLB player salaries is useful in that we can see the data are extremely skewed and centered (as gauged by the median) at about $1 million. What isn’t useful about this plot?<a href="#fn55" class="footnote-ref" id="fnref55"><sup>55</sup></a></p>
</blockquote>
<p>There are some standard transformations that are often applied when much of the data cluster near zero (relative to the larger values in the data set) and all observations are positive. A <strong>transformation</strong> is a rescaling of the data using a function. For instance, a plot of the natural logarithm<a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a> of player salaries results in a new histogram in Figure @ref(fig:hist512-fig). Transformed data are sometimes easier to work with when applying statistical models because the transformed data are much less skewed and outliers are usually less extreme.</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/hist512-fig-1.png" alt="Histogram of the log-transformed MLB player salaries for 2010." width="672" />
<p class="caption">
(#fig:hist512-fig)Histogram of the log-transformed MLB player salaries for 2010.
</p>
</div>
<p>Transformations can also be applied to one or both variables in a scatterplot. A scatterplot of the <code>line_breaks</code> and <code>num_char</code> variables is shown in Figure @ref(fig:scat52-fig) above. We can see a positive association between the variables and that many observations are clustered near zero. Later in this text, we might want to use a straight line to model the data. However, we’ll find that the data in their current state cannot be modeled very well. Figure @ref(fig:scat513-fig) shows a scatterplot where both the <code>line_breaks</code> and <code>num_char</code> variables have been transformed using a log (base <span class="math inline">\(e\)</span>) transformation. While there is a positive association in each plot, the transformed data show a steadier trend, which is easier to model than the untransformed data.</p>
<div class="figure">
<img src="05-Numerical-Data_files/figure-html/scat513-fig-1.png" alt="A scatterplot of `line_breaks` versus `num_char` for the `email50` data but where each variable has been log-transformed." width="672" />
<p class="caption">
(#fig:scat513-fig)A scatterplot of <code>line_breaks</code> versus <code>num_char</code> for the <code>email50</code> data but where each variable has been log-transformed.
</p>
</div>
<p>Transformations other than the logarithm can be useful, too. For instance, the square root (<span class="math inline">\(\sqrt{\text{original observation}}\)</span>) and inverse (<span class="math inline">\(\frac{1}{\text{original observation}}\)</span>) are used by statisticians. Common goals in transforming data are to see the data structure differently, reduce skew, assist in modeling, or straighten a nonlinear relationship in a scatterplot.</p>
</div>
</div>
<div id="homework-problems-4" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Homework Problems</h2>
<p>Create an Rmd file for the work including headers, file creation data, and explanation of your work. Make sure your plots have a title and the axes are labeled.</p>
<ol style="list-style-type: decimal">
<li><strong>Mammals exploratory</strong></li>
</ol>
<p>Data were collected on 39 species of mammals distributed over 13 orders. The data is in the <strong>openintro</strong> package as <code>mammals</code></p>
<ol style="list-style-type: lower-alpha">
<li>Using help, report the units for the variable <code>brain_Wt</code>.<br />
</li>
<li>Using <code>inspect</code> how many variables are numeric?<br />
</li>
<li>What type of variable is <code>danger</code>?</li>
<li>Create a histogram of <code>total_sleep</code> and describe the distribution.<br />
</li>
<li>Create a boxplot of <code>life_span</code> and describe the distribution.<br />
</li>
<li>Report the mean and median life span of a mammal.<br />
</li>
<li>Calculate the summary statistics for <code>life_span</code> broken down by <code>danger</code>. What is the standard deviation of life span in danger outcome 5?</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><strong>Mammals life spans</strong></li>
</ol>
<p>Continue using the <code>mammals</code> data set.</p>
<ol style="list-style-type: lower-alpha">
<li>Create side-by-side boxplots for <code>life_span</code> broken down by <code>exposure</code>. Note: you will have to change <code>exposure</code> to a <code>factor()</code>. Report on any findings.<br />
</li>
<li>What happened to the median and third quartile in exposure group 4?</li>
<li>Create faceted histograms. What are the shortcomings of this plot?</li>
<li>Create a new variable <code>exposed</code> that is a factor with level <code>Low</code> if exposure is <code>1</code> or <code>2</code> and <code>High</code> otherwise.</li>
<li>Repeat part c with the new variable. Explain what you see in the plot.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li><strong>Mammals life spans continued</strong></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Create a scatterplot of life span versus length of gestation.<br />
</li>
<li>What type of an association is apparent between life span and length of gestation?<br />
</li>
<li>What type of an association would you expect to see if the axes of the plot were reversed, i.e. if we plotted length of gestation versus life span?</li>
<li>Create the new scatterplot suggested in c.<br />
</li>
<li>Are life span and length of gestation independent? Explain your reasoning.</li>
</ol>
<!--chapter:end:05-Numerical-Data.Rmd-->
</div>
</div>
<div id="CATDATA" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Categorical Data</h1>
<div id="objectives-5" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and use properly in context all new terminology.</li>
<li>Generate in <code>R</code> tables for categorical variable(s).<br />
</li>
<li>Generate in <code>R</code> appropriate graphical summaries of categorical and numerical variables.<br />
</li>
<li>Be able to interpret and explain output both graphically and numerically.</li>
</ol>
</div>
<div id="categorical-data" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Categorical data</h2>
<p>Like numerical data, categorical data can also be organized and analyzed. This section introduces tables and other basic tools for categorical data. Remember at the beginning of this block of material, our case study had categorical data so we have seen some of the ideas in this lesson.</p>
<p>The <code>email50</code> data set represents a sample from a larger email data set called <code>email</code>. This larger data set contains information on 3,921 emails. In this section we will use the email data set to examine whether the presence of numbers, small or large, in an email provides any useful value in classifying email as spam or not spam.</p>
<div id="contingency-tables-and-bar-plots" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Contingency tables and bar plots</h3>
<p>In the <code>email</code> data set we have two variables: <code>spam</code> and <code>number</code> that we want to summarize. Let’s use <code>inspect()</code> to get information and insight about the two variables. We can also type <code>?email</code> to learn more about the data. First load the <code>openintro</code> library.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(openintro)</span></code></pre></div>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>email <span class="sc">%&gt;%</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(spam,number) <span class="sc">%&gt;%</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inspect</span>()</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##     name  class levels    n missing
## 1   spam factor      2 3921       0
## 2 number factor      3 3921       0
##                                    distribution
## 1 0 (90.6%), 1 (9.4%)                          
## 2 small (72.1%), none (14%) ...</code></pre>
<p>Notice the use of the <code>pipe</code> operator and how it adds to the ease of reading the code. The <code>select()</code> function allows us to narrow the variables down to the two of interest. Then <code>inspect()</code> gives us information about those variables. We read from top line; we start with the data set <code>email</code>, input it into <code>select()</code> and select variables from it, and then use <code>inspect()</code> to summarize the variables.</p>
<p>As is indicated <code>number</code> is a categorical variable that describes whether an email contains no numbers, only small numbers (values under 1 million), or at least one big number (a value of 1 million or more). The variable <code>spam</code> is a numeric variable where <code>1</code> indicates the email is spam. To treat it as categorical we will want to change it to a <strong>factor</strong> but first we will build a table that summarizes data for the two variables, see Table @ref(tab:contin1-tab). This table is called a <strong>contingency table</strong>. Each value in the table represents the number of times a particular combination of variable outcomes occurred. We will show you the code to generate the contingency table.</p>
<table>
<caption>
(#tab:contin1-tab)A contingency table for the <code>email</code> data.
</caption>
<thead>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Spam
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Number
</div>
</th>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
none
</th>
<th style="text-align:right;">
small
</th>
<th style="text-align:right;">
big
</th>
<th style="text-align:right;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
0
</td>
<td style="text-align:right;">
400
</td>
<td style="text-align:right;">
2659
</td>
<td style="text-align:right;">
495
</td>
<td style="text-align:right;">
3554
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
168
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
367
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:right;">
549
</td>
<td style="text-align:right;">
2827
</td>
<td style="text-align:right;">
545
</td>
<td style="text-align:right;">
3921
</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>spam<span class="sc">+</span>number,<span class="at">data=</span>email,<span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##        number
## spam    none small  big Total
##   0      400  2659  495  3554
##   1      149   168   50   367
##   Total  549  2827  545  3921</code></pre>
<p>The value 149 corresponds to the number of emails in the data set that are spam <em>and</em> had no number listed in the email. Row and column totals are also included. The <strong>row totals</strong> provide the total counts across each row (e.g. <span class="math inline">\(149 + 168 + 50 = 367\)</span>), and <strong>column totals</strong> are total counts down each column. The row and column totals are known as <strong>marginal</strong> counts and the values in the table, such as 149, as <strong>joint</strong> counts.</p>
<p>Let’s turn <code>spam</code> into a factor and update the <code>email</code> data object. We will use <code>mutate()</code> to do this.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>email <span class="ot">&lt;-</span> email <span class="sc">%&gt;%</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">spam =</span> <span class="fu">factor</span>(email<span class="sc">$</span>spam,<span class="at">levels=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;spam&quot;</span>,<span class="st">&quot;not spam&quot;</span>)))</span></code></pre></div>
<p>Now checking the data again.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>email <span class="sc">%&gt;%</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(spam,number) <span class="sc">%&gt;%</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inspect</span>()</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##     name  class levels    n missing
## 1   spam factor      2 3921       0
## 2 number factor      3 3921       0
##                                    distribution
## 1 not spam (90.6%), spam (9.4%)                
## 2 small (72.1%), none (14%) ...</code></pre>
<p>Let’s generate the table again.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>spam<span class="sc">+</span>number,<span class="at">data=</span>email,<span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##           number
## spam       none small  big Total
##   spam      149   168   50   367
##   not spam  400  2659  495  3554
##   Total     549  2827  545  3921</code></pre>
<p>A table for a single variable is called a <strong>frequency table</strong>. The table below is a frequency table for the <code>number</code> variable.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>number,<span class="at">data=</span>email)</span></code></pre></div>
<pre><code>## number
##  none small   big 
##   549  2827   545</code></pre>
<p>If we replaced the counts with percentages or proportions, the table would be called a <strong>relative frequency table</strong>.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>number,<span class="at">data=</span>email,<span class="at">format=</span><span class="st">&#39;proportion&#39;</span>)</span></code></pre></div>
<pre><code>## number
##      none     small       big 
## 0.1400153 0.7209895 0.1389952</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">tally</span>(<span class="sc">~</span>number,<span class="at">data=</span>email,<span class="at">format=</span><span class="st">&#39;percent&#39;</span>),<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## number
##  none small   big 
##  14.0  72.1  13.9</code></pre>
<p>A bar plot is a common way to display a single categorical variable. Figure @ref(fig:bar61-fig) shows a <strong>bar plot</strong> for the <code>number</code> variable.</p>
<p>(ref:quote61) Bar chart of the <code>number</code> variable.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>email <span class="sc">%&gt;%</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_bar</span>(<span class="sc">~</span>number) <span class="sc">%&gt;%</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Size of Number&quot;</span>,<span class="at">y=</span><span class="st">&quot;Count&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/bar61-fig-1.png" alt="(ref:quote61)" width="672" />
<p class="caption">
(#fig:bar61-fig)(ref:quote61)
</p>
</div>
<p>Next the counts are converted into proportions (e.g. <span class="math inline">\(549/3921=0.140\)</span> for <code>none</code>) in Figure @ref(fig:bar62-fig).</p>
<p>(ref:quote62) Bar chart of the <code>number</code> variable as a proportion.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>email <span class="sc">%&gt;%</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_props</span>(<span class="sc">~</span>number) <span class="sc">%&gt;%</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Size of Number&quot;</span>,<span class="at">y=</span><span class="st">&quot;Proportion&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/bar62-fig-1.png" alt="(ref:quote62)" width="672" />
<p class="caption">
(#fig:bar62-fig)(ref:quote62)
</p>
</div>
<p>Again, let’s clean up the plot into a style that we could use in a report.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>email <span class="sc">%&gt;%</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_props</span>(<span class="sc">~</span>number,<span class="at">title=</span><span class="st">&quot;The proportions of emails with a number in it&quot;</span>,</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">subtitle=</span><span class="st">&quot;From 2012&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;Type of number in the email&quot;</span>,</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">ylab=</span><span class="st">&quot;Proportion of emails&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<p><img src="06-Categorical-Data_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="column-proportions" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Column proportions</h3>
<p>The table below shows the column proportions. The <strong>column proportions</strong> are computed as the counts divided by their column totals. The value 149 at the intersection of <em>spam</em> and <em>none</em> is replaced by <span class="math inline">\(149/549=0.271\)</span>, i.e. 149 divided by its column total, 549. So what does 0.271 represent? It corresponds to the proportion of emails in the sample with no numbers that are spam. We are <strong>conditioning</strong>, restricting, on emails with no number. This rate of spam is much higher than emails with only small numbers (5.9%) or big numbers (9.2%). Because these spam rates vary between the three levels of <code>number</code> (<em>none</em>, <em>small</em>, <em>big</em>), this provides evidence that the <code>spam</code> and <code>number</code> variables are associated.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(spam<span class="sc">~</span>number,<span class="at">data=</span>email,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format=</span><span class="st">&#39;proportion&#39;</span>)</span></code></pre></div>
<pre><code>##           number
## spam             none      small        big
##   spam     0.27140255 0.05942695 0.09174312
##   not spam 0.72859745 0.94057305 0.90825688
##   Total    1.00000000 1.00000000 1.00000000</code></pre>
<p>The <code>tally()</code> function will always condition on the variable on the right hand side of the tilde, ~, when calculating proportions and thus only generate column proportions. The more general <code>table()</code> function of <code>R</code> will allow either column or row proportions.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Create a table of column proportions where the variable <code>spam</code> is the column variable.</p>
</blockquote>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(number<span class="sc">~</span>spam,<span class="at">data=</span>email,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format=</span><span class="st">&#39;proportion&#39;</span>)</span></code></pre></div>
<pre><code>##        spam
## number       spam  not spam
##   none  0.4059946 0.1125492
##   small 0.4577657 0.7481711
##   big   0.1362398 0.1392797
##   Total 1.0000000 1.0000000</code></pre>
<blockquote>
<p><strong>Exercise</strong>:<br />
In the table you just created, what does 0.748 represent?<a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a></p>
</blockquote>
<blockquote>
<p><em>Example</em>:<br />
Data scientists use statistics to filter spam from incoming email messages. By noting specific characteristics of an email, a data scientist may be able to classify some emails as spam or not spam with high accuracy. One of those characteristics is whether the email contains no numbers, small numbers, or big numbers. Another characteristic is whether or not an email has any HTML content. A contingency table for the <code>spam</code> and <code>format</code> variables is needed.<br />
1 Make <code>format</code> into a categorical factor variable.The levels should be “text” and “HTML”.<a href="#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a><br />
2 Create a contingency table from the <code>email</code> data set with <code>format</code> in the columns and <code>spam</code> in the rows.</p>
</blockquote>
<p>In deciding which variable to use as a column, the data scientist would be interested in how the proportion of spam changes within each email format. This corresponds to column proportions based on <code>format</code>: the proportion of spam in plain text emails and the proportion of spam in HTML emails.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>email <span class="ot">&lt;-</span> email <span class="sc">%&gt;%</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">format =</span> <span class="fu">factor</span>(email<span class="sc">$</span>format,<span class="at">levels=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;HTML&quot;</span>,<span class="st">&quot;text&quot;</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(spam<span class="sc">~</span>format,<span class="at">data=</span>email,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>##           format
## spam             HTML       text
##   spam     0.05796038 0.17489540
##   not spam 0.94203962 0.82510460
##   Total    1.00000000 1.00000000</code></pre>
<p>In generating the column proportions, we can see that a higher fraction of plain text emails are spam (<span class="math inline">\(209/1195 = 17.5\%\)</span>) than compared to HTML emails (<span class="math inline">\(158/2726 = 5.8\%\)</span>). This information on its own is insufficient to classify an email as spam or not spam, as over 80% of plain text emails are not spam. Yet, when we carefully combine this information with many other characteristics, such as <code>number</code> and other variables, we stand a reasonable chance of being able to classify some email as spam or not spam.</p>
<p>In constructing a table, we need to think about which variable we want in the column and which in the row. The formula format in some way makes us think about the response and predictor variables. However in some cases, it is not clear which variable should be in the column and row and the analyst must decide the point to be made with the table. Before settling on one form for a table, it is important to consider the audience and the message they are to receive from the table.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Create two tables with <code>number</code> and <code>spam</code> where each are in the column, so two tables where you change which variable is in the column. Which would be more useful to someone hoping to identify spam emails using the <code>number</code> variable?<a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a></p>
</blockquote>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(spam<span class="sc">~</span>number,email,<span class="at">format=</span><span class="st">&#39;proportion&#39;</span>,<span class="at">margin=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##           number
## spam             none      small        big
##   spam     0.27140255 0.05942695 0.09174312
##   not spam 0.72859745 0.94057305 0.90825688
##   Total    1.00000000 1.00000000 1.00000000</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(number<span class="sc">~</span>spam,email,<span class="at">format=</span><span class="st">&#39;proportion&#39;</span>,<span class="at">margin=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##        spam
## number       spam  not spam
##   none  0.4059946 0.1125492
##   small 0.4577657 0.7481711
##   big   0.1362398 0.1392797
##   Total 1.0000000 1.0000000</code></pre>
</div>
<div id="segmented-bar-and-mosaic-plots" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Segmented bar and mosaic plots</h3>
<p>Contingency tables using column proportions are especially useful for examining how two categorical variables are related. Segmented bar and mosaic plots provide a way to visualize the information in these tables.</p>
<p>A <strong>segmented bar plot</strong> is a graphical display of contingency table information. For example, a segmented bar plot representing the table with <code>number</code> in the column is shown in Figure @ref(fig:barseg61-fig), where we have first created a bar plot using the <code>number</code> variable and then separated each group by the levels of <code>spam</code>.</p>
<p>(ref:quote63) Segmented bar plot for numbers found in <code>emails</code>, where the counts have been further broken down by <code>spam</code>.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>email <span class="sc">%&gt;%</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_bar</span>(<span class="sc">~</span>number,<span class="at">fill=</span><span class="sc">~</span>spam) <span class="sc">%&gt;%</span></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Size of Number&quot;</span>,<span class="at">y=</span><span class="st">&quot;Count&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/barseg61-fig-1.png" alt="(ref:quote63)" width="672" />
<p class="caption">
(#fig:barseg61-fig)(ref:quote63)
</p>
</div>
<p>The column proportions of the table have been translated into a standardized segmented bar plot in Figure @ref(fig:barseg62-fig), which is a helpful visualization of the fraction of spam emails in each level of <code>number</code>.</p>
<p>(ref:quote64) Standardized version of Figure @ref(fig:barseg61-fig).</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>email <span class="sc">%&gt;%</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_props</span>(<span class="sc">~</span>number,<span class="at">fill=</span><span class="sc">~</span>spam,<span class="at">position=</span><span class="st">&#39;fill&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Size of Number&quot;</span>,<span class="at">y=</span><span class="st">&quot;Proportion&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/barseg62-fig-1.png" alt="(ref:quote64)" width="672" />
<p class="caption">
(#fig:barseg62-fig)(ref:quote64)
</p>
</div>
<blockquote>
<p><em>Example</em>:<br />
Examine both of the segmented bar plots. Which is more useful?</p>
</blockquote>
<p>Figure @ref(fig:barseg61-fig) contains more information, but Figure @ref(fig:barseg62-fig) presents the information more clearly. This second plot makes it clear that emails with no number have a relatively high rate of spam email – about 27%! On the other hand, less than 10% of email with small or big numbers are spam.</p>
<p>Since the proportion of spam changes across the groups in Figure @ref(fig:barseg62-fig), we can conclude the variables are dependent, which is something we were also able to discern using table proportions. Because both the <code>none</code> and <code>big</code> groups have relatively few observations compared to the <code>small</code> group, the association is more difficult to see in Figure @ref(fig:barseg61-fig).</p>
<p>In some other cases, a segmented bar plot that is not standardized will be more useful in communicating important information. Before settling on a particular segmented bar plot, create standardized and non-standardized forms and decide which is more effective at communicating features of the data.</p>
<p>A <strong>mosaic plot</strong> is a graphical display of contingency table information that is similar to a bar plot for one variable or a segmented bar plot when using two variables. It seems strange, but mosaic plots are not part of the <strong>mosaic</strong> package. We must load another set of packages called <strong>vcd</strong> and <strong>vcdExtra</strong>. Mosaic plot displays help to visualize the pattern of associations among variables in two-way and larger tables. Mosaic plots are controversial since they rely on the perception of area. Human vision is not good at distinguishing areas.</p>
<p>We will introduce mosaic plots because it is another way to visualize contingency tables. Figure @ref(fig:mosaic61-fig) shows a mosaic plot for the <code>number</code> variable. Each row represents a level of <code>number</code>, and the row heights correspond to the proportion of emails of each number type. For instance, there are fewer emails with no numbers than emails with only small numbers, so the <code>none</code> outcome row is shorter in height. In general, mosaic plots use box <em>areas</em> to represent the number of observations. Since there is only one variable, the widths are all constant. Thus area is simply related to row height making this visual easy to read.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vcd)</span></code></pre></div>
<p>(ref:quote65) Mosaic plot where emails are grouped by the <code>number</code> variable.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mosaic</span>(<span class="sc">~</span>number,<span class="at">data=</span>email)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/mosaic61-fig-1.png" alt="(ref:quote65)" width="672" />
<p class="caption">
(#fig:mosaic61-fig)(ref:quote65)
</p>
</div>
<p>This one-variable mosaic plot can be further divided into pieces as in Figure @ref(fig:mosaic62-fig) using the <code>spam</code> variable. The first variable in the formula is used to determine row height. That is, each row is split proportionally according to the fraction of emails in each number category, these heights are similar to Figure @ref(fig:mosaic61-fig). Next each row is split horizontally according to the proportion of emails that were spam in that number group. For example, the second row, representing emails with only small numbers, was divided into emails that were spam (left) and not spam (right). The area of the rectangles is proportional to the proportions in the table where each cell count is divided by the total count. First we will generate the table and then represent it as a mosaic plot.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>number<span class="sc">+</span>spam,<span class="at">data=</span>email,<span class="at">format=</span><span class="st">&#39;proportion&#39;</span>)</span></code></pre></div>
<pre><code>##        spam
## number        spam   not spam
##   none  0.03800051 0.10201479
##   small 0.04284621 0.67814333
##   big   0.01275185 0.12624331</code></pre>
<p>(ref:quote66) Mosaic plot with <code>number</code> as the first variable.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mosaic</span>(<span class="sc">~</span>number<span class="sc">+</span>spam,<span class="at">data=</span>email)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/mosaic62-fig-1.png" alt="(ref:quote66)" width="672" />
<p class="caption">
(#fig:mosaic62-fig)(ref:quote66)
</p>
</div>
<p>These plots are hard to use in a visual comparison of area. For example, is the area for <em>small</em> number <em>spam</em> emails different from <em>none</em> number <em>spam</em> emails? The rectangles have different shapes but from the table we can tell the areas are close.</p>
<p>An important use of the mosaic plot is to determine if an association between variables may be present. The bottom of the first column represents spam emails that had big numbers, and the bottom row of the second column represents regular emails that had big numbers. We can again use this plot to see that the <code>spam</code> and <code>number</code> variables are associated since some rows are divided in different vertical locations than others, which was the same technique used for checking an association in the standardized version of the segmented bar plot.</p>
<p>In a similar way, a mosaic plot representing column proportions where <em>spam</em> is in the column could be constructed. To completely understand the mosaic plot as shown in Figure @ref(fig:mosaic63-fig) let’s first find the proportions of <code>spam</code>.</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>spam,<span class="at">data=</span>email,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>## spam
##       spam   not spam 
## 0.09359857 0.90640143</code></pre>
<p>So the row heights will be split 90-10. Next let’s find the proportions of number within each value of spam. In the spam row, <em>none</em> will be 41%, <em>small</em> will be 46%, and <em>big</em> will be 13%.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(number<span class="sc">~</span>spam,<span class="at">data=</span>email,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>##        spam
## number       spam  not spam
##   none  0.4059946 0.1125492
##   small 0.4577657 0.7481711
##   big   0.1362398 0.1392797
##   Total 1.0000000 1.0000000</code></pre>
<p>However, because it is more insightful for this application to consider the fraction of spam in each category of the <code>number</code> variable, we prefer Figure @ref(fig:mosaic62-fig).</p>
<p>(ref:quote67) Mosaic plot with <code>spam</code> as the first variable</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mosaic</span>(<span class="sc">~</span>spam<span class="sc">+</span>number,<span class="at">data=</span>email)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/mosaic63-fig-1.png" alt="(ref:quote67)" width="672" />
<p class="caption">
(#fig:mosaic63-fig)(ref:quote67)
</p>
</div>
</div>
<div id="the-only-pie-chart-you-will-see-in-this-course-hopefully" class="section level3" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> The only pie chart you will see in this course, hopefully</h3>
<p>While pie charts are well known, they are not typically as useful as other charts in a data analysis. A <strong>pie chart</strong> is shown in Figure @ref(fig:pie61-fig). It is generally more difficult to compare group sizes in a pie chart than in a bar plot, especially when categories have nearly identical counts or proportions. In the case of the <em>none</em> and <em>big</em> categories, the difference is so slight you may be unable to distinguish any difference in group sizes.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pie</span>(<span class="fu">table</span>(email<span class="sc">$</span>number), <span class="at">col=</span>COL[<span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">2</span>)], <span class="at">radius=</span><span class="fl">0.75</span>)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/pie61-fig-1.png" alt="A pie chart number for the email data set." width="672" />
<p class="caption">
(#fig:pie61-fig)A pie chart number for the email data set.
</p>
</div>
<p>Pie charts are popular in the Air Force due to the ease of generating them in Excel and PowerPoint. However, the values for each slice are often printed on top of the chart making the chart irrelevant. We recommend a minimum use of pie charts in your work.</p>
</div>
<div id="comparing-numerical-data-across-groups" class="section level3" number="6.2.5">
<h3><span class="header-section-number">6.2.5</span> Comparing numerical data across groups</h3>
<p>Some of the more interesting investigations can be considered by examining numerical data across groups. This is the case where one variable is categorical and the other is numerical. The methods required here aren’t really new. All that is required is to make a numerical plot for each group. Here two convenient methods are introduced: side-by-side box plots and density plots.</p>
<p>We will take a look again at the subset of <code>county_complete</code> data set and compare the median household income for counties that gained population from 2000 to 2010 versus counties that had no gain. While we might like to make a causal connection here, remember that these are observational data and so such an interpretation would be unjustified.</p>
<p>This section will give us a chance to perform some data wrangling. We will be using the <code>tidyverse</code> verbs in the process. Data wrangling is an important part of analysis work and typically takes a significant portion of the analysis work.</p>
<p>Here is the code to generate the data we need.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(usdata)</span></code></pre></div>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>county_tidy <span class="ot">&lt;-</span> county_complete <span class="sc">%&gt;%</span> </span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(name, state, pop2000, pop2010, <span class="at">fed_spend=</span>fed_spending_2009, <span class="at">poverty=</span>poverty_2010, </span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">homeownership =</span> homeownership_2010, <span class="at">multi_unit =</span> housing_multi_unit_2010, </span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">income =</span> per_capita_income_2010, <span class="at">med_income =</span> median_household_income_2010) <span class="sc">%&gt;%</span></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">fed_spend=</span>fed_spend<span class="sc">/</span>pop2010)</span></code></pre></div>
<p>First, as a reminder, let’s look at the data.</p>
<p><em>What do we want <code>R</code> to do</em>? We want to select the variables <code>pop2000</code>, <code>pop2010</code>, and <code>med_income</code>.</p>
<p><em>What does <code>R</code> need</em>? It needs the data object, and variable names.</p>
<p>We will use the <code>select()</code> and <code>inspect()</code> functions.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>county_tidy <span class="sc">%&gt;%</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(pop2000,pop2010,med_income) <span class="sc">%&gt;%</span></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inspect</span>()</span></code></pre></div>
<pre><code>## 
## quantitative variables:  
##            name   class   min       Q1 median    Q3     max     mean        sd
## ...1    pop2000 numeric    67 11223.50  24621 61775 9519338 89649.99 292547.67
## ...2    pop2010 numeric    82 11114.50  25872 66780 9818605 98262.04 312946.70
## ...3 med_income numeric 19351 36956.25  42450 49144  115574 44274.12  11547.49
##         n missing
## ...1 3139       3
## ...2 3142       0
## ...3 3142       0</code></pre>
<p>Notice that three counties are missing population values, reported as <code>NA</code>. Let’s remove them and find which counties increased population by creating a new variable.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>cc_reduced <span class="ot">&lt;-</span> county_tidy <span class="sc">%&gt;%</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">drop_na</span>(pop2000) <span class="sc">%&gt;%</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(pop2000,pop2010,med_income) <span class="sc">%&gt;%</span></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pop_gain =</span> <span class="fu">sign</span>(pop2010<span class="sc">-</span>pop2000))</span></code></pre></div>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>pop_gain,<span class="at">data=</span>cc_reduced)</span></code></pre></div>
<pre><code>## pop_gain
##   -1    0    1 
## 1097    1 2041</code></pre>
<p>There were 2,041 counties where the population increased from 2000 to 2010, and there were 1,098 counties with no gain, only 1 county had a net of zero, or a loss. Let’s just look at the counties with a gain or loss in side-by-side boxplot. Again, we will use <code>filter()</code> to select the two groups and then make the variable <code>pop_gain</code> into a categorical variable, more data wrangling.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>cc_reduced <span class="ot">&lt;-</span> cc_reduced <span class="sc">%&gt;%</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(pop_gain <span class="sc">!=</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pop_gain =</span> <span class="fu">factor</span>(pop_gain,<span class="at">levels=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>),<span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;Loss&quot;</span>,<span class="st">&quot;Gain&quot;</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(cc_reduced)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##       name  class levels    n missing
## 1 pop_gain factor      2 3138       0
##                                    distribution
## 1 Gain (65%), Loss (35%)                       
## 
## quantitative variables:  
##            name   class   min       Q1  median      Q3     max     mean
## ...1    pop2000 numeric    67 11217.25 24608.0 61783.5 9519338 89669.37
## ...2    pop2010 numeric    82 11127.00 25872.0 66972.0 9818605 98359.23
## ...3 med_income numeric 19351 36950.00 42443.5 49120.0  115574 44253.24
##             sd    n missing
## ...1 292592.28 3138       0
## ...2 313133.28 3138       0
## ...3  11528.95 3138       0</code></pre>
<p>The <strong>side-by-side box plot</strong> is a traditional tool for comparing across groups. An example is shown in Figure @ref(fig:sbysbox61-fig) where there are two box plots, one for each group and drawn on the same scale.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>cc_reduced <span class="sc">%&gt;%</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_boxplot</span>(med_income<span class="sc">~</span>pop_gain,</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">subtitle=</span><span class="st">&quot;The income data were collected between 2006 and 2010.&quot;</span>,</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">xlab=</span><span class="st">&quot;Population change from 2000 to 2010&quot;</span>,</span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">ylab=</span><span class="st">&quot;Median Household Income&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/sbysbox61-fig-1.png" alt="Side-by-side box plot for median household income, where the counties are split by whether there was a population gain or loss from 2000 to 2010." width="672" />
<p class="caption">
(#fig:sbysbox61-fig)Side-by-side box plot for median household income, where the counties are split by whether there was a population gain or loss from 2000 to 2010.
</p>
</div>
<p>Another useful plotting method uses <strong>density plots</strong> to compare numerical data across groups. A histogram bins data but is highly dependent on the number and boundary of the bins. A density plot also estimates the distribution of a numerical variable but does this by estimating the density of data points in a small window around each data point. The overall curve is the sum of this small density estimate. A density plot can be thought of as a smooth version of the histogram. Several options go into a density estimate such as the width of the window and type of smoothing function. These ideas are beyond the point here and we will just use the default options. Figure @ref(fig:dens61-fig) is a plot of the two density curves.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>cc_reduced <span class="sc">%&gt;%</span></span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dens</span>(<span class="sc">~</span>med_income,<span class="at">color=</span><span class="sc">~</span>pop_gain,<span class="at">lwd=</span><span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Median household income&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>,<span class="at">col=</span><span class="st">&quot;Population </span><span class="sc">\n</span><span class="st">Change&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="06-Categorical-Data_files/figure-html/dens61-fig-1.png" alt="Density plots of median household income for counties with population gain versus population loss" width="672" />
<p class="caption">
(#fig:dens61-fig)Density plots of median household income for counties with population gain versus population loss
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Use the box plots and density plots to compare the incomes for counties across the two groups. What do you notice about the approximate center of each group? What do you notice about the variability between groups? Is the shape relatively consistent between groups? How many <em>prominent</em> modes are there for each group?<a href="#fn60" class="footnote-ref" id="fnref60"><sup>60</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
What components of each plot in Figures 8 and 9 do you find most useful?<a href="#fn61" class="footnote-ref" id="fnref61"><sup>61</sup></a></p>
</blockquote>
</div>
</div>
<div id="homework-problems-5" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Homework Problems</h2>
<p>Create an Rmd file for the work including headers, file creation data, and explanation of your work. Make sure your plots have a title and the axes are labeled.</p>
<ol style="list-style-type: decimal">
<li><strong>Views on immigration</strong></li>
</ol>
<p>910 randomly sampled registered voters from Tampa, FL were asked if they thought workers who have illegally entered the US should be (i) allowed to keep their jobs and apply for US citizenship, (ii) allowed to keep their jobs as temporary guest workers but not allowed to apply for US citizenship, or (iii) lose their jobs and have to leave the country.</p>
<p>The data is in the <strong>openintro</strong> package in the <code>immigration</code> data object.</p>
<ol style="list-style-type: lower-alpha">
<li>How many levels of <em>political</em> are there?<br />
</li>
<li>Create a table using <code>tally</code>.</li>
<li>What percent of these Tampa, FL voters identify themselves as conservatives?</li>
<li>What percent of these Tampa, FL voters are in favor of the citizenship option?</li>
<li>What percent of these Tampa, FL voters identify themselves as conservatives and are in favor of the citizenship option?</li>
<li>What percent of these Tampa, FL voters who identify themselves as conservatives are also in favor of the citizenship option? What percent of moderates and liberal share this view?</li>
<li>Create a stacked bar chart.</li>
<li>Using your plot, do political ideology and views on immigration appear to be independent? Explain your reasoning.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><strong>Views on the DREAM Act</strong> The same survey from Exercise 1 also asked respondents if they support the DREAM Act, a proposed law which would provide a path to citizenship for people brought illegally to the US as children.</li>
</ol>
<p>The data is in the <strong>openintro</strong> package in the <code>dream</code> data object.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a <strong>mosaic</strong> plot.</li>
<li>Based on the mosaic plot, are views on the DREAM Act and political ideology independent?</li>
</ol>
<div style="page-break-after: always;"></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>Heart transplants</strong></li>
</ol>
<p>The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was designated an official heart transplant candidate, meaning that he was gravely ill and would most likely benefit from a new heart. Some patients got a transplant and some did not. The variable <em>transplant</em> indicates which group the patients were in; patients in the treatment group got a transplant and those in the control group did not. Another variable called <em>survived</em> was used to indicate whether or not the patient was alive at the end of the study.</p>
<p>The data is in the <strong>openintro</strong> package and is called <code>heart_transplant</code>.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a <strong>mosaic</strong> plot.</li>
<li>Based on the mosaic plot, is survival independent of whether or not the patient got a transplant? Explain your reasoning.</li>
<li>Using the variable <code>survtime</code>, create side-by-side boxplots for the control and treatment groups.</li>
<li>What do the box plots suggest about the efficacy (effectiveness) of transplants?</li>
</ol>
<!--chapter:end:06-Categorical-Data.Rmd-->
</div>
</div>
<div id="part-probability-modeling" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Probability Modeling</h1>
</div>
<div id="CS2" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Case Study</h1>
<div id="objectives-6" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Use R to simulate a probabilistic model.<br />
</li>
<li>Use basic counting methods.</li>
</ol>
</div>
<div id="introduction-to-probability-models" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Introduction to probability models</h2>
<p>In this second block of material we will focus on probability models. We will take two approaches, one is mathematical and the other is computational. In some cases we can use both methods on a problem and in others only the computational approach is feasible. The mathematical approach to probability modeling allows us insight into the problem and the ability to understand the process. Simulation has a much greater ability to generalize but can be time intensive to run and often requires the writing of custom functions.</p>
<p>This case study is extensive and may seem overwhelming, do not worry we will discuss these ideas again in the many lessons we have coming up this block.</p>
</div>
<div id="probability-models" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Probability models</h2>
<p>Probability models are an important tool for data analysts. They are used to explain variation in outcomes that cannot be explained by other variables. We will use these ideas in the Statistical Modeling Block to help us make decisions about our statistical models.</p>
<p>Often probability models are used to answer a question of the form “What is the chance that …..?” This means that we typically have an experiment or trial where multiple outcomes are possible and we only have an idea of the frequency of those outcomes. We use this frequency as a measure of the probability of a particular outcome.</p>
<p>For this block we will focus just on probability models. To apply a probability model we will need to</p>
<ol style="list-style-type: decimal">
<li>Select the experiment and its possible outcomes.</li>
<li>Have probability values for the outcomes which may include <strong>parameters</strong> that determine the probabilities.</li>
<li>Understand the assumptions behind the model.</li>
</ol>
</div>
<div id="case-study-1" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Case study</h2>
<p>There is a famous example of a probability question that we will attack in this case study. The question we want to answer is “In a room of <span class="math inline">\(n\)</span> people what is the chance that at least two people have the same birthday?”</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
The typical classroom at USAFA has 18 students in it. What do you think the chance that at least two students have the same birthday?<a href="#fn62" class="footnote-ref" id="fnref62"><sup>62</sup></a></p>
</blockquote>
<div id="break-down-the-question" class="section level3" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Break down the question</h3>
<p>The first action we should take is to understand what is being asked.</p>
<ol style="list-style-type: decimal">
<li>What is the experiment or trial?</li>
<li>What does it mean to have the same birthday?</li>
<li>What about leap years?</li>
<li>What about the frequency of births? Are some days less likely than others?</li>
</ol>
<blockquote>
<p><strong>Exercise</strong>:<br />
Discuss these questions and others that you think are relevant.<a href="#fn63" class="footnote-ref" id="fnref63"><sup>63</sup></a></p>
</blockquote>
<p>The best first step is to make a simple model, often these are the only ones that will have a mathematical solution. For our problem this means we answer the above questions.</p>
<ol style="list-style-type: decimal">
<li>We have a room of 18 people and we look at their birthdays. We either have two or more birthdays matching or not; thus there are two outcomes.</li>
<li>We don’t care about the year, only the day and month. Thus two people born on May 16th are a match.</li>
<li>We will ignore leap years.</li>
<li>We will assume that a person has equal probability of being born on any of the 365 days of the year.</li>
<li>At least two means we could have multiple matches on the same day or several different days where multiple people have matching birthdays.</li>
</ol>
</div>
<div id="simulate-computational" class="section level3" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Simulate (computational)</h3>
<p>Now that we have an idea about the structure of the problem, we next need to think about how we would simulate a single classroom. We have 18 students in the classroom and they all could have any of the 365 days of the year as a birthday. What we need to do is sample birthdays for each of the 18 students. But how do we code the days of the year?</p>
<p>An easy solution is to just label the days from 1 to 365. The function <code>seq()</code> does this for us.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>days <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">365</span>)</span></code></pre></div>
<p>Next we need to pick one of the days using the sample function. Note that we set the seed to get repeatable results, this is not required.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2022</span>)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(days,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 228</code></pre>
<p>The first person was born on the 228th day of the year.</p>
<p>Since <code>R</code> works on vectors, we don’t have to write a loop to select 18 days, we just have <code>sample()</code> do it for us.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>class <span class="ot">&lt;-</span> <span class="fu">sample</span>(days,<span class="at">size=</span><span class="dv">18</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>class</span></code></pre></div>
<pre><code>##  [1] 206 311 331 196 262 191 206 123 233 270 248   7 349 112   1 307 288 354</code></pre>
<p>What do we want <code>R</code> to do? Sample from the numbers 1 to 365 with replacement, which means a number can be picked more than once.</p>
<p>Notice in our sample we have at least one match, although it is difficult to look at this list and see the match. Let’s sort them to make it easier for us to see.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span>(class)</span></code></pre></div>
<pre><code>##  [1]   1   7 112 123 191 196 206 206 233 248 262 270 288 307 311 331 349 354</code></pre>
<p>The next step is to find a way in <code>R</code> for the code to detect that there is a match.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
What idea(s) can we use to determine if a match exists?</p>
</blockquote>
<p>We could sort the data and look at differences in sequential values and then check if the set of differences contains a zero. This seems to be computationally expensive. Instead we will use the function <code>unique()</code> which gives a vector of unique values in an object. The function <code>length()</code> gives the number of elements in the vector.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">unique</span>(class))</span></code></pre></div>
<pre><code>## [1] 17</code></pre>
<p>Since we only have 17 unique values in a vector of size 18, we have a match. Now let’s put this all together to generate another classroom of size 18.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">unique</span>(<span class="fu">sample</span>(days,<span class="at">size=</span><span class="dv">18</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>)))</span></code></pre></div>
<pre><code>## [1] 16</code></pre>
<p>The next problem that needs to be solved is how to repeat the classrooms and keep track of those that have a match. There are several functions we could use to include <code>replicate()</code> but we will use <code>do()</code> from the <strong>mosaic</strong> package because it returns a data frame so we can use <code>tidyverse</code> verbs to wrangle the data.</p>
<p>The <code>do()</code> function allows us to repeat an operation many times. The following template</p>
<pre><code>do(n) * {stuff to do}              # pseudo-code</code></pre>
<p>where {stuff to do} is typically a single <code>R</code> command, but may be something more complicated.</p>
<p>Load the libraries.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mosaic)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">do</span>(<span class="dv">5</span>)<span class="sc">*</span><span class="fu">length</span>(<span class="fu">unique</span>(<span class="fu">sample</span>(days,<span class="at">size=</span><span class="dv">18</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>)))</span></code></pre></div>
<pre><code>##   length
## 1     18
## 2     17
## 3     17
## 4     17
## 5     18</code></pre>
<p>Let’s repeat for a larger number of simulated classroom, remember you should be asking yourself:</p>
<p><em>What do I want <code>R</code> to do?</em><br />
<em>What does <code>R</code> need to do this?</em></p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">length</span>(<span class="fu">unique</span>(<span class="fu">sample</span>(days,<span class="at">size=</span><span class="dv">18</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>)))) <span class="sc">%&gt;%</span></span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">match=</span><span class="fu">if_else</span>(length<span class="sc">==</span><span class="dv">18</span>,<span class="dv">0</span>,<span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob=</span><span class="fu">mean</span>(match))</span></code></pre></div>
<pre><code>##   prob
## 1 0.36</code></pre>
<p>This is within 2 decimal places of the mathematical solution we develop shortly.</p>
<p>How many classrooms do we need to simulate to get an accurate estimate of the probability of a match? That is a statistical modeling question and it depends on how much variability we can accept. We will discuss these ideas later in the semester. For now, you can run the code multiple times and see how the estimate varies. If computational power is cheap, you can increase the number of simulations.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">length</span>(<span class="fu">unique</span>(<span class="fu">sample</span>(days,<span class="at">size=</span><span class="dv">18</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>)))) <span class="sc">%&gt;%</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">match=</span><span class="fu">if_else</span>(length<span class="sc">==</span><span class="dv">18</span>,<span class="dv">0</span>,<span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob=</span><span class="fu">mean</span>(match))</span></code></pre></div>
<pre><code>##     prob
## 1 0.3442</code></pre>
</div>
<div id="plotting" class="section level3" number="7.4.3">
<h3><span class="header-section-number">7.4.3</span> Plotting</h3>
<p>By the way, the method we have used to create the data allows us to summarize the number of unique birthdays using a table or bar chart. Let’s do that now. Note that since the first argument in <code>tally()</code> is not data then the <strong>pipe</strong> operator will not work without some extra effort. We must tell <code>R</code> that the data is the previous argument in the pipeline and thus use the symbol <strong>.</strong> to denote this.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">length</span>(<span class="fu">unique</span>(<span class="fu">sample</span>(days,<span class="at">size=</span><span class="dv">18</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>)))) <span class="sc">%&gt;%</span></span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tally</span>(<span class="sc">~</span>length,<span class="at">data=</span>.)</span></code></pre></div>
<pre><code>## length
##  14  15  16  17  18 
##   1   7  52 253 687</code></pre>
<p>Figure @ref(fig:bar71-fig) is a plot of the number of unique birthdays in our sample.</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">length</span>(<span class="fu">unique</span>(<span class="fu">sample</span>(days,<span class="at">size=</span><span class="dv">18</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>)))) <span class="sc">%&gt;%</span></span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_bar</span>(<span class="sc">~</span>length) <span class="sc">%&gt;%</span></span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Number of unique birthdays&quot;</span>,<span class="at">y=</span><span class="st">&quot;Count&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="07-Probability-Case-Study_files/figure-html/bar71-fig-1.png" alt="Bar chart of the number of unique birthdays in the sample." width="672" />
<p class="caption">
(#fig:bar71-fig)Bar chart of the number of unique birthdays in the sample.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
What does it mean if the length of unique birthdays is 16, in terms of matches?<a href="#fn64" class="footnote-ref" id="fnref64"><sup>64</sup></a></p>
</blockquote>
</div>
<div id="mathematical-solution" class="section level3" number="7.4.4">
<h3><span class="header-section-number">7.4.4</span> Mathematical solution</h3>
<p>To solve this problem mathematically, we will step through the logic one step at a time. One of the key ideas that we will see many times is the idea of the <strong>multiplication</strong> rule. This idea is the foundation for <strong>permutation</strong> and <strong>combinations</strong> which are counting methods frequently used in probability calculations.</p>
<p>The first step that we take is to understand the idea of 2 or more people with the same birthday. With 18 people, there are a great deal of possibilities for 2 or more birthdays. We could have exactly 2 people with the same birthday. We could have 18 people with the same birthday, We could have 3 people with the same birthday and another 2 people with the same birthday but different from the other 3. Accounting for all these possibilities is too large a counting process. Instead, we will take the approach of finding the probability of no one having a matching birthday. Then the probability of at least 2 people having a matching birthday is 1 minus the probability that no one has a matching birthday. This is known as a <strong>complementary</strong> probability. A simpler example is to think about rolling a single die. The probability of rolling a 6 is equivalent to 1 minus the probability of not rolling a 6.</p>
<p>We first need to think about all the different ways we could get 18 birthdays. This is going to be our denominator in the probability calculation. First let’s just look at 2 people. The first person could have 365 different days for their birthday. The second person could also have 365 different birthdays. So for each birthday of the first person there could be 365 birthdays for the second. Thus for 2 people there are <span class="math inline">\(365^2\)</span> possible sets of birthdays. This is an example of the <em>multiplication rule</em>. For 18 people there are <span class="math inline">\(365^{18}\)</span> sets of birthdays. That is a large number. Again, this will be our denominator in calculating the probability.</p>
<p>The numerator is the number of sets of birthdays with no matches. Again, let’s consider 2 people. The first person can have a birthday on any day of the year, so 365 possibilities. Since we don’t want a match, the second person can only have 364 possibilities for a birthday. Thus we have <span class="math inline">\(365 \times 364\)</span> possibilities for two people to have different birthdays.</p>
<blockquote>
<p>Exercise:<br />
What is the number of possibilities for 18 people so that no one has the same birthday.</p>
</blockquote>
<p>The answer for 18 people is <span class="math inline">\(365 \times 364 \times 363 ... \times 349 \times 348\)</span>. This looks like a truncated factorial. Remember a factorial, written as <span class="math inline">\(n!\)</span> with an explanation point, is the product of successive positive integers. As an example <span class="math inline">\(3!\)</span> is <span class="math inline">\(3 \times 2 \times 1\)</span> or 6. We could write the multiplication for the numerator as <span class="math display">\[\frac{365!}{(365-n)!}\]</span> As we will learn, the multiplication rule for the numerator is known as a <strong>permutation</strong>.</p>
<p>We are ready to put it all together. For 18 people, the probability of 2 or more people with the same birthday is 1 minus the probability that no one has the same birthday, which is</p>
<p><span class="math display">\[1 - \frac{\frac{365!}{(365-18)!}}{365^{18}}\]</span> or</p>
<p><span class="math display">\[1 - \frac{\frac{365!}{347!}}{365^{18}}\]</span></p>
<p>In <code>R</code> there is a function called <code>factorial()</code> but factorials get large fast and we will <strong>overflow</strong> the memory. Try <code>factorial(365)</code> in <code>R</code> to see what happens.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">factorial</span>(<span class="dv">365</span>)</span></code></pre></div>
<pre><code>## [1] Inf</code></pre>
<p>It is returning <em>infinity</em> because the number is too large for the buffer. As is often the case we will have when using a computational method, we must be clever about our approach. Instead of using factorials we can make use of <code>R</code>s ability to work on vectors. If we provide <code>R</code> with a vector of values, the <code>prod()</code> will perform a product of all the elements.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="dv">365</span><span class="sc">*</span><span class="dv">364</span></span></code></pre></div>
<pre><code>## [1] 132860</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="dv">365</span><span class="sc">:</span><span class="dv">364</span>)</span></code></pre></div>
<pre><code>## [1] 132860</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span> <span class="fu">prod</span>(<span class="dv">365</span><span class="sc">:</span><span class="dv">348</span>)<span class="sc">/</span>(<span class="dv">365</span><span class="sc">^</span><span class="dv">18</span>)</span></code></pre></div>
<pre><code>## [1] 0.3469114</code></pre>
</div>
<div id="general-solution" class="section level3" number="7.4.5">
<h3><span class="header-section-number">7.4.5</span> General solution</h3>
<p>We now have the mathematics to understand the problem. We can easily generalize this to any number of people. To do this, we have to write a function in <code>R</code>. As with everything in <code>R</code>, we save a function as an object. The general format for creating a function is</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>my_function <span class="ot">&lt;-</span> <span class="cf">function</span>(parameters){</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>  code <span class="cf">for</span> <span class="cf">function</span></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>For this problem we will call the function <code>birthday_prob()</code>. The only parameter we need is the number of people in the room, <code>n</code>. Let’s write this function.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>birthday_prob <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">n=</span><span class="dv">20</span>){</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span><span class="sc">-</span> <span class="fu">prod</span>(<span class="dv">365</span><span class="sc">:</span>(<span class="dv">365</span><span class="sc">-</span>(n<span class="dv">-1</span>)))<span class="sc">/</span>(<span class="dv">365</span><span class="sc">^</span>n)</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Notice we assigned the function to the name <code>birthday_prob</code>, we told <code>R</code> to expect one argument to the function, which we are calling <code>n</code>, and then we provide <code>R</code> with the code to find the probability. We set a default value for <code>n</code> in case one is not provided to prevent an error when the function is run. We will learn more about writing functions over this and the next semester.</p>
<p>Test the code with a know answer.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="fu">birthday_prob</span>(<span class="dv">18</span>)</span></code></pre></div>
<pre><code>## [1] 0.3469114</code></pre>
<p>Now we can determine the probability for any size room. You may have heard that it only takes about 23 people in a room to have a 50% probability of at least 2 people matching birthdays.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">birthday_prob</span>(<span class="dv">23</span>)</span></code></pre></div>
<pre><code>## [1] 0.5072972</code></pre>
<p>Let’s create a plot of the probability versus number of people in the room. To do this, we need to apply the function to a vector of values. The function <code>sapply()</code> will work or we can also use <code>Vectorize()</code> to alter our existing function. We choose the latter option.</p>
<p>First notice what happens if we input a vector into our function.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">birthday_prob</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span></code></pre></div>
<pre><code>## Warning in 365:(365 - (n - 1)): numerical expression has 20 elements: only the
## first used</code></pre>
<pre><code>##  [1] 0.0000000 0.9972603 0.9999925 1.0000000 1.0000000 1.0000000 1.0000000
##  [8] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
## [15] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000</code></pre>
<p>It only uses the first value. There are several ways to solve this problem. We can use the <code>map()</code> function in the <strong>purrr</strong> package. This idea of mapping a function to a vector is important in data science. It is used in scenarios where there is a lot of data. In this case the idea of map-reduce is used to make the analysis amenable to parallel computing.</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="fu">map_dbl</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>,birthday_prob)</span></code></pre></div>
<pre><code>##  [1] 0.000000000 0.002739726 0.008204166 0.016355912 0.027135574 0.040462484
##  [7] 0.056235703 0.074335292 0.094623834 0.116948178 0.141141378 0.167024789
## [13] 0.194410275 0.223102512 0.252901320 0.283604005 0.315007665 0.346911418
## [19] 0.379118526 0.411438384</code></pre>
<p>We could also just vectorize the function.</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>birthday_prob <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(birthday_prob)</span></code></pre></div>
<p>Now notice what happens.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="fu">birthday_prob</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)</span></code></pre></div>
<pre><code>##  [1] 0.000000000 0.002739726 0.008204166 0.016355912 0.027135574 0.040462484
##  [7] 0.056235703 0.074335292 0.094623834 0.116948178 0.141141378 0.167024789
## [13] 0.194410275 0.223102512 0.252901320 0.283604005 0.315007665 0.346911418
## [19] 0.379118526 0.411438384</code></pre>
<p>We are good to go. Let’s create our line plot, Figure @ref(fig:line71-fig).</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_line</span>(<span class="fu">birthday_prob</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>)<span class="sc">~</span> <span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">100</span>),</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">&quot;Number of People&quot;</span>,</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab=</span><span class="st">&quot;Probability of Match&quot;</span>,</span>
<span id="cb156-4"><a href="#cb156-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">title=</span><span class="st">&quot;Probability of at least 2 people with matching birthdays&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb156-5"><a href="#cb156-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="07-Probability-Case-Study_files/figure-html/line71-fig-1.png" alt="The probability of at least 2 people having mathcing birthdays" width="672" />
<p class="caption">
(#fig:line71-fig)The probability of at least 2 people having mathcing birthdays
</p>
</div>
<p>Is this what you expected the curve to look like? We, the authors, did not expect this. It has a sigmodial shape with a large increase in the middle range and flatten in the tails.</p>
</div>
<div id="data-science-approach" class="section level3" number="7.4.6">
<h3><span class="header-section-number">7.4.6</span> Data science approach</h3>
<p>The final approach we will take is one based on data, a data science approach. In the <strong>mosaicData</strong> package is a data set called <code>Births</code> that contains the number of births in the US from 1969 to 1988. This data will allow us to estimate the number of births on any day of the year. This allows us to eliminate the reliance on the assumption that each day is equally likely. Let’s first <code>inspect()</code> the data object.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(Births)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##   name   class levels    n missing
## 1 wday ordered      7 7305       0
##                                    distribution
## 1 Wed (14.3%), Thu (14.3%), Fri (14.3%) ...    
## 
## Date variables:  
##   name class      first       last min_diff max_diff    n missing
## 1 date  Date 1969-01-01 1988-12-31   1 days   1 days 7305       0
## 
## quantitative variables:  
##              name   class  min   Q1 median    Q3   max        mean          sd
## ...1       births integer 6675 8792   9622 10510 12851 9648.940178 1127.315229
## ...2         year integer 1969 1974   1979  1984  1988 1978.501027    5.766735
## ...3        month integer    1    4      7    10    12    6.522930    3.448939
## ...4  day_of_year integer    1   93    184   275   366  183.753593  105.621885
## ...5 day_of_month integer    1    8     16    23    31   15.729637    8.800694
## ...6  day_of_week integer    1    2      4     6     7    4.000274    1.999795
##         n missing
## ...1 7305       0
## ...2 7305       0
## ...3 7305       0
## ...4 7305       0
## ...5 7305       0
## ...6 7305       0</code></pre>
<p>It could be argued that we could randomly pick one year and use it. Let’s see what happens if we just used 1969. Figure @ref(fig:scat71-fig) is a scatter plot of the number of births in 1969 for each day of the year.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>Births <span class="sc">%&gt;%</span></span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">1969</span>) <span class="sc">%&gt;%</span></span>
<span id="cb159-3"><a href="#cb159-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(births<span class="sc">~</span>day_of_year) <span class="sc">%&gt;%</span></span>
<span id="cb159-4"><a href="#cb159-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb159-5"><a href="#cb159-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Day of the Year&quot;</span>,<span class="at">y=</span><span class="st">&quot;Number of Births&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="07-Probability-Case-Study_files/figure-html/scat71-fig-1.png" alt="The number of births for each day of the year in 1969" width="672" />
<p class="caption">
(#fig:scat71-fig)The number of births for each day of the year in 1969
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
What patterns do you see in Figure @ref(fig:scat71-fig)? What might explain them?</p>
</blockquote>
<p>There are definitely bands appearing in the data which could be the day of the week; there are less birthdays on the weekend. There is also seasonality with more birthdays in the summer and fall. There is also probably an impact from holidays.</p>
<p>Quickly, let’s look at the impact of day of the week by using color for day of the week. Figure @ref(fig:scat72-fig) makes it clear that the weekends have less number of births as compared to the work week.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>Births <span class="sc">%&gt;%</span></span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">1969</span>) <span class="sc">%&gt;%</span></span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(births<span class="sc">~</span>day_of_year,<span class="at">color=</span><span class="sc">~</span><span class="fu">factor</span>(day_of_week)) <span class="sc">%&gt;%</span></span>
<span id="cb160-4"><a href="#cb160-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Day of the Year&quot;</span>,<span class="at">col=</span><span class="st">&quot;Day of Week&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb160-5"><a href="#cb160-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="07-Probability-Case-Study_files/figure-html/scat72-fig-1.png" alt="The number of births for each day of the year in 1969 broken down by day of the week" width="672" />
<p class="caption">
(#fig:scat72-fig)The number of births for each day of the year in 1969 broken down by day of the week
</p>
</div>
<p>By only using one year, this data might give poor results since holidays will fall on certain days of the week and the weekends will also be impacted. Note that we also still have the problem of leap years.</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>Births <span class="sc">%&gt;%</span></span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(year) <span class="sc">%&gt;%</span></span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">n=</span><span class="fu">n</span>())</span></code></pre></div>
<pre><code>## # A tibble: 20 x 2
##     year     n
##    &lt;int&gt; &lt;int&gt;
##  1  1969   365
##  2  1970   365
##  3  1971   365
##  4  1972   366
##  5  1973   365
##  6  1974   365
##  7  1975   365
##  8  1976   366
##  9  1977   365
## 10  1978   365
## 11  1979   365
## 12  1980   366
## 13  1981   365
## 14  1982   365
## 15  1983   365
## 16  1984   366
## 17  1985   365
## 18  1986   365
## 19  1987   365
## 20  1988   366</code></pre>
<p>The years 1972, 1976, 1980, 1984, and 1988 are all leap years. At this point, to make the analysis easier, we will drop those years.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>Births <span class="sc">%&gt;%</span></span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span>(year <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1972</span>,<span class="dv">1976</span>,<span class="dv">1980</span>,<span class="dv">1984</span>,<span class="dv">1988</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(year) <span class="sc">%&gt;%</span></span>
<span id="cb163-4"><a href="#cb163-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">n=</span><span class="fu">n</span>())</span></code></pre></div>
<pre><code>## # A tibble: 15 x 2
##     year     n
##    &lt;int&gt; &lt;int&gt;
##  1  1969   365
##  2  1970   365
##  3  1971   365
##  4  1973   365
##  5  1974   365
##  6  1975   365
##  7  1977   365
##  8  1978   365
##  9  1979   365
## 10  1981   365
## 11  1982   365
## 12  1983   365
## 13  1985   365
## 14  1986   365
## 15  1987   365</code></pre>
<p>Notice in <code>filter()</code> we used the <code>%in%</code> argument. This is a <strong>logical</strong> argument checking if <code>year</code> is one of the values. The <code>!</code> at the front negates this in a sense requiring <code>year</code> not to be one of those values.`</p>
<p>We are almost ready to simulate. We need to get the count of <code>births</code> on each day of the year for the non-leap years.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>birth_data <span class="ot">&lt;-</span> Births <span class="sc">%&gt;%</span></span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span>(year <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1972</span>,<span class="dv">1976</span>,<span class="dv">1980</span>,<span class="dv">1984</span>,<span class="dv">1988</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(day_of_year) <span class="sc">%&gt;%</span></span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">n=</span><span class="fu">sum</span>(births)) </span></code></pre></div>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(birth_data)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   day_of_year      n
##         &lt;int&gt;  &lt;int&gt;
## 1           1 120635
## 2           2 129042
## 3           3 135901
## 4           4 136298
## 5           5 137319
## 6           6 140044</code></pre>
<p>Let’s look at a plot of the number of births versus day of the year. We combined years in Figure @ref(fig:scat73-fig).</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>birth_data <span class="sc">%&gt;%</span></span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(n<span class="sc">~</span>day_of_year,</span>
<span id="cb168-3"><a href="#cb168-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">xlab=</span><span class="st">&quot;Day of the year&quot;</span>,</span>
<span id="cb168-4"><a href="#cb168-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">ylab=</span><span class="st">&quot;Number of births&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb168-5"><a href="#cb168-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="07-Probability-Case-Study_files/figure-html/scat73-fig-1.png" alt="Number of births by day of the year for all years." width="672" />
<p class="caption">
(#fig:scat73-fig)Number of births by day of the year for all years.
</p>
</div>
<p>This curve has the seasonal cycling we would expect. The smaller scale cycling is unexpected. Maybe because we are dropping the leap years, we are getting some days appearing in our time interval more frequently on weekends. We leave it to you to investigate this phenomenon.</p>
<p>We use these counts as weights in a sampling process. Days with more births will have a higher probability of being selected. Days such as Christmas and Christmas Eve have a lower probability of being selected. Let’s save the weights in an object to use in the <code>sample()</code> function.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>birth_data_weights <span class="ot">&lt;-</span> birth_data <span class="sc">%&gt;%</span></span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(n) <span class="sc">%&gt;%</span></span>
<span id="cb169-3"><a href="#cb169-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>()</span></code></pre></div>
<p>The <code>pull()</code> function pulls the vectors of values out of the data frame format into a vector format which the <code>sample()</code> needs.</p>
<p>Now let’s simulate the problem. The probability of a match should change slightly, maybe go down slightly?, but not much since most of the days have about the same probability or number of occurrences.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20</span>)</span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a>(<span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">length</span>(<span class="fu">unique</span>(<span class="fu">sample</span>(days,<span class="at">size=</span><span class="dv">18</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>,<span class="at">prob=</span>birth_data_weights)))) <span class="sc">%&gt;%</span></span>
<span id="cb170-3"><a href="#cb170-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">match=</span><span class="fu">if_else</span>(length<span class="sc">==</span><span class="dv">18</span>,<span class="dv">0</span>,<span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb170-4"><a href="#cb170-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">prob=</span><span class="fu">mean</span>(match))</span></code></pre></div>
<pre><code>##    prob
## 1 0.352</code></pre>
<p>We could not solve this problem of varying frequency of birth days using mathematics, at least as far as we know.</p>
<p>Cool stuff, let’s get to learning more about probability models in the next chapters.</p>
</div>
</div>
<div id="homework-problems-6" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li><strong>Exactly 2 people with the same birthday - Simulation</strong>. Complete a similar analysis for case where exactly 2 people in a room of 23 people have the same birthday. In this exercise you will use a computational simulation.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Create a new R Markdown file and create a report. Yes, we know you could use this file but we want you to practice generating your own report.<br />
</li>
<li>Simulate having 23 people in the class with each day of the year equally likely. Find the cases where exactly 2 people have the same birthday, you will have to alter the code from the Notes more than changing 18 to 23.<br />
</li>
<li>Plot the frequency of occurrences as a bar chart.<br />
</li>
<li>Estimate the probability of exactly two people having the same birthday.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><strong>Exactly 2 people with the same birthday - Mathematical</strong>. Repeat problem 1 but do it mathematically. As a big hint, you will need to use the <code>choose()</code> function. The idea is that with 23 people we need to choose 2 of them to match. We thus need to multiply, the multiplication rule again, by <code>choose(23,2)</code>. If you are having trouble, work with a total of 3 people in the room first.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Find a formula to determine the exact probability of exactly 2 people in a room of 23 having the same birthday.<br />
</li>
<li>Generalize your solution to any number <code>n</code> people in the room and create a function.<br />
</li>
<li>Vectorize the function.<br />
</li>
<li>Plot the probability of exactly 2 people having the same birthday versus number of people in the room.<br />
</li>
<li>Comment on the shape of the curve and explain it.</li>
</ol>
<!--chapter:end:07-Probability-Case-Study.Rmd-->
</div>
</div>
<div id="PROBRULES" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Probability Rules</h1>
<div id="objectives-7" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and use properly in context all new terminology related to probability to include but not limited to: outcome, event, sample space, probability.<br />
</li>
<li>Apply basic probability and counting rules to find probabilities.<br />
</li>
<li>Describe the basic axioms of probability.<br />
</li>
<li>Use <code>R</code> to calculate and simulate probabilities of events.</li>
</ol>
</div>
<div id="probability-vs-statistics" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Probability vs Statistics</h2>
<p>As a review, remember this course is divided into four general blocks: data collection/summary, probability models, inference and statistical modeling/prediction. This second block, probability, is the study of stochastic (random) processes and their properties. Specifically, we will explore random experiments. As its name suggests, a random experiment is an experiment whose outcome is not predictable with exact certainty. In the statistical models we develop in the last two blocks of this course, we will use other variables to explain the variance of the outcome of interest. Any remaining variance is modeled with probability models.</p>
<p>Even though an outcome is determined by chance, this does not mean that we know nothing about the random experiment. Our favorite simple example is that of a coin flip. If we flip a coin, the possible outcomes are heads and tails. We don’t know for sure what outcome will occur, but this doesn’t mean we don’t know anything about the experiment. If we assume the coin is fair, we know that each outcome is equally likely. Also, we know that if we flip the coin 100 times (independently), we are likely, the highest frequency event, to see around 50 heads, and very unlikely to see 10 heads or fewer.</p>
<p>It is important to distinguish probability from inference and modeling. In probability, we consider a known random experiment, including knowing the parameters, and answer questions about what we expect to see from this random experiment. In statistics (inference and modeling), we consider data (the results of a mysterious random experiment) and infer about the underlying process. For example, suppose we have a coin and we are unsure whether this coin is fair or unfair, the parameter is unknown. We flipped it 20 times and it landed on heads 14 times. Inferential statistics will help us answer questions about the underlying process (could this coin be unfair?).</p>
<p>This block (9 lessons or so) is devoted to the study of random experiments. First, we will explore simple experiments, counting rule problems, and conditional probability. Next, we will introduce the concept of a random variable and the properties of random variables. Following this, we will cover common distributions of discrete and continuous random variables. We will end the block on multivariate probability (joint distributions and covariance).</p>
</div>
<div id="basic-probability-terms" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Basic probability terms</h2>
<p>We will start our work with some definitions and examples.</p>
<div id="sample-space" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Sample space</h3>
<p>Suppose we have a random experiment. The <em>sample space</em> of this experiment, <span class="math inline">\(S\)</span>, is the set of all possible results of that experiment. For example, in the case of a coin flip, we could write <span class="math inline">\(S=\{H,T\}\)</span>. Each element of the sample space is considered an <em>outcome</em>. An <em>event</em> is a set of outcomes, it is a subset of the sample space.</p>
<blockquote>
<p><em>Example</em>:<br />
Let’s let <code>R</code> flip a coin for us and record the number of heads and tails. We will have <code>R</code> flip the coin twice. What is the sample space, what is an example of an outcome, and what is an example of an event.</p>
</blockquote>
<p>We will load the <strong>mosaic</strong> package as it has a function <code>rflip()</code> that will simulate flipping a coin.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mosaic)</span></code></pre></div>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">18</span>)</span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rflip</span>(<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## 
## Flipping 2 coins [ Prob(Heads) = 0.5 ] ...
## 
## H H
## 
## Number of Heads: 2 [Proportion Heads: 1]</code></pre>
<p>The sample space is <span class="math inline">\(S=\{HH, TH, HT, TT\}\)</span>, an example of an outcome is <span class="math inline">\(HH\)</span> which we see in the output from <code>R</code>, and finally an example of an event is the number of heads, which in this case takes on the values 0, 1, and 2. Another example of an event is “At least one heads”. In this case the event would be <span class="math inline">\(\{HH,TH, HT\}\)</span>. Also notice that <span class="math inline">\(TH\)</span> is different from <span class="math inline">\(HT\)</span> as an outcome; this is because those are different outcomes from flipping a coin twice.</p>
<blockquote>
<p><em>Example of Event</em>:<br />
Suppose you arrive at a rental car counter and they show you a list of available vehicles, and one is picked for you at random. The sample space in this experiment is
<span class="math display">\[
S=\{\mbox{red sedan}, \mbox{blue sedan}, \mbox{red truck}, \mbox{grey truck}, \mbox{grey SUV}, \mbox{black SUV}, \mbox{blue SUV}\}.
\]</span></p>
</blockquote>
<p>Each vehicle represents a possible outcome of the experiment. Let <span class="math inline">\(A\)</span> be the event that a blue vehicle is selected. This event contains the outcomes <code>blue sedan</code> and <code>blue SUV</code>.</p>
</div>
<div id="union-and-intersection" class="section level3" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Union and intersection</h3>
<p>Suppose we have two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(A\)</span> is considered a <em>subset</em> of <span class="math inline">\(B\)</span> if all of the outcomes of <span class="math inline">\(A\)</span> are also contained in <span class="math inline">\(B\)</span>. This is denoted as <span class="math inline">\(A \subset B\)</span>.</p></li>
<li><p>The <em>intersection</em> of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is all of the outcomes contained in both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. This is denoted as <span class="math inline">\(A \cap B\)</span>.</p></li>
<li><p>The <em>union</em> of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is all of the outcomes contained in either <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>, or both. This is denoted as <span class="math inline">\(A \cup B\)</span>.</p></li>
<li><p>The <em>complement</em> of <span class="math inline">\(A\)</span> is all of the outcomes not contained in <span class="math inline">\(A\)</span>. This is denoted as <span class="math inline">\(A^C\)</span> or <span class="math inline">\(A&#39;\)</span>.</p></li>
</ol>
<p>Note: Here we are treating events as sets and the above definitions are basic set operations.</p>
<p>It is sometimes helpful when reading probability notation to think of Union as an <em>or</em> and Intersection as an <em>and</em>.</p>
<blockquote>
<p><em>Example</em>:<br />
Consider our rental car example above. Let <span class="math inline">\(A\)</span> be the event that a blue vehicle is selected, let <span class="math inline">\(B\)</span> be the event that a black vehicle is selected, and let <span class="math inline">\(C\)</span> be the event that an SUV is selected.</p>
</blockquote>
<p>First, let’s list all of the outcomes of each event. <span class="math inline">\(A = \{\mbox{blue sedan},\mbox{blue SUV}\}\)</span>, <span class="math inline">\(B=\{\mbox{black SUV}\}\)</span>, and <span class="math inline">\(C= \{\mbox{grey SUV}, \mbox{black SUV}, \mbox{blue SUV}\}\)</span>.</p>
<p>Since all outcomes in <span class="math inline">\(B\)</span> are contained in <span class="math inline">\(C\)</span>, we know that <span class="math inline">\(B\)</span> is a subset of <span class="math inline">\(C\)</span>, or <span class="math inline">\(B\subset C\)</span>. Also, since <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have no outcomes in common, <span class="math inline">\(A \cap B = \emptyset\)</span>. Note that <span class="math inline">\(\emptyset = \{ \}\)</span> is the empty set and contains no elements. Further, <span class="math inline">\(A \cup C = \{\mbox{blue sedan}, \mbox{grey SUV}, \mbox{black SUV}, \mbox{blue SUV}\}\)</span>.</p>
</div>
</div>
<div id="probability" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Probability</h2>
<p><em>Probability</em> is a number assigned to an event or outcome that describes how likely it is to occur. A probability model assigns a probability to each element of the sample space. What makes a probability model is not just the values assigned to each element but the idea this model contains all the information about the outcomes and there are no other explanatory variables involved.</p>
<p>A probability model can be thought of as a function that maps outcomes, or events, to a real number in the interval <span class="math inline">\([0,1]\)</span>.</p>
<p>There are some basic axioms of probability you should know, although this list is not complete. Let <span class="math inline">\(S\)</span> be the sample space of a random experiment and let <span class="math inline">\(A\)</span> be an event where <span class="math inline">\(A\subset S\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mbox{P}(A) \geq 0\)</span>.</p></li>
<li><p><span class="math inline">\(\mbox{P}(S) = 1\)</span>.</p></li>
</ol>
<p>These two axioms essentially say that probability must be positive, and the probability of all outcomes must sum to 1.</p>
<div id="probability-properties" class="section level3" number="8.4.1">
<h3><span class="header-section-number">8.4.1</span> Probability properties</h3>
<p>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be events in a random experiment. Most of these can be proven fairly easily.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mbox{P}(\emptyset)=0\)</span></p></li>
<li><p><span class="math inline">\(\mbox{P}(A&#39;)=1-\mbox{P}(A)\)</span> We used this in the case study.</p></li>
<li><p>If <span class="math inline">\(A\subset B\)</span>, then <span class="math inline">\(\mbox{P}(A)\leq \mbox{P}(B)\)</span>.</p></li>
<li><p><span class="math inline">\(\mbox{P}(A\cup B) = \mbox{P}(A)+\mbox{P}(B)-\mbox{P}(A\cap B)\)</span>. This property can be generalized to more than two events. The intersection is subtracted because outcomes in both events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> get counted twice in the first sum.</p></li>
<li><p>Law of Total Probability: Let <span class="math inline">\(B_1, B_2,...,B_n\)</span> be <strong>mutually exclusive</strong>, this means disjoint or no outcomes in common, and <strong>exhaustive</strong>, this means the union of all the events labeled with a <span class="math inline">\(B\)</span> is the sample space. Then</p></li>
</ol>
<p><span class="math display">\[
\mbox{P}(A)=\mbox{P}(A\cap B_1)+\mbox{P}(A\cap B_2)+...+\mbox{P}(A\cap B_n)
\]</span></p>
<p>A specific application of this law appears in Bayes’ Rule (more to follow). It says that <span class="math inline">\(\mbox{P}(A)=\mbox{P}(A \cap B)+\mbox{P}(A \cap B&#39;)\)</span>. Essentially, it points out that <span class="math inline">\(A\)</span> can be partitioned into two parts: 1) everything in <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> and 2) everything in <span class="math inline">\(A\)</span> and not in <span class="math inline">\(B\)</span>.</p>
<blockquote>
<p><em>Example</em>:<br />
Consider rolling a six sided die. Let event <span class="math inline">\(A\)</span> be the number showing is less than 5. Let event <span class="math inline">\(B\)</span> be the number is even. Then</p>
</blockquote>
<p><span class="math display">\[\mbox{P}(A)=\mbox{P}(A \cap B) + \mbox{P}(A \cap B&#39;)\]</span></p>
<p><span class="math display">\[
\mbox{P}(&lt; 5)=\mbox{P}(&lt;5 \cap Even)+\mbox{P}(&lt;5 \cap Odd)
\]</span></p>
<ol start="6" style="list-style-type: decimal">
<li>DeMorgan’s Laws:
<span class="math display">\[
\mbox{P}((A \cup B)&#39;)=\mbox{P}(A&#39; \cap B&#39;)
\]</span>
<span class="math display">\[
\mbox{P}((A \cap B)&#39;)=\mbox{P}(A&#39; \cup B&#39;)
\]</span></li>
</ol>
</div>
<div id="equally-likely-scenarios" class="section level3" number="8.4.2">
<h3><span class="header-section-number">8.4.2</span> Equally likely scenarios</h3>
<p>In some random experiments, outcomes can be defined such that each individual outcome is equally likely. In this case, probability becomes a counting problem. Let <span class="math inline">\(A\)</span> be an event in an experiment where each outcome is equally likely.
<span class="math display">\[
\mbox{P}(A)=\frac{\mbox{# of outcomes in A}}{\mbox{# of outcomes in S}}
\]</span></p>
<blockquote>
<p><em>Example</em>:<br />
Suppose a family has three children, with each child being either a boy (B) or girl (G). Assume that the likelihood of boys and girls are equal and <strong>independent</strong>, this is the idea that the probability of the gender of the second child does not change based on the gender of the first child. The sample space can be written as:
<span class="math display">\[
S=\{\mbox{BBB},\mbox{BBG},\mbox{BGB},\mbox{BGG},\mbox{GBB},\mbox{GBG},\mbox{GGB},\mbox{GGG}\}
\]</span>
What is the probability that the family has exactly 2 girls?</p>
</blockquote>
<p>This only happens in three ways: BGG, GBG, and GGB. Thus, the probability of exactly 2 girls is 3/8 or 0.375.</p>
</div>
<div id="using-r-equally-likely-scenarios" class="section level3" number="8.4.3">
<h3><span class="header-section-number">8.4.3</span> Using <code>R</code> (Equally likely scenarios)</h3>
<p>The previous example above is an example of an “Equally Likely” scenario, where the sample space of a random experiment contains a list of outcomes that are equally likely. In these cases, we can sometimes use <code>R</code> to list out the possible outcomes and count them to determine probability. We can also use <code>R</code> to simulate.</p>
<blockquote>
<p><em>Example</em>:<br />
Use <code>R</code> to simulate the family of three children where each child has the same probability of being a boy or a girl.</p>
</blockquote>
<p>Instead of writing our own function, we can use <code>rflip()</code> in the <strong>mosaic</strong> package. We will let <span class="math inline">\(H\)</span> stand for girl.</p>
<p>First simulate one family.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">73</span>)</span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rflip</span>(<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## 
## Flipping 3 coins [ Prob(Heads) = 0.5 ] ...
## 
## T T H
## 
## Number of Heads: 1 [Proportion Heads: 0.333333333333333]</code></pre>
<p>In this case we got 1 girl. Next we will use the <code>do()</code> function to repeat this simulation.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">rflip</span>(<span class="dv">3</span>)</span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##   n heads tails      prop
## 1 3     1     2 0.3333333
## 2 3     3     0 1.0000000
## 3 3     3     0 1.0000000
## 4 3     3     0 1.0000000
## 5 3     1     2 0.3333333
## 6 3     1     2 0.3333333</code></pre>
<p>Next we can visualize the distribution of the number of girls, heads, in Figure @ref(fig:bar81-fig).</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_bar</span>(<span class="sc">~</span>heads) <span class="sc">%&gt;%</span></span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb179-4"><a href="#cb179-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;NUmber of girls&quot;</span>,<span class="at">y=</span><span class="st">&quot;Count&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="08-Probability-Rules_files/figure-html/bar81-fig-1.png" alt="Number of girls in a family of size 3." width="672" />
<p class="caption">
(#fig:bar81-fig)Number of girls in a family of size 3.
</p>
</div>
<p>Finally we can estimate the probability of exactly 2 girls. We need the <strong>tidyverse</strong> library.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(heads<span class="sc">==</span><span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob=</span><span class="fu">n</span>()<span class="sc">/</span><span class="dv">10000</span>)</span></code></pre></div>
<pre><code>##     prob
## 1 0.3782</code></pre>
<p>Or slightly different code.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(heads) <span class="sc">%&gt;%</span></span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prop=</span>n<span class="sc">/</span><span class="fu">sum</span>(n))</span></code></pre></div>
<pre><code>##   heads    n   prop
## 1     0 1241 0.1241
## 2     1 3786 0.3786
## 3     2 3782 0.3782
## 4     3 1191 0.1191</code></pre>
<p>Not a bad estimate of the exact probability.</p>
<p>Let’s now use an example of cards to simulate some probabilities as well as learning more about counting. The file <code>Cards.csv</code> contains the data for cards from a 52 card deck. Let’s read it in and summarize.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>Cards <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/Cards.csv&quot;</span>)</span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(Cards)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##   name     class levels  n missing
## 1 rank character     13 52       0
## 2 suit character      4 52       0
##                                    distribution
## 1 10 (7.7%), 2 (7.7%), 3 (7.7%) ...            
## 2 Club (25%), Diamond (25%) ...                
## 
## quantitative variables:  
##       name   class        min         Q1     median         Q3        max
## ...1 probs numeric 0.01923077 0.01923077 0.01923077 0.01923077 0.01923077
##            mean sd  n missing
## ...1 0.01923077  0 52       0</code></pre>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Cards)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 3
##   rank  suit   probs
##   &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;
## 1 2     Club  0.0192
## 2 3     Club  0.0192
## 3 4     Club  0.0192
## 4 5     Club  0.0192
## 5 6     Club  0.0192
## 6 7     Club  0.0192</code></pre>
<p>We can see 4 suits, and 13 ranks, the value on the face of the card.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose we draw one card out of a standard deck. Let <span class="math inline">\(A\)</span> be the event that we draw a Club. Let <span class="math inline">\(B\)</span> be the event that we draw a 10 or a face card (Jack, Queen, King or Ace). We can use <code>R</code> to define these events and find probabilities.</p>
</blockquote>
<p>Let’s find all the Clubs.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>Cards <span class="sc">%&gt;%</span></span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(suit <span class="sc">==</span> <span class="st">&quot;Club&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(rank,suit)</span></code></pre></div>
<pre><code>## # A tibble: 13 x 2
##    rank  suit 
##    &lt;chr&gt; &lt;chr&gt;
##  1 2     Club 
##  2 3     Club 
##  3 4     Club 
##  4 5     Club 
##  5 6     Club 
##  6 7     Club 
##  7 8     Club 
##  8 9     Club 
##  9 10    Club 
## 10 J     Club 
## 11 Q     Club 
## 12 K     Club 
## 13 A     Club</code></pre>
<p>So just by counting, we find the probability of drawing a Club is <span class="math inline">\(\frac{13}{52}\)</span> or 0.25.</p>
<p>We can do this by simulation, this is over kill but gets the idea of simulation across.</p>
<p>Remember, ask what do we want <code>R</code> to do and what does <code>R</code> need to do this?</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">sample</span>(Cards,<span class="dv">1</span>)</span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   rank  suit   probs orig.id  .row .index
##   &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;int&gt;  &lt;dbl&gt;
## 1 9     Spade 0.0192 47          1      1
## 2 5     Club  0.0192 4           1      2
## 3 5     Spade 0.0192 43          1      3
## 4 7     Heart 0.0192 32          1      4
## 5 4     Club  0.0192 3           1      5
## 6 A     Spade 0.0192 52          1      6</code></pre>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb193-2"><a href="#cb193-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(suit <span class="sc">==</span> <span class="st">&quot;Club&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb193-3"><a href="#cb193-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob=</span><span class="fu">n</span>()<span class="sc">/</span><span class="dv">10000</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    prob
##   &lt;dbl&gt;
## 1 0.243</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(suit) <span class="sc">%&gt;%</span></span>
<span id="cb195-3"><a href="#cb195-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prob=</span>n<span class="sc">/</span><span class="fu">sum</span>(n))</span></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   suit        n  prob
##   &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;
## 1 Club     2432 0.243
## 2 Diamond  2558 0.256
## 3 Heart    2417 0.242
## 4 Spade    2593 0.259</code></pre>
<p>Now let’s count the number of outcomes in <span class="math inline">\(B\)</span>.</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>Cards <span class="sc">%&gt;%</span></span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(rank <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="st">&quot;J&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;K&quot;</span>, <span class="st">&quot;A&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb197-3"><a href="#cb197-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(rank,suit)</span></code></pre></div>
<pre><code>## # A tibble: 20 x 2
##    rank  suit   
##    &lt;chr&gt; &lt;chr&gt;  
##  1 10    Club   
##  2 J     Club   
##  3 Q     Club   
##  4 K     Club   
##  5 A     Club   
##  6 10    Diamond
##  7 J     Diamond
##  8 Q     Diamond
##  9 K     Diamond
## 10 A     Diamond
## 11 10    Heart  
## 12 J     Heart  
## 13 Q     Heart  
## 14 K     Heart  
## 15 A     Heart  
## 16 10    Spade  
## 17 J     Spade  
## 18 Q     Spade  
## 19 K     Spade  
## 20 A     Spade</code></pre>
<p>So just by counting, we find the probability of drawing a 10 or greater is <span class="math inline">\(\frac{20}{52}\)</span> or 0.3846154.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Using simulation to estimate the probability of 10 or higher.</p>
</blockquote>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">sample</span>(Cards,<span class="dv">1</span>)</span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   rank  suit   probs orig.id  .row .index
##   &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;int&gt;  &lt;dbl&gt;
## 1 10    Heart 0.0192 35          1      1
## 2 6     Heart 0.0192 31          1      2
## 3 8     Spade 0.0192 46          1      3
## 4 J     Heart 0.0192 36          1      4
## 5 Q     Spade 0.0192 50          1      5
## 6 10    Club  0.0192 9           1      6</code></pre>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb201-2"><a href="#cb201-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(rank <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="st">&quot;J&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;K&quot;</span>, <span class="st">&quot;A&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb201-3"><a href="#cb201-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob=</span><span class="fu">n</span>()<span class="sc">/</span><span class="dv">10000</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    prob
##   &lt;dbl&gt;
## 1 0.389</code></pre>
<p>Notice that this code is not robust to change the number of simulations. If we change from 10000, then we have to change the denominator in the <code>summarize()</code> function. We can change this by using <code>mutate()</code> instead of <code>filter()</code>.</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb203-2"><a href="#cb203-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">face=</span>rank <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="st">&quot;J&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;K&quot;</span>, <span class="st">&quot;A&quot;</span>))<span class="sc">%&gt;%</span></span>
<span id="cb203-3"><a href="#cb203-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob=</span><span class="fu">mean</span>(face))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    prob
##   &lt;dbl&gt;
## 1 0.389</code></pre>
<p>Notice that in the <code>mutate()</code> function, we are creating a new logical variable called <code>face</code>. This variable takes on the values of TRUE and FALSE. In the next line we use a <code>summarize()</code> command with the function <code>mean()</code>. In <code>R</code> a function that requires numeric input takes a logical variable and converts the TRUE into 1 and the FALSE into 0. Thus the <code>mean()</code> will find the proportion of TRUE values and that is why we report it as a probability.</p>
<p>Next, let’s find a card that is 10 or greater <strong>and</strong> a club.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>Cards <span class="sc">%&gt;%</span></span>
<span id="cb205-2"><a href="#cb205-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(rank <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="st">&quot;J&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;K&quot;</span>, <span class="st">&quot;A&quot;</span>),suit<span class="sc">==</span><span class="st">&quot;Club&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb205-3"><a href="#cb205-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(rank,suit)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   rank  suit 
##   &lt;chr&gt; &lt;chr&gt;
## 1 10    Club 
## 2 J     Club 
## 3 Q     Club 
## 4 K     Club 
## 5 A     Club</code></pre>
<p>We find the probability of drawing a 10 or greater club is <span class="math inline">\(\frac{5}{52}\)</span> or 0.0961538.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Simulate drawing one card and estimate the probability of a club that is 10 or greater.</p>
</blockquote>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb207-2"><a href="#cb207-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">face=</span>(rank <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="st">&quot;J&quot;</span>, <span class="st">&quot;Q&quot;</span>, <span class="st">&quot;K&quot;</span>, <span class="st">&quot;A&quot;</span>))<span class="sc">&amp;</span>(suit<span class="sc">==</span><span class="st">&quot;Club&quot;</span>))<span class="sc">%&gt;%</span></span>
<span id="cb207-3"><a href="#cb207-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prob=</span><span class="fu">mean</span>(face))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##     prob
##    &lt;dbl&gt;
## 1 0.0963</code></pre>
</div>
<div id="note" class="section level3" number="8.4.4">
<h3><span class="header-section-number">8.4.4</span> Note</h3>
<p>We have been using <code>R</code> to count the number of outcomes in an event. This helped us to determine probabilities. We limited the problems to simple ones. In our cards example, it would be more interesting for us to explore more complex events such as drawing 5 cards from a standard deck. Each draw of 5 cards is equally likely, so in order to find the probability of a flush (5 cards of the same suit), we could simply list all the possible flushes and compare that to the sample space. Because of the large number of possible outcomes, this becomes difficult. Thus we need to explore counting rules in more detail to help us solve more complex problems. In this course we will limit our discussion to three basic cases. You should know that there are entire courses on discrete math and counting rules, so we will still be limited in our methods and the type of problems we can solve in this course.</p>
</div>
</div>
<div id="counting-rules" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Counting rules</h2>
<p>There are three types of counting problems we will consider. In each case, the multiplication rule is being used and all that changes is whether an element is allowed to be reused, replacement, and whether the order of selection matters. This latter question is difficult. Each case will be demonstrated with an example.</p>
<div id="multiplication-rule-1-order-matters-sample-with-replacement" class="section level3" number="8.5.1">
<h3><span class="header-section-number">8.5.1</span> Multiplication rule 1: Order matters, sample with replacement</h3>
<p>The multiplication rule is at the center of each of the three methods. In this first case we are using the idea that order matters and items can be reused. Let’s use an example to help.</p>
<blockquote>
<p><em>Example</em>:<br />
A license plate consists of three numeric digits (0-9) followed by three single letters (A-Z). How many possible license plates exist?</p>
</blockquote>
<p>We can divide this problem into two sections. In the numeric section, we are selecting 3 objects from 10, with replacement. This means that a number can be used more than once. Order clearly matters because a license plate starting with “432” is distinct from a license plate starting with “234”. There are <span class="math inline">\(10^3 = 1000\)</span> ways to select the first three digits; 10 for the first, 10 for the second, and 10 for the third. Why do you multiply and not add?<a href="#fn65" class="footnote-ref" id="fnref65"><sup>65</sup></a></p>
<p>In the alphabet section, we are selecting 3 objects from 26, where order matters. Thus, there are <span class="math inline">\(26^3=17576\)</span> ways to select the last three letters of the plate. Combined, there are <span class="math inline">\(10^3 \times 26^3 = 17576000\)</span> ways to select license plates. Visually,
<span class="math display">\[
\underbrace{\underline{\quad 10 \quad }}_\text{number} \times \underbrace{\underline{\quad 10 \quad }}_\text{number} \times \underbrace{\underline{\quad 10 \quad }}_\text{number} \times \underbrace{\underline{\quad 26 \quad }}_\text{letter} \times \underbrace{\underline{\quad 26 \quad }}_\text{letter} \times \underbrace{\underline{\quad 26 \quad }}_\text{letter} = 17,576,000
\]</span></p>
<p>Next we are going to use this new counting method to find a probability.</p>
<blockquote>
<p><em>Exercise</em>:<br />
What is the probability a license plate starts with the number “8” or “0” and ends with the letter “B”?</p>
</blockquote>
<p>In order to find this probability, we simply need to determine the number of ways to select a license plate starting with “8” or “0” and ending with the letter “B”. We can visually represent this event:
<span class="math display">\[
\underbrace{\underline{\quad 2 \quad }}_\text{8 or 0} \times \underbrace{\underline{\quad 10 \quad }}_\text{number} \times \underbrace{\underline{\quad 10 \quad }}_\text{number} \times \underbrace{\underline{\quad 26 \quad }}_\text{letter} \times \underbrace{\underline{\quad 26 \quad }}_\text{letter} \times \underbrace{\underline{\quad 1 \quad }}_\text{B} = 135,200
\]</span></p>
<p>Dividing this number by the total number of possible license plates yields the probability of this event occurring.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>denom<span class="ot">&lt;-</span><span class="dv">10</span><span class="sc">*</span><span class="dv">10</span><span class="sc">*</span><span class="dv">10</span><span class="sc">*</span><span class="dv">26</span><span class="sc">*</span><span class="dv">26</span><span class="sc">*</span><span class="dv">26</span></span>
<span id="cb209-2"><a href="#cb209-2" aria-hidden="true" tabindex="-1"></a>num<span class="ot">&lt;-</span><span class="dv">2</span><span class="sc">*</span><span class="dv">10</span><span class="sc">*</span><span class="dv">10</span><span class="sc">*</span><span class="dv">26</span><span class="sc">*</span><span class="dv">26</span><span class="sc">*</span><span class="dv">1</span></span>
<span id="cb209-3"><a href="#cb209-3" aria-hidden="true" tabindex="-1"></a>num<span class="sc">/</span>denom</span></code></pre></div>
<pre><code>## [1] 0.007692308</code></pre>
<p>The probability of obtaining a license plate starting with “8” or “0” and ending with “B” is 0.0077. Simulating this would be difficult because we would need special functions to check the first number and last letter. This gets into <strong>text mining</strong> an important subject in data science but unfortunately we don’t have much time in this course for the topic.</p>
</div>
<div id="multiplication-rule-2-permutation-order-matters-sampling-without-replacement" class="section level3" number="8.5.2">
<h3><span class="header-section-number">8.5.2</span> Multiplication rule 2 (Permutation): Order Matters, Sampling Without Replacement</h3>
<p>Consider a random experiment where we sample from a group of size <span class="math inline">\(n\)</span>, <strong>without</strong> replacement, and the outcome of the experiment depends on the order of the outcomes. The number of ways to select <span class="math inline">\(k\)</span> objects is given by <span class="math inline">\(n(n-1)(n-2)...(n-k+1)\)</span>. This is known as a permutation and is sometimes written as
<span class="math display">\[
{}_nP_{k} = \frac{n!}{(n-k)!}
\]</span></p>
<p>Recall that <span class="math inline">\(n!\)</span> is read as <span class="math inline">\(n\)</span> factorial and represents the number of ways to arrange <span class="math inline">\(n\)</span> objects.</p>
<blockquote>
<p><em>Example</em>:<br />
Twenty-five friends participate in a Halloween costume party. Three prizes are given during the party: most creative costume, scariest costume, and funniest costume. No one can win more than one prize. How many possible ways can the prizes by distributed?</p>
</blockquote>
<p>There are <span class="math inline">\(k=3\)</span> prizes to be assigned to <span class="math inline">\(n=25\)</span> people. Once someone is selected for a prize, they are removed from the pool of eligibles. In other words, we are sampling without replacement. Also, order matters. For example, if Tom, Mike, and Jane, win most creative, scariest and funniest costume, respectively, this is a different outcome than if Mike won creative, Jane won scariest and Tom won funniest. Thus, the number of ways the prizes can be distributed is given by <span class="math inline">\({}_{25}P_3 = \frac{25!}{22!} = 13,800\)</span>. A more visually pleasing way to express this would be:
<span class="math display">\[
\underbrace{\underline{\quad 25 \quad }}_\text{most creative} \times \underbrace{\underline{\quad 24 \quad }}_\text{scariest} \times \underbrace{\underline{\quad 23 \quad }}_\text{funniest} = 13,800
\]</span></p>
<p>Notice that it is sometime difficult to determine if order matters or not in a problem, but in this example the name of the prize was a hint that indeed order matters.</p>
<p>Let’s use the idea of a permutation to calculate a probability.</p>
<blockquote>
<p><em>Exercise</em>:<br />
Assume that all 25 participants are equally likely to win any one of the three prizes. What is the probability that Tom doesn’t win any of them?</p>
</blockquote>
<p>Just like in the previous probability calculation, we simply need to count the number of ways Tom doesn’t win any prize. In other words, we need to count the number of ways that prizes are distributed without Tom. So, remove Tom from the group of 25 eligible participants. The number of ways Tom doesn’t get a prize is <span class="math inline">\({}_{24}P_3 = \frac{24!}{21!}=12,144\)</span>. Again visually:
<span class="math display">\[
\underbrace{\underline{\quad 24 \quad }}_\text{most creative} \times \underbrace{\underline{\quad 23 \quad }}_\text{scariest} \times \underbrace{\underline{\quad 22 \quad }}_\text{funniest} = 12,144
\]</span></p>
<p>The probability Tom doesn’t get a prize is simply the second number divided by the first:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>denom<span class="ot">&lt;-</span><span class="fu">factorial</span>(<span class="dv">25</span>)<span class="sc">/</span><span class="fu">factorial</span>(<span class="dv">25-3</span>)</span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Or, denom&lt;-25*24*23</span></span>
<span id="cb211-3"><a href="#cb211-3" aria-hidden="true" tabindex="-1"></a>num<span class="ot">&lt;-</span><span class="dv">24</span><span class="sc">*</span><span class="dv">23</span><span class="sc">*</span><span class="dv">22</span></span>
<span id="cb211-4"><a href="#cb211-4" aria-hidden="true" tabindex="-1"></a>num<span class="sc">/</span>denom</span></code></pre></div>
<pre><code>## [1] 0.88</code></pre>
</div>
<div id="multiplication-rule-3-combination-order-does-not-matter-sampling-without-replacement" class="section level3" number="8.5.3">
<h3><span class="header-section-number">8.5.3</span> Multiplication rule 3 (Combination): Order Does Not Matter, Sampling Without Replacement</h3>
<p>Consider a random experiment where we sample from a group of size <span class="math inline">\(n\)</span>, without replacement, and the outcome of the experiment does not depend on the order of the outcomes. The number of ways to select <span class="math inline">\(k\)</span> objects is given by <span class="math inline">\(\frac{n!} {(n-k)!k!}\)</span>. This is known as a combination and is written as:
<span class="math display">\[
\binom{n}{k} = \frac{n!}{(n-k)!k!}
\]</span></p>
<p>This is read as “<span class="math inline">\(n\)</span> choose <span class="math inline">\(k\)</span>”. Take a moment to compare combinations to permutations, discussed in Rule 2. The difference between these two rules is that in a combination, order no longer matters. A combination is equivalent to a permutation divided by <span class="math inline">\(k!\)</span>, the number of ways to arrange the <span class="math inline">\(k\)</span> objects selected.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose we draw 5 cards out of a standard deck (52 cards, no jokers). How many possible 5 card hands are there?</p>
</blockquote>
<p>In this example, order does not matter. I don’t care if I receive 3 jacks then 2 queens or 2 queens then 3 jacks. Either way, it’s the same collection of 5 cards. Also, we are drawing without replacement. Once a card is selected, it cannot be selected again. Thus, the number of ways to select 5 cards is given by:
<span class="math display">\[
\binom{52}{5} = \frac{52!}{(52-5)!5!} = 2,598,960
\]</span></p>
<blockquote>
<p><em>Example</em>:<br />
When drawing 5 cards, what is the probability of drawing a “flush” (5 cards of the same suit)?</p>
</blockquote>
<p>Let’s determine how many ways to draw a flush. There are four suits (clubs, hearts, diamonds and spades). Each suit has 13 cards. We would like to pick 5 of those 13 cards and 0 of the remaining 39. Let’s consider just one of those suits (clubs):
<span class="math display">\[
\mbox{P}(\mbox{5 clubs})=\frac{\binom{13}{5}\binom{39}{0}}{\binom{52}{5}}
\]</span></p>
<p>The second part of the numerator (<span class="math inline">\(\binom{39}{0}\)</span>) isn’t necessary, since it simply represents the number of ways to select 0 objects from a group (1 way), but it helps clearly lay out the events. This brings up the point of what <span class="math inline">\(0!\)</span> equals. By definition it is 1. This allows us to use <span class="math inline">\(0!\)</span> in our work.</p>
<p>Now, we expand this to all four suits by multiplying by 4, or <span class="math inline">\(\binom{4}{1}\)</span> since we are selecting 1 suit out of the 4:
<span class="math display">\[
\mbox{P}(\mbox{flush})=\frac{\binom{4}{1}\binom{13}{5}\binom{39}{0}}{\binom{52}{5}}
\]</span></p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>num<span class="ot">&lt;-</span><span class="dv">4</span><span class="sc">*</span><span class="fu">choose</span>(<span class="dv">13</span>,<span class="dv">5</span>)<span class="sc">*</span><span class="dv">1</span></span>
<span id="cb213-2"><a href="#cb213-2" aria-hidden="true" tabindex="-1"></a>denom<span class="ot">&lt;-</span><span class="fu">choose</span>(<span class="dv">52</span>,<span class="dv">5</span>)</span>
<span id="cb213-3"><a href="#cb213-3" aria-hidden="true" tabindex="-1"></a>num<span class="sc">/</span>denom</span></code></pre></div>
<pre><code>## [1] 0.001980792</code></pre>
<p>There is a probability of 0.0020 of drawing a flush in a draw of 5 cards from a standard deck of cards.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
When drawing 5 cards, what is the probability of drawing a “full house” (3 cards of the same rank and the other 2 of the same rank)?</p>
</blockquote>
<p>This problem uses several ideas from this lesson. We need to pick the rank of the three of a kind. Then pick 3 cards from the 4 possible. Next we pick the rank of the pair from the remaining 12 ranks. Finally pick 2 cards of that rank from the 4 possible.</p>
<p><span class="math display">\[
\mbox{P}(\mbox{full house})=\frac{\binom{13}{1}\binom{4}{3}\binom{12}{1}\binom{4}{2}}{\binom{52}{5}}
\]</span></p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a>num<span class="ot">&lt;-</span><span class="fu">choose</span>(<span class="dv">13</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">choose</span>(<span class="dv">4</span>,<span class="dv">3</span>)<span class="sc">*</span><span class="fu">choose</span>(<span class="dv">12</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">choose</span>(<span class="dv">4</span>,<span class="dv">2</span>)</span>
<span id="cb215-2"><a href="#cb215-2" aria-hidden="true" tabindex="-1"></a>denom<span class="ot">&lt;-</span><span class="fu">choose</span>(<span class="dv">52</span>,<span class="dv">5</span>)</span>
<span id="cb215-3"><a href="#cb215-3" aria-hidden="true" tabindex="-1"></a>num<span class="sc">/</span>denom</span></code></pre></div>
<pre><code>## [1] 0.001440576</code></pre>
<p>Why not use <span class="math inline">\(\binom{13}{2}\)</span> instead of <span class="math inline">\(\binom{13}{1}\binom{12}{1}\)</span>?<a href="#fn66" class="footnote-ref" id="fnref66"><sup>66</sup></a></p>
<p>We have just determined that a full house has a lower probability of occurring than a flush. This is why in gambling, a flush is valued less than a full house.</p>
</div>
</div>
<div id="homework-problems-7" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> be events such that <span class="math inline">\(\mbox{P}(A)=0.5\)</span>, <span class="math inline">\(\mbox{P}(B)=0.3\)</span>, and <span class="math inline">\(\mbox{P}(C)=0.4\)</span>. Also, we know that <span class="math inline">\(\mbox{P}(A \cap B)=0.2\)</span>, <span class="math inline">\(\mbox{P}(B \cap C)=0.12\)</span>, <span class="math inline">\(\mbox{P}(A \cap C)=0.1\)</span>, and <span class="math inline">\(\mbox{P}(A \cap B \cap C)=0.05\)</span>. Find the following:</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\mbox{P}(A\cup B)\)</span><br />
</li>
<li><span class="math inline">\(\mbox{P}(A\cup B \cup C)\)</span><br />
</li>
<li><span class="math inline">\(\mbox{P}(B&#39;\cap C&#39;)\)</span><br />
</li>
<li><span class="math inline">\(\mbox{P}(A\cup (B\cap C))\)</span><br />
</li>
<li><span class="math inline">\(\mbox{P}((A\cup B \cup C)\cap (A\cap B \cap C)&#39;)\)</span></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><p>Consider the example of the family in the reading. What is the probability that the family has at least one boy?</p></li>
<li><p>The Birthday Problem Revisited.</p></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Suppose there are <span class="math inline">\(n=20\)</span> students in a classroom. My birthday, the instructor, is April 3rd. What is the probability that at least one student shares my birthday? Assume only 365 days in a year and assume that all birthdays are equally likely.<br />
</li>
<li>In <code>R</code>, find the probability that at least one other person shares my birthday for each value of <span class="math inline">\(n\)</span> from 1 to 300. Plot these probabilities with <span class="math inline">\(n\)</span> on the <span class="math inline">\(x\)</span>-axis and probability on the <span class="math inline">\(y\)</span>-axis. At what value of <span class="math inline">\(n\)</span> would the probability be at least 50%?</li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Thinking of the cards again. Answer the following questions:</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Define two events that are mutually exclusive.<br />
</li>
<li>Define two events that are independent.<br />
</li>
<li>Define an event and its complement.</li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li>Consider the license plate example from the reading.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>What is the probability that a license plate contains <strong>exactly</strong> one “B”?<br />
</li>
<li>What is the probability that a license plate contains <strong>at least one</strong> “B”?</li>
</ol>
<ol start="6" style="list-style-type: decimal">
<li>Consider the party example in the reading.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Suppose 8 people showed up to the party dressed as zombies. What is the probability that all three awards are won by people dressed as zombies?<br />
</li>
<li>What is the probability that zombies win “most creative” and “funniest” but not “scariest”?</li>
</ol>
<ol start="7" style="list-style-type: decimal">
<li>Consider the cards example from the reading.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>How many ways can we obtain a “two pairs” (2 of one number, 2 of another, and the final different)?<br />
</li>
<li>What is the probability of drawing a “four of a kind” (four cards of the same value)?</li>
</ol>
<ol start="8" style="list-style-type: decimal">
<li>Advanced Question: Consider rolling 5 dice. What is the <strong>probability</strong> of a pour resulting in a full house?</li>
</ol>
<!--chapter:end:08-Probability-Rules.Rmd-->
</div>
</div>
<div id="CONDPROB" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Conditional Probability</h1>
<div id="objectives-8" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define conditional probability and distinguish it from joint probability.<br />
</li>
<li>Find a conditional probability using its definition.<br />
</li>
<li>Using conditional probability, determine whether two events are independent.<br />
</li>
<li>Apply Bayes’ Rule mathematically and via simulation.</li>
</ol>
</div>
<div id="conditional-probability" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Conditional Probability</h2>
<p>So far, we’ve covered the basic axioms of probability, the properties of events (set theory) and counting rules. Another important concept, perhaps one of the most important, is conditional probability. Often, we know a certain event or sequence of events has occurred and we are interested in the probability of another event.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose you arrive at a rental car counter and they show you a list of available vehicles, and one is picked for you at random. The sample space in this experiment is
<span class="math display">\[
S=\{\mbox{red sedan}, \mbox{blue sedan}, \mbox{red truck}, \mbox{grey truck}, \mbox{grey SUV}, \mbox{black SUV}, \mbox{blue SUV}\}.
\]</span></p>
</blockquote>
<blockquote>
<p>What is the probability that a blue vehicle is selected, given a sedan was selected?</p>
</blockquote>
<p>Since we know that a sedan was selected, our sample space has been reduced to just “red sedan” and “blue sedan”. The probability of selecting a blue vehicle out of this sample space is simply 1/2.</p>
<p>In set notation, let <span class="math inline">\(A\)</span> be the event that a blue vehicle is selected. Let <span class="math inline">\(B\)</span> be the event that a sedan is selected. We are looking for <span class="math inline">\(\mbox{P}(A \mbox{ given } B)\)</span>, which is also written as <span class="math inline">\(\mbox{P}(A|B)\)</span>. By definition,
<span class="math display">\[
\mbox{P}(A|B)=\frac{\mbox{P}(A \cap B)}{\mbox{P}(B)}
\]</span></p>
<p>It is important to distinguish between the event <span class="math inline">\(A|B\)</span> and <span class="math inline">\(A \cap B\)</span>. This is a common misunderstanding about probability. <span class="math inline">\(A \cap B\)</span> is the event that an outcome was selected at random from the total sample space, and that outcome was contained in both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. On the other hand, <span class="math inline">\(A|B\)</span> assumes the <span class="math inline">\(B\)</span> has occurred, and an outcome was drawn from the remaining sample space, and that outcome was contained in <span class="math inline">\(A\)</span>.</p>
<p>Another common misunderstanding involves the direction of conditional probability. Specifically, <span class="math inline">\(A|B\)</span> is NOT the same event as <span class="math inline">\(B|A\)</span>. For example, consider a medical test for a disease. The probability that someone tests positive given they had the disease is different than the probability that someone has the disease given they tested positive. We will explore this example further in our Bayes’ Rule section.</p>
</div>
<div id="independence" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Independence</h2>
<p>Two events, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, are said to be independent if the probability of one occurring does not change whether or not the other has occurred. We looked at this last lesson but now we have another way of looking at it using conditional probabilities. For example, let’s say the probability that a randomly selected student has seen the latest superhero movie is 0.55. What if we randomly select a student and we see that he/she is wearing a black backpack? Does that probability change? Likely not, since movie attendance is probably not related to choice of backpack color. These two events are independent.</p>
<p>Mathematically, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are considered independent if and only if
<span class="math display">\[
\mbox{P}(A|B)=\mbox{P}(A)
\]</span></p>
<p><em>Result</em>: <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if and only if
<span class="math display">\[
\mbox{P}(A\cap B)=\mbox{P}(A)\mbox{P}(B)
\]</span></p>
<p>This follows from the definition of conditional probability and from above:
<span class="math display">\[
\mbox{P}(A|B)=\frac{\mbox{P}(A\cap B)}{\mbox{P}(B)}=\mbox{P}(A)
\]</span></p>
<p>Thus, <span class="math inline">\(\mbox{P}(A\cap B)=\mbox{P}(A)\mbox{P}(B)\)</span>.</p>
<blockquote>
<p><em>Example</em>:
Consider the example above. Recall events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. Let <span class="math inline">\(A\)</span> be the event that a blue vehicle is selected. Let <span class="math inline">\(B\)</span> be the event that a sedan is selected. Are <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> independent?</p>
</blockquote>
<p>No. First, recall that <span class="math inline">\(\mbox{P}(A|B)=0.5\)</span>. The probability of selecting a blue vehicle (<span class="math inline">\(\mbox{P}(A)\)</span>) is <span class="math inline">\(2/7\)</span> (the number of blue vehicles in our sample space divided by 7, the total number vehicles in <span class="math inline">\(S\)</span>). This value is different from 0.5; thus, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not independent.</p>
<p>We could also use the result above to determine whether <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent. Note that <span class="math inline">\(\mbox{P}(A)= 2/7\)</span>. Also, we know that <span class="math inline">\(\mbox{P}(B)=2/7\)</span>. So, <span class="math inline">\(\mbox{P}(A)\mbox{P}(B)=4/49\)</span>. But, <span class="math inline">\(\mbox{P}(A\cap B) = 1/7\)</span>, since there is just one blue sedan in the sample space. <span class="math inline">\(4/49\)</span> is not equal to <span class="math inline">\(1/7\)</span>; thus, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not independent.</p>
</div>
<div id="bayes-rule" class="section level2" number="9.4">
<h2><span class="header-section-number">9.4</span> Bayes’ Rule</h2>
<p>As mentioned in the introduction to this section, <span class="math inline">\(\mbox{P}(A|B)\)</span> is not the same quantity as <span class="math inline">\(\mbox{P}(B|A)\)</span>. However, if we are given information about <span class="math inline">\(A|B\)</span> and <span class="math inline">\(B\)</span>, we can use Bayes’ Rule to find <span class="math inline">\(\mbox{P}(B|A)\)</span>. Let <span class="math inline">\(B_1, B_2, ..., B_n\)</span> be mutually exclusive and exhaustive events and let <span class="math inline">\(\mbox{P}(A)&gt;0\)</span>. Then,
<span class="math display">\[
\mbox{P}(B_k|A)=\frac{\mbox{P}(A|B_k)\mbox{P}(B_k)}{\sum_{i=1}^n \mbox{P}(A|B_i)\mbox{P}(B_i)}
\]</span></p>
<p>Let’s use an example to dig into where this comes from.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose a doctor has developed a blood test for a certain rare disease (only one out of every 10,000 people have this disease). After careful and extensive evaluation of this blood test, the doctor determined the test’s sensitivity and specificity.</p>
</blockquote>
<p><strong>Sensitivity</strong> is the probability of detecting the disease for those who actually have it. Note that this is a conditional probability.</p>
<p><strong>Specificity</strong> is the probability of correctly identifying “no disease” for those who do not have it. Again, another conditional probability.</p>
<p>See Figure @ref(fig:sens) for a visual representation of these terms and others related to what is termed a <strong>confusion matrix</strong>.</p>
<p>(ref:quote2) A table of true results and test results for a hypothetical disease. The terminology is included in the table. These ideas are important when evaluating machine learning classification models.</p>
<div class="figure" style="text-align: center">
<img src="figures/sensitivity-specificity_corrected.jpg" alt="(ref:quote2)" width="100%" />
<p class="caption">
(#fig:sens)(ref:quote2)
</p>
</div>
<p>In fact, this test had a sensitivity of 100% and a specificity of 99.9%. Now suppose a patient walks in, the doctor administers the blood test, and it returns positive. What is the probability that that patient actually has the disease?</p>
<p>This is a classic example of how probability could be misunderstood. Upon reading this question, you might guess that the answer to our question is quite high. After all, this is a nearly perfect test. After exploring the problem more in depth, we find a different result.</p>
<div id="approach-using-whole-numbers" class="section level3" number="9.4.1">
<h3><span class="header-section-number">9.4.1</span> Approach using whole numbers</h3>
<p>Without going directly to the formulaic expression above, let’s consider a collection of 100,000 randomly selected people. What do we know?</p>
<ol style="list-style-type: decimal">
<li><p>Based on the prevalence of this disease (one out of every 10,000 people have this disease), we know that 10 of them should have the disease.</p></li>
<li><p>This test is perfectly sensitive. Thus, of the 10 people that have the disease, all of them test positive.</p></li>
<li><p>This test has a specificity of 99.9%. Of the 99,990 that don’t have the disease, <span class="math inline">\(0.999*99990\approx 99890\)</span> will test negative. The remaining 100 will test positive.</p></li>
</ol>
<p>Thus, of our 100,000 randomly selected people, 110 will test positive. Of these 110, only 10 actually have the disease. Thus, the probability that someone has the disease given they’ve tested positive is actually around <span class="math inline">\(10/110 = 0.0909\)</span>.</p>
</div>
<div id="mathematical-approach" class="section level3" number="9.4.2">
<h3><span class="header-section-number">9.4.2</span> Mathematical approach</h3>
<p>Now let’s put this in context of Bayes’ Rule as stated above. First, let’s define some events. Let <span class="math inline">\(D\)</span> be the event that someone has the disease. Thus, <span class="math inline">\(D&#39;\)</span> would be the event that someone does not have the disease. Similarly, let <span class="math inline">\(T\)</span> be the event that someone has tested positive. What do we already know?
<span class="math display">\[
\mbox{P}(D) = 0.0001 \hspace{1cm} \mbox{P}(D&#39;)=0.9999
\]</span>
<span class="math display">\[
\mbox{P}(T|D)= 1 \hspace{1cm} \mbox{P}(T&#39;|D)=0
\]</span>
<span class="math display">\[
\mbox{P}(T&#39;|D&#39;)=0.999 \hspace{1cm} \mbox{P}(T|D&#39;) = 0.001
\]</span></p>
<p>We are looking for <span class="math inline">\(\mbox{P}(D|T)\)</span>, the probability that someone has the disease, given he/she has tested positive. By the definition of conditional probability,
<span class="math display">\[
\mbox{P}(D|T)=\frac{\mbox{P}(D \cap T)}{\mbox{P}(T)}
\]</span></p>
<p>The numerator can be rewritten, again utilizing the definition of conditional probability: <span class="math inline">\(\mbox{P}(D\cap T)=\mbox{P}(T|D)\mbox{P}(D)\)</span>.</p>
<p>The denominator can be rewritten using the Law of Total Probability (discussed <a href="#probability-properties">here</a>) and then the definition of conditional probability: <span class="math inline">\(\mbox{P}(T)=\mbox{P}(T\cap D) + \mbox{P}(T \cap D&#39;) = \mbox{P}(T|D)\mbox{P}(D) + \mbox{P}(T|D&#39;)\mbox{P}(D&#39;)\)</span>. So, putting it all together,
<span class="math display">\[
\mbox{P}(D|T)=\frac{\mbox{P}(T|D)\mbox{P}(D)}{\mbox{P}(T|D)\mbox{P}(D) + \mbox{P}(T|D&#39;)\mbox{P}(D&#39;)}
\]</span></p>
<p>Now we have stated our problem in the context of quantities we know:
<span class="math display">\[
\mbox{P}(D|T)=\frac{1\cdot 0.0001}{1\cdot 0.0001 + 0.001\cdot 0.9999} = 0.0909
\]</span></p>
<p>Note that in the original statement of Bayes’ Rule, we considered <span class="math inline">\(n\)</span> partitions, <span class="math inline">\(B_1, B_2,...,B_n\)</span>. In this example, we only have two: <span class="math inline">\(D\)</span> and <span class="math inline">\(D&#39;\)</span>.</p>
</div>
<div id="simulation" class="section level3" number="9.4.3">
<h3><span class="header-section-number">9.4.3</span> Simulation</h3>
<p>To do the simulation, we can think of it as flipping a coin. First let’s assume we are pulling 1,000,000 people from the population. The probability that any one person has the disease is 0.0001. We will use <code>rflip()</code> to get the 1,000,000 people and designate as no disease or disease.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">43</span>)</span>
<span id="cb217-2"><a href="#cb217-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">rflip</span>(<span class="dv">1000000</span>,<span class="fl">0.0001</span>,<span class="at">summarize =</span> <span class="cn">TRUE</span>)</span>
<span id="cb217-3"><a href="#cb217-3" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<pre><code>##       n heads  tails  prob
## 1 1e+06   100 999900 1e-04</code></pre>
<p>In this case 100 people had the disease. Now let’s find the positive test results. Of the 100 with the disease, all will test positive. Of those without disease, there is a 0.001 probability of testing positive.</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rflip</span>(<span class="fu">as.numeric</span>(results[<span class="st">&#39;tails&#39;</span>]),<span class="at">prob=</span>.<span class="dv">001</span>,<span class="at">summarize =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##        n heads  tails  prob
## 1 999900   959 998941 0.001</code></pre>
<p>Now 959 tested positive. Thus the probability of having the disease given a positive test result is approximately:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="dv">100</span><span class="sc">/</span>(<span class="dv">100</span><span class="sc">+</span><span class="dv">959</span>)</span></code></pre></div>
<pre><code>## [1] 0.09442871</code></pre>
</div>
</div>
<div id="homework-problems-8" class="section level2" number="9.5">
<h2><span class="header-section-number">9.5</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Consider: <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are events such that <span class="math inline">\(\mbox{P}(A)=0.5\)</span>, <span class="math inline">\(\mbox{P}(B)=0.3\)</span>, <span class="math inline">\(\mbox{P}(C)=0.4\)</span>, <span class="math inline">\(\mbox{P}(A \cap B)=0.2\)</span>, <span class="math inline">\(\mbox{P}(B \cap C)=0.12\)</span>, <span class="math inline">\(\mbox{P}(A \cap C)=0.1\)</span>, and <span class="math inline">\(\mbox{P}(A \cap B \cap C)=0.05\)</span>.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Are <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> independent?<br />
</li>
<li>Are <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> independent?</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Suppose I have a biased coin (the probability I flip a heads is 0.6). I flip that coin twice. Assume that the coin is memoryless (flips are independent of one another).</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>What is the probability that the second flip results in heads?<br />
</li>
<li>What is the probability that the second flip results in heads, given the first also resulted in heads?<br />
</li>
<li>What is the probability both flips result in heads?<br />
</li>
<li>What is the probability exactly one coin flip results in heads?<br />
</li>
<li>Now assume I flip the coin five times. What is the probability the result is 5 heads?<br />
</li>
<li>What is the probability the result is exactly 2 heads (out of 5 flips)?</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li><p>Suppose there are three assistants working at a company: Moe, Larry and Curly. All three assist with a filing process. Only one filing assistant is needed at a time. Moe assists 60% of the time, Larry assists 30% of the time and Curly assists the remaining 10% of the time. Occasionally, they make errors (misfiles); Moe has a misfile rate of 0.01, Larry has a misfile rate of 0.025, and Curly has a rate of 0.05. Suppose a misfile was discovered, but it is unknown who was on schedule when it occurred. Who is most likely to have committed the misfile? Calculate the probabilities for each of the three assistants.</p></li>
<li><p>You are playing a game where there are two coins. One coin is fair and the other comes up <em>heads</em> 80% of the time. One coin is flipped 3 times and the result is three <em>heads</em>, what is the probability that the coin flipped is the fair coin? You will need to make an assumption about the probability of either coin being selected.</p></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Use Bayes formula to solve this problem.<br />
</li>
<li>Use simulation to solve this problem.</li>
</ol>
<!--chapter:end:09-Conditional-Probability.Rmd-->
</div>
</div>
<div id="RANDVAR" class="section level1" number="10">
<h1><span class="header-section-number">10</span> Random Variables</h1>
<div id="objectives-9" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and use properly in context all new terminology.<br />
</li>
<li>Given a discrete random variable, obtain the pmf and cdf, and use them to obtain probabilities of events.<br />
</li>
<li>Simulate random variable for a discrete distribution.<br />
</li>
<li>Find the moments of a discrete random variable.<br />
</li>
<li>Find the expected value of a linear transformation of a random variable.</li>
</ol>
</div>
<div id="random-variables" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> Random variables</h2>
<p>We have already discussed random experiments. We have also discussed <span class="math inline">\(S\)</span>, the sample space for an experiment. A random variable essentially maps the events in the sample space to the real number line. For a formal definition: A random variable <span class="math inline">\(X\)</span> is a function <span class="math inline">\(X: S\rightarrow \mathbb{R}\)</span> that assigns exactly one number to each outcome in an experiment.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose you flip a coin three times. The sample space, <span class="math inline">\(S\)</span>, of this experiment is
<span class="math display">\[
S=\{\mbox{HHH}, \mbox{HHT}, \mbox{HTH}, \mbox{HTT}, \mbox{THH}, \mbox{THT}, \mbox{TTH}, \mbox{TTT}\}
\]</span></p>
</blockquote>
<p>Let the random variable <span class="math inline">\(X\)</span> be the number of heads in three coin flips. Whenever introduced to a new random variable, you should take a moment to think about what possible values can <span class="math inline">\(X\)</span> take? When tossing a coin 3 times, we can get no heads, one head, two heads or three heads. The random variable <span class="math inline">\(X\)</span> assigns each outcome in our experiment to one of these values. Visually:
<span class="math display">\[
S=\{\underbrace{\mbox{HHH}}_{X=3}, \underbrace{\mbox{HHT}}_{X=2}, \underbrace{\mbox{HTH}}_{X=2}, \underbrace{\mbox{HTT}}_{X=1}, \underbrace{\mbox{THH}}_{X=2}, \underbrace{\mbox{THT}}_{X=1}, \underbrace{\mbox{TTH}}_{X=1}, \underbrace{\mbox{TTT}}_{X=0}\}
\]</span></p>
<p>The sample space of <span class="math inline">\(X\)</span>, sometimes referred to as the support, is the list of numerical values that <span class="math inline">\(X\)</span> can take.
<span class="math display">\[
S_X=\{0,1,2,3\}
\]</span></p>
<p>Because the sample space of <span class="math inline">\(X\)</span> is a countable list of numbers, we consider <span class="math inline">\(X\)</span> to be a <em>discrete</em> random variable (more on that later).</p>
<div id="how-does-this-help" class="section level3" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> How does this help?</h3>
<p>Sticking with our example, we can now frame a problem of interest in the context of our random variable <span class="math inline">\(X\)</span>. For example, suppose we wanted to know the probability of at least two heads. Without our random variable, we have to write this as:
<span class="math display">\[
\mbox{P}(\mbox{at least two heads})= \mbox{P}(\{\mbox{HHH},\mbox{HHT},\mbox{HTH},\mbox{THH}\})
\]</span></p>
<p>In the context of our random variable, this simply becomes <span class="math inline">\(\mbox{P}(X\geq 2)\)</span>. It may not seem important in a case like this, but imagine if we were flipping a coin 50 times and wanted to know the probability of obtaining at least 30 heads. It would be unfeasible to write out all possible ways to obtain at least 30 heads. It is much easier to write <span class="math inline">\(\mbox{P}(X\geq 30)\)</span> and explore the distribution of <span class="math inline">\(X\)</span>.</p>
<p>Essentially, a random variable often helps us reduce a complex random experiment to a simple variable that is easy to characterize.</p>
</div>
<div id="discrete-vs-continuous" class="section level3" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> Discrete vs Continuous</h3>
<p>A <em>discrete</em> random variable has a sample space that consists of a countable set of values. <span class="math inline">\(X\)</span> in our example above is a discrete random variable. Note that “countable” does not necessarily mean “finite”. For example, a random variable with a Poisson distribution (a topic for a later lesson) has a sample space of <span class="math inline">\(\{0,1,2,...\}\)</span>. This sample space is unbounded, but it is considered <em>countably</em> infinite, and thus the random variable would be considered discrete.</p>
<p>A <em>continuous</em> random variable has a sample space that is a continuous interval. For example, let <span class="math inline">\(Y\)</span> be the random variable corresponding to the height of a randomly selected individual. <span class="math inline">\(Y\)</span> is a continuous random variable because a person could measure 68.1 inches, 68.2 inches, or perhaps any value in between. Note that when we measure height, our precision is limited by our measuring device, so we are technically “discretizing” height. However, even in these cases, we typically consider height to be a continuous random variable.</p>
<p>A <em>mixed</em> random variable is exactly what it sounds like. It has a sample space that is both discrete and continuous. How could such a thing occur? Consider an experiment where a person rolls a standard six-sided die. If it lands on anything other than one, the result of the die roll is recorded. If it lands on one, the person spins a wheel, and the angle in degrees of the resulting spin, divided by 360, is recorded. If our random variable <span class="math inline">\(Z\)</span> is the number that is recorded in this experiment, the sample space of <span class="math inline">\(Z\)</span> is <span class="math inline">\([0,1] \cup \{2,3,4,5,6\}\)</span>. We will not be spending much time on mixed random variables. However they do occur in practice, consider the job of analyzing bomb error data. If the bomb hits within a certain radius, the error is 0. Otherwise it is measured in a radial direction. This data is mixed.</p>
</div>
<div id="discrete-distribution-functions" class="section level3" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> Discrete distribution functions</h3>
<p>Once we have defined a random variable, we need a way to describe its behavior and we will use probabilities for this purpose.</p>
<p><em>Distribution functions</em> describe the behavior of random variables. We can use these functions to determine the probability that a random variable takes a value or a range of values. For discrete random variables, there are two distribution functions of interest: the <em>probability mass function</em> (pmf) and the <em>cumulative distribution function</em> (cdf).</p>
</div>
<div id="probability-mass-function" class="section level3" number="10.2.4">
<h3><span class="header-section-number">10.2.4</span> Probability mass function</h3>
<p>Let <span class="math inline">\(X\)</span> be a discrete random variable. The probability mass function (pmf) of <span class="math inline">\(X\)</span>, given by <span class="math inline">\(f_X(x)\)</span>, is a function that assigns probability to each possible outcome of <span class="math inline">\(X\)</span>.
<span class="math display">\[
f_X(x)=\mbox{P}(X=x)
\]</span></p>
<p>Note that the pmf is a <em>function</em>. Functions have input and output. The input of a pmf is any real number. The output of a pmf is the probability that the random variable takes the inputted value. The pmf must follow the axioms of probability described in the Probability Rules lesson. Primarily,</p>
<ol style="list-style-type: decimal">
<li><p>For all <span class="math inline">\(x \in \mathbb{R}\)</span>, <span class="math inline">\(0 \leq f_X(x) \leq 1\)</span>.</p></li>
<li><p><span class="math inline">\(\sum_x f_X(x) = 1\)</span>, where the <span class="math inline">\(x\)</span> in the index of the sum simply denotes that we are summing across the entire domain or support of <span class="math inline">\(X\)</span>.</p></li>
</ol>
<blockquote>
<p><em>Example</em>:<br />
Recall our example again. You flip a coin three times and let <span class="math inline">\(X\)</span> be the number of heads in those three coin flips. We know that <span class="math inline">\(X\)</span> can only take values 0, 1, 2 or 3. But at what probability does it take these three values? In that example, we had listed out the possible outcomes of the experiment and denoted what value of <span class="math inline">\(X\)</span> corresponds to each outcome.
<span class="math display">\[
S=\{\underbrace{\mbox{HHH}}_{X=3}, \underbrace{\mbox{HHT}}_{X=2}, \underbrace{\mbox{HTH}}_{X=2}, \underbrace{\mbox{HTT}}_{X=1}, \underbrace{\mbox{THH}}_{X=2}, \underbrace{\mbox{THT}}_{X=1}, \underbrace{\mbox{TTH}}_{X=1}, \underbrace{\mbox{TTT}}_{X=0}\}
\]</span></p>
</blockquote>
<p>Each of these eight outcomes is equally likely (each with a probability of <span class="math inline">\(\frac{1}{8}\)</span>). Thus, building the pmf of <span class="math inline">\(X\)</span> becomes a matter of counting the number of outcomes associated with each possible value of <span class="math inline">\(X\)</span>:
<span class="math display">\[
f_X(x)=\left\{ \renewcommand{\arraystretch}{1.4} \begin{array}{ll} \frac{1}{8}, &amp; x=0 \\
\frac{3}{8}, &amp; x=1 \\
\frac{3}{8}, &amp; x=2 \\
\frac{1}{8}, &amp; x=3 \\
0, &amp; \mbox{otherwise} \end{array} \right .
\]</span></p>
<p>Note that this function specifies the probability that <span class="math inline">\(X\)</span> takes any of the four values in the sample space (0, 1, 2, and 3). Also, it specifies that the probability that <span class="math inline">\(X\)</span> takes any other value is 0.</p>
<p>Graphically, the pmf is not terribly interesting. The pmf is 0 at all values of <span class="math inline">\(X\)</span> except for 0, 1, 2 and 3, Figure @ref(fig:pmf101-fig).</p>
<div class="figure">
<img src="10-RandomVariables_files/figure-html/pmf101-fig-1.png" alt="Probability Mass Function of $X$ from Coin Flip Example" width="672" />
<p class="caption">
(#fig:pmf101-fig)Probability Mass Function of <span class="math inline">\(X\)</span> from Coin Flip Example
</p>
</div>
<blockquote>
<p><em>Example</em>:<br />
We can use a pmf to answer questions about an experiment. For example, consider the same context. What is the probability that we flip at least one heads? We can write this in the context of <span class="math inline">\(X\)</span>:
<span class="math display">\[
\mbox{P}(\mbox{at least one heads})=\mbox{P}(X\geq 1)=\mbox{P}(X=1)+\mbox{P}(X=2)+\mbox{P}(X=3)=\frac{3}{8} + \frac{3}{8}+\frac{1}{8}=\frac{7}{8}
\]</span></p>
</blockquote>
<p>Alternatively, we can recognize that <span class="math inline">\(\mbox{P}(X\geq 1)=1-\mbox{P}(X=0)=1-\frac{1}{8}=\frac{7}{8}\)</span>.</p>
</div>
<div id="cumulative-distribution-function" class="section level3" number="10.2.5">
<h3><span class="header-section-number">10.2.5</span> Cumulative distribution function</h3>
<p>Let <span class="math inline">\(X\)</span> be a discrete random variable. The cumulative distribution function (cdf) of <span class="math inline">\(X\)</span>, given by <span class="math inline">\(F_X(x)\)</span>, is a function that assigns to each value of <span class="math inline">\(X\)</span> the probability that <span class="math inline">\(X\)</span> takes that value or lower:
<span class="math display">\[
F_X(x)=\mbox{P}(X\leq x)
\]</span></p>
<p>Again, note that the cdf is a <em>function</em> with an input and output. The input of a cdf is any real number. The output of a cdf is the probability that the random variable takes the inputted value <em>or less</em>.</p>
<p>If we know the pmf, we can obtain the cdf:
<span class="math display">\[
F_X(x)=\mbox{P}(X\leq x)=\sum_{y\leq x} f_X(y)
\]</span></p>
<p>Like the pmf, the cdf must be between 0 and 1. Also, since the pmf is always non-negative, the cdf must be non-decreasing.</p>
<blockquote>
<p><em>Example</em>:<br />
Obtain and plot the cdf of <span class="math inline">\(X\)</span> of the previous example.
<span class="math display">\[
F_X(x)=\mbox{P}(X\leq x)=\left\{\renewcommand{\arraystretch}{1.4} \begin{array}{ll} 0, &amp; x &lt;0 \\
\frac{1}{8}, &amp; 0\leq x &lt; 1 \\
\frac{4}{8}, &amp; 1\leq x &lt; 2 \\
\frac{7}{8}, &amp; 2\leq x &lt; 3 \\
1, &amp; x\geq 3 \end{array}\right .
\]</span></p>
</blockquote>
<p>Visually, the cdf of a discrete random variable has a stairstep appearance. In this example, the cdf takes a value 0 up until <span class="math inline">\(X=0\)</span>, at which point the cdf increases to 1/8. It stays at this value until <span class="math inline">\(X=1\)</span>, and so on. At and beyond <span class="math inline">\(X=3\)</span>, the cdf is equal to 1, Figure @ref(fig:cdf101-fig).</p>
<div class="figure">
<img src="10-RandomVariables_files/figure-html/cdf101-fig-1.png" alt="Cumulative Distribution Function of $X$ from Coin Flip Example" width="672" />
<p class="caption">
(#fig:cdf101-fig)Cumulative Distribution Function of <span class="math inline">\(X\)</span> from Coin Flip Example
</p>
</div>
</div>
<div id="simulating-random-variables" class="section level3" number="10.2.6">
<h3><span class="header-section-number">10.2.6</span> Simulating random variables</h3>
<p>We can simulate values from a random variable using the cdf, we will use a similar idea for continuous random variables. Since the range of the cdf is in the interval <span class="math inline">\([0,1]\)</span> we will generate a random number in that same interval and then use the inverse function to find the value of the random variable. The pseudo code is:<br />
1) Generate a random number, <span class="math inline">\(U\)</span>.<br />
2) Find the index <span class="math inline">\(k\)</span> such that <span class="math inline">\(\sum_{j=1}^{k-1}f_X(x_{j}) \leq U &lt; \sum_{j=1}^{k}f_X(x_{j})\)</span> or <span class="math inline">\(F_x(k-1) \leq U &lt; F_{x}(k)\)</span>.</p>
<blockquote>
<p><em>Example</em>:<br />
Simulate a random variable for the number of heads in flipping a coin three times.</p>
</blockquote>
<p>First we will create the pmf.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a>pmf <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">8</span>,<span class="dv">3</span><span class="sc">/</span><span class="dv">8</span>,<span class="dv">3</span><span class="sc">/</span><span class="dv">8</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">8</span>)</span>
<span id="cb223-2"><a href="#cb223-2" aria-hidden="true" tabindex="-1"></a>values <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb223-3"><a href="#cb223-3" aria-hidden="true" tabindex="-1"></a>pmf</span></code></pre></div>
<pre><code>## [1] 0.125 0.375 0.375 0.125</code></pre>
<p>We get the cdf from the cumulative sum.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a>cdf <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(pmf)</span>
<span id="cb225-2"><a href="#cb225-2" aria-hidden="true" tabindex="-1"></a>cdf</span></code></pre></div>
<pre><code>## [1] 0.125 0.500 0.875 1.000</code></pre>
<p>Next, we will generate a random number between 0 and 1.</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1153</span>)</span>
<span id="cb227-2"><a href="#cb227-2" aria-hidden="true" tabindex="-1"></a>ran_num <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb227-3"><a href="#cb227-3" aria-hidden="true" tabindex="-1"></a>ran_num</span></code></pre></div>
<pre><code>## [1] 0.7381891</code></pre>
<p>Finally, we will find the value of the random variable. We will do each step separately first so you can understand the code.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a>ran_num <span class="sc">&lt;</span> cdf</span></code></pre></div>
<pre><code>## [1] FALSE FALSE  TRUE  TRUE</code></pre>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(ran_num <span class="sc">&lt;</span> cdf)</span></code></pre></div>
<pre><code>## [1] 3 4</code></pre>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(ran_num <span class="sc">&lt;</span> cdf)[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a>values[<span class="fu">which</span>(ran_num <span class="sc">&lt;</span> cdf)[<span class="dv">1</span>]]</span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<p>Let’s make this a function.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a>simple_rv <span class="ot">&lt;-</span> <span class="cf">function</span>(values,cdf){</span>
<span id="cb237-2"><a href="#cb237-2" aria-hidden="true" tabindex="-1"></a>ran_num <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb237-3"><a href="#cb237-3" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(values[<span class="fu">which</span>(ran_num <span class="sc">&lt;</span> cdf)[<span class="dv">1</span>]])</span>
<span id="cb237-4"><a href="#cb237-4" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now let’s generate 10000 values from this random variable.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">simple_rv</span>(values,cdf)</span>
<span id="cb238-2"><a href="#cb238-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(results)</span></code></pre></div>
<pre><code>## 
## quantitative variables:  
##           name   class min Q1 median Q3 max   mean       sd     n missing
## ...1 simple_rv numeric   0  1      2  2   3 1.5048 0.860727 10000       0</code></pre>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>simple_rv,<span class="at">data=</span>results,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>## simple_rv
##      0      1      2      3 
## 0.1207 0.3785 0.3761 0.1247</code></pre>
<p>Not a bad approximation.</p>
</div>
</div>
<div id="moments" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> Moments</h2>
<p>Distribution functions are excellent characterizations of random variables. The pmf and cdf will tell you exactly how often the random variables takes particular values. However, distribution functions are often a lot of information. Sometimes, we may want to describe a random variable <span class="math inline">\(X\)</span> with a single value or small set of values. For example, we may want to know the average or some measure of center of <span class="math inline">\(X\)</span>. We also may want to know a measure of spread of <span class="math inline">\(X\)</span>. <em>Moments</em> are values that summarize random variables with single numbers. Since we are dealing with the population, these moments are population values and not summary statistics as we used in the first block of material.</p>
<div id="expectation" class="section level3" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Expectation</h3>
<p>At this point, we should define the term <em>expectation</em>. Let <span class="math inline">\(g(X)\)</span> be some function of a discrete random variable <span class="math inline">\(X\)</span>. The expected value of <span class="math inline">\(g(X)\)</span> is given by:
<span class="math display">\[
\mbox{E}(g(X))=\sum_x g(x) \cdot f_X(x)
\]</span></p>
</div>
<div id="mean" class="section level3" number="10.3.2">
<h3><span class="header-section-number">10.3.2</span> Mean</h3>
<p>The most common moments used to describe random variables are <em>mean</em> and <em>variance</em>. The mean (often referred to as the expected value of <span class="math inline">\(X\)</span>), is simply the average value of a random variable. It is denoted as <span class="math inline">\(\mu_X\)</span> or <span class="math inline">\(\mbox{E}(X)\)</span>. In the discrete case, the mean is found by:
<span class="math display">\[
\mu_X=\mbox{E}(X)=\sum_x x \cdot f_X(x)
\]</span></p>
<p>The mean is also known as the first moment of <span class="math inline">\(X\)</span> around the origin. It is a weighted sum with the weight being the probability. If each outcome were equally likely, the expected value would just be the average of the values of the random variable since each weight is the reciprocal of the number of values.</p>
<blockquote>
<p><em>Example</em>:<br />
Find the expected value (or mean) of <span class="math inline">\(X\)</span>: the number of heads in three flips of a fair coin.
<span class="math display">\[
\mbox{E}(X)=\sum_x x\cdot f_X(x) = 0*\frac{1}{8} + 1*\frac{3}{8} + 2*\frac{3}{8} + 3*\frac{1}{8}=1.5
\]</span></p>
</blockquote>
<p>We are using <span class="math inline">\(\mu\)</span> because it is a population parameter.</p>
<p>From our simulation above, we can find the mean as an estimate of the expected value. This is really a statistic since our simulation is data from the population and thus will have variance from sample to sample.</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="sc">~</span>simple_rv,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>## [1] 1.5048</code></pre>
</div>
<div id="variance" class="section level3" number="10.3.3">
<h3><span class="header-section-number">10.3.3</span> Variance</h3>
<p>Variance is a measure of spread of a random variable. The variance of <span class="math inline">\(X\)</span> is denoted as <span class="math inline">\(\sigma^2_X\)</span> or <span class="math inline">\(\mbox{Var}(X)\)</span>. It is equivalent to the average squared deviation from the mean:
<span class="math display">\[
\sigma^2_X=\mbox{Var}(X)=\mbox{E}[(X-\mu_X)^2]
\]</span></p>
<p>In the discrete case, this can be evaluated by:
<span class="math display">\[
\mbox{E}[(X-\mu_X)^2]=\sum_x (x-\mu_X)^2f_X(x)
\]</span></p>
<p>Variance is also known as the second moment of <span class="math inline">\(X\)</span> around the mean.</p>
<p>The square root of <span class="math inline">\(\mbox{Var}(X)\)</span> is denoted as <span class="math inline">\(\sigma_X\)</span>, the standard deviation of <span class="math inline">\(X\)</span>. The standard deviation is often reported because it is measured in the same units as <span class="math inline">\(X\)</span>, while the variance is measured in squared units and is thus harder to interpret.</p>
<blockquote>
<p><em>Example</em>:<br />
Find the variance of <span class="math inline">\(X\)</span>: the number of heads in three flips of a fair coin.</p>
</blockquote>
<p><span class="math display">\[
\mbox{Var}(X)=\sum_x (x-\mu_X)^2 \cdot f_X(x)
\]</span></p>
<p><span class="math display">\[
= (0-1.5)^2 \times \frac{1}{8} + (1-1.5)^2 \times \frac{3}{8}+(2-1.5)^2 \times \frac{3}{8} + (3-1.5)^2\times \frac{1}{8}
\]</span>
In <code>R</code> this is:</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">0</span><span class="fl">-1.5</span>)<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="dv">1</span><span class="sc">/</span><span class="dv">8</span> <span class="sc">+</span> (<span class="dv">1</span><span class="fl">-1.5</span>)<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="dv">3</span><span class="sc">/</span><span class="dv">8</span> <span class="sc">+</span> (<span class="dv">2</span><span class="fl">-1.5</span>)<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="dv">3</span><span class="sc">/</span><span class="dv">8</span> <span class="sc">+</span> (<span class="dv">3</span><span class="fl">-1.5</span>)<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="dv">1</span><span class="sc">/</span><span class="dv">8</span></span></code></pre></div>
<pre><code>## [1] 0.75</code></pre>
<p>The variance of <span class="math inline">\(X\)</span> is 0.75.</p>
<p>We can find the variance of the simulation but <code>R</code> uses the sample variance and this is the population variance. So we need to multiply by <span class="math inline">\(\frac{n-1}{n}\)</span></p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(<span class="sc">~</span>simple_rv,<span class="at">data=</span>results)<span class="sc">*</span>(<span class="dv">10000-1</span>)<span class="sc">/</span><span class="dv">10000</span></span></code></pre></div>
<pre><code>## [1] 0.740777</code></pre>
</div>
<div id="mean-and-variance-of-linear-transformations" class="section level3" number="10.3.4">
<h3><span class="header-section-number">10.3.4</span> Mean and variance of Linear Transformations</h3>
<p><strong>Lemma</strong>: Let <span class="math inline">\(X\)</span> be a discrete random variable, and let <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> be constants. Then:
<span class="math display">\[
\mbox{E}(aX+b)=a\mbox{E}(X)+b
\]</span>
and
<span class="math display">\[
\mbox{Var}(aX+b)=a^2\mbox{Var}(X)
\]</span></p>
<p>The proof of this is left as a homework problem.</p>
</div>
</div>
<div id="homework-problems-9" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Suppose we are flipping a fair coin, and the result of a single coin flip is either heads or tails. Let <span class="math inline">\(X\)</span> be a random variable representing the number of flips until the first heads.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Is <span class="math inline">\(X\)</span> discrete or continuous? What is the domain, support, of <span class="math inline">\(X\)</span>?<br />
</li>
<li>What values do you <em>expect</em> <span class="math inline">\(X\)</span> to take? What do you think is the average of <span class="math inline">\(X\)</span>? Don’t actually do any formal math, just think about if you were flipping a regular coin, how long it would take you to get the first heads.<br />
</li>
<li>Advanced: In <code>R</code>, generate 10,000 observations from <span class="math inline">\(X\)</span>. What is the empirical, from the simulation, pmf? What is the average value of <span class="math inline">\(X\)</span> based on this simulation? Create a bar chart of the proportions. Note: Unlike the example in the Notes, we don’t have the pmf, so you will have to simulate the experiment and using <code>R</code> to find the number of flips until the first heads.</li>
</ol>
<p>Note: There are many ways to do this. Below is a description of one approach. It assumes we are extremely unlikely to go past 1000 flips.</p>
<ul>
<li><p>First, let’s sample with replacement from the vector c(“H”,“T”), 1000 times with replacement, use <code>sample()</code>.</p></li>
<li><p>As we did in the reading, use <code>which()</code> and a logical argument to find the first occurrence of a heads.</p></li>
</ul>
<ol start="4" style="list-style-type: lower-alpha">
<li>Find the theoretical distribution, use math to come up with a closed for solution for the pmf.</li>
</ol>
<p> </p>
<ol start="2" style="list-style-type: decimal">
<li>Repeat Problem 1,except part d, but with a different random variable, <span class="math inline">\(Y\)</span>: the number of coin flips until the <em>fifth</em> heads.</li>
</ol>
<p> </p>
<div style="page-break-after: always;"></div>
<ol start="3" style="list-style-type: decimal">
<li>Suppose you are a data analyst for a large international airport. Your boss, the head of the airport, is dismayed that this airport has received negative attention in the press for inefficiencies and sluggishness. In a staff meeting, your boss gives you a week to build a report addressing the “timeliness” at the airport. Your boss is in a big hurry and gives you no further information or guidance on this task.</li>
</ol>
<p>Prior to building the report, you will need to conduct some analysis. To aid you in this, create a list of at least three random variables that will help you address timeliness at the airport. For each of your random variables,</p>
<ol style="list-style-type: lower-alpha">
<li>Determine whether it is discrete or continuous.<br />
</li>
<li>Report its domain.<br />
</li>
<li>What is the experimental unit?<br />
</li>
<li>Explain how this random variable will be useful in addressing timeliness at the airport.</li>
</ol>
<p>We will provide one example:</p>
<p>Let <span class="math inline">\(D\)</span> be the difference between a flight’s actual departure and its scheduled departure. This is a continuous random variable, since time can be measured in fractions of minutes. A flight can be early or late, so domain is any real number. The experimental unit is each individual (non-canceled) flight. This is a useful random variable because the average value of <span class="math inline">\(D\)</span> will describe whether flights take off on time. We could also find out how often <span class="math inline">\(D\)</span> exceeds 0 (implying late departure) or how often <span class="math inline">\(D\)</span> exceeds 30 minutes, which could indicate a “very late” departure.</p>
<ol start="4" style="list-style-type: decimal">
<li>Consider the experiment of rolling two fair six-sided dice. Let the random variable <span class="math inline">\(Y\)</span> be the absolute difference between the two numbers that appear upon rolling the dice.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>What is the domain/support of <span class="math inline">\(Y\)</span>?<br />
</li>
<li>What values do you <em>expect</em> <span class="math inline">\(Y\)</span> to take? What do you think is the average of <span class="math inline">\(Y\)</span>? Don’t actually do any formal math, just think about the experiment.<br />
</li>
<li>Find the probability mass function and cumulative distribution function of <span class="math inline">\(Y\)</span>.<br />
</li>
<li>Find the expected value and variance of <span class="math inline">\(Y\)</span>.<br />
</li>
<li>Advanced: In <code>R</code>, obtain 10,000 realizations of <span class="math inline">\(Y\)</span>. In other words, simulate the roll of two fair dice, record the absolute difference and repeat this 10,000 times. Construct a frequency table of your results (what percentage of time did you get a difference of 0? difference of 1? etc.) Find the mean and variance of your simulated sample of <span class="math inline">\(Y\)</span>. Were they close to your answers in part d?</li>
</ol>
<p> </p>
<ol start="5" style="list-style-type: decimal">
<li>Prove the Lemma from the Notes: Let <span class="math inline">\(X\)</span> be a discrete random variable, and let <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> be constants. Show <span class="math inline">\(\mbox{E}(aX + b)=a\mbox{E}(X)+b\)</span>.</li>
</ol>
<p> </p>
<ol start="6" style="list-style-type: decimal">
<li>We saw that <span class="math inline">\(\mbox{Var}(X)=\mbox{E}[(X-\mu_X)^2]\)</span>. Show that <span class="math inline">\(\mbox{Var}(X)\)</span> is also equal to <span class="math inline">\(\mbox{E}(X^2)-[\mbox{E}(X)]^2\)</span>.</li>
</ol>
<!--chapter:end:10-RandomVariables.Rmd-->
</div>
</div>
<div id="CONRANDVAR" class="section level1" number="11">
<h1><span class="header-section-number">11</span> Continuous Random Variables</h1>
<div id="objectives-10" class="section level2" number="11.1">
<h2><span class="header-section-number">11.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and properly use the new terms to include probability density function (pdf) and cumulative distribution function (cdf) for continuous random variables.<br />
</li>
<li>Given a continuous random variable, find probabilities using the pdf and/or the cdf.<br />
</li>
<li>Find the mean and variance of a continuous random variable.</li>
</ol>
</div>
<div id="continuous-random-variables" class="section level2" number="11.2">
<h2><span class="header-section-number">11.2</span> Continuous random variables</h2>
<p>In the last lesson, we introduced random variables, and explored discrete random variables. In this lesson, we will move into continuous random variables, their properties, their distribution functions, and how they differ from discrete random variables.</p>
<p>Recall that a continuous random variable has a domain that is a continuous interval (or possibly a group of intervals). For example, let <span class="math inline">\(Y\)</span> be the random variable corresponding to the height of a randomly selected individual. While our measurement will necessitate “discretizing” height to some degree, technically, height is a continuous random variable since a person could measure 67.3 inches or 67.4 inches or anything in between.</p>
<div id="continuous-distribution-functions" class="section level3" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Continuous distribution functions</h3>
<p>So how do we describe the randomness of continuous random variables? In the case of discrete random variables, the probability mass function (pmf) and the cumulative distribution function (cdf) are used to describe randomness. However, recall that the pmf is a function that returns the probability that the random variable takes the inputted value. Due to the nature of continuous random variables, the probability that a continuous random variable takes on any one individual value is technically 0. Thus, a pmf cannot apply to a continuous random variable.</p>
<p>Rather, we describe the randomness of continuous random variables with the <em>probability density function</em> (pdf) and the <em>cumulative distribution function</em> (cdf). Note that the cdf has the same interpretation and application as in the discrete case.</p>
<div style="page-break-after: always;"></div>
</div>
<div id="probability-density-function" class="section level3" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Probability density function</h3>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable. The probability density function (pdf) of <span class="math inline">\(X\)</span>, given by <span class="math inline">\(f_X(x)\)</span> is a function that describes the behavior of <span class="math inline">\(X\)</span>. It is important to note that in the continuous case, <span class="math inline">\(f_X(x)\neq \mbox{P}(X=x)\)</span>, as the probability of <span class="math inline">\(X\)</span> taking any one individual value is 0.</p>
<p>The pdf is a <em>function</em>. The input of a pdf is any real number. The output is known as the density. The pdf has three main properties:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(f_X(x)\geq 0\)</span></p></li>
<li><p><span class="math inline">\(\int_{S_X} f_X(x)\mathop{}\!\mathrm{d}x = 1\)</span></p></li>
<li><p><span class="math inline">\(\mbox{P}(X\in A)=\int_{x\in A} f_X(x)\mathop{}\!\mathrm{d}x\)</span> or another way to write this <span class="math inline">\(\mbox{P}(a \leq X \leq b)=\int_{a}^{b} f_X(x)\mathop{}\!\mathrm{d}x\)</span></p></li>
</ol>
<p>Properties 2) and 3) imply that the area underneath a pdf represents probability. The pdf is a non-negative function, it cannot have negative values.</p>
</div>
<div id="cumulative-distribution-function-1" class="section level3" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Cumulative distribution function</h3>
<p>The cumulative distribution function (cdf) of a continuous random variable has the same interpretation as it does for a discrete random variable. It is a <em>function</em>. The input of a cdf is any real number, and the output is the probability that the random variable takes a value less than or equal to the inputted value. It is denoted as <span class="math inline">\(F\)</span> and is given by:
<span class="math display">\[
F_X(x)=\mbox{P}(X\leq x)=\int_{-\infty}^x f_x(t) \mathop{}\!\mathrm{d}t
\]</span></p>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X\)</span> be a continuous random variable with <span class="math inline">\(f_X(x)=2x\)</span> where <span class="math inline">\(0 \leq x \leq 1\)</span>. Verify that <span class="math inline">\(f\)</span> is a valid pdf. Find the cdf of <span class="math inline">\(X\)</span>. Also, find the following probabilities: <span class="math inline">\(\mbox{P}(X&lt;0.5)\)</span>, <span class="math inline">\(\mbox{P}(X&gt;0.5)\)</span>, and <span class="math inline">\(\mbox{P}(0.1\leq X &lt; 0.75)\)</span>. Finally, find the median of <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p>To verify that <span class="math inline">\(f\)</span> is a valid pdf, we simply note that <span class="math inline">\(f_X(x) \geq 0\)</span> on the range <span class="math inline">\(0 \leq x \leq 1\)</span>. Also, we note that <span class="math inline">\(\int_0^1 2x \mathop{}\!\mathrm{d}x = x^2\bigg|_0^1 = 1\)</span>.</p>
<p>Using <code>R</code>, we find</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(<span class="cf">function</span>(x)<span class="dv">2</span><span class="sc">*</span>x,<span class="dv">0</span>,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 1 with absolute error &lt; 1.1e-14</code></pre>
<p>Or we can use the <strong>mosaicCalc</strong> package to find the anti-derivative. If the package is not installed, you can use the <code>Packages</code> tab in <code>RStudio</code> or type <code>install.packages("mosaicCalc")</code> at the command prompt. Load the library.</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mosaicCalc)</span></code></pre></div>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="#cb251-1" aria-hidden="true" tabindex="-1"></a>(Fx<span class="ot">&lt;-</span><span class="fu">antiD</span>(<span class="dv">2</span><span class="sc">*</span>x<span class="sc">~</span>x))</span></code></pre></div>
<pre><code>## function (x, C = 0) 
## 1 * x^2 + C</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Fx</span>(<span class="dv">1</span>)<span class="sc">-</span><span class="fu">Fx</span>(<span class="dv">0</span>)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
Graphically, the pdf is displayed in Figure @ref(fig:plot111-fig):
<div class="figure" style="text-align: center">
<img src="11-Continuous-Random-Variables_files/figure-html/plot111-fig-1.png" alt="pdf of $X$" width="672" />
<p class="caption">
(#fig:plot111-fig)pdf of <span class="math inline">\(X\)</span>
</p>
</div>
<div style="page-break-after: always;"></div>
<p>The cdf of <span class="math inline">\(X\)</span> is found by
<span class="math display">\[
\int_0^x 2t \mathop{}\!\mathrm{d}t = t^2\bigg|_0^x = x^2
\]</span>
This is <code>antiD</code> found from the calculations above.</p>
<p>So,
<span class="math display">\[
F_X(x)=\left\{ \begin{array}{ll} 0, &amp; x&lt;0 \\ x^2, &amp; 0\leq x \leq 1 \\ 1, &amp; x&gt;1 \end{array}\right.
\]</span></p>
<p>The plot of the cdf of <span class="math inline">\(X\)</span> is shown in Figure @ref(fig:plot112-fig).</p>
<div class="figure" style="text-align: center">
<img src="11-Continuous-Random-Variables_files/figure-html/plot112-fig-1.png" alt="cdf of $X$" width="672" />
<p class="caption">
(#fig:plot112-fig)cdf of <span class="math inline">\(X\)</span>
</p>
</div>
<p>Probabilities are found either by integrating the pdf or using the cdf:</p>
<p><span class="math inline">\(\mbox{P}(X &lt; 0.5)=\mbox{P}(X\leq 0.5)=F_X(0.5)=0.5^2=0.25\)</span>. See Figure @ref(fig:plot113-fig).</p>
<div class="figure" style="text-align: center">
<img src="11-Continuous-Random-Variables_files/figure-html/plot113-fig-1.png" alt="Probability represented by shaded area" width="672" />
<p class="caption">
(#fig:plot113-fig)Probability represented by shaded area
</p>
</div>
<p><span class="math inline">\(\mbox{P}(X &gt; 0.5) = 1-\mbox{P}(X\leq 0.5)=1-0.25 = 0.75\)</span> See Figure @ref(fig:plot114-fig).</p>
<div class="figure" style="text-align: center">
<img src="11-Continuous-Random-Variables_files/figure-html/plot114-fig-1.png" alt="Probability represented by shaded area" width="672" />
<p class="caption">
(#fig:plot114-fig)Probability represented by shaded area
</p>
</div>
<p><span class="math inline">\(\mbox{P}(0.1\leq X &lt; 0.75) = \int_{0.1}^{0.75}2x\mathop{}\!\mathrm{d}x = 0.75^2 - 0.1^2 = 0.5525\)</span> See Figure @ref(fig:plot115-fig).</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="#cb255-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(<span class="cf">function</span>(x)<span class="dv">2</span><span class="sc">*</span>x,.<span class="dv">1</span>,.<span class="dv">75</span>)</span></code></pre></div>
<pre><code>## 0.5525 with absolute error &lt; 6.1e-15</code></pre>
<p>Alternatively, <span class="math inline">\(\mbox{P}(0.1\leq X &lt; 0.75) = \mbox{P}(X &lt; 0.75) -\mbox{P}(x \leq 0.1) = F(0.75)-F(0.1)=0.75^2-0.1^2 =0.5525\)</span></p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Fx</span>(<span class="fl">0.75</span>)<span class="sc">-</span><span class="fu">Fx</span>(<span class="fl">0.1</span>)</span></code></pre></div>
<pre><code>## [1] 0.5525</code></pre>
<p>Notice for a continuous random variable, we are loose with the use of the <code>=</code> sign. This is because for a continuous random variable <span class="math inline">\(\mbox{P}(X=x)=0\)</span>. Do not get sloppy when working with discrete random variables.</p>
<div class="figure" style="text-align: center">
<img src="11-Continuous-Random-Variables_files/figure-html/plot115-fig-1.png" alt="Probability represented by shaded area" width="672" />
<p class="caption">
(#fig:plot115-fig)Probability represented by shaded area
</p>
</div>
<p>The median of <span class="math inline">\(X\)</span> is the value <span class="math inline">\(x\)</span> such that <span class="math inline">\(\mbox{P}(X\leq x)=0.5\)</span>, the area under a single point is 0. So we simply solve <span class="math inline">\(x^2=0.5\)</span> for <span class="math inline">\(x\)</span>. Thus, the median of <span class="math inline">\(X\)</span> is <span class="math inline">\(\sqrt{0.5}=0.707\)</span>.</p>
<p>Or using <code>R</code></p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="#cb259-1" aria-hidden="true" tabindex="-1"></a><span class="fu">uniroot</span>(<span class="cf">function</span>(x)(<span class="fu">Fx</span>(x)<span class="sc">-</span>.<span class="dv">5</span>),<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))<span class="sc">$</span>root</span></code></pre></div>
<pre><code>## [1] 0.7071067</code></pre>
</div>
<div id="simulation-1" class="section level3" number="11.2.4">
<h3><span class="header-section-number">11.2.4</span> Simulation</h3>
<p>As in the case of the discrete random variable, we can simulate a continuous random variable if we have an inverse for the cdf. The range of the cdf is <span class="math inline">\([0,1]\)</span>, so we generate a random number in this interval and then apply the inverse cdf to obtain a random variable. In a similar manner, for a continuous random variable, we use the following pseudo code:<br />
1. Generate a random number in the interval <span class="math inline">\([0,1]\)</span>, <span class="math inline">\(U\)</span>.<br />
2. Find the random variable <span class="math inline">\(X\)</span> from <span class="math inline">\(F_{X}^{-1}(U)\)</span>.<br />
In <code>R</code> for our example, this looks like the following.</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">1</span>))</span></code></pre></div>
<pre><code>## [1] 0.6137365</code></pre>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">1</span>))</span></code></pre></div>
<div style="page-break-after: always;"></div>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="#cb264-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(results)</span></code></pre></div>
<pre><code>## 
## quantitative variables:  
##      name   class         min        Q1    median        Q3       max      mean
## ...1 sqrt numeric 0.005321359 0.4977011 0.7084257 0.8656665 0.9999873 0.6669452
##             sd     n missing
## ...1 0.2358056 10000       0</code></pre>
<div style="page-break-after: always;"></div>
<p>Figure @ref(fig:plot116-fig) is a density plot of the simulated density function.</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb266-2"><a href="#cb266-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_density</span>(<span class="sc">~</span>sqrt,<span class="at">xlab=</span><span class="st">&quot;X&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb266-3"><a href="#cb266-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb266-4"><a href="#cb266-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;X&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="11-Continuous-Random-Variables_files/figure-html/plot116-fig-1.png" alt="Density plot of the simulated random variable." width="672" />
<p class="caption">
(#fig:plot116-fig)Density plot of the simulated random variable.
</p>
</div>
</div>
</div>
<div id="moments-1" class="section level2" number="11.3">
<h2><span class="header-section-number">11.3</span> Moments</h2>
<p>As with discrete random variables, moments can be calculated to summarize characteristics such as center and spread. In the discrete case, expectation is found by multiplying each possible value by its associated probability and summing across the domain (<span class="math inline">\(\mbox{E}(X)=\sum_x x\cdot f_X(x)\)</span>). In the continuous case, the domain of <span class="math inline">\(X\)</span> consists of an infinite set of values. From your calculus days, recall that the sum across an infinite domain is represented by an integral.</p>
<p>Let <span class="math inline">\(g(X)\)</span> be any function of <span class="math inline">\(X\)</span>. The expectation of <span class="math inline">\(g(X)\)</span> is found by:
<span class="math display">\[
\mbox{E}(g(X)) = \int_{S_X} g(x)f_X(x)\mathop{}\!\mathrm{d}x
\]</span></p>
<div id="mean-and-variance" class="section level3" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> Mean and variance</h3>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable. The mean of <span class="math inline">\(X\)</span>, or <span class="math inline">\(\mu_X\)</span>, is simply <span class="math inline">\(\mbox{E}(X)\)</span>. Thus,
<span class="math display">\[
\mbox{E}(X)=\int_{S_X}x\cdot f_X(x)\mathop{}\!\mathrm{d}x
\]</span></p>
<p>As in the discrete case, the variance of <span class="math inline">\(X\)</span> is the expected squared difference from the mean, or <span class="math inline">\(\mbox{E}[(X-\mu_X)^2]\)</span>. Thus,
<span class="math display">\[
\sigma^2_X = \mbox{Var}(X)=\mbox{E}[(X-\mu_X)^2]= \int_{S_X} (x-\mu_X)^2\cdot f_X(x) \mathop{}\!\mathrm{d}x
\]</span></p>
<p>Recall homework problem 6 from the last chapter. In this problem, you showed that <span class="math inline">\(\mbox{Var}(X)=\mbox{E}(X^2)-\mbox{E}(X)^2\)</span>. Thus,
<span class="math display">\[
\mbox{Var}(X)=\mbox{E}(X^2)-\mbox{E}(X)^2 = \int_{S_X} x^2\cdot f_X(x)\mathop{}\!\mathrm{d}x - \mu_X^2
\]</span></p>
<blockquote>
<p><em>Example</em>:<br />
Consider the random variable <span class="math inline">\(X\)</span> from above. Find the mean and variance of <span class="math inline">\(X\)</span>.
<span class="math display">\[
\mu_X= \mbox{E}(X)=\int_0^1 x\cdot 2x\mathop{}\!\mathrm{d}x = \frac{2x^3}{3}\bigg|_0^1 = \frac{2}{3}=0.667
\]</span></p>
</blockquote>
<p>Side note: Since the mean of <span class="math inline">\(X\)</span> is smaller than the median of <span class="math inline">\(X\)</span>, we say that <span class="math inline">\(X\)</span> is skewed to the left, or negatively skewed.</p>
<p>Using <code>R</code>.</p>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(<span class="cf">function</span>(x)x<span class="sc">*</span><span class="dv">2</span><span class="sc">*</span>x,<span class="dv">0</span>,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 0.6666667 with absolute error &lt; 7.4e-15</code></pre>
<p>Or using <code>antiD()</code></p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="#cb269-1" aria-hidden="true" tabindex="-1"></a>Ex<span class="ot">&lt;-</span><span class="fu">antiD</span>(<span class="dv">2</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span><span class="sc">~</span>x)</span>
<span id="cb269-2"><a href="#cb269-2" aria-hidden="true" tabindex="-1"></a><span class="fu">Ex</span>(<span class="dv">1</span>)<span class="sc">-</span><span class="fu">Ex</span>(<span class="dv">0</span>)</span></code></pre></div>
<pre><code>## [1] 0.6666667</code></pre>
<p>Using our simulation.</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="#cb271-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="sc">~</span>sqrt,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>## [1] 0.6669452</code></pre>
<p><span class="math display">\[
\sigma^2_X = \mbox{Var}(X)= \mbox{E}(X^2)-\mbox{E}(X)^2 = \int_0^1 x^2\cdot 2x\mathop{}\!\mathrm{d}x - \left(\frac{2}{3}\right)^2 = \frac{2x^4}{4}\bigg|_0^1-\frac{4}{9}=\frac{1}{2}-\frac{4}{9}=\frac{1}{18}=0.056
\]</span></p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="#cb273-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(<span class="cf">function</span>(x)x<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="dv">2</span><span class="sc">*</span>x,<span class="dv">0</span>,<span class="dv">1</span>)<span class="sc">$</span>value<span class="sc">-</span>(<span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 0.05555556</code></pre>
<p>or</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a>Vx<span class="ot">&lt;-</span><span class="fu">antiD</span>(x<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="dv">2</span><span class="sc">*</span>x<span class="sc">~</span>x)</span>
<span id="cb275-2"><a href="#cb275-2" aria-hidden="true" tabindex="-1"></a><span class="fu">Vx</span>(<span class="dv">1</span>)<span class="sc">-</span><span class="fu">Vx</span>(<span class="dv">0</span>)<span class="sc">-</span>(<span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 0.05555556</code></pre>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="#cb277-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(<span class="sc">~</span>sqrt,<span class="at">data=</span>results)<span class="sc">*</span><span class="dv">9999</span><span class="sc">/</span><span class="dv">10000</span></span></code></pre></div>
<pre><code>## [1] 0.05559873</code></pre>
<p>And finally, the standard deviation of <span class="math inline">\(X\)</span> is <span class="math inline">\(\sigma_X = \sqrt{\sigma^2_X}=\sqrt{1/18}=0.236\)</span>.</p>
</div>
</div>
<div id="homework-problems-10" class="section level2" number="11.4">
<h2><span class="header-section-number">11.4</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(X\)</span> be a continuous random variable on the domain <span class="math inline">\(-k \leq X \leq k\)</span>. Also, let <span class="math inline">\(f(x)=\frac{x^2}{18}\)</span>.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Assume that <span class="math inline">\(f(x)\)</span> is a valid pdf. Find the value of <span class="math inline">\(k\)</span>.<br />
</li>
<li>Plot the pdf of <span class="math inline">\(X\)</span>.<br />
</li>
<li>Find and plot the cdf of <span class="math inline">\(X\)</span>.<br />
</li>
<li>Find <span class="math inline">\(\mbox{P}(X&lt;1)\)</span>.<br />
</li>
<li>Find <span class="math inline">\(\mbox{P}(1.5&lt;X\leq 2.5)\)</span>.<br />
</li>
<li>Find the 80th percentile of <span class="math inline">\(X\)</span> (the value <span class="math inline">\(x\)</span> for which 80% of the distribution is to the left of that value).<br />
</li>
<li>Find the value <span class="math inline">\(x\)</span> such that <span class="math inline">\(\mbox{P}(-x \leq X \leq x)=0.4\)</span>.<br />
</li>
<li>Find the mean and variance of <span class="math inline">\(X\)</span>.<br />
</li>
<li>Simulate 10000 values from this distribution and plot the density.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Let <span class="math inline">\(X\)</span> be a continuous random variable. Prove that the cdf of <span class="math inline">\(X\)</span>, <span class="math inline">\(F_X(x)\)</span> is a non-decreasing function. (Hint: show that for any <span class="math inline">\(a &lt; b\)</span>, <span class="math inline">\(F_X(a) \leq F_X(b)\)</span>.)</li>
</ol>
<!--chapter:end:11-Continuous-Random-Variables.Rmd-->
</div>
</div>
<div id="DISCRETENAMED" class="section level1" number="12">
<h1><span class="header-section-number">12</span> Named Discrete Distributions</h1>
<div id="objectives-11" class="section level2" number="12.1">
<h2><span class="header-section-number">12.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Recognize and setup for use common discrete distributions (Uniform, Binomial, Poisson, Hypergeometric) to include parameters, assumptions, and moments.<br />
</li>
<li>Use <code>R</code> to calculate probabilities and quantiles involving random variables with common discrete distributions.</li>
</ol>
</div>
<div id="named-distributions" class="section level2" number="12.2">
<h2><span class="header-section-number">12.2</span> Named distributions</h2>
<p>In the previous two lessons, we introduced the concept of random variables, distribution functions, and expectations. In some cases, the nature of an experiment may yield random variables with common distributions. In these cases, we can rely on easy-to-use distribution functions and built-in <code>R</code> functions in order to calculate probabilities and quantiles.</p>
<div id="discrete-uniform-distribution" class="section level3" number="12.2.1">
<h3><span class="header-section-number">12.2.1</span> Discrete uniform distribution</h3>
<p>The first distribution we will discuss is the discrete uniform distribution. It is not a very commonly used distribution, especially compared to its continuous counterpart. A discrete random variable has the discrete uniform distribution if probability is evenly allocated to each value in the sample space. A variable with this distribution has parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> representing the minimum and maximum of the sample space, respectively. (By default, that sample space is assumed to consist of integers only, but that is by no means always the case.)</p>
<blockquote>
<p><em>Example</em>:<br />
Rolling a fair die is an example of the discrete uniform. Each side of the die has an equal probability.</p>
</blockquote>
<p>Let <span class="math inline">\(X\)</span> be a discrete random variable with the uniform distribution. If the sample space is consecutive integers, this distribution is denoted as <span class="math inline">\(X\sim\textsf{DUnif}(a,b)\)</span>. The pmf of <span class="math inline">\(X\)</span> is given by:
<span class="math display">\[
f_X(x)=\left\{\begin{array}{ll}\frac{1}{b-a+1}, &amp; x \in \{a, a+1,...,b\} \\
0, &amp; \mbox{otherwise} \end{array}\right.
\]</span></p>
<p>For the die:<br />
<span class="math display">\[
f_X(x)=\left\{\begin{array}{ll}\frac{1}{6-1+1} = \frac{1}{6}, &amp; x \in \{1, 2,...,6\} \\
0, &amp; \mbox{otherwise} \end{array}\right.
\]</span></p>
<p>The expected value of <span class="math inline">\(X\)</span> is found by:
<span class="math display">\[
\mbox{E}(X)=\sum_{x=a}^b x\cdot\frac{1}{b-a+1}= \frac{1}{b-a+1} \cdot \sum_{x=a}^b x=\frac{1}{b-a+1}\cdot\frac{b-a+1}{2}\cdot (a+b) = \frac{a+b}{2}
\]</span></p>
<p>Where the sum of consecutive integers is a common result from discrete math, research it for more information.</p>
<p>The variance of <span class="math inline">\(X\)</span> is found by: (derivation not included)
<span class="math display">\[
\mbox{Var}(X)=\mbox{E}[(X-\mbox{E}(X))^2]=\frac{(b-a+1)^2-1}{12}
\]</span></p>
<p>Summarizing for the die:</p>
<p>Let <span class="math inline">\(X\)</span> be the result of a single roll of a fair die. We will report the distribution of <span class="math inline">\(X\)</span>, the pmf, <span class="math inline">\(\mbox{E}(X)\)</span> and <span class="math inline">\(\mbox{Var}(X)\)</span>.</p>
<p>The sample space of <span class="math inline">\(X\)</span> is <span class="math inline">\(S_X=\{1,2,3,4,5,6\}\)</span>. Since each of those outcomes is equally likely, <span class="math inline">\(X\)</span> follows the discrete uniform distribution with <span class="math inline">\(a=1\)</span> and <span class="math inline">\(b=6\)</span>. Thus,
<span class="math display">\[
f_X(x)=\left\{\begin{array}{ll}\frac{1}{6}, &amp; x \in \{1,2,3,4,5,6\} \\
0, &amp; \mbox{otherwise} \end{array}\right.
\]</span></p>
<p>Finally, <span class="math inline">\(\mbox{E}(X)=\frac{1+6}{2}=3.5\)</span>. Also, <span class="math inline">\(\mbox{Var}(X)=\frac{(6-1+1)^2-1}{12}=\frac{35}{12}=2.917\)</span>.</p>
</div>
<div id="simulating" class="section level3" number="12.2.2">
<h3><span class="header-section-number">12.2.2</span> Simulating</h3>
<p>To simulate the discrete uniform, we use <code>sample()</code>.</p>
<blockquote>
<p><em>Example</em>:<br />
To simulate rolling a die 4 times, we use <code>sample()</code>.</p>
</blockquote>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="#cb279-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">61</span>)</span>
<span id="cb279-2"><a href="#cb279-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,<span class="dv">4</span>,<span class="at">replace=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 4 2 2 1</code></pre>
<p>Let’s roll it 10,000 times and find</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="#cb281-1" aria-hidden="true" tabindex="-1"></a>results<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,<span class="dv">1</span>,<span class="at">replace=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>sample,<span class="at">data=</span>results,<span class="at">format=</span><span class="st">&quot;percent&quot;</span>)</span></code></pre></div>
<pre><code>## sample
##     1     2     3     4     5     6 
## 16.40 16.46 16.83 17.15 16.92 16.24</code></pre>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="sc">~</span>sample,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>## [1] 3.5045</code></pre>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(<span class="sc">~</span>sample,<span class="at">data=</span>results)<span class="sc">*</span>(<span class="dv">10000-1</span>)<span class="sc">/</span><span class="dv">10000</span></span></code></pre></div>
<pre><code>## [1] 2.87598</code></pre>
<p>Again as a reminder, we multiply by <span class="math inline">\(\frac{(10000-1)}{10000}\)</span> because the function <code>var()</code> is calculating a sample variance using <span class="math inline">\(n-1\)</span> in the denominator but we need the population variance.</p>
</div>
<div id="binomial-distribution" class="section level3" number="12.2.3">
<h3><span class="header-section-number">12.2.3</span> Binomial distribution</h3>
<p>The binomial distribution is extremely common, and appears in many situations. In fact, we have already discussed several examples where the binomial distribution is heavily involved.</p>
<p>Consider an experiment involving repeated <em>independent trials</em> of a binary process (two outcomes), where in each trial, there is a <em>constant probability</em> of “success” (one of the outcomes which is arbitrary). If the random variable <span class="math inline">\(X\)</span> represents the number of successes out of <span class="math inline">\(n\)</span> independent trials, then <span class="math inline">\(X\)</span> is said to follow the binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span> (the probability of a success in each trial).</p>
<p>The pmf of <span class="math inline">\(X\)</span> is given by:
<span class="math display">\[
f_X(x)=\mbox{P}(X=x)={n\choose{x}}p^x(1-p)^{n-x}
\]</span></p>
<p>for <span class="math inline">\(x \in \{0,1,...,n\}\)</span> and 0 otherwise.</p>
<p>Let’s take a moment to dissect this pmf. We are looking for the probability of obtaining <span class="math inline">\(x\)</span> successes out of <span class="math inline">\(n\)</span> trials. The <span class="math inline">\(p^x\)</span> represents the probability of <span class="math inline">\(x\)</span> successes, using the multiplication rule because of the independence assumption. The term <span class="math inline">\((1-p)^{n-x}\)</span> represents the probability of the remainder of the trials as failures. Finally, the <span class="math inline">\(n\choose x\)</span> term represents the number of ways to obtain <span class="math inline">\(x\)</span> successes out of <span class="math inline">\(n\)</span> trials. For example, there are three ways to obtain 1 success out of 3 trials (one success followed by two failures; one success, one failure then one success; or two failures followed by a success).</p>
<p>The expected value of a binomially distributed random variable is given by <span class="math inline">\(\mbox{E}(X)=np\)</span> and the variance is given by <span class="math inline">\(\mbox{Var}(X)=np(1-p)\)</span>.</p>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X\)</span> be the number of heads out of 20 independent flips of a fair coin. Note that this is a binomial because the trials are independent and the probability of success, in this case a heads, is constant, and there are two outcomes. Find the distribution, mean and variance of <span class="math inline">\(X\)</span>. Find <span class="math inline">\(\mbox{P}(X=8)\)</span>. Find <span class="math inline">\(\mbox{P}(X\leq 8)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(X\)</span> has the binomial distribution with <span class="math inline">\(n=20\)</span> and <span class="math inline">\(p=0.5\)</span>. The pmf is given by:
<span class="math display">\[
f_X(x)=\mbox{P}(X=x)={20 \choose x}0.5^x (1-0.5)^{20-x}
\]</span></p>
<p>Also, <span class="math inline">\(\mbox{E}(X)=20*0.5=10\)</span> and <span class="math inline">\(\mbox{Var}(X)=20*0.5*0.5=5\)</span>.</p>
<p>To find <span class="math inline">\(\mbox{P}(X=8)\)</span>, we can simply use the pmf:
<span class="math display">\[
\mbox{P}(X=8)=f_X(8)={20\choose 8}0.5^8 (1-0.5)^{12}
\]</span></p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a><span class="fu">choose</span>(<span class="dv">20</span>,<span class="dv">8</span>)<span class="sc">*</span><span class="fl">0.5</span><span class="sc">^</span><span class="dv">8</span><span class="sc">*</span>(<span class="dv">1</span><span class="fl">-0.5</span>)<span class="sc">^</span><span class="dv">12</span></span></code></pre></div>
<pre><code>## [1] 0.1201344</code></pre>
<p>To find <span class="math inline">\(\mbox{P}(X\leq 8)\)</span>, we would need to find the cumulative probability:
<span class="math display">\[
\mbox{P}(X\leq 8)=\sum_{x=0}^8 {20\choose 8}0.5^x (1-0.5)^{20-x}
\]</span></p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span><span class="dv">0</span><span class="sc">:</span><span class="dv">8</span></span>
<span id="cb290-2"><a href="#cb290-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">choose</span>(<span class="dv">20</span>,x)<span class="sc">*</span><span class="fl">0.5</span><span class="sc">^</span>x<span class="sc">*</span>(<span class="dv">1</span><span class="fl">-.5</span>)<span class="sc">^</span>(<span class="dv">20</span><span class="sc">-</span>x))</span></code></pre></div>
<pre><code>## [1] 0.2517223</code></pre>
</div>
<div id="software-functions" class="section level3" number="12.2.4">
<h3><span class="header-section-number">12.2.4</span> Software Functions</h3>
<p>One of the advantages of using named distributions is that most software packages have built-in functions that compute probabilities and quantiles for common named distributions. Over the course of this lesson, you will notice that each named distribution is treated similarly in <code>R</code>. There are four main functions tied to each distribution. For the binomial distribution, these are <code>dbinom()</code>, <code>pbinom()</code>, <code>qbinom()</code>, and <code>rbinom()</code>.</p>
<p><code>dbinom()</code>: This function is equivalent to the probability mass function. We use this to find <span class="math inline">\(\mbox{P}(X=x)\)</span> when <span class="math inline">\(X\sim \textsf{Binom}(n,p)\)</span>. This function takes three inputs: <code>x</code> (the value of the random variable), <code>size</code> (the number of trials, <span class="math inline">\(n\)</span>), and <code>prob</code> (the probability of success, <span class="math inline">\(p\)</span>). So,
<span class="math display">\[
\mbox{P}(X=x)={n\choose{x}}p^x(1-p)^{n-x}=\textsf{dbinom(x,n,p)}
\]</span></p>
<p><code>pbinom()</code>: This function is equivalent to the cumulative distribution function. We use this to find <span class="math inline">\(\mbox{P}(X\leq x)\)</span> when <span class="math inline">\(X\sim \textsf{Binom}(n,p)\)</span>. This function takes the same inputs as <code>dbinom()</code> but returns the cumulative probability:
<span class="math display">\[
\mbox{P}(X\leq x)=\sum_{k=0}^x{n\choose{k}}p^k(1-p)^{n-k}=\textsf{pbinom(x,n,p)}
\]</span></p>
<p><code>qbinom()</code>: This is the inverse of the cumulative distribution function and will return a percentile. This function has three inputs: <code>p</code> (a probability), <code>size</code> and <code>prob</code>. It returns the smallest value <span class="math inline">\(x\)</span> such that <span class="math inline">\(\mbox{P}(X\leq x) \geq p\)</span>.</p>
<p><code>rbinom()</code>: This function is used to randomly generate values from the binomial distribution. It takes three inputs: <code>n</code> (the number of values to generate), <code>size</code> and <code>prob</code>. It returns a vector containing the randomly generated values.</p>
<p>To learn more about these functions, type <code>?</code> followed the function in the console.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Use the built-in functions for the binomial distribution to plot the pmf of <span class="math inline">\(X\)</span> from the previous example. Also, use the built-in functions to compute the probabilities from the example.</p>
</blockquote>
<p>Figure @ref(fig:binom-fig)</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;binom&quot;</span>,<span class="at">size=</span><span class="dv">20</span>,<span class="at">prob=</span>.<span class="dv">5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb292-2"><a href="#cb292-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb292-3"><a href="#cb292-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;X&quot;</span>,<span class="at">y=</span><span class="st">&quot;P(X=x)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="12-Named-Discrete-Distributions_files/figure-html/binom-fig-1.png" alt="The pmf of a binomial random variable" width="672" />
<p class="caption">
(#fig:binom-fig)The pmf of a binomial random variable
</p>
</div>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="do">###P(X=8)</span></span>
<span id="cb293-2"><a href="#cb293-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">8</span>,<span class="dv">20</span>,<span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0.1201344</code></pre>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="do">###P(X&lt;=8)</span></span>
<span id="cb295-2"><a href="#cb295-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">8</span>,<span class="dv">20</span>,<span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0.2517223</code></pre>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or </span></span>
<span id="cb297-2"><a href="#cb297-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">8</span>,<span class="dv">20</span>,<span class="fl">0.5</span>))</span></code></pre></div>
<pre><code>## [1] 0.2517223</code></pre>
</div>
<div id="poisson-distribution" class="section level3" number="12.2.5">
<h3><span class="header-section-number">12.2.5</span> Poisson distribution</h3>
<p>The Poisson distribution is very common when considering count or arrival data. Consider a random process where events occur according to some rate over time (think arrivals to a retail register). Often, these events are modeled with the <em>Poisson process</em>. The Poisson process assumes a consistent rate of arrival and a memoryless arrival process (the time until the next arrival is independent of time since the last arrival). If we assume a particular process is a Poisson process, then there are two random variables that take common named distributions. The number of arrivals in a specified amount of time follows the <em>Poisson</em> distribution. Also, the amount of time until the next arrival follows the <em>exponential</em> distribution. We will defer discussion of the exponential distribution until the next lesson. What is random in the <em>Poisson</em> is the number of occurrences while the interval is fixed. That is why it is a discrete distribution. The parameter <span class="math inline">\(\lambda\)</span> is the average number of occurrences in the specific interval, note that the interval must be the same as is specified in the random variable.</p>
<p>Let <span class="math inline">\(X\)</span> be the number of arrivals in a length of time, <span class="math inline">\(T\)</span>, where arrivals occur according to a Poisson process with an average of <span class="math inline">\(\lambda\)</span> arrivals in length of time <span class="math inline">\(T\)</span>. Then <span class="math inline">\(X\)</span> follows a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>:
<span class="math display">\[
X\sim \textsf{Poisson}(\lambda)
\]</span></p>
<p>The pmf of <span class="math inline">\(X\)</span> is given by:
<span class="math display">\[
f_X(x)=\mbox{P}(X=x)=\frac{\lambda^xe^{-\lambda}}{x!}, \hspace{0.5cm} x=0,1,2,...
\]</span></p>
<p>One unique feature of the Poisson distribution is that <span class="math inline">\(\mbox{E}(X)=\mbox{Var}(X)=\lambda\)</span>.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose fleet vehicles arrive to a maintenance garage at an average rate of 0.4 per day. Let’s assume that these vehicles arrive according to a Poisson process. Let <span class="math inline">\(X\)</span> be the number of vehicles that arrive to the garage in a week (7 days). Notice that the time interval has changed! What is the random variable <span class="math inline">\(X\)</span>? What is the distribution (with parameter) of <span class="math inline">\(X\)</span>. What are <span class="math inline">\(\mbox{E}(X)\)</span> and <span class="math inline">\(\mbox{Var}(X)\)</span>? Find <span class="math inline">\(\mbox{P}(X=0)\)</span>, <span class="math inline">\(\mbox{P}(X\leq 6)\)</span>, <span class="math inline">\(\mbox{P}(X \geq 2)\)</span>, and <span class="math inline">\(\mbox{P}(2 \leq X \leq 8)\)</span>. Also, find the median of <span class="math inline">\(X\)</span>, and the 95th percentile of <span class="math inline">\(X\)</span> (the value of <span class="math inline">\(x\)</span> such that <span class="math inline">\(\mbox{P}(X\leq x)\geq 0.95\)</span>). Further, plot the pmf of <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p>Since vehicles arrive according to a Poisson process, the probability question leads us to define the random variable <span class="math inline">\(X\)</span> as <em>The number of vehicles that arrive in a week</em>.</p>
<p>We know that <span class="math inline">\(X\sim \textsf{Poisson}(\lambda=0.4*7=2.8)\)</span>. Thus, <span class="math inline">\(\mbox{E}(X)=\mbox{Var}(X)=2.8\)</span>.</p>
<p>The parameter is the average number of vehicles that arrive in a <strong>week</strong>.</p>
<p><span class="math display">\[
\mbox{P}(X=0)=\frac{2.8^0 e^{-2.8}}{0!}=e^{-2.8}=0.061
\]</span></p>
<p>Alternatively, we can use the built-in <code>R</code> functions for the Poisson distribution:</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="do">##P(X=0)</span></span>
<span id="cb299-2"><a href="#cb299-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dpois</span>(<span class="dv">0</span>,<span class="fl">2.8</span>)</span></code></pre></div>
<pre><code>## [1] 0.06081006</code></pre>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="#cb301-1" aria-hidden="true" tabindex="-1"></a><span class="do">##P(X&lt;=6)</span></span>
<span id="cb301-2"><a href="#cb301-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ppois</span>(<span class="dv">6</span>,<span class="fl">2.8</span>)</span></code></pre></div>
<pre><code>## [1] 0.9755894</code></pre>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="#cb303-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or</span></span>
<span id="cb303-2"><a href="#cb303-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">6</span>,<span class="fl">2.8</span>))</span></code></pre></div>
<pre><code>## [1] 0.9755894</code></pre>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a><span class="do">##P(X&gt;=2)=1-P(X&lt;2)=1-P(X&lt;=1)</span></span>
<span id="cb305-2"><a href="#cb305-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">ppois</span>(<span class="dv">1</span>,<span class="fl">2.8</span>)</span></code></pre></div>
<pre><code>## [1] 0.7689218</code></pre>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="#cb307-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or</span></span>
<span id="cb307-2"><a href="#cb307-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dpois</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">1000</span>,<span class="fl">2.8</span>))</span></code></pre></div>
<pre><code>## [1] 0.7689218</code></pre>
<p>Note that when considering <span class="math inline">\(\mbox{P}(X\geq 2)\)</span>, we recognize that this is equivalent to <span class="math inline">\(1-\mbox{P}(X\leq 1)\)</span>. We can use <code>ppois()</code> to find this probability.</p>
<p>When considering <span class="math inline">\(\mbox{P}(2\leq X \leq 8)\)</span>, we need to make sure we formulate this correctly. Below are two possible methods:</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="#cb309-1" aria-hidden="true" tabindex="-1"></a><span class="do">##P(2 &lt;= X &lt;= 8) = P(X &lt;= 8)-P(X &lt;= 1)</span></span>
<span id="cb309-2"><a href="#cb309-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ppois</span>(<span class="dv">8</span>,<span class="fl">2.8</span>)<span class="sc">-</span><span class="fu">ppois</span>(<span class="dv">1</span>,<span class="fl">2.8</span>)</span></code></pre></div>
<pre><code>## [1] 0.766489</code></pre>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="#cb311-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or</span></span>
<span id="cb311-2"><a href="#cb311-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dpois</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">8</span>,<span class="fl">2.8</span>))</span></code></pre></div>
<pre><code>## [1] 0.766489</code></pre>
<p>To find the median and the 95th percentiles, we use <code>qpois</code>:</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qpois</span>(<span class="fl">0.5</span>,<span class="fl">2.8</span>)</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="#cb315-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qpois</span>(<span class="fl">0.95</span>,<span class="fl">2.8</span>)</span></code></pre></div>
<pre><code>## [1] 6</code></pre>
<p>Figure @ref(fig:pois-fig) is a plot of the pmf of a Poisson random variable.</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="#cb317-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;pois&quot;</span>,<span class="at">lambda=</span><span class="fl">2.8</span>) <span class="sc">%&gt;%</span></span>
<span id="cb317-2"><a href="#cb317-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb317-3"><a href="#cb317-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;X&quot;</span>,<span class="at">y=</span><span class="st">&quot;P(X=x)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="12-Named-Discrete-Distributions_files/figure-html/pois-fig-1.png" alt="The pmf of a Poisson random variable." width="672" />
<p class="caption">
(#fig:pois-fig)The pmf of a Poisson random variable.
</p>
</div>
<p>Figure @ref(fig:pois2-fig) is the cdf of the same Poisson random variable in Figure @ref(fig:pois-fig).</p>
<p>(ref:quote121) The cdf of the Poisson random variable in Figure @ref(fig:pois-fig)</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;pois&quot;</span>,<span class="at">lambda=</span><span class="fl">2.8</span>,<span class="at">kind=</span><span class="st">&quot;cdf&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb318-2"><a href="#cb318-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb318-3"><a href="#cb318-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;X&quot;</span>,<span class="at">y=</span><span class="st">&quot;P(X&lt;=x)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="12-Named-Discrete-Distributions_files/figure-html/pois2-fig-1.png" alt="(ref:quote121)" width="672" />
<p class="caption">
(#fig:pois2-fig)(ref:quote121)
</p>
</div>
</div>
<div id="hypergeometric" class="section level3" number="12.2.6">
<h3><span class="header-section-number">12.2.6</span> Hypergeometric</h3>
<p>Consider an experiment where <span class="math inline">\(k\)</span> objects are to be selected from a larger, but finite, group consisting of <span class="math inline">\(m\)</span> “successes” and <span class="math inline">\(n\)</span> “failures”. This is similar to the binomial process; after all, we are selecting successes and failures. However, in this case, the results are effectively selected <em>without replacement</em>. If the random variable <span class="math inline">\(X\)</span> represents the number of successes selected in our sample of size <span class="math inline">\(k\)</span>, then <span class="math inline">\(X\)</span> follows a hypergeometric distribution with parameters <span class="math inline">\(m\)</span>, <span class="math inline">\(n\)</span>, and <span class="math inline">\(k\)</span>. The pmf of <span class="math inline">\(X\)</span> is given by:</p>
<p><span class="math display">\[
f_X(x) = \frac{{m \choose{x}}{n \choose{k-x}}}{{m+n \choose{k}}}, \qquad x = 0,1,...,m
\]</span></p>
<p>Also, <span class="math inline">\(\mbox{E}(X)=\frac{km}{m+n}\)</span> and <span class="math inline">\(\mbox{Var}(X)=k\frac{m}{m+n}\frac{n}{m+n}\frac{m+n-k}{m+n-1}\)</span></p>
<p>If you draw on your knowledge of combinations, you can see why this pmf makes sense.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose a bag contains 12 red chips and 8 black chips. I reach in blindly and randomly select 6 chips. What is the probability I select no black chips? All black chips? Between 2 and 5 black chips?</p>
</blockquote>
<p>First we should identify a random variable that will help us with this problem. Let <span class="math inline">\(X\)</span> be the number of black chips selected when randomly selecting 6 from the bag. Then <span class="math inline">\(X\sim \textsf{HyperGeom}(8,12,6)\)</span>. We can use <code>R</code> to find these probabilities.</p>
<p>First, the plot of the pmf of the hypergeometric is in Figure @ref(fig:hyper-fig).</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;hyper&quot;</span>,<span class="at">m=</span><span class="dv">8</span>,<span class="at">n=</span><span class="dv">12</span>,<span class="at">k=</span><span class="dv">6</span>) <span class="sc">%&gt;%</span></span>
<span id="cb319-2"><a href="#cb319-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb319-3"><a href="#cb319-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;X&quot;</span>,<span class="at">y=</span><span class="st">&quot;P(X=x)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="12-Named-Discrete-Distributions_files/figure-html/hyper-fig-1.png" alt="The pmf of a hypergeometric random variable." width="672" />
<p class="caption">
(#fig:hyper-fig)The pmf of a hypergeometric random variable.
</p>
</div>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="do">##P(X=0)</span></span>
<span id="cb320-2"><a href="#cb320-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dhyper</span>(<span class="dv">0</span>,<span class="dv">8</span>,<span class="dv">12</span>,<span class="dv">6</span>)</span></code></pre></div>
<pre><code>## [1] 0.02383901</code></pre>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="#cb322-1" aria-hidden="true" tabindex="-1"></a><span class="do">##P(X=6)</span></span>
<span id="cb322-2"><a href="#cb322-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dhyper</span>(<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">12</span>,<span class="dv">6</span>)</span></code></pre></div>
<pre><code>## [1] 0.0007223942</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="do">##P(2 &lt;= X &lt;=5)</span></span>
<span id="cb324-2"><a href="#cb324-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dhyper</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">12</span>,<span class="dv">6</span>))</span></code></pre></div>
<pre><code>## [1] 0.8119711</code></pre>
</div>
</div>
<div id="homework-problems-11" class="section level2" number="12.3">
<h2><span class="header-section-number">12.3</span> Homework Problems</h2>
<p>For each of the problems below, <strong><em>1)</em></strong> define a random variable that will help you answer the question, <strong><em>2)</em></strong> state the distribution and parameters of that random variable; <strong><em>3)</em></strong> determine the expected value and variance of that random variable, and <strong><em>4)</em></strong> use that random variable to answer the question.</p>
<p>We will demonstrate using 1a and 1b.</p>
<ol style="list-style-type: decimal">
<li>The T-6 training aircraft is used during UPT. Suppose that on each training sortie, aircraft return with a maintenance-related failure at a rate of 1 per 100 sorties.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Find the probability of no maintenance failures in 15 sorties.</li>
</ol>
<p><span class="math inline">\(X\)</span>: the number of maintenance failures in 15 sorties.</p>
<p><span class="math inline">\(X\sim \textsf{Bin}(n=15,p=0.01)\)</span></p>
<p><span class="math inline">\(\mbox{E}(X)=15*0.01=0.15\)</span> and <span class="math inline">\(\mbox{Var}(X)=15*0.01*0.99=0.1485\)</span>.</p>
<p><span class="math inline">\(\mbox{P}(\mbox{No mainteance failures})=\mbox{P}(X=0)={15\choose 0}0.01^0(1-0.01)^{15}=0.99^{15}\)</span></p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="fl">0.99</span><span class="sc">^</span><span class="dv">15</span></span></code></pre></div>
<pre><code>## [1] 0.8600584</code></pre>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="#cb328-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or </span></span>
<span id="cb328-2"><a href="#cb328-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">0</span>,<span class="dv">15</span>,<span class="fl">0.01</span>)</span></code></pre></div>
<pre><code>## [1] 0.8600584</code></pre>
<p>This probability makes sense, since the expected value is fairly low. Because, on average, only 0.15 failures would occur every 15 trials, 0 failures would be a very common result. Graphically, the pmf looks like Figure @ref(fig:hw1a).</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="#cb330-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;binom&quot;</span>,<span class="at">size=</span><span class="dv">15</span>,<span class="at">prob=</span><span class="fl">0.01</span>) <span class="sc">%&gt;%</span></span>
<span id="cb330-2"><a href="#cb330-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb330-3"><a href="#cb330-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;X&quot;</span>,<span class="at">y=</span><span class="st">&quot;P(X=x)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="12-Named-Discrete-Distributions_files/figure-html/hw1a-1.png" alt="The pmf for binomail in Homework Problem 1a." width="672" />
<p class="caption">
(#fig:hw1a)The pmf for binomail in Homework Problem 1a.
</p>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Find the probability of at least two maintenance failures in 15 sorties.</li>
</ol>
<p>We can use the same <span class="math inline">\(X\)</span> as above. Now, we are looking for <span class="math inline">\(\mbox{P}(X\geq 2)\)</span>. This is equivalent to finding <span class="math inline">\(1-\mbox{P}(X\leq 1)\)</span>:</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="#cb331-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Directly</span></span>
<span id="cb331-2"><a href="#cb331-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span>(<span class="fl">0.99</span><span class="sc">^</span><span class="dv">15</span> <span class="sc">+</span> <span class="dv">15</span><span class="sc">*</span><span class="fl">0.01</span><span class="sc">*</span><span class="fl">0.99</span><span class="sc">^</span><span class="dv">14</span>)</span></code></pre></div>
<pre><code>## [1] 0.009629773</code></pre>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="#cb333-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or, using R</span></span>
<span id="cb333-2"><a href="#cb333-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>,<span class="dv">15</span>,<span class="fl">0.01</span>))</span></code></pre></div>
<pre><code>## [1] 0.009629773</code></pre>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="#cb335-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or</span></span>
<span id="cb335-2"><a href="#cb335-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>,<span class="dv">15</span>,<span class="fl">0.01</span>))</span></code></pre></div>
<pre><code>## [1] 0.009629773</code></pre>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="#cb337-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or</span></span>
<span id="cb337-2"><a href="#cb337-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pbinom</span>(<span class="dv">1</span>,<span class="dv">15</span>,<span class="fl">0.01</span>)</span></code></pre></div>
<pre><code>## [1] 0.009629773</code></pre>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="#cb339-1" aria-hidden="true" tabindex="-1"></a><span class="do">## or </span></span>
<span id="cb339-2"><a href="#cb339-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">1</span>,<span class="dv">15</span>,<span class="fl">0.01</span>,<span class="at">lower.tail =</span> F)</span></code></pre></div>
<pre><code>## [1] 0.009629773</code></pre>
<ol start="3" style="list-style-type: lower-alpha">
<li>Find the probability of at least 30 successful (no mx failures) sorties before the first failure.<br />
</li>
<li>Find the probability of at least 50 successful sorties before the third failure.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>On a given Saturday, suppose vehicles arrive at the USAFA North Gate according to a Poisson process at a rate of 40 arrivals per hour.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Find the probability no vehicles arrive in 10 minutes.<br />
</li>
<li>Find the probability at least 50 vehicles arrive in an hour.<br />
</li>
<li>Find the probability that at least 5 minutes will pass before the next arrival.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Suppose there are 12 male and 7 female cadets in a classroom. I select 5 completely at random (without replacement).</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Find the probability I select no female cadets.<br />
</li>
<li>Find the probability I select more than 2 female cadets.</li>
</ol>
<!--chapter:end:12-Named-Discrete-Distributions.Rmd-->
</div>
</div>
<div id="CONTNNAMED" class="section level1" number="13">
<h1><span class="header-section-number">13</span> Named Continuous Distributions</h1>
<div id="objectives-12" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Recognize when to use common continuous distributions (Uniform, Exponential, Gamma, Normal, Weibull, and Beta), identify parameters, and find moments.<br />
</li>
<li>Use <code>R</code> to calculate probabilities and quantiles involving random variables with common continuous distributions.<br />
</li>
<li>Understand the relationship between the Poisson process and the Poisson &amp; Exponential distributions.<br />
</li>
<li>Know when to apply and then use the memoryless property.</li>
</ol>
</div>
<div id="continuous-distributions" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Continuous distributions</h2>
<p>In this lesson we will explore continuous distributions. This means we work with probability density functions and use them to find probabilities. Thus we must integrate, either numerically, graphically, or mathematically. The cumulative distribution function will also play an important role in this lesson.</p>
<p>There are many more distributions than the ones in this lesson but these are the most common and will set you up to learn and use any others in the future.</p>
<div id="uniform-distribution" class="section level3" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Uniform distribution</h3>
<p>The first continuous distribution we will discuss is the uniform distribution. By default, when we refer to the uniform distribution, we are referring to the continuous version. When referring to the discrete version, we use the full term “discrete uniform distribution.”</p>
<p>A continuous random variable has the uniform distribution if probability density is constant, <strong>uniform</strong>. The parameters of this distribution are <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, representing the minimum and maximum of the sample space. This distribution is commonly denoted as <span class="math inline">\(U(a,b)\)</span>.</p>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable with the uniform distribution. This is denoted as <span class="math inline">\(X\sim \textsf{Unif}(a,b)\)</span>. The pdf of <span class="math inline">\(X\)</span> is given by:
<span class="math display">\[
f_X(x)=\left\{\begin{array}{ll} \frac{1}{b-a}, &amp; a\leq x \leq b \\ 0, &amp; \mbox{otherwise} \end{array}\right.
\]</span></p>
<p>The mean of <span class="math inline">\(X\)</span> is <span class="math inline">\(\mbox{E}(X)=\frac{a+b}{2}\)</span> and the variance is <span class="math inline">\(\mbox{Var}(X)=\frac{(b-a)^2}{12}\)</span>. The derivation of the mean is left to the exercises.</p>
<p>The most common uniform distribution is <span class="math inline">\(U(0,1)\)</span> which we have already used several times in this book. Again, notice in Figure @ref(fig:uni-fig) that the plot of the <strong>pdf</strong> is a constant or uniform value.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="#cb341-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;unif&quot;</span>,<span class="at">title=</span><span class="st">&quot;Pdf of Uniform random variable&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;f(x)&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb341-2"><a href="#cb341-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="13-Named-Continuous-Distributions_files/figure-html/uni-fig-1.png" alt="The pdf of Uniform random variable." width="672" />
<p class="caption">
(#fig:uni-fig)The pdf of Uniform random variable.
</p>
</div>
<p>To check that it is a proper pdf, all values must be non-negative and the total probability must be 1. In <code>R</code> the function for probability density will start with the letter <strong>d</strong> and have some short descriptor for the distribution. For the uniform we use <code>dunif()</code>.</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(<span class="cf">function</span>(x)<span class="fu">dunif</span>(x),<span class="dv">0</span>,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 1 with absolute error &lt; 1.1e-14</code></pre>
</div>
<div id="exponential-distribution" class="section level3" number="13.2.2">
<h3><span class="header-section-number">13.2.2</span> Exponential distribution</h3>
<p>Recall from the lesson on named discrete distributions, we discussed the Poisson process. If arrivals follow a Poisson process, we know that the number of arrivals in a specified amount of time follows a Poisson distribution, and the time until the next arrival follows the <em>exponential</em> distribution. In the Poisson distribution, the number of arrivals is random and the interval is fixed. In the exponential distribution we change this, the interval is random and the arrivals are fixed at 1. This is a subtle point but worth the time to make sure you understand.</p>
<p>Let <span class="math inline">\(X\)</span> be the number of arrivals in a time interval <span class="math inline">\(T\)</span>, where arrivals occur according to a Poisson process with an average of <span class="math inline">\(\lambda\)</span> arrivals per unit time interval. From the previous lesson, we know that <span class="math inline">\(X\sim \textsf{Poisson}(\lambda T)\)</span>. Now let <span class="math inline">\(Y\)</span> be the time until the next arrival. Then <span class="math inline">\(Y\)</span> follows the exponential distribution with parameter <span class="math inline">\(\lambda\)</span> which has units of inverse base time:</p>
<p><span class="math display">\[
Y \sim \textsf{Expon}(\lambda)
\]</span></p>
<p>Note on <span class="math inline">\(\lambda\)</span>: One point of confusion involving the parameters of the Poisson and exponential distributions. The parameter of the Poisson distribution (usually denoted as <span class="math inline">\(\lambda\)</span>) represents the average number of arrivals in whatever amount of time specified by the random variable. In the case of the exponential distribution, the parameter (also denoted as <span class="math inline">\(\lambda\)</span>) represents the average number of arrivals per unit time. For example, suppose arrivals follow a Poisson process with an average of 10 arrivals per day. <span class="math inline">\(X\)</span>, the number of arrivals in 5 days, follows a Poisson distribution with parameter <span class="math inline">\(\lambda=50\)</span>, since that is the average number of arrivals in the amount of time specified by <span class="math inline">\(X\)</span>. Meanwhile, <span class="math inline">\(Y\)</span>, the time in days until the next arrival, follows an exponential distribution with parameter <span class="math inline">\(\lambda=10\)</span> (the average number of arrivals per day).</p>
<p>The pdf of <span class="math inline">\(Y\)</span> is given by:
<span class="math display">\[
f_Y(y)=\lambda e^{-\lambda y}, \hspace{0.3cm} y&gt;0
\]</span></p>
<p>The mean and variance of <span class="math inline">\(Y\)</span> are: <span class="math inline">\(\mbox{E}(Y)=\frac{1}{\lambda}\)</span> and <span class="math inline">\(\mbox{Var}(Y)=\frac{1}{\lambda^2}\)</span>. You should be able to derive these results but they require integration by parts and can be lengthy algebraic exercises.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose at a local retail store, customers arrive to a checkout counter according to a Poisson process with an average of one arrival every three minutes. Let <span class="math inline">\(Y\)</span> be the time (in minutes) until the next customer arrives to the counter. What is the distribution (and parameter) of <span class="math inline">\(Y\)</span>? What are <span class="math inline">\(\mbox{E}(Y)\)</span> and <span class="math inline">\(\mbox{Var}(Y)\)</span>? Find <span class="math inline">\(\mbox{P}(Y&gt;5)\)</span>, <span class="math inline">\(\mbox{P}(Y\leq 3)\)</span>, and <span class="math inline">\(\mbox{P}(1 \leq Y &lt; 5)\)</span>? Also, find the median and 95th percentile of <span class="math inline">\(Y\)</span>. Finally, plot the pdf of <span class="math inline">\(Y\)</span>.</p>
</blockquote>
<p>Since one arrival shows up every three minutes, the average number of arrivals per unit time is 1/3 arrival per minute. Thus, <span class="math inline">\(Y\sim \textsf{Expon}(\lambda=1/3)\)</span>. This means that <span class="math inline">\(\mbox{E}(Y)=3\)</span> and <span class="math inline">\(\mbox{Var}(Y)=9\)</span>.</p>
<p>To find <span class="math inline">\(\mbox{P}(Y&gt;5)\)</span>, we could integrate the pdf of <span class="math inline">\(Y\)</span>:
<span class="math display">\[
\mbox{P}(Y&gt;5)=\int_5^\infty \frac{1}{3}e^{-\frac{1}{3}y}\mathop{}\!\mathrm{d}y = \lim_{a \to +\infty}\int_5^a \frac{1}{3}e^{-\frac{1}{3}y}\mathop{}\!\mathrm{d}y = \]</span></p>
<p><span class="math display">\[\lim_{a \to +\infty} -e^{-\frac{1}{3}y}\bigg|_5^a=\lim_{a \to +\infty} -e^{-\frac{a}{3}}-(-e^{-\frac{5}{3}})= 0 + 0.189 = 0.189
\]</span></p>
<p>Alternatively, we could use <code>R</code>:</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Prob(Y&gt;5)=1-Prob(Y&lt;=5)</span></span>
<span id="cb344-2"><a href="#cb344-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pexp</span>(<span class="dv">5</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.1888756</code></pre>
<p>Or using <code>integrate()</code></p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="#cb346-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(<span class="cf">function</span>(x)<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span><span class="sc">*</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">3</span><span class="sc">*</span>x),<span class="dv">5</span>,<span class="cn">Inf</span>)</span></code></pre></div>
<pre><code>## 0.1888756 with absolute error &lt; 8.5e-05</code></pre>
<p>For the remaining probabilities, we will use <code>R</code>:</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="#cb348-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Prob(Y&lt;=3)</span></span>
<span id="cb348-2"><a href="#cb348-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pexp</span>(<span class="dv">3</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.6321206</code></pre>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Prob(1&lt;=Y&lt;5)</span></span>
<span id="cb350-2"><a href="#cb350-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pexp</span>(<span class="dv">5</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)<span class="sc">-</span><span class="fu">pexp</span>(<span class="dv">1</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.5276557</code></pre>
<p>The median is <span class="math inline">\(y\)</span> such that <span class="math inline">\(\mbox{P}(Y\leq y)=0.5\)</span>. We can find this by solving the following for <span class="math inline">\(y\)</span>:
<span class="math display">\[
\int_0^y \frac{1}{3}e^{-\frac{1}{3}y}\mathop{}\!\mathrm{d}y = 0.5
\]</span></p>
<p>Alternatively, we can use <code>qexp</code> in <code>R</code>:</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="#cb352-1" aria-hidden="true" tabindex="-1"></a><span class="do">##median</span></span>
<span id="cb352-2"><a href="#cb352-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qexp</span>(<span class="fl">0.5</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 2.079442</code></pre>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="#cb354-1" aria-hidden="true" tabindex="-1"></a><span class="do">##95th percentile</span></span>
<span id="cb354-2"><a href="#cb354-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qexp</span>(<span class="fl">0.95</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 8.987197</code></pre>
<div class="figure" style="text-align: center">
<img src="13-Named-Continuous-Distributions_files/figure-html/exp-fig-1.png" alt="pdf of exponential random varible $Y$" width="672" />
<p class="caption">
(#fig:exp-fig)pdf of exponential random varible <span class="math inline">\(Y\)</span>
</p>
</div>
<p>Both from Figure @ref(fig:exp-fig) and the mean and median, we know that the exponential distribution is skewed to the right.</p>
</div>
<div id="memoryless-property" class="section level3" number="13.2.3">
<h3><span class="header-section-number">13.2.3</span> Memoryless property</h3>
<p>The Poisson process is known for its <em>memoryless</em> property. Essentially, this means that the time until the next arrival is independent of the time since last arrival. Thus, the probability of an arrival within the next 5 minutes is the same regardless of whether an arrival just occurred or an arrival has not occurred for a long time.</p>
<p>To show this let’s consider random variable <span class="math inline">\(Y\)</span> ( time until the next arrival in minutes) where <span class="math inline">\(Y\sim\textsf{Expon}(\lambda)\)</span>. We will show that, given it has been at least <span class="math inline">\(t\)</span> minutes since the last arrival, the probability we wait at least <span class="math inline">\(y\)</span> additional minutes is equal to the marginal probability that we wait <span class="math inline">\(y\)</span> additional minutes.</p>
<p>First, note that the cdf of <span class="math inline">\(Y\)</span>, <span class="math inline">\(F_Y(y)=\mbox{P}(Y\leq y)=1-e^{-\lambda y}\)</span>, you should be able to derive this. So,
<span class="math display">\[
\mbox{P}(Y\geq y+t|Y\geq t) = \frac{\mbox{P}(Y\geq y+t \cap Y\geq t)}{\mbox{P}(Y\geq t)}=\frac{\mbox{P}(Y\geq y +t)}{\mbox{P}(Y\geq t)} = \frac{1-(1-e^{-(y+t)\lambda})}{1-(1-e^{-t\lambda})}
\]</span>
<span class="math display">\[
=\frac{e^{-\lambda y }e^{-\lambda t}}{e^{-\lambda t }}=e^{-\lambda y} = 1-(1-e^{-\lambda y})=\mbox{P}(Y\geq y).
\blacksquare
\]</span></p>
<p>Let’s simulate values for a Poisson. The Poisson is often used in modeling customer service situations such as service at Chipotle. However, some people have the mistaken idea that arrivals will be equally spaced. In fact, arrivals will come in clusters and bunches. Maybe this is the root of the common expression, “Bad news comes in threes”?</p>
<div class="figure">
<img src="13-Named-Continuous-Distributions_files/figure-html/sim-fig-1.png" alt="Simulations of Poisson random variable." width="672" />
<p class="caption">
(#fig:sim-fig)Simulations of Poisson random variable.
</p>
</div>
<p>In Figure @ref(fig:sim-fig), the number of events in a box is <span class="math inline">\(X\sim \textsf{Poisson}(\lambda = 5)\)</span>. As you can see, some boxes have more than 5 and some less because 5 is the average number of arrivals. Also note that the spacing is not equal. The 8 different runs are just repeated simulations of the same process. We can see spacing and clusters in each run.</p>
</div>
<div id="gamma-distribution" class="section level3" number="13.2.4">
<h3><span class="header-section-number">13.2.4</span> Gamma distribution</h3>
<p>The gamma distribution is a generalization of the exponential distribution. In the exponential distribution, the parameter <span class="math inline">\(\lambda\)</span> is sometimes referred to as the <em>rate</em> parameter. The gamma distribution is sometimes used to model wait times (as with the exponential distribution), but in cases without the memoryless property. The gamma distribution has two parameters, <em>rate</em> and <em>shape</em>. In some texts, <em>scale</em> (the inverse of rate) is used as an alternative parameter to rate.</p>
<p>Suppose <span class="math inline">\(X\)</span> is a random variable with the gamma distribution with shape parameter <span class="math inline">\(\alpha\)</span> and rate parameter <span class="math inline">\(\lambda\)</span>:
<span class="math display">\[
X \sim \textsf{Gamma}(\alpha,\lambda)
\]</span></p>
<p><span class="math inline">\(X\)</span> has the following pdf:
<span class="math display">\[
f_X(x)=\frac{\lambda^\alpha}{\Gamma (\alpha)}x^{\alpha-1}e^{-\lambda x}, \hspace{0.3cm} x&gt;0
\]</span></p>
<p>and 0 otherwise. The mean and variance of <span class="math inline">\(X\)</span> are <span class="math inline">\(\mbox{E}(X)=\frac{\alpha}{\lambda}\)</span> and <span class="math inline">\(\mbox{Var}(X)=\frac{\alpha}{\lambda^2}\)</span>. Looking at the pdf, the mean and the variance, one can easily see that if <span class="math inline">\(\alpha=1\)</span>, the resulting distribution is equivalent to <span class="math inline">\(\textsf{Expon}(\lambda)\)</span>.</p>
<div id="gamma-function" class="section level4" number="13.2.4.1">
<h4><span class="header-section-number">13.2.4.1</span> Gamma function</h4>
<p>You may have little to no background with the Gamma function (<span class="math inline">\(\Gamma (\alpha)\)</span>). This is different from the gamma distribution. The gamma function is simply a function and is defined by:
<span class="math display">\[
\Gamma (\alpha)=\int_0^\infty t^{\alpha-1}e^{-t}\mathop{}\!\mathrm{d}t
\]</span></p>
<p>There are some important properties of the gamma function. Notably, <span class="math inline">\(\Gamma (\alpha)=(\alpha-1)\Gamma (\alpha -1)\)</span>, and if <span class="math inline">\(\alpha\)</span> is a non-negative integer, <span class="math inline">\(\Gamma(\alpha)=(\alpha-1)!\)</span>.</p>
<p>Suppose <span class="math inline">\(X \sim \textsf{Gamma}(\alpha,\lambda)\)</span>. The pdf of <span class="math inline">\(X\)</span> for various values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\lambda\)</span> is shown in Figure @ref(fig:gamma-fig).</p>
<div class="figure" style="text-align: center">
<img src="13-Named-Continuous-Distributions_files/figure-html/gamma-fig-1.png" alt="pdf of Gamma for various values of alpha and lambda" width="672" />
<p class="caption">
(#fig:gamma-fig)pdf of Gamma for various values of alpha and lambda
</p>
</div>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X \sim \textsf{Gamma}(\alpha=5,\lambda=1)\)</span>. Find the mean and variance of <span class="math inline">\(X\)</span>. Also, compute <span class="math inline">\(\mbox{P}(X\leq 2)\)</span> and <span class="math inline">\(\mbox{P}(1\leq X &lt; 8)\)</span>. Find the median and 95th percentile of <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p>The mean and variance of <span class="math inline">\(X\)</span> are <span class="math inline">\(\mbox{E}(X)=5\)</span> and <span class="math inline">\(\mbox{Var}(X)=5\)</span>. To find probabilities and quantiles, integration will be difficult, so it’s best to use the built-in <code>R</code> functions:</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="#cb356-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Prob(X&lt;=2)</span></span>
<span id="cb356-2"><a href="#cb356-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pgamma</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 0.05265302</code></pre>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="#cb358-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Prob(1 &lt;= X &lt; 8)</span></span>
<span id="cb358-2"><a href="#cb358-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pgamma</span>(<span class="dv">8</span>,<span class="dv">5</span>,<span class="dv">1</span>)<span class="sc">-</span><span class="fu">pgamma</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 0.8967078</code></pre>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="#cb360-1" aria-hidden="true" tabindex="-1"></a><span class="do">## median</span></span>
<span id="cb360-2"><a href="#cb360-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qgamma</span>(<span class="fl">0.5</span>,<span class="dv">5</span>,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 4.670909</code></pre>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="#cb362-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 95th percentile</span></span>
<span id="cb362-2"><a href="#cb362-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qgamma</span>(<span class="fl">0.95</span>,<span class="dv">5</span>,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 9.153519</code></pre>
</div>
</div>
<div id="weibull-distribution" class="section level3" number="13.2.5">
<h3><span class="header-section-number">13.2.5</span> Weibull distribution</h3>
<p>Another common distribution used in modeling is the Weibull distribution. Like the gamma, the Weibull distribution is a generalization of the exponential distribution and is meant to model wait times. A random variable with the Weibull distribution has parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. In <code>R</code>, these are referred to as <code>shape</code> and <code>scale</code> respectively. Note that in some resources, these are represented by <span class="math inline">\(k\)</span> and <span class="math inline">\(\lambda\)</span> or even <span class="math inline">\(k\)</span> and <span class="math inline">\(\theta\)</span>.
Let <span class="math inline">\(X \sim \textsf{Weibull}(\alpha,\beta)\)</span>. The pdf of <span class="math inline">\(X\)</span> is given by:
<span class="math display">\[
f_X(x)=\frac{\alpha}{\beta} \left(\frac{x}{\beta}\right)^{\alpha-1} e^{-\left(\frac{x}{\beta}\right)^\alpha}, \hspace{0.3cm} x\geq 0
\]</span></p>
<p>The mean and variance of a random variable with a Weibull distribution can be found by consulting <code>R</code> documentation. Look them up and make sure you can use them.</p>
</div>
<div id="normal-distribution" class="section level3" number="13.2.6">
<h3><span class="header-section-number">13.2.6</span> Normal distribution</h3>
<p>The normal distribution (also referred to as Gaussian) is a common distribution found in natural processes. You have likely seen a <em>bell curve</em> in various contexts. The bell curve is often indicative of an underlying normal distribution. There are two parameters of the normal distribution: <span class="math inline">\(\mu\)</span> (the mean of <span class="math inline">\(X\)</span>) and <span class="math inline">\(\sigma\)</span> (the standard deviation of <span class="math inline">\(X\)</span>).</p>
<p>Suppose a random variable <span class="math inline">\(X\)</span> has a normal distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. The pdf of <span class="math inline">\(X\)</span> is given by:</p>
<p><span class="math display">\[
f_X(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}, \hspace{0.3cm} -\infty &lt; x &lt;\infty
\]</span></p>
<p>Some plots of normal distributions for different parameters are plotted in Figure @ref(fig:norm-fig).</p>
<div class="figure" style="text-align: center">
<img src="13-Named-Continuous-Distributions_files/figure-html/norm-fig-1.png" alt="pdf of Normal for various values of mu and sigma" width="672" />
<p class="caption">
(#fig:norm-fig)pdf of Normal for various values of mu and sigma
</p>
</div>
<div id="standard-normal" class="section level4" number="13.2.6.1">
<h4><span class="header-section-number">13.2.6.1</span> Standard normal</h4>
<p>When random variable <span class="math inline">\(X\)</span> is normally distributed with <span class="math inline">\(\mu=0\)</span> and <span class="math inline">\(\sigma=1\)</span>, <span class="math inline">\(X\)</span> is said to follow the <em>standard normal</em> distribution. Sometimes, the standard normal pdf is denoted by <span class="math inline">\(\phi(x)\)</span>.</p>
<p>Note that any normally distributed random variable can be transformed to have the standard normal distribution. Let <span class="math inline">\(X \sim \textsf{Norm}(\mu,\sigma)\)</span>. Then,
<span class="math display">\[
Z=\frac{X-\mu}{\sigma} \sim \textsf{Norm}(0,1)
\]</span></p>
<p>Partially, one can show this is true by noting that the mean of <span class="math inline">\(Z\)</span> is 0 and the variance (and standard deviation) of <span class="math inline">\(Z\)</span> is 1:
<span class="math display">\[
\mbox{E}(Z)=\mbox{E}\left(\frac{X-\mu}{\sigma}\right)=\frac{1}{\sigma}\left(\mbox{E}(X)-\mu\right)=\frac{1}\sigma(\mu-\mu)=0
\]</span>
<span class="math display">\[
\mbox{Var}(Z)=\mbox{Var}\left(\frac{X-\mu}{\sigma}\right)=\frac{1}{\sigma^2}\left(\mbox{Var}(X)-0\right)=\frac{1}{\sigma^2} \sigma^2=1
\]</span></p>
<p>Note that this does not prove that <span class="math inline">\(Z\)</span> follows the standard normal distribution; we have merely shown that <span class="math inline">\(Z\)</span> has a mean of 0 and a variance of 1. We will discuss transformation of random variables in a later lesson.</p>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X \sim \textsf{Norm}(\mu=200,\sigma=15)\)</span>. Compute <span class="math inline">\(\mbox{P}(X\leq 160)\)</span>, <span class="math inline">\(\mbox{P}(180\leq X &lt; 230)\)</span>, and <span class="math inline">\(\mbox{P}(X&gt;\mu+\sigma)\)</span>. Find the median and 95th percentile of <span class="math inline">\(X\)</span>.</p>
</blockquote>
<p>As with the gamma distribution, to find probabilities and quantiles, integration will be difficult, so it’s best to use the built-in <code>R</code> functions:</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="#cb364-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Prob(X&lt;=160)</span></span>
<span id="cb364-2"><a href="#cb364-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">160</span>,<span class="dv">200</span>,<span class="dv">15</span>)</span></code></pre></div>
<pre><code>## [1] 0.003830381</code></pre>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="#cb366-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Prob(180 &lt;= X &lt; 230)</span></span>
<span id="cb366-2"><a href="#cb366-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">230</span>,<span class="dv">200</span>,<span class="dv">15</span>)<span class="sc">-</span><span class="fu">pnorm</span>(<span class="dv">180</span>,<span class="dv">200</span>,<span class="dv">15</span>)</span></code></pre></div>
<pre><code>## [1] 0.8860386</code></pre>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="#cb368-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Prob(X&gt;mu+sig)</span></span>
<span id="cb368-2"><a href="#cb368-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pnorm</span>(<span class="dv">215</span>,<span class="dv">200</span>,<span class="dv">15</span>)</span></code></pre></div>
<pre><code>## [1] 0.1586553</code></pre>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="#cb370-1" aria-hidden="true" tabindex="-1"></a><span class="do">## median</span></span>
<span id="cb370-2"><a href="#cb370-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.5</span>,<span class="dv">200</span>,<span class="dv">15</span>)</span></code></pre></div>
<pre><code>## [1] 200</code></pre>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 95th percentile</span></span>
<span id="cb372-2"><a href="#cb372-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.95</span>,<span class="dv">200</span>,<span class="dv">15</span>)</span></code></pre></div>
<pre><code>## [1] 224.6728</code></pre>
</div>
</div>
<div id="beta-distribution" class="section level3" number="13.2.7">
<h3><span class="header-section-number">13.2.7</span> Beta distribution</h3>
<p>The last common continuous distribution we will study is the beta distribution. This has a unique application in that the domain of a random variable with the beta distribution is <span class="math inline">\([0,1]\)</span>. Thus it is typically used to model proportions. The beta distribution has two parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. (In <code>R</code>, these are denoted not so cleverly as <code>shape1</code> and <code>shape2</code>.)</p>
<p>Let <span class="math inline">\(X \sim \textsf{Beta}(\alpha,\beta)\)</span>. The pdf of <span class="math inline">\(X\)</span> is given by:
<span class="math display">\[
f_X(x)=\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}, \hspace{0.3cm} 0\leq x \leq 1
\]</span></p>
<p>Yes, our old friend the Gamma function. In some resources, <span class="math inline">\(\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\)</span> is written as <span class="math inline">\(\frac{1}{B(\alpha,\beta)}\)</span>, where <span class="math inline">\(B\)</span> is known as the beta function.</p>
<p>Note that <span class="math inline">\(\mbox{E}(X)=\frac{\alpha}{\alpha+\beta}\)</span> and <span class="math inline">\(\mbox{Var}(X)=\frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)</span>.</p>
<p>For various values <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, the pdf of a beta distributed random variable is shown in Figure @ref(fig:beta-fig).</p>
<div class="figure" style="text-align: center">
<img src="13-Named-Continuous-Distributions_files/figure-html/beta-fig-1.png" alt="pdf of Beta for various values of alpha and beta" width="672" />
<p class="caption">
(#fig:beta-fig)pdf of Beta for various values of alpha and beta
</p>
</div>
<blockquote>
<p><strong>Exercise</strong><br />
What is the distribution if <span class="math inline">\(\alpha=\beta=1\)</span>?</p>
</blockquote>
<p>It is the uniform. It is easy to verify that <span class="math inline">\(\Gamma(1)=1\)</span> so that <span class="math inline">\(B(1,1)=1\)</span>.</p>
</div>
</div>
<div id="homework-problems-12" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Homework Problems</h2>
<p>For problems 1-3 below, <strong><em>1)</em></strong> define a random variable that will help you answer the question, <strong><em>2)</em></strong> state the distribution and parameters of that random variable; <strong><em>3)</em></strong> determine the expected value and variance of that random variable, and <strong><em>4)</em></strong> use that random variable to answer the question.</p>
<ol style="list-style-type: decimal">
<li>On a given Saturday, suppose vehicles arrive at the USAFA North Gate according to a Poisson process at a rate of 40 arrivals per hour.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Find the probability no vehicles arrive in 10 minutes.<br />
</li>
<li>Find the probability that at least 5 minutes will pass before the next arrival.<br />
</li>
<li>Find the probability that the next vehicle will arrive between 2 and 10 minutes from now.<br />
</li>
<li>Find the probability that at least 7 minutes will pass before the next arrival, given that 2 minutes have already passed. Compare this answer to part (b). This is an example of the memoryless property of the exponential distribution.<br />
</li>
<li>Fill in the blank. There is a probability of 90% that the next vehicle will arrive within __ minutes. This value is known as the 90% percentile of the random variable.<br />
</li>
<li>Use the function <code>stripplot()</code> to visualize the arrival of 30 vehicles using a random sample from the appropriate exponential distribution.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Suppose time until computer errors on the F-35 follows a Gamma distribution with mean 20 hours and variance 10.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Find the probability that 20 hours pass without a computer error.<br />
</li>
<li>Find the probability that 45 hours pass without a computer error, given that 25 hours have already passed. Does the memoryless property apply to the Gamma distribution?<br />
</li>
<li>Find <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>: There is a 95% probability time until next computer error will be between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. (note: technically, there are many answers to this question, but find <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that each tail has equal probability.)</li>
</ol>
<div style="page-break-after: always;"></div>
<ol start="3" style="list-style-type: decimal">
<li>Suppose PFT scores in the cadet wing follow a normal distribution with mean 330 and standard deviation 50.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Find the probability a randomly selected cadet has a PFT score higher than 450.<br />
</li>
<li>Find the probability a randomly selected cadet has a PFT score within 2 standard deviations of the mean.<br />
</li>
<li>Find <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that 90% of PFT scores will be between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.<br />
</li>
<li>Find the probability a randomly selected cadet has a PFT score higher than 450 given he/she is among the top 10% of cadets.</li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(X \sim \textsf{Beta}(\alpha=1,\beta=1)\)</span>. Show that <span class="math inline">\(X\sim \textsf{Unif}(0,1)\)</span>. Hint: write out the beta distribution pdf where <span class="math inline">\(\alpha=1\)</span> and <span class="math inline">\(\beta=1\)</span>.</p></li>
<li><p>When using <code>R</code> to calculate probabilities related to the gamma distribution, we often use <code>pgamma</code>. Recall that <code>pgamma</code> is equivalent to the cdf of the gamma distribution. If <span class="math inline">\(X\sim\textsf{Gamma}(\alpha,\lambda)\)</span>, then
<span class="math display">\[
\mbox{P}(X\leq x)=\textsf{pgamma(x,alpha,lambda)}
\]</span>
The <code>dgamma</code> function exists in <code>R</code> too. In plain language, explain what <code>dgamma</code> returns. I’m not looking for the definition found in <code>R</code> documentation. I’m looking for a simple description of what that function returns. Is the output of <code>dgamma</code> useful? If so, how?</p></li>
<li><p>Advanced. You may have heard of the 68-95-99.7 rule. This is a helpful rule of thumb that says if a population has a normal distribution, then 68% of the data will be within one standard deviation of the mean, 95% of the data will be within two standard deviations and 99.7% of the data will be within three standard deviations. Create a function in <code>R</code> that has two inputs (a mean and a standard deviation). It should return a vector with three elements: the probability that a randomly selected observation from the normal distribution with the inputted mean and standard deviation lies within one, two and three standard deviations. Test this function with several values of the <code>mu</code> and <code>sd</code>. You should get the same answer each time.</p></li>
<li><p>Derive the mean of a general uniform distribution, <span class="math inline">\(U(a,b)\)</span>.</p></li>
</ol>
<!--chapter:end:13-Named-Continuous-Distributions.Rmd-->
</div>
</div>
<div id="MULTIDISTS" class="section level1" number="14">
<h1><span class="header-section-number">14</span> Multivariate Distributions</h1>
<div id="objectives-13" class="section level2" number="14.1">
<h2><span class="header-section-number">14.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define (and distinguish between) the terms joint probability mass/density function, marginal pmf/pdf, and conditional pmf/pdf.<br />
</li>
<li>Given a joint pmf/pdf, obtain the marginal and conditional pmfs/pdfs.<br />
</li>
<li>Use joint, marginal and conditional pmfs/pdfs to obtain probabilities.</li>
</ol>
</div>
<div id="multivariate-distributions" class="section level2" number="14.2">
<h2><span class="header-section-number">14.2</span> Multivariate distributions</h2>
<p>Multivariate situations are the more common in practice. We are often dealing with more than one variable. We have seen this in the previous block of material and will see multivariate distributions in the remainder of the book.</p>
<p>The basic idea is that we want to determine the relationship between two or more variables to include variable(s) conditional on variables.</p>
</div>
<div id="joint-probability" class="section level2" number="14.3">
<h2><span class="header-section-number">14.3</span> Joint probability</h2>
<p>Thus far, we have only considered situations involving one random variable. In some cases, we might be concerned with the behavior of multiple random variables simultaneously. This chapter and the next are dedicated to jointly distributed random variables.</p>
<div id="discrete-random-variables" class="section level3" number="14.3.1">
<h3><span class="header-section-number">14.3.1</span> Discrete random variables</h3>
<p>In the discrete case, joint probability is described by the <em>joint probability mass function</em>. In the bivariate case, suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are discrete random variables. The joint pmf is given by <span class="math inline">\(f_{X,Y}(x,y)\)</span> and represents <span class="math inline">\(\mbox{P}(X=x,Y=y) = \mbox{P}(X=x \cap Y=y)\)</span>. Note: it is common in statistical and probability models to use a comma to represent <strong>and</strong>, in fact the <code>select()</code> function in <code>tidyverse</code> does this.</p>
<p>The same rules of probability apply to the joint pmf. Each value of <span class="math inline">\(f\)</span> must be between 0 and 1, and the total probability must sum to 1:
<span class="math display">\[
\sum_{x\in S_X}\sum_{y \in S_Y} f_{X,Y}(x,y) = 1
\]</span>
This notation means that if we sum the joint probabilities over all values of the random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> we will get 1.</p>
<p>If given a joint pmf, one can obtain the <em>marginal pmf</em> of individual variables. The marginal pmf is simply the mass function of an individual random variable, summing over the possible values of all the other variables. In the bivariate case, the marginal pmf of <span class="math inline">\(X\)</span>, <span class="math inline">\(f_X(x)\)</span> is found by:
<span class="math display">\[
f_X(x)=\sum_{y \in S_Y}f_{X,Y}(x,y)
\]</span></p>
<p>Notice that in the above summation, we summed over only the <span class="math inline">\(y\)</span> values.</p>
<p>Similarly,
<span class="math display">\[
f_Y(y)=\sum_{x \in S_X}f_{X,Y}(x,y)
\]</span></p>
<p>The marginal pmf must be distinguished from the <em>conditional pmf</em>. The conditional pmf describes a discrete random variable given other random variables have taken particular values. In the bivariate case, the conditional pmf of <span class="math inline">\(X\)</span>, given <span class="math inline">\(Y=y\)</span>, is denoted as <span class="math inline">\(f_{X|Y=y}(x)\)</span> and is found by:
<span class="math display">\[
f_{X|Y=y}(x)=\mbox{P}(X=x|Y=y)=\frac{\mbox{P}(X=x,Y=y)}{\mbox{P}(Y=y)}=\frac{f_{X,Y}(x,y)}{f_Y(y)}
\]</span></p>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be discrete random variables with joint pmf below.</p>
</blockquote>
<p><span class="math display">\[
\begin{array}{cc|ccc} &amp; &amp; &amp; \textbf{Y} &amp;
\\ &amp; &amp; 0 &amp; 1 &amp; 2  
\\&amp;\hline0 &amp; 0.10 &amp; 0.08 &amp; 0.11  
\\\textbf{X} &amp;2 &amp; 0.18 &amp; 0.20 &amp; 0.12  
\\&amp;4 &amp; 0.07 &amp; 0.05 &amp; 0.09
\end{array}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Find the marginal pmfs of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Find <span class="math inline">\(f_{X|Y=0}(x)\)</span> and <span class="math inline">\(f_{Y|X=2}(y)\)</span>.</p></li>
</ol>
<p>The marginal pmfs can be found by summing across the other variable. So, to find <span class="math inline">\(f_X(x)\)</span>, we simply sum across the rows:</p>
<p><span class="math display">\[
f_X(x)=\left\{\begin{array}{ll} 0.10+0.08+0.11, &amp; x=0 \\
0.18+0.20+0.12, &amp; x=2 \\
0.07+0.05+0.09, &amp; x=4 \\
0, &amp; \mbox{otherwise}
\end{array}\right. = \left\{\begin{array}{ll} 0.29, &amp; x=0 \\
0.50, &amp; x=2 \\
0.21, &amp; x=4 \\
0, &amp; \mbox{otherwise}
\end{array}\right.
\]</span></p>
<p>Similarly, <span class="math inline">\(f_Y(y)\)</span> can be found by summing down the columns of the joint pmf:
<span class="math display">\[
f_Y(y)=\left\{\begin{array}{ll} 0.35, &amp; y=0 \\
0.33, &amp; y=1 \\
0.32, &amp; y=2 \\
0, &amp; \mbox{otherwise}
\end{array}\right.
\]</span></p>
<p>To find the conditional pmf of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=0\)</span>, it helps to recognize that once we know that <span class="math inline">\(Y=0\)</span>, the overall sample space has changed. Now the only outcomes we consider are in the first column (corresponding to <span class="math inline">\(Y=0\)</span>):</p>
<p><img src="figures/Lesson14Table.png" width="576" style="display: block; margin: auto;" /></p>
<p>We are looking for the distribution of <span class="math inline">\(X\)</span> within the circled area. So, we need to find the proportion of probability assigned to each outcome of <span class="math inline">\(X\)</span>. Mathematically:
<span class="math display">\[
f_{X|Y=0}(x)=\mbox{P}(X=x|Y=0)=\frac{\mbox{P}(X=x,Y=0)}{\mbox{P}(Y=0)}=\frac{f_{X,Y}(x,0)}{f_Y(0)}
\]</span></p>
<p>Above, we found the marginal pmf of <span class="math inline">\(Y\)</span>. We know that <span class="math inline">\(f_Y(0)=0.35\)</span>. So,
<span class="math display">\[
\renewcommand{\arraystretch}{1.25}
f_{X|Y=0}(x)=\left\{\begin{array}{ll} \frac{0.10}{0.35}, &amp; x=0 \\
\frac{0.18}{0.35}, &amp; x=2 \\
\frac{0.07}{0.35}, &amp; x=4 \\
0, &amp; \mbox{otherwise}
\end{array}\right. = \left\{\begin{array}{ll} 0.286, &amp; x=0 \\
0.514, &amp; x=2 \\
0.200, &amp; x=4 \\
0, &amp; \mbox{otherwise}
\end{array}\right.
\]</span></p>
<p>Note that the probabilities in this pmf sum to 1. It is always wise to confirm this to ensure we did not make a simple computational error along the way.</p>
<p>Similarly, we can find <span class="math inline">\(f_{Y|X=2}(y)\)</span>. First we recognize that <span class="math inline">\(f_X(2)=0.5\)</span>.
<span class="math display">\[
\renewcommand{\arraystretch}{1.25}
f_{Y|X=2}(x)=\left\{\begin{array}{ll} \frac{0.18}{0.50}, &amp; y=0 \\
\frac{0.20}{0.50}, &amp; y=1 \\
\frac{0.12}{0.50}, &amp; y=2 \\
0, &amp; \mbox{otherwise}
\end{array}\right. = \left\{\begin{array}{ll} 0.36, &amp; y=0 \\
0.40, &amp; y=1 \\
0.24, &amp; y=2 \\
0, &amp; \mbox{otherwise}
\end{array}\right.
\]</span></p>
<p>Together, these pmfs can be used to find relevant probabilities. For example, see the homework exercises.</p>
</div>
<div id="continuous-random-variables-1" class="section level3" number="14.3.2">
<h3><span class="header-section-number">14.3.2</span> Continuous random variables</h3>
<p>Many of the ideas above for discrete random variables also apply to the case of multiple continuous random variables. Suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are continuous random variables. Their joint probability is described by the <em>joint probability density function</em>. As in the discrete case, the joint pdf is represented by <span class="math inline">\(f_{X,Y}(x,y)\)</span>. Recall that while pmfs return probabilities, pdfs return <em>densities</em>, which are not equivalent to probabilities. In order to obtain probability from a pdf, one has to integrate the pdf across the applicable subset of the domain.</p>
<p>The rules of a joint pdf are analogous to the univariate case. For all <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, <span class="math inline">\(f_{X,Y}(x,y)\geq 0\)</span> and the probability must sum to one:
<span class="math display">\[
\int_{S_X}\int_{S_Y}f_{X,Y}(x,y)\mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x = 1
\]</span></p>
<p>The marginal pdf is the density function of an individual random variable, integrating out all others. In the bivariate case, the marginal pdf of <span class="math inline">\(X\)</span>, <span class="math inline">\(f_X(x)\)</span>, is found by <em>summing</em>, integrating, across the other variable:
<span class="math display">\[
f_X(x)=\int_{S_Y}f_{X,Y}(x,y)\mathop{}\!\mathrm{d}y
\]</span></p>
<p>Similarly,
<span class="math display">\[
f_Y(y)=\int_{S_X}f_{X,Y}(x,y)\mathop{}\!\mathrm{d}x
\]</span></p>
<p>The conditional pdf of <span class="math inline">\(X\)</span>, given <span class="math inline">\(Y=y\)</span> is denoted as <span class="math inline">\(f_{X|Y=y}(x)\)</span> and is found in the same way as in the discrete case:
<span class="math display">\[
f_{X|Y=y}(x)=\frac{f_{X,Y}(x,y)}{f_Y(y)}
\]</span></p>
<p>Similarly,
<span class="math display">\[
f_{Y|X=x}(y)=\frac{f_{X,Y}(x,y)}{f_X(x)}
\]</span></p>
<p>Note that we are working with the pdf and not probabilities in this case. That is because we can’t determine the probability at a point for a continuous random variable. Thus we work with conditional pdfs to find probabilities for conditional statements.</p>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be continuous random variables with joint pdf:<br />
<span class="math display">\[
f_{X,Y}(x,y)=xy
\]</span>
for <span class="math inline">\(0\leq x \leq 2\)</span> and <span class="math inline">\(0 \leq y \leq 1\)</span>.</p>
</blockquote>
<ol style="list-style-type: lower-alpha">
<li>Verify <span class="math inline">\(f\)</span> is a valid joint pdf.</li>
</ol>
<p>We need to ensure the total volume under the pdf is 1. Note that the double integral with constant limits of integration is just like doing single integrals. We just treat the other variable as a constant. In this book we will not work with limits of integration that have variables in them, this is the material of Calc III.</p>
<p>For our simple case of constant limits of integration, the order of integration does not matter. We will arbitrarily integrate <span class="math inline">\(x\)</span> first, treating <span class="math inline">\(y\)</span> as a constant. Then integrate with respect to <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[
\int_0^1 \int_0^2 xy \mathop{}\!\mathrm{d}x \mathop{}\!\mathrm{d}y = \int_0^1 \frac{x^2y}{2}\bigg|_0^2 \mathop{}\!\mathrm{d}y = \int_0^1 2y\mathop{}\!\mathrm{d}y = y^2\bigg|_0^1 = 1
\]</span></p>
<p>Using <code>R</code> to do this requires a new package <strong>cubature</strong>. You can install it from <code>RStudio</code> package tab or the command line using <code>install.packages("cubature")</code>. Then we can use it as follows:</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="#cb374-1" aria-hidden="true" tabindex="-1"></a> <span class="fu">library</span>(cubature) <span class="co"># load the package &quot;cubature&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="#cb375-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(x) { (x[<span class="dv">1</span>] <span class="sc">*</span> x[<span class="dv">2</span>]) } <span class="co"># &quot;x&quot; is vector</span></span>
<span id="cb375-2"><a href="#cb375-2" aria-hidden="true" tabindex="-1"></a><span class="fu">adaptIntegrate</span>(f, <span class="at">lowerLimit =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="at">upperLimit =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## $integral
## [1] 1
## 
## $error
## [1] 0
## 
## $functionEvaluations
## [1] 17
## 
## $returnCode
## [1] 0</code></pre>
<p>Notice the function <code>adaptIntegrate</code> returned four objects. You can read the help menu to learn more about them but we are only interested in the result contained in the object <code>integral</code>.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Find <span class="math inline">\(\mbox{P}(X &gt; 1, Y \leq 0.5)\)</span>.
<span class="math display">\[
\mbox{P}(X&gt;1,Y\leq 0.5)=\int_0^{0.5}\int_1^2 xy \mathop{}\!\mathrm{d}x \mathop{}\!\mathrm{d}y = \int_0^{0.5} \frac{x^2 y}{2}\bigg|_1^2 \mathop{}\!\mathrm{d}y = \int_0^{0.5}2y - \frac{y}{2}\mathop{}\!\mathrm{d}y
\]</span>
<span class="math display">\[
= \frac{3y^2}{4}\bigg|_0^{0.5}=0.1875
\]</span></li>
</ol>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="#cb377-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(x) { (x[<span class="dv">1</span>] <span class="sc">*</span> x[<span class="dv">2</span>]) } <span class="co"># &quot;x&quot; is vector</span></span>
<span id="cb377-2"><a href="#cb377-2" aria-hidden="true" tabindex="-1"></a><span class="fu">adaptIntegrate</span>(f, <span class="at">lowerLimit =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="at">upperLimit =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## $integral
## [1] 0.1875
## 
## $error
## [1] 2.775558e-17
## 
## $functionEvaluations
## [1] 17
## 
## $returnCode
## [1] 0</code></pre>
<ol start="3" style="list-style-type: lower-alpha">
<li>Find the marginal pdfs of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.
<span class="math display">\[
f_X(x)=\int_0^1 xy \mathop{}\!\mathrm{d}y = \frac{xy^2}{2}\bigg|_0^1=\frac{x}{2}
\]</span></li>
</ol>
<p>where <span class="math inline">\(0 \leq x \leq 2\)</span>.</p>
<p><span class="math display">\[
f_Y(y)=\int_0^2 xy \mathop{}\!\mathrm{d}x = \frac{x^2y}{2}\bigg|_0^2= 2y
\]</span></p>
<p>where <span class="math inline">\(0 \leq y \leq 1\)</span>.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Find the conditional pdfs of <span class="math inline">\(X|Y=y\)</span> and <span class="math inline">\(Y|X=x\)</span>.
<span class="math display">\[
f_{X|Y=y}(x)=\frac{f_{X,Y}(x,y)}{f_Y(y)}=\frac{xy}{2y}=\frac{x}{2}
\]</span></li>
</ol>
<p>where <span class="math inline">\(0 \leq x \leq 2\)</span>.</p>
<p>Similarly,
<span class="math display">\[
f_{Y|X=x}(y)=\frac{f_{X,Y}(x,y)}{f_X(x)}=\frac{xy}{\frac{x}{2}}=2y
\]</span></p>
<p>where <span class="math inline">\(0 \leq y \leq 1\)</span>.</p>
</div>
</div>
<div id="homework-problems-13" class="section level2" number="14.4">
<h2><span class="header-section-number">14.4</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be continuous random variables with joint pdf:
<span class="math display">\[
f_{X,Y}(x,y)=x + y
\]</span></li>
</ol>
<p>where <span class="math inline">\(0 \leq x \leq 1\)</span> and <span class="math inline">\(0 \leq y \leq 1\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Verify that <span class="math inline">\(f\)</span> is a valid pdf.<br />
</li>
<li>Find the marginal pdfs of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.<br />
</li>
<li>Find the conditional pdfs of <span class="math inline">\(X|Y=y\)</span> and <span class="math inline">\(Y|X=x\)</span>.<br />
</li>
<li>Find the following probabilities: <span class="math inline">\(\mbox{P}(X&lt;0.5)\)</span>; <span class="math inline">\(\mbox{P}(Y&gt;0.8)\)</span>; <span class="math inline">\(\mbox{P}(X&lt;0.2,Y\geq 0.75)\)</span>; <span class="math inline">\(\mbox{P}(X&lt;0.2|Y\geq 0.75)\)</span>; <span class="math inline">\(\mbox{P}(X&lt;0.2|Y= 0.25)\)</span>; Optional - <span class="math inline">\(\mbox{P}(X\leq Y)\)</span>.</li>
</ol>
<p> </p>
<ol start="2" style="list-style-type: decimal">
<li>In the reading, we saw an example where <span class="math inline">\(f_X(x)=f_{X|Y=y}(x)\)</span> and <span class="math inline">\(f_Y(y)=f_{Y|X=x}(y)\)</span>. This is not common and is important. What does this imply about <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>?</li>
</ol>
<div style="page-break-after: always;"></div>
<ol start="3" style="list-style-type: decimal">
<li>ADVANCED: Recall on an earlier assignment, we came up with random variables to describe timeliness at an airport. Suppose over the course of 210 days, on each day we recorded the number of customer complaints regarding timeliness. Also on each day, we recorded the weather (our airport is located somewhere without snow and without substantial wind). The data are displayed below.</li>
</ol>
<p><span class="math display">\[
\begin{array}{cc|cc} &amp; &amp; &amp;\textbf{Weather Status}\\
&amp; &amp; \mbox{Clear} &amp; \mbox{Light Rain} &amp; \mbox{Rain}  \\
&amp; \hline0 &amp; 28 &amp; 11 &amp; 4  \\
&amp; 1 &amp; 18 &amp; 15 &amp; 8  \\
&amp; 2 &amp; 17 &amp; 25 &amp; 12  \\
\textbf{# of complaints} &amp; 3 &amp; 13 &amp; 15 &amp; 16  \\
&amp; 4 &amp; 8 &amp; 8 &amp; 10 \\
&amp; 5 &amp; 0 &amp; 1 &amp; 1 \\
\end{array}
\]</span></p>
<p>First, define two random variables for this scenario. One of them (# of complaints) is essentially already a random variable. For the other (weather status) you will need to assign a number to each status.</p>
<ol style="list-style-type: lower-alpha">
<li>Use the table above to build an empirical joint pmf of the two random variables.<br />
</li>
<li>Find the marginal pmfs of each random variable.<br />
</li>
<li>Find the probability of fewer than 3 complaints.<br />
</li>
<li>Find the probability of fewer than 3 complaints given there is no rain.</li>
</ol>
<p> </p>
<p><strong>Optional</strong> for those of you that like Calc III and want a challenge.</p>
<ol start="4" style="list-style-type: decimal">
<li>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be continuous random variables with joint pmf:
<span class="math display">\[
f_{X,Y}(x,y)=1
\]</span></li>
</ol>
<p>where <span class="math inline">\(0 \leq x \leq 1\)</span> and <span class="math inline">\(0 \leq y \leq 2x\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Verify that <span class="math inline">\(f\)</span> is a valid pdf.<br />
</li>
<li>Find the marginal pdfs of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.<br />
</li>
<li>Find the conditional pdfs of <span class="math inline">\(X|Y=y\)</span> and <span class="math inline">\(Y|X=x\)</span>.<br />
</li>
<li>Find the following probabilities: <span class="math inline">\(\mbox{P}(X&lt;0.5)\)</span>; <span class="math inline">\(\mbox{P}(Y&gt;1)\)</span>; <span class="math inline">\(\mbox{P}(X&lt;0.5,Y\leq 0.8)\)</span>; Optional <span class="math inline">\(\mbox{P}(X&lt;0.5|Y= 0.8)\)</span>; <span class="math inline">\(\mbox{P}(Y\leq 1-X)\)</span>. (It would probably help to draw some pictures.)</li>
</ol>
<!--chapter:end:14-Multivariate-Distributions.Rmd-->
</div>
</div>
<div id="MULTIEXP" class="section level1" number="15">
<h1><span class="header-section-number">15</span> Multivariate Expectation</h1>
<div id="objectives-14" class="section level2" number="15.1">
<h2><span class="header-section-number">15.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Given a joint pmf/pdf, obtain means and variances of random variables and functions of random variables.<br />
</li>
<li>Define the terms covariance and correlation, and given a joint pmf/pdf, obtain the covariance and correlation between two random variables.<br />
</li>
<li>Given a joint pmf/pdf, determine whether random variables are independent of one another.<br />
</li>
<li>Find conditional expectations.</li>
</ol>
</div>
<div id="expectation---moments" class="section level2" number="15.2">
<h2><span class="header-section-number">15.2</span> Expectation - moments</h2>
<p>Computing expected values of random variables in the joint context is similar to the univariate case. Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be discrete random variables with joint pmf <span class="math inline">\(f_{X,Y}(x,y)\)</span>. Let <span class="math inline">\(g(X,Y)\)</span> be some function of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Then:
<span class="math display">\[
\mbox{E}[g(X,Y)]=\sum_x\sum_y g(x,y)f_{X,Y}(x,y)
\]</span></p>
<p>(Note that <span class="math inline">\(\sum\limits_{x}\)</span> is shorthand for the sum across all possible values of <span class="math inline">\(x\)</span>.)</p>
<p>In the case of continuous random variables with a joint pdf <span class="math inline">\(f_{X,Y}(x,y)\)</span>, expectation becomes:
<span class="math display">\[
\mbox{E}[g(X,Y)]=\int_x\int_y g(x,y)f_{X,Y}(x,y)\mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x
\]</span></p>
<div id="expectation-of-discrete-random-variables" class="section level3" number="15.2.1">
<h3><span class="header-section-number">15.2.1</span> Expectation of discrete random variables</h3>
<p>Given a joint pmf, one can find the mean of <span class="math inline">\(X\)</span> by using the joint function or by finding the marginal pmf first and then using that to find <span class="math inline">\(\mbox{E}(X)\)</span>. In the end, both ways are the same. For the discrete case:
<span class="math display">\[
\mbox{E}(X)=\sum_x\sum_y xf_{X,Y}(x,y) = \sum_x x \sum_y f_{X,Y}(x,y)
\]</span></p>
<p>The <span class="math inline">\(x\)</span> can be moved outside the inner sum since the inner sum is with respect to variable <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is a constant with respect to <span class="math inline">\(y\)</span>. Note that the inner sum is the marginal pmf of <span class="math inline">\(X\)</span>. So,
<span class="math display">\[
\mbox{E}(X)=\sum_x x \sum_y f_{X,Y}(x,y)=\sum_x x f_X(x)
\]</span></p>
<div style="page-break-after: always;"></div>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be discrete random variables with joint pmf below.</p>
</blockquote>
<p><span class="math display">\[
\begin{array}{cc|ccc} &amp; &amp; &amp; \textbf{Y} &amp;
\\ &amp; &amp; 0 &amp; 1 &amp; 2  
\\&amp;\hline0 &amp; 0.10 &amp; 0.08 &amp; 0.11  
\\\textbf{X} &amp;1 &amp; 0.18 &amp; 0.20 &amp; 0.12  
\\&amp;2 &amp; 0.07 &amp; 0.05 &amp; 0.09
\end{array}
\]</span></p>
<p>Find <span class="math inline">\(\mbox{E}(X)\)</span></p>
<p>First we will use the joint pmf directly, then we find the marginal pmf of <span class="math inline">\(X\)</span> and use that as we would in a univariate case.</p>
<p><span class="math display">\[
\mbox{E}(X)=\sum_{x=0}^2 \sum_{y=0}^2 x f_{X,Y}(x,y)=0*0.10+0*0.08+0*0.11+1*0.18+...+2*0.09 = 0.92
\]</span></p>
<p>The marginal pmf of <span class="math inline">\(X\)</span> is
<span class="math display">\[
f_X(x)=\left\{\begin{array}{ll} 0.10+0.08+0.11, &amp; x=0 \\
0.18+0.20+0.12, &amp; x=1 \\
0.07+0.05+0.09, &amp; x=2 \\
0, &amp; \mbox{otherwise}
\end{array}\right. = \left\{\begin{array}{ll} 0.29, &amp; x=0 \\
0.50, &amp; x=1 \\
0.21, &amp; x=2 \\
0, &amp; \mbox{otherwise}
\end{array}\right.
\]</span></p>
<p>So, <span class="math inline">\(\mbox{E}(X)=0*0.29+1*0.5+2*0.21=0.92\)</span>.</p>
</div>
</div>
<div id="exercises-to-apply-what-we-learned" class="section level2" number="15.3">
<h2><span class="header-section-number">15.3</span> Exercises to apply what we learned</h2>
<blockquote>
<p><strong>Exercise</strong>:
Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be defined above. Find <span class="math inline">\(\mbox{E}(Y)\)</span>, <span class="math inline">\(\mbox{E}(X+Y)\)</span>, <span class="math inline">\(\mbox{E}(XY)\)</span>, and <span class="math inline">\(\mbox{E}\left(\frac{1}{2X+Y+1}\right)\)</span>.</p>
</blockquote>
<div id="ey" class="section level3" number="15.3.1">
<h3><span class="header-section-number">15.3.1</span> E(Y)</h3>
<p>As with <span class="math inline">\(\mbox{E}(X)\)</span>, <span class="math inline">\(\mbox{E}(Y)\)</span> can be found in two ways. We will use the marginal pmf of <span class="math inline">\(Y\)</span>, which we will not derive:</p>
<p><span class="math display">\[
\mbox{E}(Y)=\sum_{y=0}^2 y \cdot f_Y(y)=0*0.35+1*0.33+2*0.32 = 0.97
\]</span></p>
</div>
<div id="exy" class="section level3" number="15.3.2">
<h3><span class="header-section-number">15.3.2</span> E(X+Y)</h3>
<p>To find <span class="math inline">\(\mbox{E}(X+Y)\)</span> we will use the joint pmf. In the discrete case, it helps to first identify all of the possible values of <span class="math inline">\(X+Y\)</span> and then figure out what probabilities are associated with each value. This problem is really a transformation problem where we are finding the distribution of <span class="math inline">\(X+Y\)</span>. In this example, <span class="math inline">\(X+Y\)</span> can take on values 0, 1, 2, 3, and 4. The value 0 only happens when <span class="math inline">\(X=Y=0\)</span> and the probability of this outcome is 0.10. The value 1 occurs when <span class="math inline">\(X=0\)</span> and <span class="math inline">\(Y=1\)</span> or when <span class="math inline">\(X=1\)</span> and <span class="math inline">\(Y=0\)</span>. This occurs with probability 0.08 + 0.18. We continue in this manner:
<span class="math display">\[
\mbox{E}(X+Y)=\sum_{x=0}^2\sum_{y=0}^2 (x+y)f_{X,Y}(x,y) = 0*0.1+1*(0.18+0.08)+2*(0.11+0.07+0.20)
\]</span>
<span class="math display">\[
+3*(0.12+0.05)+4*0.09 = 1.89
\]</span></p>
<p>Note that <span class="math inline">\(\mbox{E}(X+Y)=\mbox{E}(X)+\mbox{E}(Y)\)</span>. (The proof of this is left to the reader.)</p>
</div>
<div id="exy-1" class="section level3" number="15.3.3">
<h3><span class="header-section-number">15.3.3</span> E(XY)</h3>
<p><span class="math display">\[
\mbox{E}(XY)=\sum_{x=0}^2\sum_{y=0}^2 xyf_{X,Y}(x,y) = 0*(0.1+0.08+0.11+0.18+0.07)+1*0.20
\]</span>
<span class="math display">\[
+2*(0.12+0.05)+4*0.09= 0.9
\]</span></p>
<p>Note that <span class="math inline">\(\mbox{E}(XY)\)</span> is not necessarily equal to <span class="math inline">\(\mbox{E}(X)\mbox{E}(Y)\)</span>.</p>
</div>
<div id="e12xy1" class="section level3" number="15.3.4">
<h3><span class="header-section-number">15.3.4</span> E(1/2X+Y+1)</h3>
<p><span class="math display">\[
\mbox{E}\left(\frac{1}{2X+Y+1}\right) = \sum_{x=0}^2\sum_{y=0}^2 \frac{1}{2x+y+1}f_{X,Y}(x,y) = 1*0.1+\frac{1}{2}*0.08+\frac{1}{3}*(0.11+0.18)
\]</span>
<span class="math display">\[
+\frac{1}{4}*0.20+\frac{1}{5}*(0.12+0.07)+\frac{1}{6}*0.05+\frac{1}{7}*0.09 = 0.3125
\]</span></p>
</div>
<div id="expectation-of-continuous-random-variables" class="section level3" number="15.3.5">
<h3><span class="header-section-number">15.3.5</span> Expectation of continuous random variables</h3>
<p>Let’s consider an example with continuous random variables where summation is replaced with integration:</p>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be continuous random variables with joint pdf:
<span class="math display">\[
f_{X,Y}(x,y)=xy
\]</span>
for <span class="math inline">\(0\leq x \leq 2\)</span> and <span class="math inline">\(0 \leq y \leq 1\)</span>.</p>
</blockquote>
</div>
</div>
<div id="exercises-to-apply-what-we-learned-1" class="section level2" number="15.4">
<h2><span class="header-section-number">15.4</span> Exercises to apply what we learned</h2>
<blockquote>
<p><strong>Exercise</strong>:
Find <span class="math inline">\(\mbox{E}(X)\)</span>, <span class="math inline">\(\mbox{E}(X+Y)\)</span>, <span class="math inline">\(\mbox{E}(XY)\)</span>, and <span class="math inline">\(\mbox{Var}(XY)\)</span>.</p>
</blockquote>
<div id="ex" class="section level3" number="15.4.1">
<h3><span class="header-section-number">15.4.1</span> E(X)</h3>
<p>We found the marginal pdf of <span class="math inline">\(X\)</span> in a previous lesson, so we should use that now:
<span class="math display">\[
\mbox{E}(X)=\int_0^2 x\frac{x}{2}\mathop{}\!\mathrm{d}x = \frac{x^3}{6}\bigg|_0^2= \frac{4}{3}
\]</span>
Or using <code>R</code></p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="#cb379-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fractions</span>(<span class="fu">integrate</span>(<span class="cf">function</span>(x){x<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>},<span class="dv">0</span>,<span class="dv">2</span>)<span class="sc">$</span>value)</span></code></pre></div>
<pre><code>## [1] 4/3</code></pre>
</div>
<div id="exy-2" class="section level3" number="15.4.2">
<h3><span class="header-section-number">15.4.2</span> E(X+Y)</h3>
<p>To find <span class="math inline">\(\mbox{E}(X+Y)\)</span>, we could use the joint pdf directly, or use the marginal pdf of <span class="math inline">\(Y\)</span> to find <span class="math inline">\(\mbox{E}(Y)\)</span> and then add the result to <span class="math inline">\(\mbox{E}(X)\)</span>. The reason this is valid is because when we integrate <span class="math inline">\(x\)</span> with the joint pdf, integrating with respect to <span class="math inline">\(y\)</span> first, we can treat <span class="math inline">\(x\)</span> as a constant and bring it out side the integral. Then we are integrating the joint pdf with respect <span class="math inline">\(y\)</span> which results in the marginal pdf of <span class="math inline">\(X\)</span>.</p>
<p>We’ll use the joint pdf:
<span class="math display">\[
\mbox{E}(X+Y)=\int_0^2\int_0^1 (x+y)xy\mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x=\int_0^2\int_0^1 (x^2y+xy^2)\mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x = \int_0^2 \frac{x^2y^2}{2}+\frac{xy^3}{3} \bigg|_{y=0}^{y=1}\mathop{}\!\mathrm{d}x
\]</span></p>
<p><span class="math display">\[
= \int_0^2 \frac{x^2}{2}+\frac{x}{3} \mathop{}\!\mathrm{d}x= \frac{x^3}{6}+\frac{x^2}{6}\bigg|_0^2=\frac{8}{6}+\frac{4}{6}=2
\]</span></p>
<p>Or using <code>R</code>:</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="#cb381-1" aria-hidden="true" tabindex="-1"></a><span class="fu">adaptIntegrate</span>(<span class="cf">function</span>(x){(x[<span class="dv">1</span>]<span class="sc">+</span>x[<span class="dv">2</span>])<span class="sc">*</span>x[<span class="dv">1</span>]<span class="sc">*</span>x[<span class="dv">2</span>]},<span class="at">lowerLimit =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">upperLimit =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))<span class="sc">$</span>integral</span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<p>If we wanted to use simulation to find this expectation, we could simulate variables from the marginal of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> and then add them together to create a new variable.</p>
<p>The cdf for <span class="math inline">\(X\)</span> is <span class="math inline">\(\frac{x^2}{4}\)</span> so we simulate a random variable from <span class="math inline">\(X\)</span> by sampling from a random uniform and then taking the inverse of the cdf. For <span class="math inline">\(Y\)</span> the cdf is <span class="math inline">\(y^2\)</span> and do a similar simulation.</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="#cb383-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1820</span>)</span>
<span id="cb383-2"><a href="#cb383-2" aria-hidden="true" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x=</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">10000</span>)),<span class="at">y=</span><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">10000</span>)))</span>
<span id="cb383-3"><a href="#cb383-3" aria-hidden="true" tabindex="-1"></a>new_data <span class="sc">%&gt;%</span></span>
<span id="cb383-4"><a href="#cb383-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">z=</span>x<span class="sc">+</span>y) <span class="sc">%&gt;%</span></span>
<span id="cb383-5"><a href="#cb383-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">Ex=</span><span class="fu">mean</span>(x),<span class="at">Ey=</span><span class="fu">mean</span>(y),<span class="at">Explusy =</span> <span class="fu">mean</span>(z))</span></code></pre></div>
<pre><code>##         Ex        Ey  Explusy
## 1 1.338196 0.6695514 2.007748</code></pre>
<p>We can see that <span class="math inline">\(E(X + Y) = E(X) + E(Y)\)</span>.</p>
</div>
<div id="exy-3" class="section level3" number="15.4.3">
<h3><span class="header-section-number">15.4.3</span> E(XY)</h3>
<p>Next, we have</p>
<p><span class="math display">\[
\mbox{E}(XY)=\int_0^2\int_0^1 xy*xy\mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x = \int_0^2 \frac{x^2y^3}{3}\bigg|_0^1 \mathop{}\!\mathrm{d}x = \int_0^2 \frac{x^2}{3}\mathop{}\!\mathrm{d}x
\]</span>
<span class="math display">\[
=\frac{x^3}{9}\bigg|_0^2 = \frac{8}{9}
\]</span></p>
<p>Using <code>R</code>:</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fractions</span>(<span class="fu">adaptIntegrate</span>(<span class="cf">function</span>(x){(x[<span class="dv">1</span>]<span class="sc">*</span>x[<span class="dv">2</span>])<span class="sc">*</span>x[<span class="dv">1</span>]<span class="sc">*</span>x[<span class="dv">2</span>]},<span class="at">lowerLimit =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">upperLimit =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))<span class="sc">$</span>integral)</span></code></pre></div>
<pre><code>## [1] 8/9</code></pre>
<p>Or by simulating, we have:</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="#cb387-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">191</span>)</span>
<span id="cb387-2"><a href="#cb387-2" aria-hidden="true" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x=</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">10000</span>)),<span class="at">y=</span><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">10000</span>)))</span>
<span id="cb387-3"><a href="#cb387-3" aria-hidden="true" tabindex="-1"></a>new_data <span class="sc">%&gt;%</span></span>
<span id="cb387-4"><a href="#cb387-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">z=</span>x<span class="sc">*</span>y) <span class="sc">%&gt;%</span></span>
<span id="cb387-5"><a href="#cb387-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">Ex=</span><span class="fu">mean</span>(x),<span class="at">Ey=</span><span class="fu">mean</span>(y),<span class="at">Extimesy =</span> <span class="fu">mean</span>(z))</span></code></pre></div>
<pre><code>##        Ex        Ey  Extimesy
## 1 1.33096 0.6640436 0.8837552</code></pre>
</div>
<div id="vxy" class="section level3" number="15.4.4">
<h3><span class="header-section-number">15.4.4</span> V(XY)</h3>
<p>Recall that the variance of a random variable is the expected value of the squared difference from its mean. So,
<span class="math display">\[
\mbox{Var}(XY)=\mbox{E}\left[\left(XY-\mbox{E}(XY)\right)^2\right]=\mbox{E}\left[\left(XY-\frac{8}{9}\right)^2\right]
\]</span>
<span class="math display">\[
=\int_0^2\int_0^1 \left(xy-\frac{8}{9}\right)^2 xy\mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x =\int_0^2\int_0^1 \left(x^2y^2-\frac{16xy}{9}+\frac{64}{81}\right)xy\mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x
\]</span></p>
<p>Yuck!! But we will continue because we are determined to integrate after so much Calculus in our core curriculum.</p>
<p><span class="math display">\[
=\int_0^2\int_0^1 \left(x^3y^3-\frac{16x^2y^2}{9}+\frac{64xy}{81}\right)\mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x
\]</span></p>
<p><span class="math display">\[
=\int_0^2 \frac{x^3y^4}{4}-\frac{16x^2y^3}{27}+\frac{32xy^2}{81}\bigg|_0^1 \mathop{}\!\mathrm{d}x
\]</span></p>
<p><span class="math display">\[
= \int_0^2 \frac{x^3}{4}-\frac{16x^2}{27}+\frac{32x}{81}\mathop{}\!\mathrm{d}x
\]</span></p>
<p><span class="math display">\[
= \frac{x^4}{16}-\frac{16x^3}{81}+\frac{16x^2}{81}\bigg|_0^2
\]</span>
<span class="math display">\[
=\frac{16}{16}-\frac{128}{81}+\frac{64}{81}=\frac{17}{81}
\]</span></p>
<p>Using <code>R</code>:</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="#cb389-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fractions</span>(<span class="fu">adaptIntegrate</span>(<span class="cf">function</span>(x){(x[<span class="dv">1</span>]<span class="sc">*</span>x[<span class="dv">2</span>]<span class="sc">-</span><span class="dv">8</span><span class="sc">/</span><span class="dv">9</span>)<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>x[<span class="dv">1</span>]<span class="sc">*</span>x[<span class="dv">2</span>]},<span class="at">lowerLimit =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>),<span class="at">upperLimit =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))<span class="sc">$</span>integral)</span></code></pre></div>
<pre><code>## [1] 17/81</code></pre>
<p>Next we will estimate the variance using a simulation:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="#cb391-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">816</span>)</span>
<span id="cb391-2"><a href="#cb391-2" aria-hidden="true" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x=</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">10000</span>)),<span class="at">y=</span><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">10000</span>)))</span>
<span id="cb391-3"><a href="#cb391-3" aria-hidden="true" tabindex="-1"></a>new_data <span class="sc">%&gt;%</span></span>
<span id="cb391-4"><a href="#cb391-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">z=</span>(x<span class="sc">*</span>y<span class="dv">-8</span><span class="sc">/</span><span class="dv">9</span>)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb391-5"><a href="#cb391-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">Var =</span> <span class="fu">mean</span>(z))</span></code></pre></div>
<pre><code>##         Var
## 1 0.2098769</code></pre>
<p>That was much easier. Notice that we are really just estimating these expectations with the simulations. The mathematical answers are the true population values while our simulations are sample estimates. In a few lessons we will discuss estimators in more detail.</p>
</div>
</div>
<div id="covariancecorrelation" class="section level2" number="15.5">
<h2><span class="header-section-number">15.5</span> Covariance/Correlation</h2>
<p>We have discussed expected values of random variables and functions of random variables in a joint context. It would be helpful to have some kind of consistent measure to describe <em>how</em> two random variables are related to one another. <em>Covariance</em> and <em>correlation</em> do just that. It is important to understand that these are measures of a linear relationship between variables.</p>
<p>Consider two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. (We could certainly consider more than two, but for demonstration, let’s consider only two for now). The covariance between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is denoted as <span class="math inline">\(\mbox{Cov}(X,Y)\)</span> and is found by:
<span class="math display">\[
\mbox{Cov}(X,Y)=\mbox{E}\left[(X-\mbox{E}(X))(Y-\mbox{E}(Y))\right]
\]</span></p>
<p>We can simplify this expression to make it a little more usable:
<span class="math display">\[
\begin{align}
\mbox{Cov}(X,Y) &amp; = \mbox{E}\left[(X-\mbox{E}(X))(Y-\mbox{E}(Y))\right] \\
&amp; = \mbox{E}\left[XY - Y\mbox{E}(X) - X\mbox{E}(Y) + \mbox{E}(X)\mbox{E}(Y)\right] \\
&amp; = \mbox{E}(XY) - \mbox{E}(Y\mbox{E}(X)) - \mbox{E}(X\mbox{E}(Y)) + \mbox{E}(X)\mbox{E}(Y) \\
&amp; = \mbox{E}(XY)-\mbox{E}(X)\mbox{E}(Y)-\mbox{E}(X)\mbox{E}(Y)+\mbox{E}(X)\mbox{E}(Y) \\
&amp; = \mbox{E}(XY)-\mbox{E}(X)\mbox{E}(Y)
\end{align}
\]</span></p>
<p>Thus,
<span class="math display">\[
\mbox{Cov}(X,Y)=\mbox{E}(XY)-\mbox{E}(X)\mbox{E}(Y)
\]</span></p>
<p>This expression is a little easier to use, since it’s typically straightforward to find each of these quantities.</p>
<p>It is important to note that while variance is a positive quantity, covariance can be positive or negative. A positive covariance implies that as the value of one variable increases, the other tends to increase. This is a statement about a linear relationship. Likewise, a negative covariance implies that as the value of one variable increases, the other tends to decrease.</p>
<blockquote>
<p><em>Example</em>:<br />
An example of positive covariance is human height and weight. As height increase, weight tends to increase. An example of negative covariance is gas mileage and car weight. As car weight increases, gas mileage decreases.</p>
</blockquote>
<p>Remember that if <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are constants, <span class="math inline">\(\mbox{E}(aX+b) =a\mbox{E}(X)+b\)</span> and <span class="math inline">\(\mbox{Var}(aX+b)=a^2\mbox{Var}(X)\)</span>. Similarly, if <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(d\)</span> are all constants,
<span class="math display">\[
\mbox{Cov}(aX+b,cY+d)=ac\mbox{Cov}(X,Y)
\]</span></p>
<p>One disadvantage of covariance is its dependence on the scales of the random variables involved. This makes it difficult to compare covariances of multiple sets of variables. <em>Correlation</em> avoids this problem. Correlation is a scaled version of covariance. It is denoted by <span class="math inline">\(\rho\)</span> and found by:
<span class="math display">\[
\rho = \frac{\mbox{Cov}(X,Y)}{\sqrt{\mbox{Var}(X)\mbox{Var}(Y)}}
\]</span></p>
<p>While covariance could take on any real number, correlation is bounded by -1 and 1. Two random variables with a correlation of 1 are said to be perfectly positively correlated, while a correlation of -1 implies perfect negative correlation. Two random variables with a correlation (and thus covariance) of 0 are said to be uncorrelated, that is they do not have a linear relationship but could have a non-linear relationship. This last point is important; random variables with no relationship will have a 0 covariance. However, a 0 covariance only implies that the random variables do not have a linear relationship.</p>
<p>Let’s look at some plots, Figures @ref(fig:cor1-fig), @ref(fig:cor2-fig), @ref(fig:cor3-fig), and @ref(fig:cor4-fig) of different correlations. Remember that the correlation we are calculating in this section is for the population, while the plots are showing sample points from a population.</p>
<div class="figure" style="text-align: center">
<img src="15-Multivariate-Expectation_files/figure-html/cor1-fig-1.png" alt="Correlation of 1" width="672" />
<p class="caption">
(#fig:cor1-fig)Correlation of 1
</p>
</div>
<div class="figure" style="text-align: center">
<img src="15-Multivariate-Expectation_files/figure-html/cor2-fig-1.png" alt="Correlation of .8" width="672" />
<p class="caption">
(#fig:cor2-fig)Correlation of .8
</p>
</div>
<div class="figure" style="text-align: center">
<img src="15-Multivariate-Expectation_files/figure-html/cor3-fig-1.png" alt="Correlation of .5" width="672" />
<p class="caption">
(#fig:cor3-fig)Correlation of .5
</p>
</div>
<div class="figure" style="text-align: center">
<img src="15-Multivariate-Expectation_files/figure-html/cor4-fig-1.png" alt="Correlation of 0" width="672" />
<p class="caption">
(#fig:cor4-fig)Correlation of 0
</p>
</div>
<div style="page-break-after: always;"></div>
<div id="variance-of-sums" class="section level3" number="15.5.1">
<h3><span class="header-section-number">15.5.1</span> Variance of sums</h3>
<p>Suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two random variables. Then,
<span class="math display">\[
\mbox{Var}(X+Y)=\mbox{E}\left[(X+Y-\mbox{E}(X+Y))^2\right]=\mbox{E}[(X+Y)^2]-\left[\mbox{E}(X+Y)\right]^2
\]</span></p>
<p>In the last step, we are using the alternative expression for variance (<span class="math inline">\(\mbox{Var}(X)=\mbox{E}(X^2)-\mbox{E}(X)^2\)</span>). Evaluating:
<span class="math display">\[
\mbox{Var}(X+Y)=\mbox{E}(X^2)+\mbox{E}(Y^2)+2\mbox{E}(XY)-\mbox{E}(X)^2-\mbox{E}(Y)^2-2\mbox{E}(X)\mbox{E}(Y)
\]</span></p>
<p>Regrouping the terms:
<span class="math display">\[
=\mbox{E}(X^2)-\mbox{E}(X)^2+\mbox{E}(Y^2)-\mbox{E}(Y)^2+2\left(\mbox{E}(XY)-\mbox{E}(X)\mbox{E}(Y)\right)
\]</span></p>
<p><span class="math display">\[
=\mbox{Var}(X)+\mbox{Var}(Y)+2\mbox{Cov}(X,Y)
\]</span></p>
<blockquote>
<p><em>Example</em>:<br />
Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be defined as above. Find <span class="math inline">\(\mbox{Cov}(X,Y)\)</span>, <span class="math inline">\(\rho\)</span>, and <span class="math inline">\(\mbox{Var}(X+Y)\)</span>.</p>
</blockquote>
<p><span class="math display">\[
\mbox{Cov}(X,Y)=\mbox{E}(XY)-\mbox{E}(X)\mbox{E}(Y)=0.9-0.92*0.97=0.0076
\]</span></p>
<p><span class="math display">\[
\rho=\frac{\mbox{Cov}(X,Y)}{\sqrt{\mbox{Var}(X)\mbox{Var}(Y)}}
\]</span></p>
<p>Quickly, <span class="math inline">\(\mbox{Var}(X)=\mbox{E}(X^2)-\mbox{E}(X)^2= 1.34-0.92^2 =0.4936\)</span> and <span class="math inline">\(\mbox{Var}(Y)=0.6691\)</span>. So,
<span class="math display">\[
\rho=\frac{0.0076}{\sqrt{0.4936*0.6691}}=0.013
\]</span></p>
<p>With such a low <span class="math inline">\(\rho\)</span>, we would say that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are only slightly positively correlated.</p>
<p><span class="math display">\[
\mbox{Var}(X+Y)=\mbox{Var}(X)+\mbox{Var}(Y)+2\mbox{Cov}(X,Y)=0.4936+0.6691+2*0.0076=1.178
\]</span></p>
</div>
</div>
<div id="independence-1" class="section level2" number="15.6">
<h2><span class="header-section-number">15.6</span> Independence</h2>
<p>Two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are said to be <em>independent</em> if their joint pmf/pdf is the product of their marginal pmfs/pdfs:
<span class="math display">\[
f_{X,Y}(x,y)=f_X(x)f_Y(y)
\]</span></p>
<p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, then <span class="math inline">\(\mbox{Cov}(X,Y) = 0\)</span>. The converse is not necessarily true, however because they could have a non-linear relationship.</p>
<p>For a discrete distribution, you must check that each cell, joint probabilities, are equal to the product of the marginal probability. Back to our joint pmf from above:</p>
<p><span class="math display">\[
\begin{array}{cc|ccc} &amp; &amp; &amp; \textbf{Y} &amp;
\\ &amp; &amp; 0 &amp; 1 &amp; 2  
\\&amp;\hline0 &amp; 0.10 &amp; 0.08 &amp; 0.11  
\\\textbf{X} &amp;1 &amp; 0.18 &amp; 0.20 &amp; 0.12  
\\&amp;2 &amp; 0.07 &amp; 0.05 &amp; 0.09
\end{array}
\]</span></p>
<p>The marginal pmf of <span class="math inline">\(X\)</span> is</p>
<p><span class="math display">\[
f_X(x) = \left\{\begin{array}{ll} 0.29, &amp; x=0 \\
0.50, &amp; x=1 \\
0.21, &amp; x=2 \\
0, &amp; \mbox{otherwise}
\end{array}\right.
\]</span>
The marginal pmf of <span class="math inline">\(Y\)</span> is</p>
<p><span class="math display">\[
f_Y(y) = \left\{\begin{array}{ll} 0.35, &amp; y=0 \\
0.33, &amp; y=1 \\
0.32, &amp; y=2 \\
0, &amp; \mbox{otherwise}
\end{array}\right.
\]</span>
Checking the first cell, we immediately see that <span class="math inline">\(f_{X,Y}(x=0,y=0) \neq f_{X}(x=0)\cdot f_{Y}(y=0)\)</span> so <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not independent.</p>
<p>An easy way to determine if continuous variables are independent is to first check that the domain only contains constants, it is rectangular, and second that the joint pdf can be written as a product of a function of <span class="math inline">\(X\)</span> only and a function of <span class="math inline">\(Y\)</span> only.</p>
<p>Thus for our examples above even though the domains were rectangular, in <span class="math inline">\(f(x,y)=xy\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> were independent while <span class="math inline">\(f(x,y)=x+y\)</span> they were not.</p>
</div>
<div id="conditional-expectation" class="section level2" number="15.7">
<h2><span class="header-section-number">15.7</span> Conditional expectation</h2>
<p>An important idea in graph theory, network analysis, Bayesian networks, and queuing theory is conditional expectation. We will only briefly introduce the ideas here so that you have a basic understanding. This does not imply it is not an important topic.</p>
<p>Let’s start with a simple example to illustrate the ideas.</p>
<blockquote>
<p><em>Example</em>:<br />
Sam will read either one chapter of his history book or one chapter of his philosophy book. If the number of misprints in a chapter of his history book is Poisson with mean 2 and if the number of misprints in a chapter of his philosophy book is Poisson with mean 5, then assuming Sam is equally likely to choose either book, what is the expected number of misprints that Sam will find?</p>
</blockquote>
<p>Note: in the next chapter we are working with transformations and could attack the problem using that method.</p>
<p>First let’s use simulation to get an idea what value the answer should be and then use algebraic techniques and definitions we have learned in this book.</p>
<p>Simulate 5000 reads from the history book and 5000 from philosophy and combine:</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="#cb393-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2011</span>)</span>
<span id="cb393-2"><a href="#cb393-2" aria-hidden="true" tabindex="-1"></a>my_data<span class="ot">&lt;-</span><span class="fu">data.frame</span>(<span class="at">misprints=</span><span class="fu">c</span>(<span class="fu">rpois</span>(<span class="dv">5000</span>,<span class="dv">2</span>),<span class="fu">rpois</span>(<span class="dv">5000</span>,<span class="dv">5</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="#cb394-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(my_data)</span></code></pre></div>
<pre><code>##   misprints
## 1         1
## 2         1
## 3         2
## 4         1
## 5         2
## 6         4</code></pre>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="#cb396-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(my_data)</span></code></pre></div>
<pre><code>## [1] 10000     1</code></pre>
<p>Figure @ref(fig:hist151-fig) is a histogram of the data.</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="#cb398-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_histogram</span>(<span class="sc">~</span>misprints,<span class="at">data=</span>my_data,<span class="at">breaks=</span><span class="fu">seq</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">15.5</span>, <span class="at">by=</span><span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb398-2"><a href="#cb398-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb398-3"><a href="#cb398-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Number of Misprints&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="15-Multivariate-Expectation_files/figure-html/hist151-fig-1.png" alt="Misprints from combined history and philosphy books." width="672" />
<p class="caption">
(#fig:hist151-fig)Misprints from combined history and philosphy books.
</p>
</div>
<p>Or as a bar chart in Figure @ref(fig:bar151-fig)</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="#cb399-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_bar</span>(<span class="sc">~</span>misprints,<span class="at">data=</span>my_data)<span class="sc">%&gt;%</span></span>
<span id="cb399-2"><a href="#cb399-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb399-3"><a href="#cb399-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Number of Misprints&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="15-Multivariate-Expectation_files/figure-html/bar151-fig-1.png" alt="Misprints from combined history and philosphy books as a bar chart." width="672" />
<p class="caption">
(#fig:bar151-fig)Misprints from combined history and philosphy books as a bar chart.
</p>
</div>
<p>And now find the average.</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="#cb400-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="sc">~</span>misprints,<span class="at">data=</span>my_data)</span></code></pre></div>
<pre><code>## [1] 3.4968</code></pre>
<p>Now for a mathematical solution. Let <span class="math inline">\(X\)</span> stand for the number of misprints and <span class="math inline">\(Y\)</span> for the book, to make <span class="math inline">\(Y\)</span> a random variable let’s call 0 history and 1 philosophy. Then <span class="math inline">\(E[X|Y]\)</span> is the expected number of misprints given the book. This is a conditional expectation. For example <span class="math inline">\(E[X|Y=0]\)</span> is the expected number of misprints in the history book.</p>
<p>Now here is the tricky part, without specifying a value of <span class="math inline">\(Y\)</span>, called a realization, this expectation function is a random variable that depends on <span class="math inline">\(Y\)</span>. In other words, if we don’t know the book, the expected number of misprints depends on <span class="math inline">\(Y\)</span> and thus is a random variable. If we take the expected value of this random variable we get</p>
<p><span class="math display">\[E[X]=E[E[X|Y]]\]</span></p>
<p>The inner expectation in the right hand side is for the conditional distribution and the outer is for the marginal with respect to <span class="math inline">\(Y\)</span>. This seems confusing, so let’s go back to our example.</p>
<p><span class="math display">\[E[X]=E[E[X|Y]]\]</span>
<span class="math display">\[=E[X|Y=0] \cdot \mbox{P}(Y=0)+E[X|Y=1] \cdot \mbox{P}(Y=1)\]</span>
<span class="math display">\[=2*\frac{1}{2}+5*\frac{1}{2}=\frac{7}{2}=3.5\]</span>
These ideas are going to be similar for continuous random variables. There is so much more that you can do with conditional expectations, but these are beyond the scope of the book.</p>
</div>
<div id="homework-problems-14" class="section level2" number="15.8">
<h2><span class="header-section-number">15.8</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be continuous random variables with joint pdf:
<span class="math display">\[
f_{X,Y}(x,y)=x + y
\]</span></li>
</ol>
<p>where <span class="math inline">\(0 \leq x \leq 1\)</span> and <span class="math inline">\(0 \leq y \leq 1\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Find <span class="math inline">\(\mbox{E}(X)\)</span> and <span class="math inline">\(\mbox{E}(Y)\)</span>.<br />
</li>
<li>Find <span class="math inline">\(\mbox{Var}(X)\)</span> and <span class="math inline">\(\mbox{Var}(Y)\)</span>.<br />
</li>
<li>Find <span class="math inline">\(\mbox{Cov}(X,Y)\)</span> and <span class="math inline">\(\rho\)</span>. Are <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> independent?<br />
</li>
<li>Find <span class="math inline">\(\mbox{Var}(3X+2Y)\)</span>.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><p>Optional - not difficult but does have small Calc III idea. Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be continuous random variables with joint pmf:
<span class="math display">\[
f_{X,Y}(x,y)=1
\]</span></p></li>
<li><p>Suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <em>independent</em> random variables. Show that <span class="math inline">\(\mbox{E}(XY)=\mbox{E}(X)\mbox{E}(Y)\)</span>.</p></li>
<li><p>You are playing a game with a friend. Each of you roll a fair sided die and record the result.</p></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Write the joint probability mass function.</p></li>
<li><p>Find the expected value of the product of your score and your friend’s score.</p></li>
<li><p>Verify the previous part using simulation.</p></li>
<li><p>Using simulation, find the expected value of the maximum number on the two roles.</p></li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li><p>A miner is trapped in a mine containing three doors. The first door leads to a tunnel that takes him to safety after two hours of travel. The second door leads to a tunnel that returns him to the mine after three hours of travel. The third door leads to a tunnel that returns him to his mine after five hours. Assuming that the miner is at all times equally likely to choose any one of the doors, yes a bad assumption but it makes for a nice problem, what is the expected length of time until the miner reaches safety?</p></li>
<li><p>ADVANCED: Let <span class="math inline">\(X_1,X_2,...,X_n\)</span> be independent, identically distributed random variables. (This is often abbreviated as “iid”). Each <span class="math inline">\(X_i\)</span> has mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span> (i.e., for all <span class="math inline">\(i\)</span>, <span class="math inline">\(\mbox{E}(X_i)=\mu\)</span> and <span class="math inline">\(\mbox{Var}(X_i)=\sigma^2\)</span>).</p></li>
</ol>
<p>Let <span class="math inline">\(S=X_1+X_2+...+X_n=\sum_{i=1}^n X_i\)</span>. And let <span class="math inline">\(\bar{X}={\sum_{i=1}^n X_i \over n}\)</span>.</p>
<p>Find <span class="math inline">\(\mbox{E}(S)\)</span>, <span class="math inline">\(\mbox{Var}(S)\)</span>, <span class="math inline">\(\mbox{E}(\bar{X})\)</span> and <span class="math inline">\(\mbox{Var}(\bar{X})\)</span>.</p>
<!--chapter:end:15-Multivariate-Expectation.Rmd-->
</div>
</div>
<div id="TRANS" class="section level1" number="16">
<h1><span class="header-section-number">16</span> Transformations</h1>
<div id="objectives-15" class="section level2" number="16.1">
<h2><span class="header-section-number">16.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Given a discrete random variable, determine the distribution of a transformation of that random variable.<br />
</li>
<li>Given a continuous random variable, use the cdf method to determine the distribution of a transformation of that random variable.<br />
</li>
<li>Use simulation methods to find the distribution of a transform of single or multivariate random variables.</li>
</ol>
</div>
<div id="transformations" class="section level2" number="16.2">
<h2><span class="header-section-number">16.2</span> Transformations</h2>
<p>Throughout our coverage of random variables, we have mentioned transformations of random variables. These have been in the context of linear transformations. We have discussed expected value and variance of linear transformations. Recall that <span class="math inline">\(\mbox{E}(aX+b)=a\mbox{E}(X)+b\)</span> and <span class="math inline">\(\mbox{Var}(aX+b)=a^2\mbox{Var}(X)\)</span>.</p>
<p>In this chapter, we will discuss transformations of random variables in general, beyond the linear case.</p>
<div id="transformations-of-discrete-random-variables" class="section level3" number="16.2.1">
<h3><span class="header-section-number">16.2.1</span> Transformations of discrete random variables</h3>
<p>Let <span class="math inline">\(X\)</span> be a discrete random variable and let <span class="math inline">\(g\)</span> be a function. The variable <span class="math inline">\(Y=g(X)\)</span> is a discrete random variable with pmf:
<span class="math display">\[
f_Y(y)=\mbox{P}(Y=y)=\sum_{\forall x: g(x)=y}\mbox{P}(X=x)=\sum_{\forall x: g(x)=y}f_X(x)
\]</span></p>
<p>An example would help since the notation can be confusing.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose <span class="math inline">\(X\)</span> is a discrete random variable with pmf:
<span class="math display">\[
f_X(x)=\left\{\begin{array}{ll} 0.05, &amp; x=-2 \\
0.10, &amp; x=-1 \\
0.35, &amp; x=0 \\
0.30, &amp; x=1 \\
0.20, &amp; x=2 \\
0, &amp; \mbox{otherwise} \end{array}\right.
\]</span></p>
</blockquote>
<p>Find the pmf for <span class="math inline">\(Y=X^2\)</span>.</p>
<p>It helps to identify the support of <span class="math inline">\(Y\)</span>, that is where <span class="math inline">\(f_{Y}(y)&gt;0\)</span>. Since the support of <span class="math inline">\(X\)</span> is <span class="math inline">\(S_X=\{-2,-1,0,1,2\}\)</span>, the support of <span class="math inline">\(Y\)</span> is <span class="math inline">\(S_Y=\{0,1,4\}\)</span>.
<span class="math display">\[
f_Y(0)=\sum_{x^2=0}f_X(x)=f_X(0)=0.35
\]</span></p>
<p><span class="math display">\[
f_Y(1)=\sum_{x^2=1}f_X(x)=f_X(-1)+f_X(1)=0.1+0.3=0.4
\]</span>
<span class="math display">\[
f_Y(4)=\sum_{x^2=4}f_X(x)=f_X(-2)+f_X(2)=0.05+0.2=0.25
\]</span></p>
<p>So,
<span class="math display">\[
f_Y(y)=\left\{\begin{array}{ll} 0.35, &amp; y=0 \\
0.4, &amp; y=1 \\
0.25, &amp; y=4 \\
0, &amp; \mbox{otherwise} \end{array}\right.
\]</span></p>
<p>It also helps to confirm that these probabilities add to one, which they do. This is the pmf of <span class="math inline">\(Y=X^2\)</span>.</p>
<p>The key idea is to find the support of the new random variable and then go back to the original random variable and sum all the probabilities that get mapped into that new support element.</p>
</div>
<div id="transformations-of-continuous-random-variables" class="section level3" number="16.2.2">
<h3><span class="header-section-number">16.2.2</span> Transformations of continuous random variables</h3>
<p>The methodology above will not work directly in the case of continuous random variables. This is because in the continuous case, the pdf, <span class="math inline">\(f_X(x)\)</span>, represents <strong>density</strong> and not <strong>probability</strong>.</p>
</div>
<div id="the-cdf-method" class="section level3" number="16.2.3">
<h3><span class="header-section-number">16.2.3</span> The cdf method</h3>
<p>The <strong>cdf method</strong> is one of several methods that can be used for transformations of continuous random variables. The idea is to find the cdf of the new random variable and then find the pdf by way of the fundamental theorem of calculus.</p>
<p>Suppose <span class="math inline">\(X\)</span> is a continuous random variable with cdf <span class="math inline">\(F_X(x)\)</span>. Let <span class="math inline">\(Y=g(X)\)</span>. We can find the cdf of <span class="math inline">\(Y\)</span> as:</p>
<p><span class="math display">\[
F_Y(y)=\mbox{P}(Y\leq y)=\mbox{P}(g(X)\leq y)=\mbox{P}(X\leq g^{-1}(y))=F_X(g^{-1}(y))
\]</span></p>
<p>To get the pdf of <span class="math inline">\(Y\)</span> we would need to take the derivative of the cdf. Note that <span class="math inline">\(g^{-1}(y)\)</span> is the function inverse while <span class="math inline">\(g(y)^{-1}\)</span> is the multiplicative inverse.</p>
<p>This method requires the transformation function to have an inverse. Sometimes we can break the domain of the original random variables into regions where an inverse of the transformation function exists.</p>
<blockquote>
<p><em>Example</em>:
Let <span class="math inline">\(X\sim \textsf{Unif}(0,1)\)</span> and let <span class="math inline">\(Y=X^2\)</span>. Find the pdf of <span class="math inline">\(Y\)</span>.</p>
</blockquote>
<p>Before we start, let’s think about the distribution of <span class="math inline">\(Y\)</span>. We are randomly taking numbers between 0 and 1 and then squaring them. Squaring a positive number less than 1 makes it even smaller. We thus suspect the pdf of <span class="math inline">\(Y\)</span> will have larger density near 0 than 1. The shape is hard to determine so let’s do some math.</p>
<p>Since <span class="math inline">\(X\)</span> has the uniform distribution, we know that <span class="math inline">\(f_X(x)\)</span> and <span class="math inline">\(F_X(x)=x\)</span> for <span class="math inline">\(0\leq x \leq 1\)</span>. So,
<span class="math display">\[
F_Y(y)=\mbox{P}(Y\leq y)=\mbox{P}(X^2\leq y)=\mbox{P}(X\leq \sqrt{y})=F_X\left(\sqrt{y}\right)=\sqrt{y}
\]</span></p>
<p>Taking the derivative of this yields:
<span class="math display">\[
f_Y(y)=\frac{1}{2\sqrt{y}}
\]</span></p>
<p>for <span class="math inline">\(0 &lt; y \leq 1\)</span> and 0 otherwise. Notice we can’t have <span class="math inline">\(y=0\)</span> since we would be dividing by zero. This is not a problem since we have a continuous distribution. We could verify this a proper pdf by determining if the pdf integrates to 1 over the domain:
<span class="math display">\[
\int_0^1 \frac{1}{2\sqrt{y}} \mathop{}\!\mathrm{d}y = \sqrt{y}\bigg|_0^1 = 1
\]</span>
We can also do this using <code>R</code> but we first have to create a function that can take vector input.</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="#cb402-1" aria-hidden="true" tabindex="-1"></a>y_pdf <span class="ot">&lt;-</span> <span class="cf">function</span>(y) {</span>
<span id="cb402-2"><a href="#cb402-2" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span><span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">sqrt</span>(y))</span>
<span id="cb402-3"><a href="#cb402-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="#cb403-1" aria-hidden="true" tabindex="-1"></a>y_pdf<span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(y_pdf)</span></code></pre></div>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="#cb404-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(y_pdf,<span class="dv">0</span>,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 1 with absolute error &lt; 2.9e-15</code></pre>
<p>Notice that since the domain of the original random variable was non-negative, the squared function had an inverse.</p>
<p>The pdf of the random variable <span class="math inline">\(Y\)</span> is plotted in Figure @ref(fig:pdf161-fig).</p>
<p>(ref:quote161) The pdf of the transformed random variable <span class="math inline">\(Y\)</span>.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="#cb406-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_line</span>(<span class="fu">y_pdf</span>(<span class="fu">seq</span>(<span class="fl">0.01</span>,<span class="dv">1</span>,.<span class="dv">01</span>))<span class="sc">~</span><span class="fu">seq</span>(<span class="fl">0.01</span>,<span class="dv">1</span>,.<span class="dv">01</span>),<span class="at">xlab=</span><span class="st">&quot;Y&quot;</span>,<span class="at">ylab=</span><span class="fu">expression</span>(<span class="fu">f</span>(y))) <span class="sc">%&gt;%</span></span>
<span id="cb406-2"><a href="#cb406-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="16-Transformations_files/figure-html/pdf161-fig-1.png" alt="(ref:quote161)" width="672" />
<p class="caption">
(#fig:pdf161-fig)(ref:quote161)
</p>
</div>
<p>We can see that the density is much larger at we approach 0.</p>
</div>
<div id="the-pdf-method" class="section level3" number="16.2.4">
<h3><span class="header-section-number">16.2.4</span> The pdf method</h3>
<p>The cdf method of transforming continuous random variables also yields to another method called the <strong>pdf method</strong>. Recall that the cdf method tells us that if <span class="math inline">\(X\)</span> is a continuous random variable with cdf <span class="math inline">\(F_X\)</span>, and <span class="math inline">\(Y=g(X)\)</span>, then</p>
<p><span class="math display">\[
F_Y(y)=F_X(g^{-1}(y))
\]</span></p>
<p>We can find the pdf of <span class="math inline">\(Y\)</span> by differentiating the cdf:
<span class="math display">\[
f_Y(y)=\frac{\mathop{}\!\mathrm{d}}{\mathop{}\!\mathrm{d}y}F_Y(y)=\frac{\mathop{}\!\mathrm{d}}{\mathop{}\!\mathrm{d}y} F_X(g^{-1}(y)) = f_X(g^{-1}(y))\bigg| \frac{\mathop{}\!\mathrm{d}}{\mathop{}\!\mathrm{d}y}  g^{-1}(y) \bigg|
\]</span></p>
<p>So, as long as <span class="math inline">\(g^{-1}\)</span> is differentiable, we can use this method to directly obtain the pdf of <span class="math inline">\(Y\)</span>.</p>
<p>Note that in some texts, the portion of this expression <span class="math inline">\(\frac{\mathop{}\!\mathrm{d}}{\mathop{}\!\mathrm{d}y} g^{-1}(y)\)</span> is sometimes referred to as the <em>Jacobian</em>. We need to take the absolute value of the transformation function <span class="math inline">\(g(x)\)</span> because if it is a decreasing function, we have</p>
<p><span class="math display">\[
F_Y(y)=\mbox{P}(Y\leq y)=\mbox{P}(g(X) \leq y)=\mbox{P}(X \geq g^{-1}(y))= 1 - F_X(g^{-1}(y))
\]</span></p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Repeat the previous example using the pdf method.</p>
</blockquote>
<p>Since <span class="math inline">\(X\)</span> has the uniform distribution, we know that <span class="math inline">\(f_X(x)=1\)</span> for <span class="math inline">\(0\leq x \leq 1\)</span>. Also, <span class="math inline">\(g(x)=x^2\)</span> and <span class="math inline">\(g^{-1}(y)=\sqrt{y}\)</span>, which is differentiable. So,</p>
<p><span class="math display">\[
f_Y(y)=f_X(\sqrt{y})\bigg|\frac{\mathop{}\!\mathrm{d}}{\mathop{}\!\mathrm{d}y} \sqrt{y}\bigg| = \frac{1}{2\sqrt{y}}
\]</span></p>
</div>
<div id="simulation-2" class="section level3" number="16.2.5">
<h3><span class="header-section-number">16.2.5</span> Simulation</h3>
<p>We can also get an estimate of the distribution by simulating the random variable. If we have the cdf and can find its inverse, then just like we did in an earlier lesson, we sample from a uniform distribution and apply the inverse to get the distribution.</p>
<p>In an earlier chapter we had the example:</p>
<blockquote>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable with <span class="math inline">\(f_X(x)=2x\)</span> where <span class="math inline">\(0 \leq x \leq 1\)</span>.</p>
</blockquote>
<p>Now let’s find an approximation to the distribution of <span class="math inline">\(Y = \ln{X}\)</span> using simulation.</p>
<p>The cdf of <span class="math inline">\(X\)</span> is <span class="math inline">\(F_X(x)=x^2\)</span> where <span class="math inline">\(0 \leq x \leq 1\)</span>. We will draw a uniform random variable and then take the square root to simulate a random variable from <span class="math inline">\(f_X(x)\)</span>. We will replicate this 10,000 times. In <code>R</code> our code, which we have done before, is:</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="#cb407-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">runif</span>(<span class="dv">1</span>))</span></code></pre></div>
<p>Remember, we are using the square root because we want the inverse of the cdf and not, for this method, the inverse of the transformation function as when we were using the mathematical method. This can be a point of confusion.</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="#cb408-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(results)</span></code></pre></div>
<pre><code>## 
## quantitative variables:  
##      name   class         min        Q1    median        Q3       max      mean
## ...1 sqrt numeric 0.004675867 0.5072335 0.7078661 0.8696528 0.9999747 0.6697756
##             sd     n missing
## ...1 0.2350824 10000       0</code></pre>
<p>Figure @ref(fig:dens161-fig) is a density plot of the simulated original random variable.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="#cb410-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb410-2"><a href="#cb410-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_density</span>(<span class="sc">~</span>sqrt,<span class="at">xlab=</span><span class="st">&quot;X&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb410-3"><a href="#cb410-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb410-4"><a href="#cb410-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="16-Transformations_files/figure-html/dens161-fig-1.png" alt="The density plot of the original using simulation." width="672" />
<p class="caption">
(#fig:dens161-fig)The density plot of the original using simulation.
</p>
</div>
<p>Now to find the distribution of <span class="math inline">\(Y\)</span> we just apply the transformation.</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="#cb411-1" aria-hidden="true" tabindex="-1"></a>y_results <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span></span>
<span id="cb411-2"><a href="#cb411-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">y=</span><span class="fu">log</span>(sqrt))</span></code></pre></div>
<p>Figure @ref(fig:dens162-fig) is the density plot of the transformed random variable from the simulation. We can see that the support for <span class="math inline">\(Y\)</span> is <span class="math inline">\(-\infty &lt; y \leq 0\)</span> and the density is tight near zero but skewed to the left.</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="#cb412-1" aria-hidden="true" tabindex="-1"></a>y_results <span class="sc">%&gt;%</span></span>
<span id="cb412-2"><a href="#cb412-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_density</span>(<span class="sc">~</span>y,<span class="at">xlab=</span><span class="st">&quot;X&quot;</span>)  <span class="sc">%&gt;%</span></span>
<span id="cb412-3"><a href="#cb412-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb412-4"><a href="#cb412-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="16-Transformations_files/figure-html/dens162-fig-1.png" alt="The density plot of the transformed random variable from the simulation." width="672" />
<p class="caption">
(#fig:dens162-fig)The density plot of the transformed random variable from the simulation.
</p>
</div>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="#cb413-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(y_results)</span></code></pre></div>
<pre><code>## 
## quantitative variables:  
##      name   class       min         Q1     median         Q3           max
## ...1    y numeric -5.365341 -0.6787839 -0.3455003 -0.1396613 -2.527336e-05
##            mean        sd     n missing
## ...1 -0.4940434 0.4979518 10000       0</code></pre>
</div>
<div id="multivariate-transformations" class="section level3" number="16.2.6">
<h3><span class="header-section-number">16.2.6</span> Multivariate Transformations</h3>
<p>For the discrete case, if you have the joint pmf, then if the transformation is to a univariate random variable, the process is similar to what see learned above. For continuous random variables, the mathematics are a little more difficult so we will just use simulation.</p>
<p>Here’s the scenario. Suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent random variables, both uniformly distributed on <span class="math inline">\([5,6]\)</span>.
<span class="math display">\[
X\sim \textsf{Unif}(5,6)\hspace{1.5cm} Y\sim \textsf{Unif}(5,6)
\]</span></p>
<p>Let <span class="math inline">\(X\)</span> be your arrival time for dinner and <span class="math inline">\(Y\)</span> your friends arrival time. We picked 5 to 6 because this is the time in the evening we want to meet. Also assume you both travel independently.</p>
<p>Define <span class="math inline">\(Z\)</span> as a transformation of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> such that <span class="math inline">\(Z=|X-Y|\)</span>. Thus <span class="math inline">\(Z\)</span> is the absolute value of the difference between your arrival times. The units for <span class="math inline">\(Z\)</span> are hours. We would like to explore the distribution of <span class="math inline">\(Z\)</span>. We could do this via calc III methods but we will simulate instead.</p>
<p>We can use <code>R</code> to obtain simulated values from <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (and thus find <span class="math inline">\(Z\)</span>).</p>
<p>First, simulate 100,000 observations from the uniform distribution with parameters 5 and 6. Assign those random observations to a variable. Next, repeat that process, assigning those to a different variable. These two vectors represent your simulated values from <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Finally, obtain your simulated values of <span class="math inline">\(Z\)</span> by taking the absolute value of the difference.</p>
<blockquote>
<p><strong>Exercise</strong>:</p>
</blockquote>
<p>Complete the code on your own before looking at the code below.</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="#cb415-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">354</span>)</span>
<span id="cb415-2"><a href="#cb415-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">100000</span>)<span class="sc">*</span><span class="fu">abs</span>(<span class="fu">diff</span>(<span class="fu">runif</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">6</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="#cb416-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##          abs
## 1 0.03171229
## 2 0.77846706
## 3 0.29111599
## 4 0.06700434
## 5 0.08663187
## 6 0.40622840</code></pre>
<p>Figure @ref(fig:dens163-fig) is a plot of the estimated density of the transformation.</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="#cb418-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb418-2"><a href="#cb418-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_density</span>(<span class="sc">~</span>abs) <span class="sc">%&gt;%</span></span>
<span id="cb418-3"><a href="#cb418-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb418-4"><a href="#cb418-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;|X-Y|&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="16-Transformations_files/figure-html/dens163-fig-1.png" alt="The density of the absolute value of the difference in uniform random variables." width="672" />
<p class="caption">
(#fig:dens163-fig)The density of the absolute value of the difference in uniform random variables.
</p>
</div>
<p>Or as a histogram in Figure @ref(fig:hist163-fig).</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="#cb419-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb419-2"><a href="#cb419-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>abs)<span class="sc">%&gt;%</span></span>
<span id="cb419-3"><a href="#cb419-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb419-4"><a href="#cb419-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;|X-Y|&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="16-Transformations_files/figure-html/hist163-fig-1.png" alt="Histogram of the absolute value of the difference in random variables." width="672" />
<p class="caption">
(#fig:hist163-fig)Histogram of the absolute value of the difference in random variables.
</p>
</div>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="#cb420-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(results)</span></code></pre></div>
<pre><code>## 
## quantitative variables:  
##      name   class          min       Q1    median        Q3       max     mean
## ...1  abs numeric 1.265667e-06 0.133499 0.2916012 0.4990543 0.9979459 0.332799
##             sd      n missing
## ...1 0.2358863 100000       0</code></pre>
<blockquote>
<p><strong>Exercise</strong>:<br />
Now suppose whomever arrives first will only wait 5 minutes and then leave. What is the probability you eat together?</p>
</blockquote>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="#cb422-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(results) <span class="sc">%&gt;%</span></span>
<span id="cb422-2"><a href="#cb422-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">mean</span>(abs<span class="sc">&lt;=</span><span class="dv">5</span><span class="sc">/</span><span class="dv">60</span>))</span></code></pre></div>
<pre><code>##   mean(abs &lt;= 5/60)
## 1           0.15966</code></pre>
<blockquote>
<p><strong>Exercise</strong>:<br />
How long should the first person wait so that there is at least a 50% probability of you eating together?</p>
</blockquote>
<p>Let’s write a function to find the cdf.</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="#cb424-1" aria-hidden="true" tabindex="-1"></a>z_cdf <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb424-2"><a href="#cb424-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(results<span class="sc">$</span>abs<span class="sc">&lt;=</span>x)</span>
<span id="cb424-3"><a href="#cb424-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="#cb425-1" aria-hidden="true" tabindex="-1"></a>z_cdf<span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(z_cdf)</span></code></pre></div>
<p>Now test for 5 minutes to make sure our function is correct since we determined above that this value should be 0.15966.</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="#cb426-1" aria-hidden="true" tabindex="-1"></a><span class="fu">z_cdf</span>(<span class="dv">5</span><span class="sc">/</span><span class="dv">60</span>)</span></code></pre></div>
<pre><code>## [1] 0.15966</code></pre>
<p>Let’s plot to see what the cdf looks like.</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="#cb428-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_line</span>(<span class="fu">z_cdf</span>(<span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,.<span class="dv">01</span>))<span class="sc">~</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,.<span class="dv">01</span>),<span class="at">xlab=</span><span class="st">&quot;Time Difference&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;CDF&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb428-2"><a href="#cb428-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<p><img src="16-Transformations_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>It looks like somewhere around 15 minutes, a quarter of an hour. But we will find a better answer by finding the root. In the code that follows we want to find where the cdf equals 0.5. The function <code>uniroot()</code> solves the given equations for roots so we want to put in the cdf minus 0.5. In other words, <code>uniroot()</code> solves <span class="math inline">\(f(x)=0\)</span> for x.</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="fu">uniroot</span>(<span class="cf">function</span>(x)<span class="fu">z_cdf</span>(x)<span class="sc">-</span>.<span class="dv">5</span>,<span class="fu">c</span>(.<span class="dv">25</span>,<span class="dv">35</span>))<span class="sc">$</span>root</span></code></pre></div>
<pre><code>## [1] 0.2916077</code></pre>
<p>So it is actually 0.292 hours, 17.5 minutes. So round up and wait 18 minutes.</p>
</div>
</div>
<div id="homework-problems-15" class="section level2" number="16.3">
<h2><span class="header-section-number">16.3</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(X\)</span> be a random variable and let <span class="math inline">\(g\)</span> be a function. By this point, it should be clear that <span class="math inline">\(\mbox{E}[g(X)]\)</span> is not necessarily equal to <span class="math inline">\(g(\mbox{E}[X])\)</span>.</li>
</ol>
<p>Let <span class="math inline">\(X\sim \textsf{Expon}(\lambda=0.5)\)</span> and <span class="math inline">\(g(X)=X^2\)</span>. We know that <span class="math inline">\(\mbox{E}(X)=\frac{1}{0.5}=2\)</span> so <span class="math inline">\(g(\mbox{E}(X))=\mbox{E}(X)^2=4\)</span>. Use <code>R</code> to find <span class="math inline">\(\mbox{E}[g(X)]\)</span>. Make use of the fact that <code>R</code> has <code>rexp()</code> built into it, so you don’t have to create your own random variable generator.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(X\sim \textsf{Binom}(n,\pi)\)</span>. What is the pmf for <span class="math inline">\(Y = X+3\)</span>? Make sure you specify the domain of <span class="math inline">\(Y\)</span>. [Note, we have used <span class="math inline">\(p\)</span> for the probability of success in a binomial distribution in past chapters but some references use <span class="math inline">\(\pi\)</span> instead.]</p></li>
<li><p>Let <span class="math inline">\(X\sim \textsf{Expon}(\lambda)\)</span>. Let <span class="math inline">\(Y=X^2\)</span>. Find the pdf of <span class="math inline">\(Y\)</span>.</p></li>
<li><p>OPTIONAL: In exercise 3, you found the pdf of <span class="math inline">\(Y=X^2\)</span> when <span class="math inline">\(X\sim \textsf{Expon}(\lambda)\)</span>. Rearrange the pdf to show that <span class="math inline">\(Y\sim \textsf{Weibull}\)</span> and find the parameters of that distribution.</p></li>
<li><p>You are on a team of two. You are both tasked to complete an exercise. The time it takes you, <span class="math inline">\(T_1\)</span>, and likewise, your teammate, <span class="math inline">\(T_2\)</span>, to complete the exercise are independent random variables. Exercise completion time, in minutes, is distributed with the following pdf:</p></li>
</ol>
<p><span class="math display">\[
f_T(t)= \frac{-t}{200}+\frac{3}{20}; 10 \leq t \leq30
\]</span></p>
<p>Figure @ref(fig:fig1) is a plot of the pdf.</p>
<div class="figure" style="text-align: center">
<img src="16-Transformations_files/figure-html/fig1-1.png" alt="pdf of $T$" width="672" />
<p class="caption">
(#fig:fig1)pdf of <span class="math inline">\(T\)</span>
</p>
</div>
<p>We want to find the probability our combined time is less than 40 minutes, <span class="math inline">\(\mbox{P}(T_1 + T_2 &lt; 40)\)</span>. We will solve this in steps in this problem. We are going to use a computational method because the mathematics is long and algebra intensive. You are welcome to try a mathematical solution if you like but we will not provide a mathematical solution.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Use the <code>integrate()</code> function to confirm this is a valid pdf.</p></li>
<li><p>Find the cdf of <span class="math inline">\(T\)</span> mathematically.</p></li>
<li><p>To use the cdf to simulate random variables from this distribution, we need the inverse of the cdf which means we have to solve a quadratic equation. We can do this mathematically or just use the function <code>uniroot()</code>. So first, we will make sure we understand how to use <code>uniroot()</code>.</p></li>
</ol>
<p>As a check, we know the median of the distribution is approximately 15.857. Here is code to show that 15.857 is approximately the median. We are integrating the pdf from 10 to 15.857 to confirm that this is 0.5.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="#cb431-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(<span class="cf">function</span>(x)<span class="sc">-</span>x<span class="sc">/</span><span class="dv">200</span><span class="sc">+</span><span class="dv">3</span><span class="sc">/</span><span class="dv">20</span>,<span class="dv">10</span>,<span class="fl">15.857</span>)</span></code></pre></div>
<pre><code>## 0.4999389 with absolute error &lt; 5.6e-15</code></pre>
<p>Use <code>uniroot()</code> and your cdf to confirm that 15.857 is the median.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>We will create a function to take a random uniform variable on the interval <span class="math inline">\([0,1]\)</span> and return a value of our random variable, <span class="math inline">\(T\)</span>, exercise time. We can then use this function to simulate each of the exercise times and then create a new random variable that is the sum. Complete the <code>R</code> code and check that it returns the median.</li>
</ol>
<pre><code>T &lt;- function(y){
  uniroot(function(x)&quot;YOUR CDF HERE as a function of x&quot;-y,c(10,30))$root
}</code></pre>
<p>We made it a function of <span class="math inline">\(y\)</span> since we are using <span class="math inline">\(x\)</span> in our cdf. There are two function calls here, can you see why?</p>
<ol start="5" style="list-style-type: lower-alpha">
<li><p>Vectorize the function you just created using the <code>Vectorize()</code> function. Check that it is vectorized by entering <code>c(.5,.75)</code> into the function. You should get 15.85786 20.00000 as an output.</p></li>
<li><p>We are ready. Let’s create a data frame with 10000 simulation for our time and another 10000 for our teammates. Remember to set a seed. At this point it may be hard to remember what we have done. The function we created takes as input a vector of random number from a uniform distribution and then applies the inverse cdf to generate a random sample from our given pdf.</p></li>
<li><p>Do a numerical summary of the data and plot a density plot of your exercise times to give us confidence that we simulated the process correctly.</p></li>
<li><p>Create the new variable that is the sum of the two exercise time and then find the probability that the sum is less than 40.</p></li>
</ol>
<!--chapter:end:16-Transformations.Rmd-->
</div>
</div>
<div id="EST" class="section level1" number="17">
<h1><span class="header-section-number">17</span> Estimation Methods</h1>
<div id="objectives-16" class="section level2" number="17.1">
<h2><span class="header-section-number">17.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Obtain a method of moments estimate of a parameter or set of parameters.<br />
</li>
<li>Given a random sample from a distribution, obtain the likelihood function.<br />
</li>
<li>Obtain a maximum likelihood estimate of a parameter or set of parameters.<br />
</li>
<li>Determine if an estimator is unbiased.</li>
</ol>
</div>
<div id="transition" class="section level2" number="17.2">
<h2><span class="header-section-number">17.2</span> Transition</h2>
<p>We started this book with descriptive models of data and then moved onto probability models. In these probability models, we have been characterizing experiments and random processes using both theory and simulation. These models are using a model about a random event to make decisions about data. These models are about the population and are used to make decisions about samples and data. For example, suppose we flip a fair coin 10 times, and record the number of heads. The population is the collection of all possible outcomes of this experiment. In this case, the population is infinite, as we could run this experiment repeatedly without limit. If we assume, model, the number of heads as a binomial distribution, we know the exact distribution of the outcomes. For example, we know that exactly 24.61% of the time, we will obtain 5 heads out of 10 flips of a fair coin. We can also use the model to characterize the variance, that is when it does not equal 5 and how much different from 5 it will be. However, these probability models are highly dependent on the assumptions and the values of the parameters.</p>
<p>From this point on in the book, we will focus on <em>statistical</em> models. Statistical models describe one or more variables and their relationships. We use these models to make decisions about the population, to predict future outcomes, or both. Often we don’t know the true underlying process; all we have is a <em>sample</em> of observations and perhaps some context. Using <em>inferential</em> statistics, we can draw conclusions about the underlying process. For example, suppose we are given a coin and we don’t know whether it is fair. So, we flip it a number of times to obtain a sample of outcomes. We can use that sample to decide whether the coin could be fair.</p>
<p>In some sense, we’ve already explored some of these concepts. In our simulation examples, we have drawn observations from a population of interest and used those observations to estimate characteristics of another population or segment of the experiment. For example, we explored random variable <span class="math inline">\(Z\)</span>, where <span class="math inline">\(Z=|X - Y|\)</span> and <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> were both uniform random variables. Instead of dealing with the distribution of <span class="math inline">\(Z\)</span> directly, we simulated many observations from <span class="math inline">\(Z\)</span> and used this simulation to describe the behavior of <span class="math inline">\(Z\)</span>.</p>
<p>Statistical models and probability models are not separate. In statistical models we find relationships, the explained portion of variation, and use probability models for the remaining random variation. In Figure @ref(fig:prob-stats), we demonstrate this relationship between the two types of models. In the first part of our studies, we will use univariate data in statistical models to estimate the parameters of a probability model. From there we will develop more sophisticated models to include multivariate models.</p>
<div class="figure" style="text-align: center">
<img src="figures/Prob_Stats.png" alt="A graphical representation of probability and statistics. In probability, we describe what we expect to happen if we know that underlying process; in statistics, we don't know the underlying process, and must infer based on representative samples." width="576" />
<p class="caption">
(#fig:prob-stats)A graphical representation of probability and statistics. In probability, we describe what we expect to happen if we know that underlying process; in statistics, we don’t know the underlying process, and must infer based on representative samples.
</p>
</div>
</div>
<div id="estimation" class="section level2" number="17.3">
<h2><span class="header-section-number">17.3</span> Estimation</h2>
<p>Recall that in probability models, we have complete information about the population and we use that to describe the expected behavior of samples from that population. In statistics we are given a sample from a population about which we know little or nothing.</p>
<p>In this lesson, we will discuss <em>estimation</em>. Given a sample, we would like to estimate population parameters. There are several ways to do that. We will discuss two methods: <em>method of moments</em> and <em>maximum likelihood</em>.</p>
</div>
<div id="method-of-moments" class="section level2" number="17.4">
<h2><span class="header-section-number">17.4</span> Method of Moments</h2>
<p>Recall earlier we discussed moments. We can refer to <span class="math inline">\(\mbox{E}(X) = \mu\)</span> as the first moment or mean. Further, we can refer to <span class="math inline">\(\mbox{E}(X^k)\)</span> as the <span class="math inline">\(k\)</span>th central moment and <span class="math inline">\(\mbox{E}[(X-\mu)^k]\)</span> as the <span class="math inline">\(k\)</span> moment around the mean. The second moment around the mean is also known as variance. It is important to point out that these are <strong>POPULATION</strong> moments and are typically some function of the parameters of a probability model.</p>
<p>Suppose <span class="math inline">\(X_1,X_2,...,X_n\)</span> is a sequence of independent, identically distributed random variables with some distribution and parameters <span class="math inline">\(\boldsymbol{\theta}\)</span>. When provided with a random sample of data, we will not know the population moments. However, we can obtain <em>sample moments</em>. The <span class="math inline">\(k\)</span>th central sample moment is denoted by <span class="math inline">\(\hat{\mu}_k\)</span> and is given by
<span class="math display">\[
\hat{\mu}_k = \frac{1}{n}\sum_{i=1}^n x_i^k
\]</span></p>
<p>The <span class="math inline">\(k\)</span>th sample moment around the mean is denoted by <span class="math inline">\(\hat{\mu}&#39;_k\)</span> and is given by
<span class="math display">\[
\hat{\mu}&#39;_k=\frac{1}{n} \sum_{i=1}^n (x_i-\bar{x})^k
\]</span></p>
<p>The value <span class="math inline">\(\hat{\mu}\)</span> is read “mu-hat”. The hat denotes that the value is an estimate.</p>
<p>We can use the sample moments to estimate the population moments since the population moments are usually functions of a distribution’s parameters, <span class="math inline">\(\boldsymbol{\theta}\)</span>. Thus, we can solve for the parameters to obtain method of moments estimates of <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<p>This is all technical, so let’s look at an example.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose <span class="math inline">\(x_1,x_2,...,x_n\)</span> is an iid, independent and identically distributed, sample from a uniform distribution <span class="math inline">\(\textsf{Unif}(0,\theta)\)</span>, and we don’t know <span class="math inline">\(\theta\)</span>. That is, our data consists of positive random numbers but we don’t know the upper bound. Find the method of moments estimator for <span class="math inline">\(\theta\)</span>, the upper bound.</p>
</blockquote>
<p>We know that if <span class="math inline">\(X\sim \textsf{Unif}(a,b)\)</span>, then <span class="math inline">\(\mbox{E}(X)=\frac{a+b}{2}\)</span>. So, in this case, <span class="math inline">\(\mbox{E}(X)={\theta \over 2}\)</span>. This is the first population moment. We can estimate this with the first <em>sample</em> moment, which is just the sample mean:
<span class="math display">\[
\hat{\mu}_1=\frac{1}{n}\sum_{i=1}^n x_i = \bar{x}
\]</span></p>
<p>Our best guess for the first population moment (<span class="math inline">\(\theta/2\)</span>) is the first sample moment (<span class="math inline">\(\bar{x}\)</span>). From a common sense perspective, we are hoping that the sample moment will be close in value to the population moment, so we can set them equal and solve for the unknown population parameter. This is essentially what we were doing in our simulations of probability models. Solving for <span class="math inline">\(\theta\)</span> yields our method of moments estimator for <span class="math inline">\(\theta\)</span>:
<span class="math display">\[
\hat{\theta}_{MoM}=2\bar{x}
\]</span></p>
<p>Note that we could have used the second moments about the mean as well. This is less intuitive but still applicable. In this case we know that if <span class="math inline">\(X\sim \textsf{Unif}(a,b)\)</span>, then <span class="math inline">\(\mbox{Var}(X)=\frac{(b - a)^2}{12}\)</span>. So, in this case, <span class="math inline">\(\mbox{Var}(X)=\frac{\theta ^2}{ 12}\)</span>. We use the second sample moment about the mean <span class="math inline">\(\hat{\mu}&#39;_2=\frac{1}{n} \sum_{i=1}^n (x_i-\bar{x})^2\)</span> which is not quite the sample variance. In fact, the sample variance is related to the second sample moment about the mean by <span class="math inline">\(\hat{\mu}&#39;_2 = s^2 \frac{n}{n-1}\)</span>. Setting the population moment and sample moment equal and solving we get</p>
<p><span class="math display">\[
\hat{\theta}_{MoM}=\sqrt{\frac{12n}{n-1}}s
\]</span></p>
<p>To decide which is better we need a criteria of comparison. This is beyond the scope of this book, but some common criteria are <em>unbiased</em> and <em>minimum variance</em>.</p>
<p>The method of moments can be used to estimate more than one parameter as well. We simply would have to incorporate higher order moments.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose we take an iid sample from the normal distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. Find method of moments estimates of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
</blockquote>
<p>First, we remember that we know two population moments for the normal distribution:
<span class="math display">\[
\mbox{E}(X)=\mu \hspace{1cm} \mbox{Var}(X)=\mbox{E}[(X-\mu)^2]=\sigma^2
\]</span></p>
<p>Setting these equal to the sample moments yields:
<span class="math display">\[
\hat{\mu}_{MoM}=\bar{x} \hspace{1cm} \hat{\sigma}_{MoM} = \sqrt{\frac{1}{n}\sum_{i=1}^n (x_i-\bar{x})^2}
\]</span></p>
<p>Again, we notice that the estimate for <span class="math inline">\(\sigma\)</span> is different from sample standard deviation discussed earlier in the book. The reason for this is a property of estimators called <em>unbiased</em>. Notice that if we treat the data points as random variables then the estimators are random variables. We can then take the expected value of the estimator and if this equals the parameter being estimated, then it is unbiased. Mathematically, this is written
<span class="math display">\[
E(\hat{\theta})=\theta
\]</span>
Unbiased is not a required property for an estimated but many practitioners find it desirable. In words, unbiased means that on average the estimator will equal the true value. Sample variance using <span class="math inline">\(n-1\)</span> in the denominator is an unbiased estimate of the population variance.</p>
<blockquote>
<p><em>Exercise</em>:<br />
You shot 25 free throws and make 21. Assuming a binomial model fits. Find an estimate of the probability of making a free throw.</p>
</blockquote>
<p>There are two ways to approach this problem depending on how we define the random variable. In the first case we will use a binomial random variable, <span class="math inline">\(X\)</span> the number of made free throws in 25 attempts. In this case, we only ran the experiment once and have the observed result of 21. Recall for the binomial <span class="math inline">\(E(X)=np\)</span> where <span class="math inline">\(n\)</span> is the number of attempts and <span class="math inline">\(p\)</span> is the probability of success. The sample mean is 21 since we only have one data point. Using the method of moments, we set the first population mean equal to the first sample mean <span class="math inline">\(np=\frac{\sum{x_i}}{m}\)</span>, notice <span class="math inline">\(n\)</span> is the number of trials 25 and <span class="math inline">\(m\)</span> is the number of data points 1, or <span class="math inline">\(25 \hat{p} = 21\)</span>. Thus <span class="math inline">\(\hat{p} = \frac{21}{25}\)</span>.</p>
<p>A second approach is to let <span class="math inline">\(X_i\)</span> be a single free throw, we have a Bernoulli random variable. This variable takes on the values of 0 if we miss and 1 if we make the free throw. Thus we have 25 data points. For a Bernoulli random variable <span class="math inline">\(E(X)=p\)</span>. The sample is <span class="math inline">\(\bar{x} = \frac{21}{25}\)</span>. Using the method of moments, we set the sample mean equal to the population mean. We have <span class="math inline">\(E(X) = \hat{p} = \bar{x} = \frac{21}{25}\)</span>. This is a natural estimate; we estimate our probability of success as the number of made free throws divided by the number of shots. As a side note, this is an unbiased estimator since
<span class="math display">\[
E(\hat{p})=E\left( \sum{\frac{X_i}{n}} \right)
\]</span></p>
<p><span class="math display">\[
=  \sum{E\left( \frac{X_i}{n} \right)}= \sum{ \frac{E\left(X_i\right)}{n}}=\sum{\frac{p}{n}}=\frac{np}{n}=p
\]</span></p>
</div>
<div id="maximum-likelihood" class="section level2" number="17.5">
<h2><span class="header-section-number">17.5</span> Maximum likelihood</h2>
<p>Recall that using method of moments involves finding values of the parameters that cause the population moments to be equal to the sample moments. Solving for the parameters yields method of moments estimates.</p>
<p>Next we will discuss one more estimation method, <em>maximum likelihood estimation</em>. In this method, we are finding values of parameters that would make the observed data most “likely”. In order to do this, we first need to introduce the <em>likelihood function</em>.</p>
<div id="likelihood-function" class="section level3" number="17.5.1">
<h3><span class="header-section-number">17.5.1</span> Likelihood Function</h3>
<p>Suppose <span class="math inline">\(x_1,x_2,...,x_n\)</span> is an iid random sample from a distribution with mass/density function <span class="math inline">\(f_{X}(x;\boldsymbol{\theta})\)</span> where <span class="math inline">\(\boldsymbol{\theta}\)</span> are the parameters. Let’s take a second to explain this notation. We are using a bold symbol for <span class="math inline">\(\boldsymbol{\theta}\)</span> to indicate it is a vector, that it can be one or more values. However, in the pmf/pdf <span class="math inline">\(x\)</span> is not bold since it is a scalar variable. In our probability models we know <span class="math inline">\(\boldsymbol{\theta}\)</span> and then use to model to make decision about the random variable <span class="math inline">\(X\)</span>.</p>
<p>The likelihood function is denoted as <span class="math inline">\(L(\boldsymbol{\theta};x_1,x_2,...,x_n) = L(\boldsymbol{\theta};\boldsymbol{x})\)</span>. Now we have multiple instances of the random variable, we use <span class="math inline">\(\boldsymbol{x}\)</span>. Since our random sample is iid, independent and identically distributed, we can write the likelihood function as a product of the pmfs/pdfs:
<span class="math display">\[
L(\boldsymbol{\theta};\boldsymbol{x})=\prod_{i=1}^n f_X(x_i;\boldsymbol{\theta})
\]</span></p>
<p>The likelihood function is really the pmf/pdf except instead of the variables being random and the parameter(s) fixed, the values of the variable are known and the parameter(s) are unknown. A note on notation, we are using the semicolon in the pdf and likelihood function to denote what is known or given. In the pmf/pdf the parameters are known and thus follow the semicolon. The opposite is the case in the likelihood function.</p>
<p>Let’s do an example to help understand these ideas.</p>
<blockquote>
<p><em>Example</em>:<br />
Suppose we are presented with a coin and are unsure of its fairness. We toss the coin 50 times and obtain 18 heads and 32 tails. Let <span class="math inline">\(\pi\)</span> be the probability that a coin flip results in heads, we could use <span class="math inline">\(p\)</span> but we are getting you used to the two different common ways to represent a binomial parameter. What is the likelihood function of <span class="math inline">\(\pi\)</span>?</p>
</blockquote>
<p>This is a binomial process, but each individual coin flip can be thought of as a Bernoulli experiment. That is, <span class="math inline">\(x_1,x_2,...,x_{50}\)</span> is an iid sample from <span class="math inline">\(\textsf{Binom}(1,\pi)\)</span> or, in other words, <span class="math inline">\(\textsf{Bernoulli}(\pi)\)</span>. Each <span class="math inline">\(x_i\)</span> is either 1 or 0. The pmf of <span class="math inline">\(X\)</span>, a Bernoulli random variable, is simply:
<span class="math display">\[
f_X(x;\pi)= \binom{1}{x} \pi^x(1-\pi)^{1-x} = \pi^x(1-\pi)^{1-x}
\]</span></p>
<p>Notice this makes sense</p>
<p><span class="math display">\[
f_X(1)=P(X=1)= \pi^1(1-\pi)^{1-1}=\pi
\]</span></p>
<p>and</p>
<p><span class="math display">\[
f_X(0)=P(X=0)= \pi^0(1-\pi)^{1-0}=(1-\pi)
\]</span></p>
<p>Generalizing for any sample size <span class="math inline">\(n\)</span>, the likelihood function is:
<span class="math display">\[
L(\pi;\boldsymbol{x})=\prod_{i=1}^{n} \pi^{x_i}(1-\pi)^{1-x_i} = \pi^{\sum_{i=1}^{n} x_i}(1-\pi)^{n-\sum_{i=1}^{n} x_i}
\]</span></p>
<p>For our example <span class="math inline">\(n=50\)</span> and the</p>
<p><span class="math display">\[
L(\pi;\boldsymbol{x})=\prod_{i=1}^{50} \pi^{x_i}(1-\pi)^{1-x_i} = \pi^{18}(1-\pi)^{32}
\]</span></p>
<p>which makes sense because we had 18 successes, heads, and 32 failures, tails. The likelihood function is a function of the unknown parameter <span class="math inline">\(\pi\)</span>.</p>
</div>
<div id="maximum-likelihood-estimation" class="section level3" number="17.5.2">
<h3><span class="header-section-number">17.5.2</span> Maximum Likelihood Estimation</h3>
<p>Once we have a likelihood function <span class="math inline">\(L(\boldsymbol{\theta},\boldsymbol{x})\)</span>, we need to figure out which value of <span class="math inline">\(\boldsymbol{\theta}\)</span> makes the data most likely. In other words, we need to maximize <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<p>Most of the time (but not always), this will involve simple optimization through calculus (i.e., take the derivative with respect to the parameter, set to 0 and solve for the parameter). When maximizing the likelihood function through calculus, it is often easier to maximize the log of the likelihood function, denoted as <span class="math inline">\(l\)</span> and often referred to as the “log-likelihood function”:
<span class="math display">\[
l(\boldsymbol{\theta};\boldsymbol{x})= \log L(\boldsymbol{\theta};\boldsymbol{x})
\]</span>
Note that since logarithm is one-to-one, onto and increasing, maximizing the log-likelihood function is equivalent to maximizing the likelihood function, and the maximum will occur at the same values of the parameters. We are using <code>log</code> because now we can take the derivative of a sum instead of a product, thus making it much easier.</p>
<blockquote>
<p><em>Example</em>:<br />
Continuing our example. Find the maximum likelihood estimator for <span class="math inline">\(\pi\)</span>.</p>
</blockquote>
<p>Recall that our likelihood function is
<span class="math display">\[
L(\pi;\boldsymbol{x})= \pi^{\sum x_i}(1-\pi)^{n-\sum x_i}
\]</span></p>
<p>Figure @ref(fig:lik1-fig) is a plot of the likelihood function as a function of the unknown parameter <span class="math inline">\(\pi\)</span>.</p>
<pre><code>## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided.</code></pre>
<div class="figure">
<img src="17-Estimation-Methods_files/figure-html/lik1-fig-1.png" alt="Likelihood function for 18 successes in 50 trials" width="672" />
<p class="caption">
(#fig:lik1-fig)Likelihood function for 18 successes in 50 trials
</p>
</div>
<p>By visual inspection, the value of <span class="math inline">\(\pi\)</span> that makes our data most likely, maximizes the likelihood function, is something a little less than 0.4, the actual value is 0.36 as indicated by the blue line in Figure @ref(fig:lik1-fig).</p>
<p>To maximize by mathematical methods, we need to take the derivative of the likelihood function with respect to <span class="math inline">\(\pi\)</span>. We can do this because the likelihood function is a continuous function. Even though the binomial is a discrete random variable, its likelihood is a continuous function.</p>
<p>We can find the derivative of the likelihood function by applying the product rule:
<span class="math display">\[
{\mathop{}\!\mathrm{d}L(\pi;\boldsymbol{x})\over \mathop{}\!\mathrm{d}\pi} = \left(\sum x_i\right) \pi^{\sum x_i -1}(1-\pi)^{n-\sum x_i} + \pi^{\sum x_i}\left(\sum x_i -n\right)(1-\pi)^{n-\sum x_i -1}
\]</span></p>
<p>We could simplify this, set to 0, and solve for <span class="math inline">\(\pi\)</span>. However, it may be easier to use the log-likelihood function:
<span class="math display">\[
l(\pi;\boldsymbol{x})=\log L(\pi;\boldsymbol{x})= \log \left(\pi^{\sum x_i}(1-\pi)^{n-\sum x_i}\right) = \sum x_i \log \pi + (n-\sum x_i)\log (1-\pi)
\]</span></p>
<p>Now, taking the derivative does not require the product rule:
<span class="math display">\[
{\mathop{}\!\mathrm{d}l(\pi;\boldsymbol{x})\over \mathop{}\!\mathrm{d}\pi}= {\sum x_i \over \pi} - {n-\sum x_i\over (1-\pi)}
\]</span></p>
<p>Setting equal to 0 yields:
<span class="math display">\[
{\sum x_i \over \pi} ={n-\sum x_i\over (1-\pi)}
\]</span></p>
<p>Solving for <span class="math inline">\(\pi\)</span> yields
<span class="math display">\[
\hat{\pi}_{MLE}={\sum x_i \over n}
\]</span></p>
<p>Note that technically, we should confirm that the function is concave down at our critical value, ensuring that <span class="math inline">\(\hat{\pi}_{MLE}\)</span> is, in fact, a maximum:
<span class="math display">\[
{\mathop{}\!\mathrm{d}^2 l(\pi;\boldsymbol{x})\over \mathop{}\!\mathrm{d}\pi^2}= {-\sum x_i \over \pi^2} - {n-\sum x_i\over (1-\pi)^2}
\]</span></p>
<p>This value is negative for all relevant values of <span class="math inline">\(\pi\)</span>, so <span class="math inline">\(l\)</span> is concave down and <span class="math inline">\(\hat{\pi}_{MLE}\)</span> is a maximum.</p>
<p>In the case of our example (18 heads out of 50 trials), <span class="math inline">\(\hat{\pi}_{MLE}=18/50=0.36\)</span>.</p>
<p>This seems to make sense. Our best guess for the probability of heads is the number of observed heads divided by our number of trials. That was a great deal of algebra and calculus for what appears to be an obvious answer. However, in more difficult problems, it is not as obvious what to use for a MLE.</p>
</div>
<div id="numerical-methods" class="section level3" number="17.5.3">
<h3><span class="header-section-number">17.5.3</span> Numerical Methods</h3>
<p>When obtaining MLEs, there are times when analytical methods (calculus) are not feasible or not possible. In the Pruim book <span class="citation">(<a href="#ref-pruim2011foundations" role="doc-biblioref">R. J. Pruim 2011</a>)</span>, there is a good example regarding data from Old Faithful at Yellowstone National Park. We need to load the <strong>fastR2</strong> package for this example.</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="#cb435-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fastR2)</span></code></pre></div>
<p>The <code>faithful</code> data set is preloaded into <code>R</code> and contains 272 observations of 2 variables: eruption time in minutes and waiting time until next eruption. If we plot eruption durations, we notice that the distribution appears bimodal, see Figure @ref(fig:hist171-fig).</p>
<div class="figure">
<img src="17-Estimation-Methods_files/figure-html/hist171-fig-1.png" alt="Histogram of eruption durations of Old Faithful." width="672" />
<p class="caption">
(#fig:hist171-fig)Histogram of eruption durations of Old Faithful.
</p>
</div>
<p>Within each section, the distribution appears somewhat bell-curve-ish so we’ll model the eruption time with a mixture of two normal distributions. In this mixture, a proportion <span class="math inline">\(\alpha\)</span> of our eruptions belong to one normal distribution and the remaining <span class="math inline">\(1-\alpha\)</span> belong to the other normal distribution. The density function of eruptions is given by:
<span class="math display">\[
\alpha f(x;\mu_1,\sigma_1)+(1-\alpha)f(x;\mu_2,\sigma_2)
\]</span></p>
<p>where <span class="math inline">\(f\)</span> is the pdf of the normal distribution with parameters specified.</p>
<p>We have five parameters to estimate: <span class="math inline">\(\alpha, \mu_1, \mu_2, \sigma_1, \sigma_2\)</span>. Obviously, estimation through differentiation is not feasible and thus we will use numerical methods. This code is less in the spirit of <code>tidyverse</code> but we want you to see the example. Try to work your way through the code below:</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="#cb436-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define function for pdf of eruptions as a mixture of normals</span></span>
<span id="cb436-2"><a href="#cb436-2" aria-hidden="true" tabindex="-1"></a>dmix<span class="ot">&lt;-</span><span class="cf">function</span>(x,alpha,mu1,mu2,sigma1,sigma2){</span>
<span id="cb436-3"><a href="#cb436-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(alpha <span class="sc">&lt;</span> <span class="dv">0</span>) <span class="fu">dnorm</span>(x,mu2,sigma2)</span>
<span id="cb436-4"><a href="#cb436-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(alpha <span class="sc">&gt;</span> <span class="dv">1</span>) <span class="fu">dnorm</span>(x,mu1,sigma1)</span>
<span id="cb436-5"><a href="#cb436-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(alpha <span class="sc">&gt;=</span> <span class="dv">0</span> <span class="sc">&amp;&amp;</span> alpha <span class="sc">&lt;=</span><span class="dv">1</span>){</span>
<span id="cb436-6"><a href="#cb436-6" aria-hidden="true" tabindex="-1"></a>    alpha<span class="sc">*</span><span class="fu">dnorm</span>(x,mu1,sigma1)<span class="sc">+</span>(<span class="dv">1</span><span class="sc">-</span>alpha)<span class="sc">*</span><span class="fu">dnorm</span>(x,mu2,sigma2)</span>
<span id="cb436-7"><a href="#cb436-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb436-8"><a href="#cb436-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Next write a function for the log-likelihood function. <code>R</code> is a vector based programming language so we send <code>theta</code> into the function as a vector argument.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="#cb437-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the log-likelihood function</span></span>
<span id="cb437-2"><a href="#cb437-2" aria-hidden="true" tabindex="-1"></a>loglik<span class="ot">&lt;-</span><span class="cf">function</span>(theta,x){</span>
<span id="cb437-3"><a href="#cb437-3" aria-hidden="true" tabindex="-1"></a>  alpha<span class="ot">=</span>theta[<span class="dv">1</span>]</span>
<span id="cb437-4"><a href="#cb437-4" aria-hidden="true" tabindex="-1"></a>  mu1<span class="ot">=</span>theta[<span class="dv">2</span>]</span>
<span id="cb437-5"><a href="#cb437-5" aria-hidden="true" tabindex="-1"></a>  mu2<span class="ot">=</span>theta[<span class="dv">3</span>]</span>
<span id="cb437-6"><a href="#cb437-6" aria-hidden="true" tabindex="-1"></a>  sigma1<span class="ot">=</span>theta[<span class="dv">4</span>]</span>
<span id="cb437-7"><a href="#cb437-7" aria-hidden="true" tabindex="-1"></a>  sigma2<span class="ot">=</span>theta[<span class="dv">5</span>]</span>
<span id="cb437-8"><a href="#cb437-8" aria-hidden="true" tabindex="-1"></a>  density<span class="ot">&lt;-</span><span class="cf">function</span>(x){</span>
<span id="cb437-9"><a href="#cb437-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(alpha<span class="sc">&lt;</span><span class="dv">0</span>) <span class="fu">return</span> (<span class="cn">Inf</span>)</span>
<span id="cb437-10"><a href="#cb437-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(alpha<span class="sc">&gt;</span><span class="dv">1</span>) <span class="fu">return</span> (<span class="cn">Inf</span>)</span>
<span id="cb437-11"><a href="#cb437-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(sigma1<span class="sc">&lt;</span><span class="dv">0</span>) <span class="fu">return</span> (<span class="cn">Inf</span>)</span>
<span id="cb437-12"><a href="#cb437-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(sigma2<span class="sc">&lt;</span><span class="dv">0</span>) <span class="fu">return</span> (<span class="cn">Inf</span>)</span>
<span id="cb437-13"><a href="#cb437-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">dmix</span>(x,alpha,mu1,mu2,sigma1,sigma2)</span>
<span id="cb437-14"><a href="#cb437-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb437-15"><a href="#cb437-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">sapply</span>(x,density)))</span>
<span id="cb437-16"><a href="#cb437-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Find the sample mean and standard deviation of the eruption data to use as starting points in the optimization routine.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="#cb438-1" aria-hidden="true" tabindex="-1"></a>m<span class="ot">&lt;-</span><span class="fu">mean</span>(faithful<span class="sc">$</span>eruptions)</span>
<span id="cb438-2"><a href="#cb438-2" aria-hidden="true" tabindex="-1"></a>s<span class="ot">&lt;-</span><span class="fu">sd</span>(faithful<span class="sc">$</span>eruptions)</span></code></pre></div>
<p>Use the function <code>nlmax()</code> to maximize the non-linear log-likelihood function.</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="#cb439-1" aria-hidden="true" tabindex="-1"></a>mle<span class="ot">&lt;-</span><span class="fu">nlmax</span>(loglik,<span class="at">p=</span><span class="fu">c</span>(<span class="fl">0.5</span>,m<span class="dv">-1</span>,m<span class="sc">+</span><span class="dv">1</span>,s,s),<span class="at">x=</span>faithful<span class="sc">$</span>eruptions)<span class="sc">$</span>estimate</span>
<span id="cb439-2"><a href="#cb439-2" aria-hidden="true" tabindex="-1"></a>mle</span></code></pre></div>
<pre><code>## [1] 0.3484040 2.0186065 4.2733410 0.2356208 0.4370633</code></pre>
<p>So, according to our MLEs, about 34.84% of the eruptions belong to the first normal distribution (the one on the left). Furthermore the parameters of that first distribution are a mean of 2.019 and a standard deviation of 0.236. Likewise, 65.16% of the eruptions belong to the second normal with mean of 4.27 and standard deviation of 0.437.</p>
<p>Plotting the density atop the histogram shows a fairly good fit:</p>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="#cb441-1" aria-hidden="true" tabindex="-1"></a>dmix2<span class="ot">&lt;-</span><span class="cf">function</span>(x) <span class="fu">dmix</span>(x,mle[<span class="dv">1</span>],mle[<span class="dv">2</span>],mle[<span class="dv">3</span>],mle[<span class="dv">4</span>],mle[<span class="dv">5</span>])</span>
<span id="cb441-2"><a href="#cb441-2" aria-hidden="true" tabindex="-1"></a><span class="co">#y_old&lt;-dmix2(seq(1,6,.01))</span></span>
<span id="cb441-3"><a href="#cb441-3" aria-hidden="true" tabindex="-1"></a><span class="co">#x_old&lt;-seq(1,6,.01)</span></span>
<span id="cb441-4"><a href="#cb441-4" aria-hidden="true" tabindex="-1"></a><span class="co">#dens_data&lt;-data.frame(x=x_old,y=y_old)</span></span>
<span id="cb441-5"><a href="#cb441-5" aria-hidden="true" tabindex="-1"></a><span class="co">#faithful%&gt;%</span></span>
<span id="cb441-6"><a href="#cb441-6" aria-hidden="true" tabindex="-1"></a><span class="co">#gf_histogram(~eruptions,fill=&quot;cyan&quot;,color = &quot;black&quot;) %&gt;%</span></span>
<span id="cb441-7"><a href="#cb441-7" aria-hidden="true" tabindex="-1"></a><span class="co">#  gf_curve(y~x,data=dens_data)%&gt;%</span></span>
<span id="cb441-8"><a href="#cb441-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  gf_theme(theme_bw()) %&gt;%</span></span>
<span id="cb441-9"><a href="#cb441-9" aria-hidden="true" tabindex="-1"></a><span class="co">#  gf_labs(x=&quot;Duration in minutes&quot;,y=&quot;Count&quot;) </span></span>
<span id="cb441-10"><a href="#cb441-10" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(faithful<span class="sc">$</span>eruptions,<span class="at">breaks=</span><span class="dv">40</span>,<span class="at">freq=</span>F,<span class="at">main=</span><span class="st">&quot;&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;Duration in minutes.&quot;</span>)</span>
<span id="cb441-11"><a href="#cb441-11" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(dmix2,<span class="at">from=</span><span class="dv">1</span>,<span class="at">to=</span><span class="dv">6</span>,<span class="at">add=</span>T)</span></code></pre></div>
<div class="figure">
<img src="17-Estimation-Methods_files/figure-html/hist172-fig-1.png" alt="Histogram of eruption duration with estimated mixture of normals plotted on top." width="672" />
<p class="caption">
(#fig:hist172-fig)Histogram of eruption duration with estimated mixture of normals plotted on top.
</p>
</div>
<p>This is a fairly elaborate example but it is cool. You can see the power of the method and the software.</p>
</div>
</div>
<div id="homework-problems-16" class="section level2" number="17.6">
<h2><span class="header-section-number">17.6</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>In the Notes, we found that if we take a sample from the uniform distribution <span class="math inline">\(\textsf{Unif}(0,\theta)\)</span>, the method of moments estimate of <span class="math inline">\(\theta\)</span> is <span class="math inline">\(\hat{\theta}_{MoM}=2\bar{x}\)</span>. Suppose our sample consists of the following values:
<span class="math display">\[
0.2 \hspace{0.4cm} 0.9 \hspace{0.4cm} 1.9 \hspace{0.4cm} 2.2 \hspace{0.4cm} 4.7 \hspace{0.4cm} 5.1
\]</span></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>What is <span class="math inline">\(\hat{\theta}_{MoM}\)</span> for this sample?<br />
</li>
<li>What is an wrong with this estimate?<br />
</li>
<li>Show that this estimator is unbiased.<br />
</li>
<li>ADVANCED: Use simulation in <code>R</code> to find out how often the method of moment estimator is less the maximum observed value, (<span class="math inline">\(\hat{\theta}_{MoM} &lt; \max x\)</span>). Report an answer for various sizes of samples. You can just pick an arbitrary value for <span class="math inline">\(\theta\)</span> when you sample from the uniform. However, the minimum must be 0.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(x_1,x_2,...,x_n\)</span> be a simple random sample from an exponentially distributed population with parameter <span class="math inline">\(\lambda\)</span>. Find <span class="math inline">\(\hat{\lambda}_{MoM}\)</span>.</p></li>
<li><p>Let <span class="math inline">\(x_1,x_2,...,x_n\)</span> be an iid random sample from an exponentially distributed population with parameter <span class="math inline">\(\lambda\)</span>. Find <span class="math inline">\(\hat{\lambda}_{MLE}\)</span>.</p></li>
<li><p>It is mathematically difficult to determine if the estimators found in questions 2 and 3 are unbiased. Since the sample mean is in the denominator; mathematically we may have to work with the joint pdf. So instead, use simulation to get an sense of whether the method of moments estimator for the exponential distribution is unbiased.</p></li>
<li><p>Find a maximum likelihood estimator for <span class="math inline">\(\theta\)</span> when <span class="math inline">\(X\sim\textsf{Unif}(0,\theta)\)</span>. Compare this to the method of moments estimator we found. Hint: Do not take the derivative of the likelihood function.</p></li>
</ol>
<!--chapter:end:17-Estimation-Methods.Rmd-->
</div>
</div>
<div id="part-statistical-modeling" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Statistical Modeling</h1>
</div>
<div id="CS3" class="section level1" number="18">
<h1><span class="header-section-number">18</span> Case Study</h1>
<div id="objectives-17" class="section level2" number="18.1">
<h2><span class="header-section-number">18.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Define and use properly in context all new terminology.<br />
</li>
<li>Conduct a hypothesis test using a permutation test to include all 4 steps.</li>
</ol>
</div>
<div id="introduction" class="section level2" number="18.2">
<h2><span class="header-section-number">18.2</span> Introduction</h2>
<p>We now have the foundation to move onto statistical modeling. First we will begin with inference where we use the ideas of estimation and the variance of estimates to make decisions about the population. We will also briefly introduce the ideas of prediction. Then in the final block of material, we will examine some common linear models and use them both in prediction situations as well as inference.</p>
</div>
<div id="foundation-for-inference" class="section level2" number="18.3">
<h2><span class="header-section-number">18.3</span> Foundation for inference</h2>
<p>Suppose a professor randomly splits the students in class into two groups: students on the left and students on the right. If <span class="math inline">\(\hat{p}_{_L}\)</span> and <span class="math inline">\(\hat{p}_{_R}\)</span> represent the proportion of students who own an Apple product on the left and right, respectively, would you be surprised if <span class="math inline">\(\hat{p}_{_L}\)</span> did not <em>exactly</em> equal <span class="math inline">\(\hat{p}_{_R}\)</span>?</p>
<p>While the proportions would probably be close to each other, they are probably not exactly the same. We would probably observe a small difference due to <em>chance</em>.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
If we don’t think the side of the room a person sits on in class is related to whether the person owns an Apple product, what assumption are we making about the relationship between these two variables?<a href="#fn67" class="footnote-ref" id="fnref67"><sup>67</sup></a></p>
</blockquote>
<p>Studying randomness of this form is a key focus of statistical modeling. In this block, we’ll explore this type of randomness in the context of several applications, and we’ll learn new tools and ideas that can be applied to help make decisions from data.</p>
</div>
<div id="randomization-case-study-gender-discrimination" class="section level2" number="18.4">
<h2><span class="header-section-number">18.4</span> Randomization case study: gender discrimination</h2>
<p>We consider a study investigating gender discrimination in the 1970s, which is set in the context of personnel decisions within a bank.<a href="#fn68" class="footnote-ref" id="fnref68"><sup>68</sup></a> The research question we hope to answer is, “Are females discriminated against in promotion decisions made by male managers?”</p>
<div id="variability-within-data" class="section level3" number="18.4.1">
<h3><span class="header-section-number">18.4.1</span> Variability within data</h3>
<p>The participants in this study were 48 male bank supervisors attending a management institute at the University of North Carolina in 1972. They were asked to assume the role of the personnel director of a bank and were given a personnel file to judge whether the person should be promoted to a branch manager position. The files given to the participants were identical, except that half of them indicated the candidate was male and the other half indicated the candidate was female. These files were randomly assigned to the subjects.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Is this an observational study or an experiment? How does the type of study impact what can be inferred from the results?<a href="#fn69" class="footnote-ref" id="fnref69"><sup>69</sup></a></p>
</blockquote>
<p>For each supervisor we recorded the gender associated with the assigned file and the promotion decision. Using the results of the study summarized in the table below, we would like to evaluate if females are unfairly discriminated against in promotion decisions. In this study, a smaller proportion of females are promoted than males (0.583 versus 0.875), but it is unclear whether the difference provides <strong>convincing evidence</strong> that females are unfairly discriminated against.</p>
<p><span class="math display">\[
\begin{array}{cc|ccc} &amp; &amp; &amp;\textbf{Decision}\\
&amp; &amp; \mbox{Promoted} &amp; \mbox{Not Promoted} &amp; \mbox{Total}  \\
&amp; \hline \mbox{male} &amp; 21 &amp; 3 &amp; 24  \\
\textbf{Gender}&amp; \mbox{female} &amp; 14 &amp; 10 &amp; 24  \\
&amp; \mbox{Total} &amp; 35 &amp; 13 &amp; 48  \\
\end{array}
\]</span></p>
<blockquote>
<p><em>Thought Question</em>:<br />
Statisticians are sometimes called upon to evaluate the strength of evidence. When looking at the rates of promotion for males and females in this study, why might we be tempted to immediately conclude that females are being discriminated against?</p>
</blockquote>
<p>The large difference in promotion rates (58.3% for females versus 87.5% for males) suggest there might be discrimination against women in promotion decisions. Most people come to this conclusion because they think these sample statistics are the actual population parameters. We cannot yet be sure if the observed difference represents discrimination or is just from random variability. Generally there is fluctuation in sample data; if we conducted the experiment again, we would get different values. We also wouldn’t expect the sample proportions to be <strong>exactly</strong> equal, even if the truth was that the promotion decisions were independent of gender. To make a decision, we must understand the random variability and compare it with the observed difference.</p>
<p>This question is a reminder that the observed outcomes in the sample may not perfectly reflect the true relationships between variables in the underlying population. The table shows there were 7 fewer promotions in the female group than in the male group, a difference in promotion rates of 29.2% <span class="math inline">\(\left( \frac{21}{24} - \frac{14}{24} = 0.292 \right)\)</span>. This observed difference is what we call a <em>point estimate</em> of the true effect. The point estimate of the difference is large, but the sample size for the study is small, making it unclear if this observed difference represents discrimination or whether it is simply due to chance. We label these two competing claims, chance or discrimination, as <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_A\)</span>:</p>
<p><span class="math inline">\(H_0\)</span>: <strong>Null hypothesis.</strong> The variables <em>gender</em> and <em>decision</em> are independent. They have no relationship, and the observed difference between the proportion of males and females who were promoted, 29.2%, was due to chance.<br />
<span class="math inline">\(H_A\)</span>: <strong>Alternative hypothesis.</strong> The variables <em>gender</em> and <em>decision</em> are <strong>not</strong> independent. The difference in promotion rates of 29.2% was not due to chance, and equally qualified females are less likely to be promoted than males.</p>
<blockquote>
<p>Hypothesis testing<br />
These hypotheses are part of what is called a <strong>hypothesis test</strong>. A hypothesis test is a statistical technique used to evaluate competing claims using data. Often times, the null hypothesis takes a stance of <strong>no difference</strong> or <strong>no effect</strong> and thus is <code>skeptical</code> of the research claim. If the null hypothesis and the data notably disagree, then we will reject the null hypothesis in favor of the alternative hypothesis.</p>
</blockquote>
<p>Don’t worry if you aren’t a master of hypothesis testing at the end of this lesson. We’ll discuss these ideas and details many times in this block.</p>
<p>What would it mean if the null hypothesis, which says the variables <em>gender</em> and <em>decision</em> are unrelated, is true? It would mean each banker would decide whether to promote the candidate without regard to the gender indicated on the file. That is, the difference in the promotion percentages would be due to the way the files were randomly divided to the bankers, and the randomization just happened to give rise to a relatively large difference of 29.2%.</p>
<p>Consider the alternative hypothesis: bankers were influenced by which gender was listed on the personnel file. If this was true, and especially if this influence was substantial, we would expect to see some difference in the promotion rates of male and female candidates. If this gender bias was against females, we would expect a smaller fraction of promotion recommendations for female personnel files relative to the male files.</p>
<p>We will choose between these two competing claims by assessing if the data conflict so much with <span class="math inline">\(H_0\)</span> that the null hypothesis cannot be deemed reasonable. If this is the case, and the data support <span class="math inline">\(H_A\)</span>, then we will reject the notion of independence and conclude that these data provide strong evidence of discrimination. Again, we will do this by determining how much difference in promotion rates would happen by random variation and compare this with the observed difference. We will make a decision based on probability considerations.</p>
</div>
<div id="simulating-the-study" class="section level3" number="18.4.2">
<h3><span class="header-section-number">18.4.2</span> Simulating the study</h3>
<p>The table of data shows that 35 bank supervisors recommended promotion and 13 did not. Now, suppose the bankers’ decisions were independent of gender, that is the null hypothesis is true. Then, if we conducted the experiment again with a different random assignment of files, differences in promotion rates would be based only on random fluctuation. We can actually perform this <strong>randomization</strong>, which simulates what would have happened if the bankers’ decisions had been independent of gender but we had distributed the files differently.<a href="#fn70" class="footnote-ref" id="fnref70"><sup>70</sup></a> We will walk through the steps next.</p>
<p>First let’s import the data.</p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="#cb442-1" aria-hidden="true" tabindex="-1"></a>discrim <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/discrimination_study.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="#cb443-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(discrim)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##       name     class levels  n missing
## 1   gender character      2 48       0
## 2 decision character      2 48       0
##                                    distribution
## 1 female (50%), male (50%)                     
## 2 promoted (72.9%), not_promoted (27.1%)</code></pre>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="#cb445-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>gender<span class="sc">+</span>decision,discrim,<span class="at">margins=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##         decision
## gender   not_promoted promoted Total
##   female           10       14    24
##   male              3       21    24
##   Total            13       35    48</code></pre>
<p>Let’s do some categorical data cleaning. To get the <code>tally()</code> results to look like our table, we need to change to factors and reorder the levels.</p>
<p>We will use <code>mutate_if()</code> to convert characters to factors and <code>fct_relevel()</code> to change levels.</p>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="#cb447-1" aria-hidden="true" tabindex="-1"></a>discrim <span class="ot">&lt;-</span> discrim <span class="sc">%&gt;%</span></span>
<span id="cb447-2"><a href="#cb447-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_if</span>(is.character,as.factor) <span class="sc">%&gt;%</span></span>
<span id="cb447-3"><a href="#cb447-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">gender=</span><span class="fu">fct_relevel</span>(gender,<span class="st">&quot;male&quot;</span>),</span>
<span id="cb447-4"><a href="#cb447-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">decision=</span><span class="fu">fct_relevel</span>(decision,<span class="st">&quot;promoted&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="#cb448-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(discrim)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   gender decision    
##   &lt;fct&gt;  &lt;fct&gt;       
## 1 female not_promoted
## 2 female not_promoted
## 3 male   promoted    
## 4 female promoted    
## 5 female promoted    
## 6 female promoted</code></pre>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="#cb450-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>gender<span class="sc">+</span>decision,discrim,<span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##         decision
## gender   promoted not_promoted Total
##   male         21            3    24
##   female       14           10    24
##   Total        35           13    48</code></pre>
<p>Now that we have the data in form that we want, we are ready to conduct the <em>permutation test</em>. To think about this <em>simulation</em>, imagine we actually had the personnel files. We thoroughly shuffle 48 personnel files, 24 labeled <em>male</em> and 24 labeled <em>female</em>, and deal these files into two stacks. We will deal 35 files into the first stack, which will represent the 35 supervisors who recommended promotion. The second stack will have 13 files, and it will represent the 13 supervisors who recommended against promotion. Remember that the files are identical except for the listed gender. This simulation then assumes that gender is not important and thus we can randomly assign the files to any of the supervisors. Then, as we did with the original data, we tabulate the results and determine the fraction of <em>male</em> and <em>female</em> who were promoted. Since we don’t actually physically have the files, we will do this shuffle via computer code.</p>
<p>Since the randomization of files in this simulation is independent of the promotion decisions, any difference in the two fractions is entirely due to chance. The following code shows the results of such a simulation.</p>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="#cb452-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb452-2"><a href="#cb452-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span><span class="fu">shuffle</span>(gender)<span class="sc">+</span>decision,discrim,<span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##                decision
## shuffle(gender) promoted not_promoted Total
##          male         18            6    24
##          female       17            7    24
##          Total        35           13    48</code></pre>
<p>The <code>shuffle()</code> function randomly rearranges the gender column while keeping the decision column the same. It is really a sampling without replacement.</p>
<blockquote>
<p><strong>Exercise</strong>:
What is the difference in promotion rates between the two simulated groups? How does this compare to the observed difference 29.2% from the actual study?<a href="#fn71" class="footnote-ref" id="fnref71"><sup>71</sup></a></p>
</blockquote>
<p>Calculating by hand will not help in a simulation, so we must write a function or use an existing one. We will use <code>diffprop</code> from the <strong>mosiac</strong> package. The code to find the difference for the original data is:</p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="#cb454-1" aria-hidden="true" tabindex="-1"></a>(obs<span class="ot">&lt;-</span><span class="fu">diffprop</span>(decision<span class="sc">~</span>gender,<span class="at">data=</span>discrim))</span></code></pre></div>
<pre><code>##   diffprop 
## -0.2916667</code></pre>
<p>Notice that this is subtracting proportion of males promoted from the proportion of females. This does not impact our results as this is an arbitrary decision. We just need to be consistent in our analysis. If we prefer to use positive values we can adjust the order easily.</p>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="#cb456-1" aria-hidden="true" tabindex="-1"></a><span class="fu">diffprop</span>(decision<span class="sc">~</span><span class="fu">fct_relevel</span>(gender,<span class="st">&quot;female&quot;</span>),<span class="at">data=</span>discrim)</span></code></pre></div>
<pre><code>##  diffprop 
## 0.2916667</code></pre>
<p>Notice that what we have done here, we developed a single number metric to measure the relationship between <em>gender</em> and <em>decision</em>. This single value metric is called the <strong>test statistic</strong>. We could have used a number of different metrics to include just the difference in males and females. The key idea in hypothesis testing is that once you decide on a test statistic, you need to find the distribution of that test statistic assuming the null hypothesis is true.</p>
</div>
<div id="checking-for-independence" class="section level3" number="18.4.3">
<h3><span class="header-section-number">18.4.3</span> Checking for independence</h3>
<p>We computed one possible difference under the null hypothesis in the exercise above, which represents one difference due to chance. Repeating the simulation, we get another difference due to chance: -0.042. And another: 0.208. And so on until we repeat the simulation enough times that we have a good idea of what represents the <strong>distribution of differences from chance alone</strong>. That is the difference if there really is no relationship between gender and the promotion decision. We are using a simulation when there is actually a finite number of permutations of the <code>gender</code> label. From our lesson on counting, we have 48 labels of which 24 are <code>male</code> and 24 are <code>female</code>. Thus the total number of ways to arrange the labels differently is:</p>
<p><span class="math display">\[
\frac{48!}{24!\cdot24!} \approx 3.2 \cdot 10^{13}
\]</span></p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="#cb458-1" aria-hidden="true" tabindex="-1"></a><span class="fu">factorial</span>(<span class="dv">48</span>)<span class="sc">/</span>(<span class="fu">factorial</span>(<span class="dv">24</span>)<span class="sc">*</span><span class="fu">factorial</span>(<span class="dv">24</span>))</span></code></pre></div>
<pre><code>## [1] 3.22476e+13</code></pre>
<p>This number of permutations is too large to find by hand or even via code and thus we will use a simulation. This is not quite accurate for what we are doing though. We only have 13 not promoted positions. So we could have anywhere between 0 females up to 13 females in the not promoted position. Thus to calculate the probabilities we could use a hypergeometric.</p>
<p>Let’s simulate the experiment and plot the simulated values of the difference in the proportions of male and female files recommended for promotion.</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="#cb460-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2022</span>)</span>
<span id="cb460-2"><a href="#cb460-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">diffprop</span>(decision<span class="sc">~</span><span class="fu">shuffle</span>(gender),<span class="at">data=</span>discrim)</span></code></pre></div>
<p>In Figure @ref(fig:teststat1-fig), we will insert a vertical line at the value of our observed difference.</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="#cb461-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb461-2"><a href="#cb461-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>diffprop) <span class="sc">%&gt;%</span></span>
<span id="cb461-3"><a href="#cb461-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span><span class="sc">-</span><span class="fl">0.2916667</span> ) <span class="sc">%&gt;%</span></span>
<span id="cb461-4"><a href="#cb461-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb461-5"><a href="#cb461-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Difference in proportions&quot;</span>,<span class="at">y=</span><span class="st">&quot;Counts&quot;</span>,</span>
<span id="cb461-6"><a href="#cb461-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">title=</span><span class="st">&quot;Gender discrimination in hiring permutation test&quot;</span>,</span>
<span id="cb461-7"><a href="#cb461-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">subtitle=</span><span class="st">&quot;Test statistic is difference in promotion for female and male&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="18-Hypothesis-Testing-Case-Study_files/figure-html/teststat1-fig-1.png" alt="Distribution of test statistic." width="672" />
<p class="caption">
(#fig:teststat1-fig)Distribution of test statistic.
</p>
</div>
<p>Note that the distribution of these simulated differences is centered around 0 and is roughly symmetrical. It is centered on zero because we simulated differences in a way that made no distinction between men and women. This makes sense: we should expect differences from chance alone to fall around zero with some random fluctuation for each simulation under the assumption of the null hypothesis. The histogram also looks like a normal distribution; this is not a coincidence, it is a result of what is called the <strong>Central Limit Theorem</strong> which we will learn about in this block.</p>
<blockquote>
<p><em>Example</em>:<br />
How often would you observe a difference of at least -29.2% (-0.292) according to the figure? (Often, sometimes, rarely, or never?)</p>
</blockquote>
<p>It appears that a difference of at least -29.2% due to chance alone would only happen rarely. We can estimate the probability using the <code>results</code> object.</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="#cb462-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb462-2"><a href="#cb462-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">p_value =</span> <span class="fu">mean</span>(diffprop<span class="sc">&lt;=</span>obs))</span></code></pre></div>
<pre><code>##   p_value
## 1  0.0257</code></pre>
<p>In our simulations, only 2.6% of the simulated test statistics were less than or equal to the observed test statistic, more extreme relative to the null hypothesis. Such a low probability indicates that observing such a large difference in proportions from chance alone is rare. This probability is known as a <strong>p-value</strong>. The p-value is a conditional probability, the probability of the observed value or more extreme given that the null hypothesis is true.</p>
<p>As noted above, we could have found the exact p-value using the hypergeometric. We want 10 or more women not promoted when we select 13 people from a pool of 24 men and 24 women and the selection is done without replacement.</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="#cb464-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">phyper</span>(<span class="dv">9</span>,<span class="dv">24</span>,<span class="dv">24</span>,<span class="dv">13</span>)</span></code></pre></div>
<pre><code>## [1] 0.02449571</code></pre>
<p>The observed difference of -29.2% is a rare event if there really is no impact from listing gender in the candidates’ files, which provides us with two possible interpretations of the study results:</p>
<p><span class="math inline">\(H_0\)</span>: <strong>Null hypothesis.</strong> Gender has no effect on promotion decision, and we observed a difference that is so large that it would only happen rarely.<br />
<span class="math inline">\(H_A\)</span>: <strong>Alternative hypothesis.</strong> Gender has an effect on promotion decision, and what we observed was actually due to equally qualified women being discriminated against in promotion decisions, which explains the large difference of -29.2%.</p>
<p>When we conduct formal studies, we reject a skeptical position if the data strongly conflict with that position.<a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a></p>
<p>In our analysis, we determined that there was only a ~ 2% probability of obtaining a test statistic where the difference between female and male promotion proportions was 29.2% or larger assuming gender had no impact. So we conclude the data provide evidence of gender discrimination against women by the supervisors. In this case, we reject the null hypothesis in favor of the alternative.</p>
<p>Statistical inference is the practice of making decisions and conclusions from data in the context of uncertainty. Errors do occur, just like rare events, and the data set at hand might lead us to the wrong conclusion. While a given data set may not always lead us to a correct conclusion, statistical inference gives us tools to control and evaluate how often these errors occur.</p>
<p>Let’s summarize what we did in this case study. We had a research question and some data to test the question. We then performed 4 steps:</p>
<ol style="list-style-type: decimal">
<li>State the null and alternative hypotheses.<br />
</li>
<li>Compute a test statistic.<br />
</li>
<li>Determine the p-value.<br />
</li>
<li>Draw a conclusion.</li>
</ol>
<p>We decided to use a randomization, a permutation test, to answer the question. When creating a randomization distribution, we attempted to satisfy 3 guiding principles.</p>
<ol style="list-style-type: decimal">
<li>Be consistent with the null hypothesis.<br />
We need to simulate a world in which the null hypothesis is true. If we don’t do this, we won’t be testing our null hypothesis. In our problem, we assumed gender and promotion were independent.<br />
</li>
<li>Use the data in the original sample.<br />
The original data should shed light on some aspects of the distribution that are not determined by null hypothesis. For our problem we used the difference in promotion rates. The data does not give us the distribution direction, but it gives us an idea that there is a large difference.<br />
</li>
<li>Reflect the way the original data were collected.<br />
There were 48 files and 48 supervisors. A total of 35 files indicated promote. We keep this the same in our simulation.</li>
</ol>
<p>The remainder of this block expands on the ideas of this case study.</p>
</div>
</div>
<div id="homework-problems-17" class="section level2" number="18.5">
<h2><span class="header-section-number">18.5</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Side effects of Avandia</li>
</ol>
<p>Rosiglitazone is the active ingredient in the controversial type~2 diabetes medicine Avandia and has been linked to an increased risk of serious cardiovascular problems such as stroke, heart failure, and death. A common alternative treatment is pioglitazone, the active ingredient in a diabetes medicine called Actos. In a nationwide retrospective observational study of 227,571 Medicare beneficiaries aged 65 years or older, it was found that 2,593 of the 67,593 patients using rosiglitazone and 5,386 of the 159,978 using pioglitazone had serious cardiovascular problems. These data are summarized in the contingency table below.</p>
<p><span class="math display">\[
\begin{array}{cc|ccc} &amp; &amp; &amp;\textit{Cardiovascular problems}\\
&amp; &amp; \text{Yes}  &amp; \text{No} &amp; \textbf{Total}  \\
&amp; \hline \text{Rosiglitazone}   &amp; 2,593 &amp; 65,000        &amp; 67,593 \\
\textit{Treatment}&amp; \text{Pioglitazone}     &amp; 5,386     &amp; 154,592   &amp; 159,978  \\
&amp; \textbf{Total}            &amp; 7,979 &amp; 219,592       &amp; 227,571 \\
\end{array}
\]</span></p>
<p>Determine if each of the following statements is true or false. If false, explain why. The reasoning may be wrong even if the statement’s conclusion is correct. In such cases, the statement should be considered false.</p>
<ol style="list-style-type: lower-alpha">
<li>Since more patients on pioglitazone had cardiovascular problems (5,386 vs. 2,593), we can conclude that the rate of cardiovascular problems for those on a pioglitazone treatment is higher.<br />
</li>
<li>The data suggest that diabetic patients who are taking rosiglitazone are more likely to have cardiovascular problems since the rate of incidence was (2,593 / 67,593 = 0.038) 3.8% for patients on this treatment, while it was only (5,386 / 159,978 = 0.034) 3.4% for patients on pioglitazone.<br />
</li>
<li>The fact that the rate of incidence is higher for the rosiglitazone group proves that rosiglitazone causes serious cardiovascular problems.<br />
</li>
<li>Based on the information provided so far, we cannot tell if the difference between the rates of incidences is due to a relationship between the two variables or due to chance.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Heart transplants</li>
</ol>
<p>The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was designated an official heart transplant candidate, meaning that he was gravely ill and would most likely benefit from a new heart. Some patients got a transplant and some did not. The variable indicates which group the patients were in; patients in the treatment group got a transplant and those in the control group did not. Another variable called was used to indicate whether or not the patient was alive at the end of the study.</p>
<p>In the study, of the 34 patients in the control group, 4 were alive at the end of the study. Of the 69 patients in the treatment group, 24 were alive. The contingency table below summarizes these results.</p>
<p><span class="math display">\[
\begin{array}{cc|ccc} &amp; &amp; &amp;\textit{Group}\\
&amp; &amp; \text{Control}  &amp; \text{Treatment}  &amp; \textbf{Total}  \\
&amp; \hline \text{Alive}   &amp; 4     &amp; 24            &amp; 28 \\
\textit{Outcome}&amp; \text{Dead}   &amp; 30        &amp; 45            &amp; 75  \\
&amp; \textbf{Total}            &amp; 34        &amp; 69            &amp; 103\\
\end{array}
\]</span></p>
<p>The data is in a file called <code>Stanford_heart_study.csv</code>. Read the data in and answer the following questions.</p>
<ol style="list-style-type: lower-alpha">
<li>What proportion of patients in the treatment group and what proportion of patients in the control group died?</li>
</ol>
<p>One approach for investigating whether or not the treatment is effective is to use a randomization technique.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>What are the claims being tested? Use the same null and alternative hypothesis notation used in the lesson notes.<br />
</li>
<li>The paragraph below describes the set up for such approach, if we were to do it without using statistical software. Fill in the blanks with a number or phrase, whichever is appropriate.</li>
</ol>
<p>We write <em>alive</em> on _______ cards representing patients who were alive at the end of the study, and <em>dead</em> on _______ cards representing patients who were not. Then, we shuffle these cards and split them into two groups: one group of size _______ representing treatment, and another group of size _______ representing control. We calculate the difference between the proportion of cards in the control and treatment groups (control - treatment), this is just so we have positive observed value, and record this value. We repeat this many times to build a distribution centered at _______. Lastly, we calculate the fraction of simulations where the simulated differences in proportions are _______ or _______. If this fraction of simulations, the empirical p-value, is low, we conclude that it is unlikely to have observed such an outcome by chance and that the null hypothesis should be rejected in favor of the alternative.</p>
<p>Next we will perform the simulation and use results to decide the effectiveness of the transplant program.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Find observed value of the test statistic, which we decided to use the difference in proportions.<br />
</li>
<li>Simulate 1000 values of the test statistic by using <code>shuffle()</code> on the variable <code>group</code>.<br />
</li>
<li>Plot distribution of results. Include a vertical line for the observed value. Clean up the plot as if you were presenting to a decision maker.<br />
</li>
<li>Find p-value. Think carefully about what more extreme would mean.<br />
</li>
<li>Decide if the treatment is effective.</li>
</ol>
<!--chapter:end:18-Hypothesis-Testing-Case-Study.Rmd-->
</div>
</div>
<div id="HYPOTEST" class="section level1" number="19">
<h1><span class="header-section-number">19</span> Hypothesis Testing</h1>
<div id="objectives-18" class="section level2" number="19.1">
<h2><span class="header-section-number">19.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Know and properly use the terminology of a hypothesis test.<br />
</li>
<li>Conduct all four steps of a hypothesis test using randomization.<br />
</li>
<li>Discuss and explain the ideas of decision errors, one-sided versus two-sided, and choice of statistical significance.</li>
</ol>
</div>
<div id="decision-making-under-uncertainty" class="section level2" number="19.2">
<h2><span class="header-section-number">19.2</span> Decision making under uncertainty</h2>
<p>At this point, it is useful to take a look at where we have been in this book and where we are going. We did this in the case study, but we want to discuss it again in a little more detail. We first looked at descriptive models to help us understand our data. This also required us to get familiar with software. We learned about graphical summaries, data collection methods, and summary metrics.</p>
<p>Next we learned about probability models. These models allowed us to use assumptions and a small number of parameters to make statements about data and also to simulate data. We found that there is a close tie between probability models and statistical models. In our first efforts at statistical modeling, we started to use data to create estimates for parameters of a probability model. This work resulted in point estimates via method of moments and maximum likelihood.</p>
<p>Now we are moving more in depth into statistical models. This is going to tie all the ideas together. We are going to use data from a sample and ideas of randomization to make conclusions about a population. This will require probability models, descriptive models, and some new ideas and terminology. We will generate point estimates for a metric designed to answer the research question and then find ways to determine the variability in the metric.</p>
<p><strong>Computational/Mathematical and hypothesis testing/confidence intervals context</strong></p>
<p>We are going to be using data from a sample of the population to make decisions about the population. There are many approaches and techniques for this. In this course we will be introducing and exploring different approaches; we are establishing foundations. As you can imagine, these ideas are varied, subtle, and at times difficult. We will just be exposing you to the foundational ideas. We want to make sure you understand that to become an accomplished practitioner, you must master the fundamentals and continue to learn the advanced ideas after the course.</p>
<p>Historically there have been two approaches to statistical decision making, hypothesis testing and confidence intervals. At their mathematical foundation, they are equivalent but sometimes in practice they offer different perspectives on the problem. We will learn about both of these.</p>
<p>The engines that drive the numeric results of a decision making model are either mathematical or computational. In reality, computational methods have mathematics behind them, and mathematical methods often require computer computations. The real distinction between them is the assumptions we are making about our population. Mathematical solutions typically have stricter assumptions thus leading to a tractable mathematical solution to the sampling distribution of the test statistic while computational models relax assumptions but may require extensive computational power. Like all problems, there is a trade off when one is better than the other. There is no one universal best method, some methods perform better in certain contexts. Do not think that computational methods such as the <strong>bootstrap</strong> are all you need to know.</p>
</div>
<div id="introduction-1" class="section level2" number="19.3">
<h2><span class="header-section-number">19.3</span> Introduction</h2>
<p>In this chapter we will introduce hypothesis testing. It is really an extension of our last chapter, the case study. We will put more emphasis on terms and core concepts. In this chapter we will use a computational solution but this will lead us into thinking of mathematical solutions.<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a> The role of the analyst is always key regardless of the perceived power of the computer. The analyst must take the research question and translate it into a numeric metric for evaluation. The analyst must decide on the type of data and its collection to evaluate the question. The analyst must evaluate the variability in the metric and determine what that means in relation to the original research question. The analyst must propose an answer.</p>
</div>
<div id="hypothesis-testing" class="section level2" number="19.4">
<h2><span class="header-section-number">19.4</span> Hypothesis testing</h2>
<p>We will continue to emphasize the ideas of hypothesis testing through a data-driven example but also via analogy to the US court system. So let’s begin our journey.</p>
<blockquote>
<p><strong>Example</strong>:<br />
You are annoyed by TV commercials. You suspect that there were more commercials in the <em>basic</em> TV channels, typically the local area channels, than in the <em>premium</em> channels you pay extra for. To test this claim, hypothesis, you want to collect some data and decide. How would you collect his data?</p>
</blockquote>
<p>Here is one approach, we watch 20 random half hour shows of TV. Ten of those hours are basic TV and the other 10 are premium. In each case you record the total length of commercials in each show.</p>
<blockquote>
<p><strong>Exercise</strong>:
Is this enough data? You decide to have your friends help you, so you actually only watch 5 hours and got the rest of the data from your friends. Is this a problem?</p>
</blockquote>
<p>We cannot determine if this is enough data without some type of subject matter knowledge. First we need to decide on what metric to use to determine if a difference exists, more to come on this, and second how big of a difference from a practical standpoint is of interest. Is a loss of 1 minute of TV show enough to say there is a difference? How about 5 minutes? These are not statistical questions, but depend on the context of the problem and often need subject matter expertise to answer. Often data is collected without thought to these considerations. There are several methods that attempt to answer these questions, they are loosely called sample size calculations. This book will not focus on sample size calculations and leave it to the reader to learn more from other sources. For the second question, the answer depends on the protocol and operating procedures used. If your friends are trained on how to measure the length of commercials, what counts as an ad, and their skills verified, then it is probably not a problem to use them to collect data. Consistency in measurement is the key.</p>
<p>The file <code>ads.csv</code> contains the data. Let’s read the data into <code>R</code> and start to summarize. Remember to load the appropriate <code>R</code> packages.</p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="#cb466-1" aria-hidden="true" tabindex="-1"></a>ads<span class="ot">&lt;-</span><span class="fu">read_csv</span>(<span class="st">&quot;data/ads.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="#cb467-1" aria-hidden="true" tabindex="-1"></a>ads</span></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    basic premium
##    &lt;dbl&gt;   &lt;dbl&gt;
##  1  6.95    3.38
##  2 10.0     7.8 
##  3 10.6     9.42
##  4 10.2     4.66
##  5  8.58    5.36
##  6  7.62    7.63
##  7  8.23    4.95
##  8 10.4     8.01
##  9 11.0     7.8 
## 10  8.52    9.58</code></pre>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="#cb469-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(ads)</span></code></pre></div>
<pre><code>## Rows: 10
## Columns: 2
## $ basic   &lt;dbl&gt; 6.950, 10.013, 10.620, 10.150, 8.583, 7.620, 8.233, 10.350, 11~
## $ premium &lt;dbl&gt; 3.383, 7.800, 9.416, 4.660, 5.360, 7.630, 4.950, 8.013, 7.800,~</code></pre>
<p>Notice that this data may not be <code>tidy</code>, what does each row represent and is it a single observations? We don’t know how the data was obtained, but if each row is a different friend who watches one basic and one premium channel, then it is possible this data is <code>tidy</code>. We want each observation to be a single show, wo let’s clean up, <code>tidy</code>, our data. Remember to ask yourself “What do I want <code>R</code> to do?” and “What does it need to do this?” We want one column that specifies the channel type and the other to specify length.</p>
<p>We need <code>R</code> to put, <em>pivot</em>, the data into a longer form. We need the function <code>pivot_longer()</code>. For more information type <code>vignette("pivot")</code> at the command prompt in <code>R</code>.</p>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="#cb471-1" aria-hidden="true" tabindex="-1"></a>ads <span class="ot">&lt;-</span> ads <span class="sc">%&gt;%</span></span>
<span id="cb471-2"><a href="#cb471-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols=</span><span class="fu">everything</span>(),<span class="at">names_to=</span><span class="st">&quot;channel&quot;</span>,<span class="at">values_to =</span> <span class="st">&quot;length&quot;</span>)</span>
<span id="cb471-3"><a href="#cb471-3" aria-hidden="true" tabindex="-1"></a>ads</span></code></pre></div>
<pre><code>## # A tibble: 20 x 2
##    channel length
##    &lt;chr&gt;    &lt;dbl&gt;
##  1 basic     6.95
##  2 premium   3.38
##  3 basic    10.0 
##  4 premium   7.8 
##  5 basic    10.6 
##  6 premium   9.42
##  7 basic    10.2 
##  8 premium   4.66
##  9 basic     8.58
## 10 premium   5.36
## 11 basic     7.62
## 12 premium   7.63
## 13 basic     8.23
## 14 premium   4.95
## 15 basic    10.4 
## 16 premium   8.01
## 17 basic    11.0 
## 18 premium   7.8 
## 19 basic     8.52
## 20 premium   9.58</code></pre>
<p>Looks good. Let’s summarize the data.</p>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="#cb473-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(ads)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##      name     class levels  n missing
## 1 channel character      2 20       0
##                                    distribution
## 1 basic (50%), premium (50%)                   
## 
## quantitative variables:  
##        name   class   min     Q1 median      Q3    max    mean       sd  n
## ...1 length numeric 3.383 7.4525  8.123 9.68825 11.016 8.03215 2.121412 20
##      missing
## ...1       0</code></pre>
<p>This summary is not what we want, since we want to break it down by <code>channel</code> type.</p>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="#cb475-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(length<span class="sc">~</span>channel,<span class="at">data=</span>ads)</span></code></pre></div>
<pre><code>##   channel   min      Q1 median       Q3    max   mean       sd  n missing
## 1   basic 6.950 8.30375  9.298 10.30000 11.016 9.2051 1.396126 10       0
## 2 premium 3.383 5.05250  7.715  7.95975  9.580 6.8592 2.119976 10       0</code></pre>
<blockquote>
<p><strong>Exercise</strong>:
Visualize the data using a boxplot.</p>
</blockquote>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="#cb477-1" aria-hidden="true" tabindex="-1"></a>ads <span class="sc">%&gt;%</span></span>
<span id="cb477-2"><a href="#cb477-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_boxplot</span>(channel<span class="sc">~</span>length) <span class="sc">%&gt;%</span></span>
<span id="cb477-3"><a href="#cb477-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Commercial Length&quot;</span>,<span class="at">subtitle =</span> <span class="st">&quot;Random 30 minute shows for 2 channel types&quot;</span>,</span>
<span id="cb477-4"><a href="#cb477-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Length&quot;</span>,<span class="at">y=</span><span class="st">&quot;Channel Type&quot;</span> ) <span class="sc">%&gt;%</span></span>
<span id="cb477-5"><a href="#cb477-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(theme_bw)</span></code></pre></div>
<p><img src="19-Hypothesis-Testing_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>It appears that the <em>premium</em> channels are skewed to the left. A <code>density</code> plot may help us compare the distributions and see the skewness, Figure @ref(fig:dens191-fig).</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="#cb478-1" aria-hidden="true" tabindex="-1"></a>ads <span class="sc">%&gt;%</span></span>
<span id="cb478-2"><a href="#cb478-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dens</span>(<span class="sc">~</span>length,<span class="at">color =</span> <span class="sc">~</span>channel)<span class="sc">%&gt;%</span></span>
<span id="cb478-3"><a href="#cb478-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Commercial Length&quot;</span>,<span class="at">subtitle =</span> <span class="st">&quot;Random 30 minute shows for 2 channel types&quot;</span>,</span>
<span id="cb478-4"><a href="#cb478-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Length&quot;</span>,<span class="at">y=</span><span class="st">&quot;Density&quot;</span>,<span class="at">color=</span><span class="st">&quot;Channel Type&quot;</span> ) <span class="sc">%&gt;%</span></span>
<span id="cb478-5"><a href="#cb478-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(theme_bw)</span></code></pre></div>
<div class="figure">
<img src="19-Hypothesis-Testing_files/figure-html/dens191-fig-1.png" alt="Commercial length broken down by channel type." width="672" />
<p class="caption">
(#fig:dens191-fig)Commercial length broken down by channel type.
</p>
</div>
<p>From this data, it looks like there is a difference between the two type of channels, but we must put the research question into a metric that will allow us to reach a decision. We will do this in a hypothesis test. As a reminder, the steps are</p>
<ol style="list-style-type: decimal">
<li>State the null and alternative hypotheses.<br />
</li>
<li>Compute a test statistic.<br />
</li>
<li>Determine the p-value.<br />
</li>
<li>Draw a conclusion.</li>
</ol>
<p>Before doing this, let’s visit an example of hypothesis testing that has become <em>common</em> knowledge for us, the US criminal trial system, we could also use the cadet honor system. This analogy allows to remember and apply the steps.</p>
<div id="hypothesis-testing-in-the-us-court-system" class="section level3" number="19.4.1">
<h3><span class="header-section-number">19.4.1</span> Hypothesis testing in the US court system</h3>
<p>A US court considers two possible claims about a defendant: she is either innocent or guilty. Imagine you are the prosecutor. If we set these claims up in a hypothesis framework, the null hypothesis is that the defendant is innocent and the alternative is guilty. Your job as the prosecutor is to use evidence to demonstrate to the jury that the alternative hypothesis is the reasonable conclusion.</p>
<p>The jury considers whether the evidence under the null hypothesis, innocence, is so convincing (strong) that there is no reasonable doubt regarding the person’s guilt. That is, the skeptical perspective (null hypothesis) is that the person is innocent until evidence is presented that convinces the jury that the person is guilty (alternative hypothesis).</p>
<p>Jurors examine the evidence under the assumption of innocence to see whether the evidence is so unlikely that it convincingly shows a defendant is guilty. Notice that if a jury finds a defendant <strong>not guilty</strong>, this does not necessarily mean the jury is confident in the person’s innocence. They are simply not convinced of the alternative that the person is guilty.</p>
<p>This is also the case with hypothesis testing: even if we fail to reject the null hypothesis, we typically do not accept the null hypothesis as truth. Failing to find strong evidence for the alternative hypothesis is not equivalent to providing evidence that the null hypothesis is true.</p>
<p>There are two types of mistakes, letting a guilty person go free and sending an innocent person to jail. The criteria for making the decision, reasonable doubt, establishes the likelihood of those errors.</p>
<p>Now back to our problem.</p>
</div>
<div id="step-1--state-the-null-and-alternative-hypotheses" class="section level3" number="19.4.2">
<h3><span class="header-section-number">19.4.2</span> Step 1- State the null and alternative hypotheses</h3>
<p>The first step is to translate the research question into hypotheses. As a reminder, our research question is <em>do premium channels have less ad time than basic channels?</em> In collecting the data, we already decided the total length of time of commercials in a 30 minute shows was the correct data for answering this question. We believe that premium channels have less commercial time. However, the null hypothesis, the straw man, has to be the default case that makes it possible to generate a sampling distribution.</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(H_0\)</span>: <strong>Null hypothesis</strong>. The distribution of length of commercials in premium and basic channels is the same.</li>
<li><span class="math inline">\(H_A\)</span>: <strong>Alternative hypothesis</strong>. The distribution of length of commercials in premium and basic channels is different.</li>
</ol>
<p>These hypotheses are vague, what does it mean to be different and how do we measure and summarize this? Let’s move to the second step and then come back and modify our hypotheses. Notice that the null states the distributions are the same. When we generate our sampling distribution of the test statistic, we will sample under this null.</p>
</div>
<div id="step-2---compute-a-test-statistic." class="section level3" number="19.4.3">
<h3><span class="header-section-number">19.4.3</span> Step 2 - Compute a test statistic.</h3>
<blockquote>
<p><strong>Exercise</strong>:<br />
What type of metric could we use to test for a difference in commercials between the two channels?</p>
</blockquote>
<p>There are many ways for the distributions of lengths of commercials to differ. The easiest is to think of the summary statistics such as mean, median, standard deviation, or some combination of all of these. Historically, for mathematical reasons, it has been common to look at differences in measures of centrality, mean or median. The second consideration is what kind of difference? For example a ratio or an actual difference, subtraction. Again for historical reasons, the difference in means has been used as a measure. To keep things interesting, and to force those with some high school stats experience to think about this problem differently, we are going to use a different metric than has historically been used and taught. This also requires us to write some of our own code. Later we will ask you to complete the same analysis with a different test statistic either with your own code or using code from <code>mosaic</code>.</p>
<p>Our metric is the ratio of the median length of commercials in basic channels to premium. Thus our hypotheses are now</p>
<p><span class="math inline">\(H_0\)</span>: <strong>Null hypothesis</strong>. The distribution of length of commercials in premium and basic channels is the same.</p>
<p><span class="math inline">\(H_A\)</span>: <strong>Alternative hypothesis</strong>. The distribution of length of commercials in premium and basic channels are different because the median length of basic channels ads is bigger than premium.</p>
<p>First let’s calculate the median length of commercials for your data.</p>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="#cb479-1" aria-hidden="true" tabindex="-1"></a><span class="fu">median</span>(length<span class="sc">~</span>channel,<span class="at">data=</span>ads) </span></code></pre></div>
<pre><code>##   basic premium 
##   9.298   7.715</code></pre>
<p>so the ratio is</p>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="#cb481-1" aria-hidden="true" tabindex="-1"></a><span class="fu">median</span>(length<span class="sc">~</span>channel,<span class="at">data=</span>ads)[<span class="dv">1</span>]<span class="sc">/</span><span class="fu">median</span>(length<span class="sc">~</span>channel,<span class="at">data=</span>ads)[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>##    basic 
## 1.205185</code></pre>
<p>Let’s put this into a function.</p>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb483-1"><a href="#cb483-1" aria-hidden="true" tabindex="-1"></a>metric <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb483-2"><a href="#cb483-2" aria-hidden="true" tabindex="-1"></a>  temp<span class="ot">&lt;-</span>x[<span class="dv">1</span>]<span class="sc">/</span>x[<span class="dv">2</span>]</span>
<span id="cb483-3"><a href="#cb483-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">names</span>(temp) <span class="ot">&lt;-</span> <span class="st">&quot;test_stat&quot;</span></span>
<span id="cb483-4"><a href="#cb483-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(temp)</span>
<span id="cb483-5"><a href="#cb483-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="#cb484-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metric</span>(<span class="fu">median</span>(length<span class="sc">~</span>channel,<span class="at">data=</span>ads) )</span></code></pre></div>
<pre><code>## test_stat 
##  1.205185</code></pre>
<p>Now the observed value of the test statistic is saved in an object.</p>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb486-1"><a href="#cb486-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">metric</span>(<span class="fu">median</span>(length<span class="sc">~</span>channel,<span class="at">data=</span>ads) )</span>
<span id="cb486-2"><a href="#cb486-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>## test_stat 
##  1.205185</code></pre>
<p>Here is what we have done; we needed a single number metric to use in evaluating the null and alternative hypotheses. The null is that they have the same distribution and the alternative is that they don’t. To measure the alternative we decided to use a ratio of the medians. If the number is close to 1 then the medians are not different. There may be other ways in which the distributions are different but we have decided on the ratio of medians.</p>
</div>
<div id="step-3---determine-the-p-value." class="section level3" number="19.4.4">
<h3><span class="header-section-number">19.4.4</span> Step 3 - Determine the p-value.</h3>
<p>As a reminder, the <strong>p-value</strong> is the probability of our observed test statistic or more extreme given the null hypothesis. Since our null hypothesis is that the distributions are the same we can use a <strong>randomization</strong>, permutation, test. We will shuffle the channel labels since under the null they are irrelevant. Here is the code for one run.</p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="#cb488-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">371</span>)</span>
<span id="cb488-2"><a href="#cb488-2" aria-hidden="true" tabindex="-1"></a><span class="fu">metric</span>(<span class="fu">median</span>(length<span class="sc">~</span><span class="fu">shuffle</span>(channel),<span class="at">data=</span>ads))</span></code></pre></div>
<pre><code>## test_stat 
## 0.9957097</code></pre>
<p>Let’s generate our empirical sampling distribution of the test statistic we developed.</p>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="#cb490-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">metric</span>(<span class="fu">median</span>(length<span class="sc">~</span><span class="fu">shuffle</span>(channel),<span class="at">data=</span>ads))</span></code></pre></div>
<p>Next we create a plot of the distribution of the ratio of medians commercial length in basic and premium channels assuming they come from the same population, Figure @ref(fig:hist191-fig).</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="#cb491-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb491-2"><a href="#cb491-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>test_stat) <span class="sc">%&gt;%</span></span>
<span id="cb491-3"><a href="#cb491-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span>obs ) <span class="sc">%&gt;%</span></span>
<span id="cb491-4"><a href="#cb491-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb491-5"><a href="#cb491-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Test statistic&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="19-Hypothesis-Testing_files/figure-html/hist191-fig-1.png" alt="Historgram of the sampling distribution by an approxiamte permutation test" width="672" />
<p class="caption">
(#fig:hist191-fig)Historgram of the sampling distribution by an approxiamte permutation test
</p>
</div>
<p>Notice that this distribution is centered on 1 and appears to be roughly symmetrical. The vertical line is our observed value of the test statistic. It seems to be in the tail, larger than expected if the channels came from the same distribution. Let’s calculate the p-value.</p>
<div class="sourceCode" id="cb492"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb492-1"><a href="#cb492-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb492-2"><a href="#cb492-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">p_value =</span> <span class="fu">mean</span>(test_stat<span class="sc">&gt;=</span>obs))</span></code></pre></div>
<pre><code>##   p_value
## 1   0.026</code></pre>
<p>Before proceeding, we have a technical question: Should we include the observed data in the calculation of the p-value? The answer is that most people would conclude that the original data is one of the possible permutations and thus include it. This practice will also insure that the p-value from a randomization test is never zero. In practice, this simply means adding 1 to both the numerator and denominator. The <strong>mosaic</strong> package has done this with the <code>prop1()</code> function.</p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="#cb494-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop1</span>(<span class="sc">~</span>(test_stat<span class="sc">&gt;=</span>obs),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##  prop_TRUE 
## 0.02697303</code></pre>
<p>The test we performed is called a one-sided test since we only checked if the median length for the basic channels is larger than that of the premium. In this case of a one-sided test, more extreme meant a number much bigger than 1. A two-sided test is also common, in fact it is the more common, and is used if we did not apriori think one channel had longer commercials than the other. In this case we find the p-value by doubling the single-sided value. This is the case because more extreme could have happened in either tail.</p>
</div>
<div id="step-4---draw-a-conclusion" class="section level3" number="19.4.5">
<h3><span class="header-section-number">19.4.5</span> Step 4 - Draw a conclusion</h3>
<p>In the last lesson we encountered a study from the 1970’s that explored whether there was strong evidence that women were less likely to be promoted than men. The research question – are females discriminated against in promotion decisions made by male managers? – was framed in the context of hypotheses:</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(H_0\)</span>: Gender has no effect on promotion decisions.<br />
</li>
<li><span class="math inline">\(H_A\)</span>: Women are discriminated against in promotion decisions.</li>
</ol>
<p>We used a difference in promotion proportions as our test statistic. The null hypothesis (<span class="math inline">\(H_0\)</span>) was a perspective of no difference. The data provided a point estimate of a -29.2% difference in recommended promotion rates between men and women. We determined that such a difference from chance alone would be rare: it would only happen about 2 in 100 times. When results like these are inconsistent with <span class="math inline">\(H_0\)</span>, we reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span>. Here, we concluded there was evidence of discrimination against women.</p>
<p>The 2-in-100 chance is the p-value, which is a probability quantifying the strength of the evidence against the null hypothesis and in favor of the alternative.</p>
<p>When the p-value is small, i.e. less than a previously set threshold, we say the results are <strong>statistically significant</strong>. This means the data provide such strong evidence against <span class="math inline">\(H_0\)</span> that we reject the null hypothesis in favor of the alternative hypothesis. The threshold, called the <strong>significance level</strong> and often represented by the Greek letter <span class="math inline">\(\alpha\)</span>, is typically set to <span class="math inline">\(\alpha = 0.05\)</span>, but can vary depending on the field or the application. Using a significance level of <span class="math inline">\(\alpha = 0.05\)</span> in the discrimination study, we can say that the data provided statistically significant evidence against the null hypothesis.</p>
<blockquote>
<p>We say that the data provide statistically significant evidence against the null hypothesis if the p-value is less than some reference value, usually <span class="math inline">\(\alpha=0.05\)</span>.</p>
</blockquote>
<p>If the null hypothesis is true, unknown to us, the significance level <span class="math inline">\(\alpha\)</span> defines the probability that we will make a Type 1 Error, we will define errors in the next section.</p>
<blockquote>
<p><em>Side note</em>:
What’s so special about 0.05? We often use a threshold of 0.05 to determine whether a result is statistically significant. But why 0.05? Maybe we should use a bigger number, or maybe a smaller number. If you’re a little puzzled, that probably means you’re reading with a critical eye – good job! There are many <a href="http://www.openintro.org/why05%7D%7Bwww.openintro.org/why05">video clips</a> that explain the use of 0.05. Sometimes it’s also a good idea to deviate from the standard and it depends on the risk that the decision maker wants in terms of the two types of errors.</p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
Using our p-value make a decision.</p>
</blockquote>
<p>Based on our data, if there were really no difference in the distribution of lengths of commercials in 30 minute shows between basic and premium channels then the probability of finding our observed ratio of medians is 0.027. Since this is less than our significance level of 0.05, we reject the null in favor of the alternative that the basic channel has longer commercials.</p>
</div>
<div id="decision-errors" class="section level3" number="19.4.6">
<h3><span class="header-section-number">19.4.6</span> Decision errors</h3>
<p>Hypothesis tests are not flawless. Just think of the court system: innocent people are sometimes wrongly convicted and the guilty sometimes walk free. Similarly, data can point to the wrong conclusion. However, what distinguishes statistical hypothesis tests from a court system is that our framework allows us to quantify and control how often the data lead us to the incorrect conclusion.</p>
<p>There are two competing hypotheses: the null and the alternative. In a hypothesis test, we make a statement about which one might be true, but we might choose incorrectly. There are four possible scenarios in a hypothesis test, which are summarized below.</p>
<p><span class="math display">\[
\begin{array}{cc|cc} &amp; &amp; &amp;\textbf{Test Conclusion}\\
&amp; &amp; \text{do not reject } H_0 &amp;  \text{reject } H_0 \text{ in favor of }H_A  \\
&amp; \hline H_0 \text{ true} &amp; \text{okay} &amp;  \text{Type~1 Error}  \\
\textbf{Truth}&amp; H_A \text{true} &amp; \text{Type 2 Error} &amp; \text{okay}  \\
\end{array}
\]</span></p>
<p>A <strong>Type 1</strong> Error, also called a <strong>false positive</strong>, is rejecting the null hypothesis when <span class="math inline">\(H_0\)</span> is actually true. Since we rejected the null hypothesis in the gender discrimination and the commercial length studies, it is possible that we made a Type 1 Error in one or both of those studies. A <strong>Type 2</strong> Error, also called a <strong>false negative</strong>, is failing to reject the null hypothesis when the alternative is actually true.</p>
<blockquote>
<p><em>Example</em>:<br />
In a US court, the defendant is either innocent (<span class="math inline">\(H_0\)</span>) or guilty (<span class="math inline">\(H_A\)</span>). What does a Type 1 Error represent in this context? What does a Type 2 Error represent?</p>
</blockquote>
<p>If the court makes a Type 1 Error, this means the defendant is innocent (<span class="math inline">\(H_0\)</span> true) but wrongly convicted. A Type 2 Error means the court failed to reject <span class="math inline">\(H_0\)</span> (i.e. failed to convict the person) when she was in fact guilty (<span class="math inline">\(H_A\)</span> true).</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Consider the commercial length study where we concluded basic channels had longer commercials than premium channels. What would a Type 1 Error represent in this context?<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
How could we reduce the Type 1 Error rate in US courts? What influence would this have on the Type 2 Error rate?</p>
</blockquote>
<p>To lower the Type 1 Error rate, we might raise our standard for conviction from “beyond a reasonable doubt” to “beyond a conceivable doubt” so fewer people would be wrongly convicted. However, this would also make it more difficult to convict the people who are actually guilty, so we would make more Type 2 Errors.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
How could we reduce the Type 2 Error rate in US courts? What influence would this have on the Type 1 Error rate?</p>
</blockquote>
<p>To lower the Type 2 Error rate, we want to convict more guilty people. We could lower the standards for conviction from “beyond a reasonable doubt” to “beyond a little doubt”. Lowering the bar for guilt will also result in more wrongful convictions, raising the Type 1 Error rate. Think about the cadet honor system, its metric of evaluation, and the impact on the types of errors.</p>
<p>These exercises provide an important lesson: if we reduce how often we make one type of error, we generally make more of the other type for given amount of data, information.</p>
</div>
<div id="choosing-a-significance-level" class="section level3" number="19.4.7">
<h3><span class="header-section-number">19.4.7</span> Choosing a significance level</h3>
<p>Choosing a significance level for a test is important in many contexts, and the traditional level is 0.05. However, it is sometimes helpful to adjust the significance level based on the application. We may select a level that is smaller or larger than 0.05 depending on the consequences of any conclusions reached from the test.</p>
<p>If making a Type 1 Error is dangerous or especially costly, we should choose a small significance level (e.g. 0.01 or 0.001). Under this scenario, we want to be very cautious about rejecting the null hypothesis, so we demand very strong evidence favoring the alternative <span class="math inline">\(H_A\)</span> before we would reject <span class="math inline">\(H_0\)</span>.</p>
<p>If a Type 2 Error is relatively more dangerous or much more costly than a Type 1 Error, then we should choose a higher significance level (e.g. 0.10). Here we want to be cautious about failing to reject <span class="math inline">\(H_0\)</span> when the null is actually false. The significance level selected for a test should reflect the real-world consequences associated with making a Type 1 or Type 2 Error.</p>
</div>
<div id="introducing-two-sided-hypotheses" class="section level3" number="19.4.8">
<h3><span class="header-section-number">19.4.8</span> Introducing two-sided hypotheses</h3>
<p>So far we have explored whether women were discriminated against and whether commercials were longer depending on the type of channel. In these two case studies, we’ve actually ignored some possibilities:</p>
<ol style="list-style-type: decimal">
<li>What if <strong>men</strong> are actually discriminated against?<br />
</li>
<li>What if ads on premium channels are actually <strong>longer</strong>?</li>
</ol>
<p>These possibilities weren’t considered in our hypotheses or analyses. This may have seemed natural since the data pointed in the directions in which we framed the problems. However, there are two dangers if we ignore possibilities that disagree with our data or that conflict with our worldview:</p>
<ol style="list-style-type: decimal">
<li>Framing an alternative hypothesis simply to match the direction that the data point will generally inflate the Type 1 Error rate. After all the work we’ve done (and will continue to do) to rigorously control the error rates in hypothesis tests, careless construction of the alternative hypotheses can disrupt that hard work.<br />
</li>
<li>If we only use alternative hypotheses that agree with our worldview, then we’re going to be subjecting ourselves to <strong>confirmation bias</strong>, which means we are looking for data that supports our ideas. That’s not very scientific, and we can do better!</li>
</ol>
<p>The previous hypotheses we’ve seen are called <strong>one-sided hypothesis tests</strong> because they only explored one direction of possibilities. Such hypotheses are appropriate when we are exclusively interested in the single direction, but usually we want to consider all possibilities. To do so, let’s discuss <strong>two-sided hypothesis tests</strong> in the context of a new study that examines the impact of using blood thinners on patients who have undergone CPR.</p>
</div>
</div>
<div id="two-sided-hypothesis-test" class="section level2" number="19.5">
<h2><span class="header-section-number">19.5</span> Two-sided hypothesis test</h2>
<p>It is important to distinguish between a <em>two-sided</em> hypothesis test and a <em>one-sided</em> test. In a two-sided test, we are concerned with whether or not the population parameter could take a particular value. For parameter <span class="math inline">\(\theta\)</span>, a set of two-sided hypotheses looks like:</p>
<p><span class="math display">\[
H_0: \theta=\theta_0 \hspace{0.75cm} H_1: \theta\neq \theta_0
\]</span></p>
<p>In a one-sided test, we are concerned with whether a parameter exceeds or does not exceed a specific value. A set of one-sided hypotheses looks like:
<span class="math display">\[
H_0: \theta = \theta_0 \hspace{0.75cm} H_1:\theta&gt;\theta_0
\]</span>
or
<span class="math display">\[
H_0: \theta = \theta_0 \hspace{0.75cm} H_1:\theta&lt;\theta_0
\]</span></p>
<p>In some texts, one-sided null hypotheses include an inequality (<span class="math inline">\(\geq\)</span> or <span class="math inline">\(\leq\)</span>). We have demonstrated one-sided tests and in the next example we will use a two-sided test.</p>
<div id="example-cpr" class="section level3" number="19.5.1">
<h3><span class="header-section-number">19.5.1</span> Example CPR</h3>
<p>Cardiopulmonary resuscitation (CPR) is a procedure used on individuals suffering a heart attack when other emergency resources are unavailable. This procedure is helpful in providing some blood circulation to keep a person alive, but CPR chest compressions can also cause internal injuries. Internal bleeding and other injuries that can result from CPR complicate additional treatment efforts. For instance, blood thinners may be used to help release a clot that is causing the heart attack once a patient arrives in the hospital. However, blood thinners negatively affect internal injuries.</p>
<p>Here we consider an experiment with patients who underwent CPR for a heart attack and were subsequently admitted to a hospital.<a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a> Each patient was randomly assigned to either receive a blood thinner (treatment group) or not receive a blood thinner (control group). The outcome variable of interest was whether the patient survived for at least 24 hours.</p>
</div>
<div id="step-1--state-the-null-and-alternative-hypotheses-1" class="section level3" number="19.5.2">
<h3><span class="header-section-number">19.5.2</span> Step 1- State the null and alternative hypotheses</h3>
<blockquote>
<p><strong>Exercise</strong>:
Form hypotheses for this study in plain and statistical language. Let <span class="math inline">\(p_c\)</span> represent the true survival rate of people who do not receive a blood thinner (corresponding to the control group) and <span class="math inline">\(p_t\)</span> represent the survival rate for people receiving a blood thinner (corresponding to the treatment group).</p>
</blockquote>
<p>We want to understand whether blood thinners are helpful or harmful. We’ll consider both of these possibilities using a two-sided hypothesis test.</p>
<p><span class="math inline">\(H_0\)</span>: Blood thinners do not have an overall survival effect, experimental treatment is independent of survival rate. <span class="math inline">\(p_c - p_t = 0\)</span>.<br />
<span class="math inline">\(H_A\)</span>: Blood thinners have an impact on survival, either positive or negative, but not zero. <span class="math inline">\(p_c - p_t \neq 0\)</span>.</p>
<p>Notice here that we accelerated the process by already defining our test statistic, our metric, in the hypothesis. It is the difference in survival rates for the control and treatment groups. This is a similar metric to what we used in the case study. We could use others but this will allow us to use functions from the <strong>mosaic</strong> package and will also help us to understand metrics for mathematically derived sampling distributions.</p>
<p>There were 50 patients in the experiment who did not receive a blood thinner and 40 patients who did. The study results are in the file <code>blood_thinner.csv</code>.</p>
<div class="sourceCode" id="cb496"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb496-1"><a href="#cb496-1" aria-hidden="true" tabindex="-1"></a>thinner <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/blood_thinner.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="#cb497-1" aria-hidden="true" tabindex="-1"></a>thinner</span></code></pre></div>
<pre><code>## # A tibble: 90 x 2
##    group     outcome 
##    &lt;chr&gt;     &lt;chr&gt;   
##  1 treatment survived
##  2 control   survived
##  3 control   died    
##  4 control   died    
##  5 control   died    
##  6 treatment survived
##  7 control   died    
##  8 control   died    
##  9 treatment died    
## 10 treatment survived
## # ... with 80 more rows</code></pre>
<p>Let’s put it in a table.</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="#cb499-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>group<span class="sc">+</span>outcome,<span class="at">data=</span>thinner,<span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##            outcome
## group       died survived Total
##   control     39       11    50
##   treatment   26       14    40
##   Total       65       25    90</code></pre>
</div>
<div id="step-2---compute-a-test-statistic.-1" class="section level3" number="19.5.3">
<h3><span class="header-section-number">19.5.3</span> Step 2 - Compute a test statistic.</h3>
<p>The test statistic we have selected is the difference in survival rate in the control group versus the treatment group. The following <code>R</code> finds the observed proportions.</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="#cb501-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(outcome<span class="sc">~</span>group,<span class="at">data=</span>thinner,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>##           group
## outcome    control treatment
##   died        0.78      0.65
##   survived    0.22      0.35
##   Total       1.00      1.00</code></pre>
<p>Notice the formula we used to get the correct variable in the column for the summary proportions.</p>
<p>The observed test statistic can now be found.<a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a></p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="#cb503-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">diffprop</span>(outcome<span class="sc">~</span>group,<span class="at">data=</span>thinner)</span>
<span id="cb503-2"><a href="#cb503-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>## diffprop 
##    -0.13</code></pre>
<p>Based on the point estimate, for patients who have undergone CPR outside of the hospital, an additional 13% of these patients survive when they are treated with blood thinners. However, we wonder if this difference could be easily explainable by chance.</p>
</div>
<div id="step-3---determine-the-p-value.-1" class="section level3" number="19.5.4">
<h3><span class="header-section-number">19.5.4</span> Step 3 - Determine the p-value.</h3>
<p>As we did in our past two studies, we will simulate what type of differences we might see from chance alone under the null hypothesis. By randomly assigning <em>simulated treatment</em> and <em>simulated control</em> stickers to the patients’ files, we get a new grouping. If we repeat this simulation 10,000 times, we can build a <strong>null distribution</strong> of the differences, this is our empirical sampling distribution.</p>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb505-1"><a href="#cb505-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">655</span>)</span>
<span id="cb505-2"><a href="#cb505-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">diffprop</span>(outcome<span class="sc">~</span><span class="fu">shuffle</span>(group),<span class="at">data=</span>thinner)</span></code></pre></div>
<p>Figure @ref(fig:dens912-fig) is a histogram of the estimated sampling distribution.</p>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="#cb506-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb506-2"><a href="#cb506-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>diffprop) <span class="sc">%&gt;%</span></span>
<span id="cb506-3"><a href="#cb506-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span>obs ) <span class="sc">%&gt;%</span></span>
<span id="cb506-4"><a href="#cb506-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb506-5"><a href="#cb506-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Test statistic&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="19-Hypothesis-Testing_files/figure-html/dens912-fig-1.png" alt="Histogram of the estiamted sampling distribution." width="672" />
<p class="caption">
(#fig:dens912-fig)Histogram of the estiamted sampling distribution.
</p>
</div>
<p>Notice how it is centered on zero, the assumption of no difference. Also notice that it is unimodal and symmetrical. We will use this when we develop mathematical sampling distributions.</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="#cb507-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop1</span>(<span class="sc">~</span>(diffprop<span class="sc">&lt;=</span>obs),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>## prop_TRUE 
## 0.1283872</code></pre>
<p>The left tail area is about 0.13. (Note: it is only a coincidence that we also have <span class="math inline">\(\hat{p}_c - \hat{p}_t= - 0.13\)</span>.) However, contrary to how we calculated the p-value in previous studies, the p-value of this test is not 0.13!</p>
<p>The p-value is defined as the chance we observe a result at least as favorable to the alternative hypothesis as the result (i.e. the difference) we observe. In this case, any differences greater than or equal to 0.13 would also provide equally strong evidence favoring the alternative hypothesis as a difference of - 0.13. A difference of 0.13 would correspond to 13% higher survival rate in the treatment group than the control group.</p>
<p>There is something different in this study than in the past studies: in this study, we are particularly interested in whether blood thinners increase <strong>or</strong> decrease the risk of death in patients who undergo CPR before arriving at the hospital.<a href="#fn77" class="footnote-ref" id="fnref77"><sup>77</sup></a></p>
<p>For a two-sided test, take the single tail (in this case, 0.13) and double it to get the p-value: 0.26.</p>
</div>
<div id="step-4---draw-a-conclusion-1" class="section level3" number="19.5.5">
<h3><span class="header-section-number">19.5.5</span> Step 4 - Draw a conclusion</h3>
<p>Since this p-value is larger than 0.05, we do not reject the null hypothesis. That is, we do not find statistically significant evidence that the blood thinner has any influence on survival of patients who undergo CPR prior to arriving at the hospital. Once again, we can discuss the causal conclusion since this is an experiment.</p>
<blockquote>
<p><strong>Default to a two-sided test</strong>
We want to be rigorous and keep an open mind when we analyze data and evidence. Use a one-sided hypothesis test only if you truly have interest in only one direction.</p>
</blockquote>
<blockquote>
<p><strong>Computing a p-value for a two-sided test</strong><br />
First compute the p-value for one tail of the distribution, then double that value to get the two-sided p-value. That’s it!</p>
</blockquote>
<p>It is never okay to change two-sided tests to one-sided tests after observing the data.</p>
<blockquote>
<p><strong>Hypothesis tests should be set up before seeing the data</strong><br />
After observing data, it is tempting to turn a two-sided test into a one-sided test. Avoid this temptation. Hypotheses should be set up <strong>before</strong> observing the data.</p>
</blockquote>
</div>
<div id="how-to-use-a-hypothesis-test" class="section level3" number="19.5.6">
<h3><span class="header-section-number">19.5.6</span> How to use a hypothesis test</h3>
<p>This is a summary of the general framework for using hypothesis testing. It is the same steps with just slightly different wording.</p>
<ol style="list-style-type: decimal">
<li>Frame the research question in terms of hypotheses.</li>
</ol>
<p>Hypothesis tests are appropriate for research questions that can be summarized in two competing hypotheses. The null hypothesis (<span class="math inline">\(H_0\)</span>) usually represents a skeptical perspective or a perspective of no difference. The alternative hypothesis (<span class="math inline">\(H_A\)</span>) usually represents a new view or a difference.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Collect data with an observational study or experiment.<br />
If a research question can be formed into two hypotheses, we can collect data to run a hypothesis test. If the research question focuses on associations between variables but does not concern causation, we would run an observational study. If the research question seeks a causal connection between two or more variables, then an experiment should be used.</p></li>
<li><p>Analyze the data.<br />
Choose an analysis technique appropriate for the data and identify the p-value. So far, we’ve only seen one analysis technique: randomization. We’ll encounter several new methods suitable for many other contexts.</p></li>
<li><p>Form a conclusion.
Using the p-value from the analysis, determine whether the data provide statistically significant evidence against the null hypothesis. Also, be sure to write the conclusion in plain language so casual readers can understand the results.</p></li>
</ol>
</div>
</div>
<div id="homework-problems-18" class="section level2" number="19.6">
<h2><span class="header-section-number">19.6</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Repeat the analysis of the commercial length in the notes. This time use a different test statistic.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses.<br />
</li>
<li>Compute a test statistic. Remember to use something different than what was used above.<br />
</li>
<li>Determine the p-value.<br />
</li>
<li>Draw a conclusion.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Is yawning contagious?</li>
</ol>
<p>An experiment conducted by the , a science entertainment TV program on the Discovery Channel, tested if a person can be subconsciously influenced into yawning if another person near them yawns. 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a group where there wasn’t a person yawning near them (control). The following table shows the results of this experiment.</p>
<p><span class="math display">\[
\begin{array}{cc|ccc} &amp; &amp; &amp;\textbf{Group}\\
&amp; &amp; \text{Treatment } &amp;  \text{Control} &amp; \text{Total}  \\
&amp; \hline \text{Yawn}    &amp;   10      &amp; 4     &amp; 14  \\
\textbf{Result} &amp; \text{Not Yawn}   &amp; 24        &amp; 12        &amp; 36   \\
    &amp;\text{Total}       &amp; 34        &amp; 16        &amp; 50 \\
\end{array}
\]</span></p>
<p>The data is in the file <code>yawn.csv</code>.</p>
<ol style="list-style-type: lower-alpha">
<li>What are the hypotheses?</li>
<li>Calculate the observed difference between the yawning rates under the two scenarios. Yes we are giving you the test statistic.</li>
<li>Estimate the p-value using randomization.</li>
<li>Plot the empirical sampling distribution.</li>
<li>Determine the conclusion of the hypothesis test.</li>
<li>The traditional belief is that yawning is contagious – one yawn can lead to another yawn, which might lead to another, and so on. In this exercise, there was the option of selecting a one-sided or two-sided test. Which would you recommend (or which did you choose)? Justify your answer in 1-3 sentences.</li>
<li>How did you select your level of significance? Explain in 1-3 sentences.</li>
</ol>
<!--chapter:end:19-Hypothesis-Testing.Rmd-->
</div>
</div>
<div id="PVALUES" class="section level1" number="20">
<h1><span class="header-section-number">20</span> Empirical p-values</h1>
<div id="objective" class="section level2" number="20.1">
<h2><span class="header-section-number">20.1</span> Objective</h2>
<p>Conduct all four steps of a hypothesis test using probability models.</p>
</div>
<div id="hypothesis-testing-using-probability-models" class="section level2" number="20.2">
<h2><span class="header-section-number">20.2</span> Hypothesis testing using probability models</h2>
<p>As a lead into the central limit theorem and mathematical sampling distributions, we will look at a class of hypothesis testing where the null hypothesis specifies a probability model. In some cases we can get an exact answer and in others we will use simulation to get an empirical p-value. By the way, a permutation test is an exact test; by this we mean we are finding all the possible permutations in the calculation of the p-value. However, since the complete enumeration of all permutations is often difficult, we approximate it with randomization, simulation. Thus the p-value from a randomization test is an approximation of the exact test.</p>
<p>Let’s use three examples to illustrate the ideas of this lesson.</p>
</div>
<div id="tappers-and-listeners" class="section level2" number="20.3">
<h2><span class="header-section-number">20.3</span> Tappers and listeners</h2>
<p>Here’s a game you can try with your friends or family: pick a simple, well-known song, tap that tune on your desk, and see if the other person can guess the song. In this simple game, you are the tapper, and the other person is the listener.</p>
<p>A Stanford University graduate student named Elizabeth Newton conducted an experiment using the tapper-listener game.<a href="#fn78" class="footnote-ref" id="fnref78"><sup>78</sup></a> In her study, she recruited 120 tappers and 120 listeners into the study. About 50% of the tappers expected that the listener would be able to guess the song. Newton wondered, is 50% a reasonable expectation?</p>
<div id="step-1--state-the-null-and-alternative-hypotheses-2" class="section level3" number="20.3.1">
<h3><span class="header-section-number">20.3.1</span> Step 1- State the null and alternative hypotheses</h3>
<p>Newton’s research question can be framed into two hypotheses:</p>
<p><span class="math inline">\(H_0\)</span>: The tappers are correct, and generally 50% of the time listeners are able to guess the tune. <span class="math inline">\(p = 0.50\)</span><br />
<span class="math inline">\(H_A\)</span>: The tappers are incorrect, and either more than or less than 50% of listeners will be able to guess the tune. <span class="math inline">\(p \neq 0.50\)</span></p>
<blockquote>
<p><strong>Exercise</strong>:
Is this a two-sided or one-sided hypothesis test? How many variables are in this model?</p>
</blockquote>
<p>The tappers think that listeners will guess the song 50% of the time, so this is a two-sided test since we don’t know before hand if listeners will be better or worse than this value.</p>
<p>There is only one variable, is the listener correct?</p>
</div>
<div id="step-2---compute-a-test-statistic.-2" class="section level3" number="20.3.2">
<h3><span class="header-section-number">20.3.2</span> Step 2 - Compute a test statistic.</h3>
<p>In Newton’s study, only 42, (we changed the number to make this problem more interesting from an educational perspective) out of 120 listeners (<span class="math inline">\(\hat{p} = 0.35\)</span>) were able to guess the tune! From the perspective of the null hypothesis, we might wonder, how likely is it that we would get this result from chance alone? That is, what’s the chance we would happen to see such a small fraction if <span class="math inline">\(H_0\)</span> were true and the true correct-guess rate is 0.50?</p>
<p>Now before we use simulation, let’s frame this as a probability model. The random variable <span class="math inline">\(X\)</span> is the number of correct out of 120. If the observations are independent and the probability of success is constant then we could use a binomial model. We can’t answer the validity of these assumptions without knowing more about the experiment, the subjects, and the data collection. For educational purposes, we will assume they are valid. Thus our test statistic is the number of successes in 120 trials. The observed value is 42.</p>
</div>
<div id="step-3---determine-the-p-value.-2" class="section level3" number="20.3.3">
<h3><span class="header-section-number">20.3.3</span> Step 3 - Determine the p-value.</h3>
<p>We now want to find the p-value as <span class="math inline">\(2 \cdot \mbox{P}(X \leq 42)\)</span> where <span class="math inline">\(X\)</span> is a binomial with <span class="math inline">\(p=0.5\)</span> and <span class="math inline">\(n=120\)</span>. Again, the p-value is the probability of the data or more extreme given the null hypothesis is true. Here the null hypothesis being true implies that the probability of success is 0.50. We will use <code>R</code> to get the one-sided p-value and then double to get the p-value for the problem. We selected <span class="math inline">\(\mbox{P}(X \leq 42)\)</span> because more extreme means the observed values and values further from the value you would get if the null hypothesis were true, which is 60 for this problem.</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="#cb509-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pbinom</span>(<span class="dv">42</span>,<span class="dv">120</span>,<span class="at">prob=</span><span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0.001299333</code></pre>
<p>That is a small p-value.</p>
</div>
<div id="step-4---draw-a-conclusion-2" class="section level3" number="20.3.4">
<h3><span class="header-section-number">20.3.4</span> Step 4 - Draw a conclusion</h3>
<p>Based on our data, if the listeners were guessing correct 50% of the time, there is less than a <span class="math inline">\(0.0013\)</span> probability that only 42 or less or 78 or more listeners would get it right. This is much less than 0.05, so we reject that the listeners are guessing correctly half of the time.</p>
<p>This decision region looks like the pmf in Figure @ref(fig:dist201-fig), any observed values inside the red boundary lines would be consistent with the null hypothesis. Any values at the red line or more extreme would be in the rejection region. We also plotted the observed values in black.</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="#cb511-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;binom&quot;</span>,<span class="at">size=</span><span class="dv">120</span>,<span class="at">prob=</span>.<span class="dv">5</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">115</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb511-2"><a href="#cb511-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="dv">49</span>,<span class="dv">71</span>),<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb511-3"><a href="#cb511-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="dv">42</span>),<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb511-4"><a href="#cb511-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(theme_bw) <span class="sc">%&gt;%</span></span>
<span id="cb511-5"><a href="#cb511-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Binomial pmf&quot;</span>,<span class="at">subtitle=</span><span class="st">&quot;Probability of success is 0.5&quot;</span>,<span class="at">y=</span><span class="st">&quot;Probability&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="20-Empirical-p-values_files/figure-html/dist201-fig-1.png" alt="Binomial pmf" width="672" />
<p class="caption">
(#fig:dist201-fig)Binomial pmf
</p>
</div>
</div>
<div id="repeat-using-simulation" class="section level3" number="20.3.5">
<h3><span class="header-section-number">20.3.5</span> Repeat using simulation</h3>
<p>We will repeat the analysis using an empirical p-value. Step 1 is the same.</p>
</div>
<div id="step-2---compute-a-test-statistic.-3" class="section level3" number="20.3.6">
<h3><span class="header-section-number">20.3.6</span> Step 2 - Compute a test statistic.</h3>
<p>We will use the proportion of listeners that get the song correct instead of the number, this is a minor change since we are simply dividing by 120.</p>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="#cb512-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="dv">42</span><span class="sc">/</span><span class="dv">120</span></span>
<span id="cb512-2"><a href="#cb512-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>## [1] 0.35</code></pre>
</div>
<div id="step-3---determine-the-p-value.-3" class="section level3" number="20.3.7">
<h3><span class="header-section-number">20.3.7</span> Step 3 - Determine the p-value.</h3>
<p>To simulate 120 games under the null hypothesis where <span class="math inline">\(p = 0.50\)</span>, we could flip a coin 120 times. Each time the coin came up heads, this could represent the listener guessing correctly, and tails would represent the listener guessing incorrectly. For example, we can simulate 5 tapper-listener pairs by flipping a coin 5 times:</p>
<p><span class="math display">\[
\begin{array}{ccccc}
H &amp; H &amp; T &amp; H &amp; T \\
Correct &amp; Correct &amp; Wrong &amp; Correct &amp; Wrong \\
\end{array}
\]</span></p>
<p>After flipping the coin 120 times, we got 56 heads for <span class="math inline">\(\hat{p}_{sim} = 0.467\)</span>. As we did with the randomization technique, seeing what would happen with one simulation isn’t enough. In order to evaluate whether our originally observed proportion of 0.35 is unusual or not, we should generate more simulations. Here we’ve repeated this simulation 10000 times:</p>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="#cb514-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">10000</span>, <span class="dv">120</span>, <span class="fl">0.5</span>) <span class="sc">/</span> <span class="dv">120</span></span></code></pre></div>
<p>Note, we could simulate it a number of ways. Here is a way using <code>do()</code> that will look like how we have coded for other randomization tests.</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb515-1"><a href="#cb515-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">604</span>)</span>
<span id="cb515-2"><a href="#cb515-2" aria-hidden="true" tabindex="-1"></a>results<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">mean</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">size=</span><span class="dv">120</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb516-1"><a href="#cb516-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##        mean
## 1 0.4250000
## 2 0.5250000
## 3 0.5916667
## 4 0.5000000
## 5 0.5250000
## 6 0.5083333</code></pre>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="#cb518-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb518-2"><a href="#cb518-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>mean,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb518-3"><a href="#cb518-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span><span class="fu">c</span>(obs,<span class="dv">1</span><span class="sc">-</span>obs),<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb518-4"><a href="#cb518-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb518-5"><a href="#cb518-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Test statistic&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="20-Empirical-p-values_files/figure-html/dens202-fig-1.png" alt="The estimated sampling distribution." width="672" />
<p class="caption">
(#fig:dens202-fig)The estimated sampling distribution.
</p>
</div>
<p>Notice in Figre @ref(fig:dens202-fig) how the sampling distribution is centered at 0.5 and looks symmetrical.</p>
<p>The p-value is found using the <code>prop1</code> function, in this problem we really need the observed case added back in to prevent a p-value of zero.</p>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb519-1"><a href="#cb519-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">prop1</span>(<span class="sc">~</span>(mean<span class="sc">&lt;=</span>obs),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##  prop_TRUE 
## 0.00119988</code></pre>
</div>
<div id="step-4---draw-a-conclusion-3" class="section level3" number="20.3.8">
<h3><span class="header-section-number">20.3.8</span> Step 4 - Draw a conclusion</h3>
<p>In these 10,000 simulations, we see very few results close to 0.35. Based on our data, if the listeners were guessing correct 50% of the time, there is less than a <span class="math inline">\(0.0012\)</span> probability that only 35% or less or 65% or more listeners would get it right. This is much less than 0.05, so we reject that the listeners are guessing correctly half of the time.</p>
<blockquote>
<p><strong>Exercise</strong>:
In the context of the experiment, what is the p-value for the hypothesis test?<a href="#fn79" class="footnote-ref" id="fnref79"><sup>79</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
Do the data provide statistically significant evidence against the null hypothesis? State an appropriate conclusion in the context of the research question.<a href="#fn80" class="footnote-ref" id="fnref80"><sup>80</sup></a></p>
</blockquote>
</div>
</div>
<div id="cardiopulmonary-resuscitation-cpr" class="section level2" number="20.4">
<h2><span class="header-section-number">20.4</span> Cardiopulmonary resuscitation (CPR)</h2>
<p>Let’s return to the CPR example from last lesson. As a reminder, we will repeat the background material.</p>
<p>Cardiopulmonary resuscitation (CPR) is a procedure used on individuals suffering a heart attack when other emergency resources are unavailable. This procedure is helpful in providing some blood circulation to keep a person alive, but CPR chest compressions can also cause internal injuries. Internal bleeding and other injuries that can result from CPR complicate additional treatment efforts. For instance, blood thinners may be used to help release a clot that is causing the heart attack once a patient arrives in the hospital. However, blood thinners negatively affect internal injuries.</p>
<p>Here we consider an experiment with patients who underwent CPR for a heart attack and were subsequently admitted to a hospital.<a href="#fn81" class="footnote-ref" id="fnref81"><sup>81</sup></a> Each patient was randomly assigned to either receive a blood thinner (treatment group) or not receive a blood thinner (control group). The outcome variable of interest was whether the patient survived for at least 24 hours.</p>
<div id="step-1--state-the-null-and-alternative-hypotheses-3" class="section level3" number="20.4.1">
<h3><span class="header-section-number">20.4.1</span> Step 1- State the null and alternative hypotheses</h3>
<p>We want to understand whether blood thinners are helpful or harmful. We’ll consider both of these possibilities using a two-sided hypothesis test.</p>
<p><span class="math inline">\(H_0\)</span>: Blood thinners do not have an overall survival effect, experimental treatment is independent of survival rate. <span class="math inline">\(p_c - p_t = 0\)</span>.<br />
<span class="math inline">\(H_A\)</span>: Blood thinners have an impact on survival, either positive or negative, but not zero. <span class="math inline">\(p_c - p_t \neq 0\)</span>.</p>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb521-1"><a href="#cb521-1" aria-hidden="true" tabindex="-1"></a>thinner <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/blood_thinner.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="#cb522-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(thinner)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   group     outcome 
##   &lt;chr&gt;     &lt;chr&gt;   
## 1 treatment survived
## 2 control   survived
## 3 control   died    
## 4 control   died    
## 5 control   died    
## 6 treatment survived</code></pre>
<p>Let’s put it in a table.</p>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="#cb524-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>group<span class="sc">+</span>outcome,<span class="at">data=</span>thinner,<span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##            outcome
## group       died survived Total
##   control     39       11    50
##   treatment   26       14    40
##   Total       65       25    90</code></pre>
</div>
<div id="step-2---compute-a-test-statistic.-4" class="section level3" number="20.4.2">
<h3><span class="header-section-number">20.4.2</span> Step 2 - Compute a test statistic.</h3>
<p>In this case the data is from a <strong>hypergeometric</strong> distribution, this is really a binomial from a finite population. We can calculate the p-value using this probability distribution. The random variable is the number of control patients that survived from a population of 90, where 50 are control patients and 40 are treatment patients, and where a total of 25 survived.</p>
</div>
<div id="step-3---determine-the-p-value.-4" class="section level3" number="20.4.3">
<h3><span class="header-section-number">20.4.3</span> Step 3 - Determine the p-value.</h3>
<p>In this case we want to find <span class="math inline">\(\mbox{P}(X \leq 11)\)</span> and double it since it is a two-sided test.</p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="#cb526-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">phyper</span>(<span class="dv">11</span>,<span class="dv">50</span>,<span class="dv">40</span>,<span class="dv">25</span>)</span></code></pre></div>
<pre><code>## [1] 0.2581356</code></pre>
<p>Note: We could have picked the lower right cell as the reference cell. But now I want the <span class="math inline">\(\mbox{P}(X \geq 14)\)</span> with the appropriate change in parameter values. Notice we get the same answer.</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="#cb528-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">phyper</span>(<span class="dv">13</span>,<span class="dv">40</span>,<span class="dv">50</span>,<span class="dv">25</span>))</span></code></pre></div>
<pre><code>## [1] 0.2581356</code></pre>
<p>We could the same thing for the other two cells.</p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="#cb530-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">phyper</span>(<span class="dv">26</span>,<span class="dv">40</span>,<span class="dv">50</span>,<span class="dv">65</span>)</span></code></pre></div>
<pre><code>## [1] 0.2581356</code></pre>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb532-1"><a href="#cb532-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">phyper</span>(<span class="dv">38</span>,<span class="dv">50</span>,<span class="dv">40</span>,<span class="dv">65</span>))</span></code></pre></div>
<pre><code>## [1] 0.2581356</code></pre>
<p>Or <code>R</code> has a built in function, <code>fisher.test()</code>, that we could use.</p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb534-1"><a href="#cb534-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.test</span>(<span class="fu">tally</span>(<span class="sc">~</span>group<span class="sc">+</span>outcome,<span class="at">data=</span>thinner))</span></code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  tally(~group + outcome, data = thinner)
## p-value = 0.2366
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.6794355 5.4174460
## sample estimates:
## odds ratio 
##   1.895136</code></pre>
<p>The p-value is slightly different since the <strong>hypergeometric</strong> is not symmetric. Doubling the p-value from the single side result is not quite right. The algorithm in <code>fisher.test()</code> finds and adds all probabilities less than or equal to value of <span class="math inline">\(\mbox{P}(X = 11)\)</span>, see Figure @ref(fig:dens203-fig). This is the correct p-value.</p>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb536-1"><a href="#cb536-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;hyper&quot;</span>,<span class="at">m=</span><span class="dv">50</span>,<span class="at">n=</span><span class="dv">40</span>,<span class="at">k=</span><span class="dv">25</span>) <span class="sc">%&gt;%</span></span>
<span id="cb536-2"><a href="#cb536-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_hline</span>(<span class="at">yintercept =</span> <span class="fu">dhyper</span>(<span class="dv">11</span>,<span class="dv">50</span>,<span class="dv">40</span>,<span class="dv">25</span>),<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb536-3"><a href="#cb536-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Hypergeometric pmf&quot;</span>,<span class="at">subtitle=</span><span class="st">&quot;Red line is P(X=11)&quot;</span>,<span class="at">y=</span><span class="st">&quot;Probability&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb536-4"><a href="#cb536-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="20-Empirical-p-values_files/figure-html/dens203-fig-1.png" alt="Hypergeometric pmf showing the cutoff for p-value calculation." width="672" />
<p class="caption">
(#fig:dens203-fig)Hypergeometric pmf showing the cutoff for p-value calculation.
</p>
</div>
<p>This is how <code>fisher.test()</code> is calculating the p-value:</p>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="#cb537-1" aria-hidden="true" tabindex="-1"></a>temp<span class="ot">&lt;-</span><span class="fu">dhyper</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">25</span>,<span class="dv">50</span>,<span class="dv">40</span>,<span class="dv">25</span>)</span>
<span id="cb537-2"><a href="#cb537-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(temp[temp<span class="sc">&lt;=</span><span class="fu">dhyper</span>(<span class="dv">11</span>,<span class="dv">50</span>,<span class="dv">40</span>,<span class="dv">25</span>)])</span></code></pre></div>
<pre><code>## [1] 0.2365928</code></pre>
<p>The randomization test in the last lesson yielded a p-value of 0.257 so all tests are consistent.</p>
</div>
<div id="step-4---draw-a-conclusion-4" class="section level3" number="20.4.4">
<h3><span class="header-section-number">20.4.4</span> Step 4 - Draw a conclusion</h3>
<p>Since this p-value is larger than 0.05, we do not reject the null hypothesis. That is, we do not find statistically significant evidence that the blood thinner has any influence on survival of patients who undergo CPR prior to arriving at the hospital. Once again, we can discuss the causal conclusion since this is an experiment.</p>
<p>Notice that in these first two examples, we had a test of a single proportion and a test of two proportions. The single proportion test did not have an equivalent randomization test since there is not a second variable to shuffle. We were able to get answers since we found a probability model that we could use in each case.</p>
</div>
</div>
<div id="golf-balls" class="section level2" number="20.5">
<h2><span class="header-section-number">20.5</span> Golf Balls</h2>
<p>Our last example will be interesting because the distribution has multiple parameters and a test metric is not obvious at this point.</p>
<p>The owners of a residence located along a golf course collected the first 500 golf balls that landed on their property. Most golf balls are labeled with the make of the golf ball and a number, for example “Nike 1” or “Titleist 3”. The numbers are typically between 1 and 4, and the owners of the residence wondered if these numbers are equally likely (at least among golf balls used by golfers of poor enough quality that they lose them in the yards of the residences along the fairway.)</p>
<p>We will use a significance level of <span class="math inline">\(\alpha = 0.05\)</span> since there is no reason to favor one error over the other.</p>
<div id="step-1--state-the-null-and-alternative-hypotheses-4" class="section level3" number="20.5.1">
<h3><span class="header-section-number">20.5.1</span> Step 1- State the null and alternative hypotheses</h3>
<p>We think that the numbers are not all equally likely. The question of one-sided versus two-sided is not relevant in this test, you will see this when we write the hypotheses.</p>
<p><span class="math inline">\(H_0\)</span>: All of the numbers are equally likely.<span class="math inline">\(\pi_1 = \pi_2 = \pi_3 = \pi_4\)</span> Or <span class="math inline">\(\pi_1 = \frac{1}{4}, \pi_2 =\frac{1}{4}, \pi_3 =\frac{1}{4}, \pi_4 =\frac{1}{4}\)</span><br />
<span class="math inline">\(H_A\)</span>: There is some other distribution of percentages in the population. At least one population proportion is not <span class="math inline">\(\frac{1}{4}\)</span>.</p>
<p>Notice that we switched to using <span class="math inline">\(\pi\)</span> instead of <span class="math inline">\(p\)</span> for the population parameter. There is no reason other than to make you aware that both are used.</p>
<p>This problem is an extension of the binomial, instead of two outcomes, there are four outcomes. This is called a multinomial distribution. You can read more about it if you like, but our methods will not make it necessary to learn the probability mass function.</p>
<p>Of the 500 golf balls collected, 486 of them had a number between 1 and 4. Let’s get the data from `golf_balls.csv”.</p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="#cb539-1" aria-hidden="true" tabindex="-1"></a>golf_balls <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/golf_balls.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="#cb540-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(golf_balls)</span></code></pre></div>
<pre><code>## 
## quantitative variables:  
##        name   class min Q1 median Q3 max     mean       sd   n missing
## ...1 number numeric   1  1      2  3   4 2.366255 1.107432 486       0</code></pre>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="#cb542-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>number,<span class="at">data=</span>golf_balls)</span></code></pre></div>
<pre><code>## number
##   1   2   3   4 
## 137 138 107 104</code></pre>
</div>
<div id="step-2---compute-a-test-statistic.-5" class="section level3" number="20.5.2">
<h3><span class="header-section-number">20.5.2</span> Step 2 - Compute a test statistic.</h3>
<p>If all numbers were equally likely, we would expect to see 121.5 balls of each number, this is a point estimate and thus not an actual value that could be realized. Of course, in a sample we will have variation and thus departure from this state. We need a test statistic that will help us determine if the observed values are reasonable under the null hypothesis. Remember that the test statistics is a single number metric used to evaluate the hypothesis.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
What would you propose for the test statistic?</p>
</blockquote>
<p>With four proportions, we need a way to combine them. This seems tricky, so let’s just use a simple one. Let’s take the maximum number of balls in any cell and subtract the minimum, this is called the range and we will denote the parameter as <span class="math inline">\(R\)</span>. Under the null this should be zero. We could re-write our hypotheses as:</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(R=0\)</span><br />
<span class="math inline">\(H_A\)</span>: <span class="math inline">\(R&gt;0\)</span></p>
<p>Notice that <span class="math inline">\(R\)</span> will always be non-negative, thus this test is one-sided.</p>
<p>The observed range is 34, 138 - 104.</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="#cb544-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">diff</span>(<span class="fu">range</span>(<span class="fu">tally</span>(<span class="sc">~</span>number,<span class="at">data=</span>golf_balls)))</span>
<span id="cb544-2"><a href="#cb544-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>## [1] 34</code></pre>
</div>
<div id="step-3---determine-the-p-value.-5" class="section level3" number="20.5.3">
<h3><span class="header-section-number">20.5.3</span> Step 3 - Determine the p-value.</h3>
<p>We don’t know the distribution of our test statistic so we will use simulation. We will simulate data from a multinomial under the null hypothesis and calculate a new value of the test statistic. We will repeat this 10000 times and this we give us an estimate of the sampling distribution.</p>
<p>We will use the <code>sample()</code> function again to simulate the distribution of numbers under the null hypothesis. To help us understand the process and build the code, we are only initially using a sample size of 12 to keep the printout reasonable and easy to read.</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="#cb546-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3311</span>)</span>
<span id="cb546-2"><a href="#cb546-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diff</span>(<span class="fu">range</span>(<span class="fu">table</span>(<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="at">size=</span><span class="dv">12</span>,<span class="at">replace=</span><span class="cn">TRUE</span>))))</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>Notice this is not using <code>tidyverse</code> coding ideas. We don’t think we need tibbles or data frames so we went with straight nested <code>R</code> code. You can break this code down by starting with the code in the center.</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="#cb548-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3311</span>)</span>
<span id="cb548-2"><a href="#cb548-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="at">size=</span><span class="dv">12</span>,<span class="at">replace=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##  [1] 3 1 2 3 2 3 1 3 3 4 1 1</code></pre>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb550-1"><a href="#cb550-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3311</span>)</span>
<span id="cb550-2"><a href="#cb550-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="at">size=</span><span class="dv">12</span>,<span class="at">replace=</span><span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## 
## 1 2 3 4 
## 4 2 5 1</code></pre>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="#cb552-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3311</span>)</span>
<span id="cb552-2"><a href="#cb552-2" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span>(<span class="fu">table</span>(<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="at">size=</span><span class="dv">12</span>,<span class="at">replace=</span><span class="cn">TRUE</span>)))</span></code></pre></div>
<pre><code>## [1] 1 5</code></pre>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="#cb554-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3311</span>)</span>
<span id="cb554-2"><a href="#cb554-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diff</span>(<span class="fu">range</span>(<span class="fu">table</span>(<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="at">size=</span><span class="dv">12</span>,<span class="at">replace=</span><span class="cn">TRUE</span>))))</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>We are now ready to ramp up to the full problem. Let’s simulated the data under the null hypothesis. We are sampling 486 golf balls with the numbers 1 through 4 on them. Each number is equally likely. We then find the range, our test statistic. Finally we repeat this 10,000 to get an estimate of the sampling distribution of our test statistic.</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb556-1"><a href="#cb556-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">diff</span>(<span class="fu">range</span>(<span class="fu">table</span>(<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="at">size=</span><span class="dv">486</span>,<span class="at">replace=</span><span class="cn">TRUE</span>))))</span></code></pre></div>
<p>Figure @ref(fig:dens204-fig) is a plot of the sampling distribution of the range.</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="#cb557-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb557-2"><a href="#cb557-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>diff,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb557-3"><a href="#cb557-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> obs,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb557-4"><a href="#cb557-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Sampling Distribution of Range&quot;</span>,<span class="at">subtitle=</span><span class="st">&quot;Multinomial with equal probability&quot;</span>,</span>
<span id="cb557-5"><a href="#cb557-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Range&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb557-6"><a href="#cb557-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(theme_bw)</span></code></pre></div>
<div class="figure">
<img src="20-Empirical-p-values_files/figure-html/dens204-fig-1.png" alt="Sampling distribution of the range." width="672" />
<p class="caption">
(#fig:dens204-fig)Sampling distribution of the range.
</p>
</div>
<p>Notice how this distribution is skewed to the right.</p>
<p>The p-value is 0.14, this value is greater than 0.05 so we fail to reject. However, it is not that much greater than 0.05, so the residents may want to repeat the study with more data.</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb558-1"><a href="#cb558-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop1</span>(<span class="sc">~</span>(diff<span class="sc">&gt;=</span>obs),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>## prop_TRUE 
##  0.140286</code></pre>
</div>
<div id="step-4---draw-a-conclusion-5" class="section level3" number="20.5.4">
<h3><span class="header-section-number">20.5.4</span> Step 4 - Draw a conclusion</h3>
<p>Since this p-value is larger than 0.05, we do not reject the null hypothesis. That is, based on our data, we do not find statistically significant evidence against the claim that the number on the golf balls are equally likely.</p>
</div>
</div>
<div id="repeat-with-a-different-test-statistic" class="section level2" number="20.6">
<h2><span class="header-section-number">20.6</span> Repeat with a different test statistic</h2>
<p>The test statistic we developed helped but it seems weak because we did not use the information in all four cells. So let’s devise a metric that does this. We will jump to step 2.</p>
<div id="step-2---compute-a-test-statistic.-6" class="section level3" number="20.6.1">
<h3><span class="header-section-number">20.6.1</span> Step 2 - Compute a test statistic.</h3>
<p>If each number were equally likely, we would have 121.5 balls in each bin. We can find a test statistic by looking at the deviation in each cell from 121.5.</p>
<div class="sourceCode" id="cb560"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb560-1"><a href="#cb560-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>number,<span class="at">data=</span>golf_balls) <span class="sc">-</span><span class="fl">121.5</span></span></code></pre></div>
<pre><code>## number
##     1     2     3     4 
##  15.5  16.5 -14.5 -17.5</code></pre>
<p>Now we need to collapse these into a single number. Just adding will always result in a value of 0, why? So let’s take the absolute value and then add.</p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="#cb562-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">sum</span>(<span class="fu">abs</span>(<span class="fu">tally</span>(<span class="sc">~</span>number,<span class="at">data=</span>golf_balls) <span class="sc">-</span><span class="fl">121.5</span>))</span>
<span id="cb562-2"><a href="#cb562-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>## [1] 64</code></pre>
<p>This will be our test statistic.</p>
</div>
<div id="step-3---determine-the-p-value.-6" class="section level3" number="20.6.2">
<h3><span class="header-section-number">20.6.2</span> Step 3 - Determine the p-value.</h3>
<p>We will use similar code from above with our new metric.</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">9697</span>)</span>
<span id="cb564-2"><a href="#cb564-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">abs</span>(<span class="fu">table</span>(<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="at">size=</span><span class="dv">486</span>,<span class="at">replace=</span><span class="cn">TRUE</span>))<span class="sc">-</span><span class="fl">121.5</span>))</span></code></pre></div>
<p>Figure @ref(fig:dens205-fig) is a plot of the sampling distribution of the absolute value of deviations.</p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="#cb565-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb565-2"><a href="#cb565-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>sum,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb565-3"><a href="#cb565-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> obs,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb565-4"><a href="#cb565-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Sampling Distribution of Absolute Deviations&quot;</span>,</span>
<span id="cb565-5"><a href="#cb565-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">subtitle=</span><span class="st">&quot;Multinomial with equal probability&quot;</span>,</span>
<span id="cb565-6"><a href="#cb565-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Absolute deviations&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb565-7"><a href="#cb565-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(theme_bw)</span></code></pre></div>
<div class="figure">
<img src="20-Empirical-p-values_files/figure-html/dens205-fig-1.png" alt="Sampling distribution of the absolute deviations." width="672" />
<p class="caption">
(#fig:dens205-fig)Sampling distribution of the absolute deviations.
</p>
</div>
<p>Notice how this distribution is skewed to the right and our test statistic seems to be more extreme.</p>
<p>The p-value is 0.014, this value is much smaller than our previous result. The test statistic matters in our decision process as nothing about this problem has changed except the test statistic.</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="#cb566-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop1</span>(<span class="sc">~</span>(sum<span class="sc">&gt;=</span>obs),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##  prop_TRUE 
## 0.01359864</code></pre>
</div>
<div id="step-4---draw-a-conclusion-6" class="section level3" number="20.6.3">
<h3><span class="header-section-number">20.6.3</span> Step 4 - Draw a conclusion</h3>
<p>Since this p-value is smaller than 0.05, we reject the null hypothesis. That is, based on our data, we find statistically significant evidence against the claim that the number on the golf balls are equally likely.</p>
</div>
</div>
<div id="summary" class="section level2" number="20.7">
<h2><span class="header-section-number">20.7</span> Summary</h2>
<p>In this lesson we used probability models to help us make decisions from data. This lesson is different from the randomization section in that randomization had two variables and the null hypothesis of no difference. In the case of a 2 x 2 table, we were able to show that we could use the hypergeometric distribution to get an exact p-value under the assumptions of the model.</p>
<p>We also found that the choice of test statistic has an impact on our decision. Even though we get valid p-values and the desired Type 1 error rate, if the information in the data is not used to its fullest, we will lose power. Note: <strong>power</strong> is the probability of rejecting the null hypothesis when the alternative hypothesis is true.</p>
<p>In this next lesson we will learn about mathematical solutions to finding the sampling distribution. The key difference in all these methods is the selection of the test statistic and the assumptions made to derive a sampling distribution.</p>
</div>
<div id="homework-problems-19" class="section level2" number="20.8">
<h2><span class="header-section-number">20.8</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Repeat the analysis of the yawning data from last lesson but this time use the hypergeometric distribution.</li>
</ol>
<p>Is yawning contagious?</p>
<p>An experiment conducted by the , a science entertainment TV program on the Discovery Channel, tested if a person can be subconsciously influenced into yawning if another person near them yawns. 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a group where there wasn’t a person yawning near them (control). The following table shows the results of this experiment.</p>
<p><span class="math display">\[
\begin{array}{cc|ccc} &amp; &amp; &amp;\textbf{Group}\\
&amp; &amp; \text{Treatment } &amp;  \text{Control} &amp; \text{Total}  \\
&amp; \hline \text{Yawn}    &amp;   10      &amp; 4     &amp; 14  \\
\textbf{Result} &amp; \text{Not Yawn}   &amp; 24        &amp; 12        &amp; 36   \\
    &amp;\text{Total}       &amp; 34        &amp; 16        &amp; 50 \\
\end{array}
\]</span></p>
<p>The data is in the file <code>yawn.csv</code>.</p>
<ol style="list-style-type: lower-alpha">
<li>What are the hypotheses?<br />
</li>
<li>Calculate the observed statistic, pick a cell.<br />
</li>
<li>Find the p-value using the hypergeometric distribution.<br />
</li>
<li>Plot the the sampling distribution.<br />
</li>
<li>Determine the conclusion of the hypothesis test.<br />
</li>
<li>Compare your results with the randomization test.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Repeat the golf ball example using a different test statistic.</li>
</ol>
<p>Use a level of significance of 0.05.</p>
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses.<br />
</li>
<li>Compute a test statistic.<br />
</li>
<li>Determine the p-value.<br />
</li>
<li>Draw a conclusion.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Body Temperature</li>
</ol>
<p>Shoemaker<a href="#fn82" class="footnote-ref" id="fnref82"><sup>82</sup></a> cites a paper from the American Medical Association<a href="#fn83" class="footnote-ref" id="fnref83"><sup>83</sup></a> that questions conventional wisdom that the average body temperature of a human is 98.6. One of the main points of the original article – the traditional mean of 98.6 is, in essence, 100 years out of date. The authors cite problems with Wunderlich’s original methodology, diurnal fluctuations (up to 0.9 degrees F per day), and unreliable thermometers. The authors believe the average temperature is less than 98.6. Test the hypothesis.</p>
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses.</li>
<li>State the significance level that will be used.<br />
</li>
<li>Load the data from the file “temperature.csv” and generate summary statistics and a boxplot of the temperature data. We will not be using gender or heart rate for this problem.<br />
</li>
<li>Compute a test statistic. We are going to help you with this part. We cannot do a randomization test since we don’t have a second variable. It would be nice to use the mean as a test statistic but we don’t yet know the sampling distribution of the sample mean.</li>
</ol>
<p>Let’s get clever. If the distribution of the sample is symmetric, this is an assumption but look at the boxplot and summary statistics to determine if you are comfortable with it, then under the null hypothesis the observed values should be equally likely to either be greater or less than 98.6. Thus our test statistic is the number of cases that have a positive difference between the observed value and 98.6. This will be a binomial distribution with a probability of success of 0.5. You must also account for the possibility that there are observations of 98.6 in the data.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Determine the p-value.<br />
</li>
<li>Draw a conclusion.</li>
</ol>
<!--chapter:end:20-Empirical-p-values.Rmd-->
</div>
</div>
<div id="CLT" class="section level1" number="21">
<h1><span class="header-section-number">21</span> Central Limit Theorem</h1>
<div id="objectives-19" class="section level2" number="21.1">
<h2><span class="header-section-number">21.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Explain the central limit theorem and when you can use it for inference.<br />
</li>
<li>Conduct hypothesis tests of a single mean and proportion using the CLT and <code>R</code>.<br />
</li>
<li>Explain how the chi-squared and <span class="math inline">\(t\)</span> distributions relate to the normal distribution, where we use them, and describe the impact on the shape of the distribution when the parameters are changed.</li>
</ol>
</div>
<div id="central-limit-theorem" class="section level2" number="21.2">
<h2><span class="header-section-number">21.2</span> Central limit theorem</h2>
<p>We’ve encountered several research questions and associated hypothesis tests so far in this block of material. While they differ in the settings, in their outcomes, and also in the technique we’ve used to analyze the data, many of them had something in common: for a certain class of test statistics, the general shape of the sampling distribution under the null hypothesis looks like a normal distribution.</p>
<div id="null-distribution" class="section level3" number="21.2.1">
<h3><span class="header-section-number">21.2.1</span> Null distribution</h3>
<p>As a reminder, in the tapping and listening problem, we used the proportion of correct answers as our test statistic. Under the null hypothesis we assumed the probability of success was 0.5. The estimate of the sampling distribution of our test statistic is shown in Figure @ref(fig:dens211-fig).</p>
<div class="figure">
<img src="21-Central-Limit-Theorem_files/figure-html/dens211-fig-1.png" alt="Sampling distribution of the proportion." width="672" />
<p class="caption">
(#fig:dens211-fig)Sampling distribution of the proportion.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Describe the shape of the distribution and note anything that you find interesting.<a href="#fn84" class="footnote-ref" id="fnref84"><sup>84</sup></a></p>
</blockquote>
<p>In the Figure @ref(fig:dens212-fig) we have overlayed a normal distribution on the histogram of the estimated sampling distribution. This allows us to visually compare a normal probability density curve with the empirical distribution of the sampling distribution.</p>
<div class="figure">
<img src="21-Central-Limit-Theorem_files/figure-html/dens212-fig-1.png" alt="Sampling distribution of the sample proportion." width="672" />
<p class="caption">
(#fig:dens212-fig)Sampling distribution of the sample proportion.
</p>
</div>
<p>This similarity between the empirical and theoretical distributions is not a coincidence, but rather, is guaranteed by mathematical theory. This chapter will be a little more notation and algebra intensive than the previous chapters. However, the goal is to develop a tool that will help us find sampling distributions for test statistics and thus find p-values. This chapter is classical statistics often taught in AP high school classes as well as many introductory undergraduate statistics courses. Remember that before the advances of modern computing, these mathematical solutions were all that was available.</p>
</div>
<div id="theorem---central-limit-theorem" class="section level3" number="21.2.2">
<h3><span class="header-section-number">21.2.2</span> Theorem - central limit theorem</h3>
<p>Theorem: Let <span class="math inline">\(X_1,X_2,...,X_n\)</span> be a sequence of iid, independent and identically distributed, random variables from a distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma&lt;\infty\)</span>. Then,
<span class="math display">\[
\bar{X} \overset{approx}{\sim}\textsf{Norm}\left(\mu,{\sigma\over\sqrt{n}}\right)
\]</span></p>
<p>There is a lot going on in this theorem. First notice we are drawing independent samples from the same parent population. The central limit theorem (CLT) does not specify the form of this parent distribution, only that it has a finite variance. Then if we form a new random variable that involves the sum of the individual random variables, in this case the sample mean, the distribution of the new random variable is approximately normal. In the case of the sample mean, the expected value is the same mean as the parent population and the variance is the variance of the parent population divided by the sample size. Let’s summarize these ideas.</p>
<ol style="list-style-type: decimal">
<li>The process of creating a new random variable from the sum of independent identically distributed random variables is approximately normal.</li>
<li>The approximation to a normal distribution improves with sample size <span class="math inline">\(n\)</span>.</li>
<li>The mean and variance of the sampling distribution are a function of the mean and variance of the parent population, the sample size <span class="math inline">\(n\)</span>, and the form of the new random variable.</li>
</ol>
<p>If you go back and review examples, exercises, and homework problems from the previous lessons on hypothesis testing, you will see that we get symmetric normal “looking” distributions when we created test statistics that involved the process of summing. The example of a skewed distribution was the golf ball example where our test statistic was the difference of the max and min. It is hard to overstate the historical importance of this theorem to the field of inferential statistics and science in general.</p>
<p>To get an understanding and some intuition of the central limit theorem, let’s simulate some data and evaluate.</p>
</div>
<div id="simulating-data-for-clt" class="section level3" number="21.2.3">
<h3><span class="header-section-number">21.2.3</span> Simulating data for CLT</h3>
<p>For this section, we are going to use an artificial example where we know the population distribution and parameters. We will repeat sampling from this many times and plot the distribution of the summary statistic of interest, the sample mean, to demonstrate the CLT. This is purely an educational thought experiment to give ourselves confidence about the validity of the CLT.</p>
<p>Suppose there is an upcoming election in Colorado and Proposition A is on the ballot. Now suppose that 65% of Colorado voters support Proposition A. We poll a random sample of <span class="math inline">\(n\)</span> Colorado voters. Prior to conducting the sample, we can think about the sample as a sequence of iid random variables from the binomial distribution with one trial in each run and a probability of success (support for the measure) of 0.65. In other words, each random variable will take a value of 1 (support) or 0 (oppose). Figure @ref(fig:dens213-fig) is a plot of the pmf of the parent distribution (<span class="math inline">\(\textsf{Binom}(1,0.65)\)</span>):</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="#cb568-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;binom&quot;</span>,<span class="at">size=</span><span class="dv">1</span>,<span class="at">prob=</span>.<span class="dv">65</span>,<span class="at">plot_size=</span><span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb568-2"><a href="#cb568-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb568-3"><a href="#cb568-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb568-4"><a href="#cb568-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">y=</span><span class="st">&quot;Probability&quot;</span>,<span class="at">x=</span><span class="st">&quot;X&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="21-Central-Limit-Theorem_files/figure-html/dens213-fig-1.png" alt="Binomial pmf with 1 trial and probability of succes of 0.65." width="672" />
<p class="caption">
(#fig:dens213-fig)Binomial pmf with 1 trial and probability of succes of 0.65.
</p>
</div>
<p>This is clearly not normal, it is in fact discrete. The mean of <span class="math inline">\(X\)</span> is 0.65 and the standard deviation is <span class="math inline">\(\sqrt{0.65(1-0.65)}=0.477\)</span>.</p>
<p>In our first simulation, we let the sample size be ten, <span class="math inline">\(n=10\)</span>. This is typically too small for the CLT to apply but we will still use it as a starting point. In the code box below, we will obtain a sample of size 10 from this distribution and record the observed mean <span class="math inline">\(\bar{x}\)</span>, which is our method of moments estimate of the probability of success. We will repeat this 10,000 times to get an empirical distribution of <span class="math inline">\(\bar{X}\)</span>. (Note that <span class="math inline">\(\bar{X}\)</span> is a mean of 1s and 0s and can be thought of as a proportion of voters in the sample that support the measure. Often, population proportion is denoted as <span class="math inline">\(\pi\)</span> and the sample proportion is denoted as <span class="math inline">\(\hat{\pi}\)</span>.)</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="#cb569-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5501</span>)</span>
<span id="cb569-2"><a href="#cb569-2" aria-hidden="true" tabindex="-1"></a>results<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">mean</span>(<span class="fu">rbinom</span>(<span class="dv">10</span>,<span class="dv">1</span>,<span class="fl">0.65</span>))</span></code></pre></div>
<p>Since we are summing iid variables, the sampling distribution of the mean should look like a normal distribution. The mean should be close to 0.65, and the standard deviation <span class="math inline">\(\sqrt{\frac{p(1-p)}{n}} = \sqrt{\frac{0.65(1-0.65)}{10}}=0.151\)</span></p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb570-1"><a href="#cb570-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(<span class="sc">~</span>mean,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##  min  Q1 median  Q3 max    mean        sd     n missing
##  0.1 0.5    0.7 0.8   1 0.64932 0.1505716 10000       0</code></pre>
<p>Remember from our lessons on probability, these results for the mean and standard deviation do not depend on the CLT, they are results from the properties of expectation on independent samples. The distribution of the sample mean, the shape of the sampling distribution, is approximately normal as a result of the CLT, Figure @ref(fig:dens214-fig).</p>
<div class="figure">
<img src="21-Central-Limit-Theorem_files/figure-html/dens214-fig-1.png" alt="Sampling distribution of the sample proportion with sample size of 10." width="672" />
<p class="caption">
(#fig:dens214-fig)Sampling distribution of the sample proportion with sample size of 10.
</p>
</div>
<p>Note the sampling distribution of the sample mean has a bell-curvish shape, but with some skew to the left for this particular small sample size. That is why we state that the approximation improves with sample size.</p>
<p>As a way to determine the impact of the sample size on the inference to the population, let’s record how often a sample of 10 failed to indicate support for the measure. (How often was the sample proportion less than or equal to 0.5?) Remember, in this artificial example, we know that the population is in favor of the measure, 65% approval. However, if our point estimate is below 0.5, we would be led to believe that the population does not support the measure.</p>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="#cb572-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb572-2"><a href="#cb572-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">summarise</span>(<span class="at">low_result=</span><span class="fu">mean</span>(<span class="sc">~</span>mean<span class="sc">&lt;=</span><span class="fl">0.5</span>))</span></code></pre></div>
<pre><code>##   low_result
## 1     0.2505</code></pre>
<p>Even though we know that 65% of Colorado voters support the measure, a sample of size 10 failed to indicate support 25.05% of the time.</p>
<p>Let’s take a larger sample. In the code below, we will repeat the above but with a sample of size 25. Figure @ref(fig:dens215-fig) plots the sampling distribution.</p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb574-1"><a href="#cb574-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5501</span>)</span>
<span id="cb574-2"><a href="#cb574-2" aria-hidden="true" tabindex="-1"></a>results<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">mean</span>(<span class="fu">rbinom</span>(<span class="dv">25</span>,<span class="dv">1</span>,<span class="fl">0.65</span>))</span></code></pre></div>
<div class="figure">
<img src="21-Central-Limit-Theorem_files/figure-html/dens215-fig-1.png" alt="Sampling distribution of the sample proportion with sample size of 25." width="672" />
<p class="caption">
(#fig:dens215-fig)Sampling distribution of the sample proportion with sample size of 25.
</p>
</div>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="#cb575-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb575-2"><a href="#cb575-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">summarise</span>(<span class="at">low_result=</span><span class="fu">mean</span>(<span class="sc">~</span>mean<span class="sc">&lt;=</span><span class="fl">0.5</span>))</span></code></pre></div>
<pre><code>##   low_result
## 1     0.0623</code></pre>
<p>When increasing the sample size to 25, the standard deviation of our sample proportion decreased. According to the central limit theorem, it should have decreased to <span class="math inline">\(\sigma/\sqrt{25}=\sqrt{\frac{p(1-p)}{25}}=0.095\)</span>. Also, the skew became less severe. Further, the sample of size 25 failed to indicate support only 6.23% of the time. It reasonably follows that an even larger sample would continue these trends. Figure @ref(fig:dens216-fig) demonstrates these trends.</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="#cb577-1" aria-hidden="true" tabindex="-1"></a>clt <span class="sc">%&gt;%</span></span>
<span id="cb577-2"><a href="#cb577-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>mean,<span class="at">color=</span><span class="st">&quot;black&quot;</span>,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb577-3"><a href="#cb577-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_facet_grid</span>(<span class="sc">~</span>samp) <span class="sc">%&gt;%</span></span>
<span id="cb577-4"><a href="#cb577-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="21-Central-Limit-Theorem_files/figure-html/dens216-fig-1.png" alt="Sampling distribution of the proportion for different trail sizes." width="672" />
<p class="caption">
(#fig:dens216-fig)Sampling distribution of the proportion for different trail sizes.
</p>
</div>
</div>
<div id="summary-of-example" class="section level3" number="21.2.4">
<h3><span class="header-section-number">21.2.4</span> Summary of example</h3>
<p>In this example, we knew the true proportion of voters who supported the proposition. Based on that knowledge, we simulated the behavior of the sample proportion. We did this by taking a sample of size <span class="math inline">\(n\)</span>, recording the sample proportion, sample mean, and repeating that process thousands of times. In reality, we will not know the true underlying level of support; further, we will not take a sample repeatedly thousands of times from the parent population. Sampling can be expensive and time-consuming. Thus, we would take one random sample of size <span class="math inline">\(n\)</span>, and acknowledge that the resulting sample proportion is but one observation from an underlying normal distribution. We would then determine what values of <span class="math inline">\(\pi\)</span> (the true unknown population proportion) could reasonably have resulted in the observed sample proportion.</p>
</div>
</div>
<div id="other-distribution-for-estimators" class="section level2" number="21.3">
<h2><span class="header-section-number">21.3</span> Other distribution for estimators</h2>
<p>Prior to using the CLT in hypothesis testing, we want to discuss other sampling distributions that are based on the CLT or normality assumptions. A large part of theoretical statistics has been about mathematically deriving the distribution of sample statistics. In these methods we obtain a sample statistic, determine the distribution of that statistic under certain conditions, and then use that information to make a statement about the population parameter.</p>
<div id="chi-sqaured" class="section level3" number="21.3.1">
<h3><span class="header-section-number">21.3.1</span> Chi-sqaured</h3>
<p>Recall that the central limit theorem tells us that for reasonably large sample sizes, <span class="math inline">\(\bar{X}\overset{approx}{\sim}\textsf{Norm}(\mu,\sigma/\sqrt{n})\)</span>. However, this expression involves two unknowns: <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. In the case of binary data, population variance is a function of population proportion (<span class="math inline">\(\mbox{Var}(X)=\pi(1-\pi)\)</span>), so there is really just one unknown. In the case of continuous data, the standard deviation would need to be estimated.</p>
<p>Let <span class="math inline">\(S^2\)</span> be defined as:
<span class="math display">\[
S^2={\sum (X_i-\bar{X})^2\over n-1}
\]</span></p>
<p>Recall that this is an unbiased estimate for <span class="math inline">\(\sigma^2\)</span>. The sampling distribution of <span class="math inline">\(S^2\)</span> can be found using the following lemma:</p>
<p>Lemma: Let <span class="math inline">\(X_1,X_2,...,X_n\)</span> be an iid sequence of random variables from a normal population with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. Then,
<span class="math display">\[
{(n-1)S^2\over \sigma^2}\sim \textsf{Chisq}(n-1)
\]</span></p>
<p>The <span class="math inline">\(\textsf{Chisq}(n-1)\)</span> distribution is read as the “chi-squared” distribution (“chi” is pronounced “kye”). The chi-squared distribution has one parameter: degrees of freedom. The chi-squared distribution is used in other contexts such as goodness of fit problems like the golf ball example from last lesson, we will discuss this particular application in a later chapter.</p>
<p>The proof of this lemma is outside the scope of this book, but it is not terribly complicated. It follows from the fact that the sum of <span class="math inline">\(n\)</span> squared random variables, each with the standard normal distribution, follows the chi-squared distribution with <span class="math inline">\(n\)</span> degrees of freedom.</p>
<p>This lemma can be used to draw inferences about <span class="math inline">\(\sigma^2\)</span>. For a particular value of <span class="math inline">\(\sigma^2\)</span>, we know how <span class="math inline">\(S^2\)</span> should behave. So, for a particular value of <span class="math inline">\(S^2\)</span>, we can figure out reasonable values of <span class="math inline">\(\sigma^2\)</span>.</p>
<p>In practice, one rarely estimates <span class="math inline">\(\sigma\)</span> for the purpose of inferring on <span class="math inline">\(\sigma\)</span>. Typically, we are interested in estimating <span class="math inline">\(\mu\)</span> and we need to account for the added uncertainty in estimating <span class="math inline">\(\sigma\)</span> as well. That is what we will discuss in the next section.</p>
</div>
<div id="students-t" class="section level3" number="21.3.2">
<h3><span class="header-section-number">21.3.2</span> Student’s t</h3>
<p>Let <span class="math inline">\(X_1,X_2,...,X_n\)</span> be an iid sequence of random variables, each with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. Recall that the central limit theorem tells us that
<span class="math display">\[
\bar{X}\overset{approx}{\sim}\textsf{Norm}(\mu,\sigma/\sqrt{n})
\]</span></p>
<p>Rearranging:
<span class="math display">\[
{\bar{X}-\mu\over\sigma/\sqrt{n}}\overset{approx}{\sim}\textsf{Norm}(0,1)
\]</span></p>
<p>Again, <span class="math inline">\(\sigma\)</span> is unknown. Thus, we have to estimate it. We can estimate it with <span class="math inline">\(S\)</span>, but now we need to know the distribution of <span class="math inline">\({\bar{X}-\mu\over S/\sqrt{n}}\)</span>. This <em>does not</em> follow the normal distribution.</p>
<p>Lemma: Let <span class="math inline">\(X_1,X_2,...,X_n\)</span> be an iid sequence of random variables from a normal population with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. Then,
<span class="math display">\[
{\bar{X}-\mu\over S/\sqrt{n}} \sim \textsf{t}(n-1)
\]</span></p>
<p>The <span class="math inline">\(\textsf{t}(n-1)\)</span> distribution is read as the “<span class="math inline">\(t\)</span>” distribution. The <span class="math inline">\(t\)</span> distribution has one parameter: degrees of freedom. The expression above <span class="math inline">\(\left({\bar{X}-\mu\over S/\sqrt{n}}\right)\)</span> is referred to as the <span class="math inline">\(t\)</span> statistic.</p>
<p>Similar to the chi-squared distribution, we won’t go over the proof, but it follows from some simple algebra and from the fact that the ratio between a standard normal random variable and the square root of a chi-squared random variable, divided by it’s degrees of freedom follows a <span class="math inline">\(t\)</span> distribution.</p>
<p>The <span class="math inline">\(t\)</span> distribution is very similar to the standard normal distribution, but has longer tails. This seems to make sense in the context of estimating <span class="math inline">\(\mu\)</span> since substituting <span class="math inline">\(S\)</span> for <span class="math inline">\(\sigma\)</span> adds variability to the random variable.
Figure @ref(fig:t211-fig) is a plot of the <span class="math inline">\(t\)</span> distribution, shown as a blue line, and has a bell shape that looks very similar to a normal distribution, red line. However, its tails are thicker, which means observations are more likely to fall beyond two standard deviations from the mean than under the normal distribution. When our sample is small, the value <span class="math inline">\(s\)</span> used to compute the standard error isn’t very reliable. The extra thick tails of the <span class="math inline">\(t\)</span> distribution are exactly the correction we need to resolve this problem. When the degrees of freedom is about 30 or more, the <span class="math inline">\(t\)</span> distribution is nearly indistinguishable from the normal distribution.</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="#cb578-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;norm&quot;</span>,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb578-2"><a href="#cb578-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dist</span>(<span class="st">&quot;t&quot;</span>,<span class="at">df=</span><span class="dv">3</span>,<span class="at">color=</span><span class="st">&quot;blue&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb578-3"><a href="#cb578-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="21-Central-Limit-Theorem_files/figure-html/t211-fig-1.png" alt="The distibtion of t." width="672" />
<p class="caption">
(#fig:t211-fig)The distibtion of t.
</p>
</div>
</div>
<div id="important-note" class="section level3" number="21.3.3">
<h3><span class="header-section-number">21.3.3</span> Important Note</h3>
<p>You may have noticed an important condition in the two lemmas above. It was assumed that each <span class="math inline">\(X_i\)</span> in the sequence of random variables was <em>normally</em> distributed. While the central limit theorem has no such normality assumption, the distribution of the <span class="math inline">\(t\)</span>-statistic is subject to the distribution of the underlying population. With a large enough sample size, this assumption is not necessary. There is no magic number, but some resources state that as long as <span class="math inline">\(n\)</span> is at least 30-40, the underlying distribution doesn’t matter. For smaller sample sizes, the underlying distribution should be relatively symmetric and unimodal.</p>
<p>One advantage of simulation-based inference methods is that these methods do not rely on any such distributional assumptions. However, the simulation-based methods may have a smaller power for the same sample size.</p>
</div>
</div>
<div id="hypotheses-tests-using-clt" class="section level2" number="21.4">
<h2><span class="header-section-number">21.4</span> Hypotheses tests using CLT</h2>
<p>We are now ready to repeat some of our previous problems using the mathematically derived sampling distribution via the CLT.</p>
<div id="tappers-and-listeners-1" class="section level3" number="21.4.1">
<h3><span class="header-section-number">21.4.1</span> Tappers and listeners</h3>
<div id="step-1--state-the-null-and-alternative-hypotheses-5" class="section level4" number="21.4.1.1">
<h4><span class="header-section-number">21.4.1.1</span> Step 1- State the null and alternative hypotheses</h4>
<p>Here are the two hypotheses:</p>
<p><span class="math inline">\(H_0\)</span>: The tappers are correct, and generally 50% of the time listeners are able to guess the tune. <span class="math inline">\(p = 0.50\)</span><br />
<span class="math inline">\(H_A\)</span>: The tappers are incorrect, and either more than or less than 50% of listeners will be able to guess the tune. <span class="math inline">\(p \neq 0.50\)</span></p>
</div>
<div id="step-2---compute-a-test-statistic.-7" class="section level4" number="21.4.1.2">
<h4><span class="header-section-number">21.4.1.2</span> Step 2 - Compute a test statistic.</h4>
<p>The test statistic that we want to use is the sample mean <span class="math inline">\(\bar{X}\)</span>, this is a method of moments estimate of the probability of success. Since these are independent samples from the same binomial distribution, by the CLT</p>
<p><span class="math display">\[
\bar{X} \overset{approx}{\sim}\textsf{Norm}\left(\pi,\sqrt\frac{\pi(1-\pi)}{n}\right)
\]</span></p>
<p>As we learned, this approximation improves with sample size. As a rule of thumb, most analysts are comfortable with using the CLT for this problem if the number of success and failures are both 10 or greater.</p>
<p>In our study 42 out of 120 listeners (<span class="math inline">\(\bar{x}=\hat{p} = 0.35\)</span>) were able to guess the tune. This is the observed value of test statistic.</p>
</div>
<div id="step-3---determine-the-p-value.-7" class="section level4" number="21.4.1.3">
<h4><span class="header-section-number">21.4.1.3</span> Step 3 - Determine the p-value.</h4>
<p>We now want to find the p-value from the one-sided probability <span class="math inline">\(\mbox{P}(\bar{X} \leq 0.35)\)</span> given the null hypothesis is true, the probability of success is 0.50. We will use <code>R</code> to get the one-sided value and then double it since the test is two-sided and the sampling distribution is symmetrical.</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="#cb579-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pnorm</span>(<span class="fl">0.35</span>,<span class="at">mean=</span>.<span class="dv">5</span>,<span class="at">sd=</span><span class="fu">sqrt</span>(.<span class="dv">5</span><span class="sc">*</span>.<span class="dv">5</span><span class="sc">/</span><span class="dv">120</span>))</span></code></pre></div>
<pre><code>## [1] 0.001015001</code></pre>
<p>That is a small p-value and consistent with what we would got using both the exact binomial test and the simulation empirical p-values.</p>
<blockquote>
<p><strong>Important note</strong>:
In the calculation of the standard deviation of the sampling distribution, we used the null hypothesized value of the probability of success.</p>
</blockquote>
</div>
<div id="step-4---draw-a-conclusion-7" class="section level4" number="21.4.1.4">
<h4><span class="header-section-number">21.4.1.4</span> Step 4 - Draw a conclusion</h4>
<p>Based on our data, if the listeners were guessing correct 50% of the time, there is less than a 1 in 1000 probability that only 42 or less or 78 or more listeners would get it right. This is much less than 0.05, so we reject that the listeners are guessing correctly half of the time.</p>
<p>Note that <code>R</code> has built in functions to perform this test. If you explore these functions, use <code>?prop.test</code> to learn more, you will find options to improve the performance of the test. You are welcome and should read about these methods. Again, before computers, researchers spent time optimizing the performance of the asymptotic methods such as the CLT.</p>
<p>Here is the test of a single proportion using <code>R</code>.</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="#cb581-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop.test</span>(<span class="dv">42</span>,<span class="dv">120</span>)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test with continuity correction
## 
## data:  42 out of 120
## X-squared = 10.208, df = 1, p-value = 0.001398
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.2667083 0.4430441
## sample estimates:
##    p 
## 0.35</code></pre>
<p>The p-value is small, reported as <span class="math inline">\(0.0014\)</span>. We will study the confidence interval soon so don’t worry about that part of the output. The alternative hypothesis is also listed.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
How do you conduct a one-sided test? What if the null value where 0.45?<a href="#fn85" class="footnote-ref" id="fnref85"><sup>85</sup></a></p>
</blockquote>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="#cb583-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pval</span>(<span class="fu">prop.test</span>(<span class="dv">42</span>,<span class="dv">120</span>,<span class="at">alternative=</span><span class="st">&quot;less&quot;</span>,<span class="at">p=</span>.<span class="dv">45</span>))</span></code></pre></div>
<pre><code>##   p.value 
## 0.0174214</code></pre>
<p>The exact test uses the function <code>binom.test()</code>.</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="#cb585-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.test</span>(<span class="dv">42</span>,<span class="dv">120</span>)</span></code></pre></div>
<pre><code>## 
## 
## 
## data:  42 out of 120
## number of successes = 42, number of trials = 120, p-value = 0.001299
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.2652023 0.4423947
## sample estimates:
## probability of success 
##                   0.35</code></pre>
<p>This is the same as</p>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb587-1"><a href="#cb587-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pbinom</span>(<span class="dv">42</span>,<span class="dv">120</span>,.<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## [1] 0.001299333</code></pre>
</div>
</div>
<div id="body-temperature" class="section level3" number="21.4.2">
<h3><span class="header-section-number">21.4.2</span> Body temperature</h3>
<p>We will repeat the body temperature analysis using the CLT. We will use <span class="math inline">\(\alpha = 0.05\)</span></p>
<div id="step-1--state-the-null-and-alternative-hypotheses-6" class="section level4" number="21.4.2.1">
<h4><span class="header-section-number">21.4.2.1</span> Step 1- State the null and alternative hypotheses</h4>
<p><span class="math inline">\(H_0\)</span>: The average body temperature is 98.6; <span class="math inline">\(\mu = 98.6\)</span><br />
<span class="math inline">\(H_A\)</span>: The average body temperature is less than 98.6; <span class="math inline">\(\mu &lt; 98.6\)</span></p>
</div>
<div id="step-2---compute-a-test-statistic.-8" class="section level4" number="21.4.2.2">
<h4><span class="header-section-number">21.4.2.2</span> Step 2 - Compute a test statistic.</h4>
<p>We don’t know the population variance, so we will use the <span class="math inline">\(t\)</span> distribution. Remember that</p>
<p><span class="math display">\[
{\bar{X}-\mu\over S/\sqrt{n}} \sim \textsf{t}(n-1)
\]</span>
thus our test statistic is</p>
<p><span class="math display">\[
\frac{\bar{x}-98.6}{s/\sqrt{n}}
\]</span></p>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="#cb589-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>temperature)</span></code></pre></div>
<pre><code>##   min   Q1 median   Q3   max     mean        sd   n missing
##  96.3 97.8   98.3 98.7 100.8 98.24923 0.7331832 130       0</code></pre>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="#cb591-1" aria-hidden="true" tabindex="-1"></a>temperature <span class="sc">%&gt;%</span></span>
<span id="cb591-2"><a href="#cb591-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean=</span><span class="fu">mean</span>(temperature),<span class="at">sd=</span><span class="fu">sd</span>(temperature),<span class="at">test_stat=</span>(mean<span class="fl">-98.6</span>)<span class="sc">/</span>(sd<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">130</span>)))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##    mean    sd test_stat
##   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
## 1  98.2 0.733     -5.45</code></pre>
<p>We are over 5 standard deviation below the null hypothesis mean. We have some assumptions that we will discuss at the end of this problem.</p>
</div>
<div id="step-3---determine-the-p-value.-8" class="section level4" number="21.4.2.3">
<h4><span class="header-section-number">21.4.2.3</span> Step 3 - Determine the p-value.</h4>
<p>We now want to find the p-value from <span class="math inline">\(\mbox{P}(t \leq -5.45)\)</span> on 129 degrees of freedom, given the null hypothesis is true, which is that the probability of success is 0.50. We will use <code>R</code> to get the one-sided p-value.</p>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="#cb593-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pt</span>(<span class="sc">-</span><span class="fl">5.45</span>,<span class="dv">129</span>)</span></code></pre></div>
<pre><code>## [1] 1.232178e-07</code></pre>
<p>We could also use the <code>R</code> function <code>t_test()</code>.</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="#cb595-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t_test</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>temperature,<span class="at">mu=</span><span class="fl">98.6</span>,<span class="at">alternative=</span><span class="st">&quot;less&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  temperature
## t = -5.4548, df = 129, p-value = 1.205e-07
## alternative hypothesis: true mean is less than 98.6
## 95 percent confidence interval:
##      -Inf 98.35577
## sample estimates:
## mean of x 
##  98.24923</code></pre>
<p>Notice this p-value is much smaller than the p-value from the method used in homework problem 3 in the last chapter. That is because this test statistic has more assumptions and uses the data as continuous and not discrete.</p>
</div>
<div id="step-4---draw-a-conclusion-8" class="section level4" number="21.4.2.4">
<h4><span class="header-section-number">21.4.2.4</span> Step 4 - Draw a conclusion</h4>
<p>Based our data, if the true mean body temperature is 98.6, then the probability of observing a mean of 98.25 or less is 0.00000012. This is too unlikely so we reject the hypothesis that the average body temperature is 98.6.</p>
</div>
</div>
</div>
<div id="summary-and-rules-of-thumb" class="section level2" number="21.5">
<h2><span class="header-section-number">21.5</span> Summary and rules of thumb</h2>
<p>We have covered a great deal in this lesson. At its core, the central limit theorem is a statement about the distribution of a sum of independent identically distributed random variables. This sum is approximately normal. First we summarize rules of thumb for the use of the CLT and <span class="math inline">\(t\)</span> distribution.</p>
<div id="numerical-data-1" class="section level3" number="21.5.1">
<h3><span class="header-section-number">21.5.1</span> Numerical data</h3>
<ol style="list-style-type: decimal">
<li><p>The central limit works regardless of the distribution. However, if the parent population is highly skewed, then more data is needed. The CLT works well once the sample sizes exceed 30 to 40. If the data is fairly symmetric, then less data is needed.</p></li>
<li><p>When estimating the mean and standard error from a sample of numerical data, the <span class="math inline">\(t\)</span> distribution is a little more accurate than the normal model. But there is an assumption that the parent population is normally distributed. This distribution works well even for small samples as long as the data is close to symmetrical and unimodal.</p></li>
<li><p>For medium samples, at least 15 data points, the <span class="math inline">\(t\)</span> distribution still works as long as the data is roughly symmetric and unimodal.</p></li>
<li><p>For large data sets 30-40 or more, the <span class="math inline">\(t\)</span> or even the normal can be used but we suggest you always use the <span class="math inline">\(t\)</span>.</p></li>
</ol>
<p>Now, let’s discuss the assumptions of the <span class="math inline">\(t\)</span> distribution and how to check them.</p>
<ol style="list-style-type: decimal">
<li><p>Independence of observations. This is a difficult assumption to verify. If we collect a simple random sample from less than 10% of the population, or if the data are from an experiment or random process, we feel better about this assumption. If the data comes from an experiment, we can plot the data versus time collected to see if there are any patterns that indicate a relationship. A design of experiment course discusses these ideas.</p></li>
<li><p>Observations come from a nearly normal distribution. This second condition is difficult to verify with small data sets. We often (i) take a look at a plot of the data for obvious departures from the normal model, usually in the form of prominent outliers, and (ii) consider whether any previous experiences alert us that the data may not be nearly normal. However, if the sample size is somewhat large, then we can relax this condition, e.g. moderate skew is acceptable when the sample size is 30 or more, and strong skew is acceptable when the size is about 60 or more.</p></li>
</ol>
<p>A typical plot to use to evaluate the normality assumption is called the quantile-quantile plot. We form a scatterplot of the empirical quantiles from the data versus exact quantile values from the theoretical distribution. If the points fall along a line then the data match the distribution. An exact match is not realistic, so we look for major departures from the line.</p>
<p>Figure @ref(fig:qq211-fig) is our normal-quantile plot for the body temperature data. The largest value may be an outlier, we may want to verify it was entered correctly. The fact that the points are above the line for the larger values and below the line for the smaller values indicates that our data may have longer tails than the normal distribution. There are really only 3 values in the larger quantiles so in fact the data may be slightly skewed to the left, this was also indicated by a comparison of the mean and median. However, since we have 130 data points these results should not impact our findings.</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="#cb597-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_qq</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>temperature) <span class="sc">%&gt;%</span></span>
<span id="cb597-2"><a href="#cb597-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_qqline</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>temperature) <span class="sc">%&gt;%</span></span>
<span id="cb597-3"><a href="#cb597-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="21-Central-Limit-Theorem_files/figure-html/qq211-fig-1.png" alt="Q-Q plot for body temperature data." width="672" />
<p class="caption">
(#fig:qq211-fig)Q-Q plot for body temperature data.
</p>
</div>
<p>Extreme data points, outliers, can be cause for concern. In later chapters, we will look for ways to detect outliers but we have seen them in our boxplots. Outliers are problematic because normal distributions rarely have outliers so the presence of one may indicate a departure from normality. Second, outliers have a big impact on estimation methods for the mean and standard deviation whether it is a method of moments or maximum likelihood estimate.</p>
<p>We can also check the impacts of the assumptions by using other methods for the hypothesis test. If all methods give the same conclusion, we can be confident in the results. Another way to check robustness to assumptions is to simulate data from different distributions and evaluate the performance of the test under the simulated data.</p>
</div>
<div id="binary-data" class="section level3" number="21.5.2">
<h3><span class="header-section-number">21.5.2</span> Binary data</h3>
<p>The distribution of a binomial random variable or simple scalar transformations of it, such as the proportions of success found by dividing by the sample size, are approximately normal by the CLT. Since binomial random variables are bounded by zero and the number of trails, we have to make sure our probability of success is not close to zero or one, that is the number of successes is not close to 0 or <span class="math inline">\(n\)</span>. A general rule of thumb is that the number of success and failures be at least 10.</p>
</div>
</div>
<div id="homework-problems-20" class="section level2" number="21.6">
<h2><span class="header-section-number">21.6</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Suppose we roll a fair six-sided die and let <span class="math inline">\(X\)</span> be the resulting number. The distribution of <span class="math inline">\(X\)</span> is discrete uniform. (Each of the six discrete outcomes is equally likely.)</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Suppose we roll the fair die 5 times and record the value of <span class="math inline">\(\bar{X}\)</span>, the <em>mean</em> of the resulting rolls. Under the central limit theorem, what should be the distribution of <span class="math inline">\(\bar{X}\)</span>?<br />
</li>
<li>Simulate this process in <code>R</code>. Plot the resulting empirical distribution of <span class="math inline">\(\bar{X}\)</span> and report the mean and standard deviation of <span class="math inline">\(\bar{X}\)</span>. Was it what you expected?</li>
</ol>
<p>(HINT: You can simulate a die roll using the <code>sample</code> function. Be careful and make sure you use it properly.)<br />
c. Repeat parts a) and b) for <span class="math inline">\(n=20\)</span> and <span class="math inline">\(n=50\)</span>. Describe what you notice. Make sure all three plots are plotted on the same <span class="math inline">\(x\)</span>-axis scale. You can use facets if you combine your data into one <code>tibble</code>.</p>
<ol start="2" style="list-style-type: decimal">
<li>The nutrition label on a bag of potato chips says that a one ounce (28 gram) serving of potato chips has 130 calories and contains ten grams of fat, with three grams of saturated fat. A random sample of 35 bags yielded a sample mean of 134 calories with a standard deviation of 17 calories. Is there evidence that the nutrition label does not provide an accurate measure of calories in the bags of potato chips? The conditions necessary for applying the normal model have been checked and are satisfied.</li>
</ol>
<p>The question has been framed in terms of two possibilities: the nutrition label accurately lists the correct average calories per bag of chips or it does not, which may be framed as a hypothesis test.</p>
<ol style="list-style-type: lower-alpha">
<li>Write the null and alternative hypothesis.<br />
</li>
<li>What level of significance are you going to use?<br />
</li>
<li>What is the distribution of the test statistic <span class="math inline">\({\bar{X}-\mu\over S/\sqrt{n}}\)</span>? Calculate the observed value.<br />
</li>
<li>Calculate a p-value.<br />
</li>
<li>Draw a conclusion.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Exploration of the chi-squared and <span class="math inline">\(t\)</span> distributions.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>In <code>R</code>, plot the pdf of a random variable with the chi-squared distribution with 1 degree of freedom. On the same plot, include the pdfs with degrees of freedom of 5, 10 and 50. Describe how the behavior of the pdf changes with increasing degrees of freedom.<br />
</li>
<li>Repeat part (a) with the <span class="math inline">\(t\)</span> distribution. Add the pdf of a standard normal random variable as well. What do you notice?</li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li><p>In this lesson, we have used the expression <em>degrees of freedom</em> a lot. What does this expression mean? When we have sample of size <span class="math inline">\(n\)</span>, why are there <span class="math inline">\(n-1\)</span> degrees of freedom for the <span class="math inline">\(t\)</span> distribution? Give a short concise answer (about one paragraph). You will likely have to do a little research on your own.</p></li>
<li><p>Deborah Toohey is running for Congress, and her campaign manager claims she has more than 50% support from the district’s electorate. Ms. Toohey’s opponent claimed that Ms. Toohey has <strong>less</strong> than 50%. Set up a hypothesis test to evaluate who is right.</p></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Should we run a one-sided or two-sided hypothesis test?<br />
</li>
<li>Write the null and alternative hypothesis.<br />
</li>
<li>What level of significance are you going to use?<br />
</li>
<li>What are the assumptions of this test?<br />
</li>
<li>Calculate the test statistic.<br />
</li>
<li>Calculate a p-value.<br />
</li>
<li>Draw a conclusion.</li>
</ol>
<p>Note: A newspaper collects a simple random sample of 500 likely voters in the district and estimates Toohey’s support to be 52%.</p>
<!--chapter:end:21-Central-Limit-Theorem.Rmd-->
</div>
</div>
<div id="CI" class="section level1" number="22">
<h1><span class="header-section-number">22</span> Confidence Intervals</h1>
<div id="objectives-20" class="section level2" number="22.1">
<h2><span class="header-section-number">22.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Using asymptotic methods based on the normal distribution, construct and interpret a confidence interval for an unknown parameter.<br />
</li>
<li>Describe the relationships between confidence intervals, confidence level, and sample size.<br />
</li>
<li>For proportions, be able to calculate the three different approaches for confidence intervals using <code>R</code>.</li>
</ol>
</div>
<div id="confidence-interval" class="section level2" number="22.2">
<h2><span class="header-section-number">22.2</span> Confidence interval</h2>
<p>A point estimate provides a single plausible value for a parameter. However, a point estimate is rarely perfect; usually there is some error in the estimate. In addition to supplying a point estimate of a parameter, a next logical step would be to provide a plausible <strong>range of values</strong> for the parameter.</p>
<div id="capturing-the-population-parameter" class="section level3" number="22.2.1">
<h3><span class="header-section-number">22.2.1</span> Capturing the population parameter</h3>
<p>A plausible range of values for the population parameter is called a <strong>confidence interval</strong>. Using only a point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net. We can throw a spear where we saw a fish, but we will probably miss. On the other hand, if we toss a net in that area, we have a good chance of catching the fish.</p>
<p>If we report a point estimate, we probably will not hit the exact population parameter. On the other hand, if we report a range of plausible values – a confidence interval – we have a good shot at capturing the parameter.</p>
<blockquote>
<p><strong>Exercise</strong>:
If we want to be very certain we capture the population parameter, should we use a wider interval or a smaller interval?<a href="#fn86" class="footnote-ref" id="fnref86"><sup>86</sup></a></p>
</blockquote>
</div>
<div id="constructing-a-confidence-interval" class="section level3" number="22.2.2">
<h3><span class="header-section-number">22.2.2</span> Constructing a confidence interval</h3>
<p>A point estimate is our best guess for the value of the parameter, so it makes sense to build the confidence interval around that value. The standard error, which is a measure of the uncertainty associated with the point estimate, provides a guide for how large we should make the confidence interval.</p>
<p>Generally, what you should know about building confidence intervals is laid out in the following steps:</p>
<ol style="list-style-type: decimal">
<li><p>Identify the parameter you would like to estimate (for example, <span class="math inline">\(\mu\)</span>).</p></li>
<li><p>Identify a good estimate for that parameter (sample mean, <span class="math inline">\(\bar{X}\)</span>).</p></li>
<li><p>Determine the distribution of your estimate or a function of your estimate.</p></li>
<li><p>Use this distribution to obtain a range of feasible values (confidence interval) for the parameter. (For example if <span class="math inline">\(\mu\)</span> is the parameter of interest and we are using the CLT, then <span class="math inline">\(\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim \textsf{Norm}(0,1)\)</span>. We can solve the equation for <span class="math inline">\(\mu\)</span> to find a reasonable range of feasible values.)</p></li>
</ol>
<p>Let’s do an example to solidify these ideas.</p>
<blockquote>
<p>Constructing a 95% confidence interval for the mean<br />
When the sampling distribution of a point estimate can reasonably be modeled as normal, the point estimate we observe will be within 1.96 standard errors of the true value of interest about 95% of the time. Thus, a <strong>95% confidence interval</strong> for such a point estimate can be constructed:</p>
</blockquote>
<p><span class="math display">\[ \hat{\theta} \pm\ 1.96 \times SE_{\hat{\theta}}\]</span>
Where <span class="math inline">\(\hat{\theta}\)</span> is our estimate of the parameter and <span class="math inline">\(SE_{\hat{\theta}}\)</span> is the standard error of that estimate.</p>
<p>We can be <strong>95% confident</strong> this interval captures the true value. The 1.96 can be found using the <code>qnorm()</code> function. If we want .95 in the middle, that leaves 0.025 in each tail. Thus we use .975 in the <code>qnorm()</code> function.</p>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="#cb598-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(.<span class="dv">975</span>)</span></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<blockquote>
<p><strong>Exercise</strong>:<br />
Compute the area between -1.96 and 1.96 for a normal distribution with mean 0 and standard deviation 1.</p>
</blockquote>
<div class="sourceCode" id="cb600"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb600-1"><a href="#cb600-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">1.96</span>)<span class="sc">-</span><span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">1.96</span>)</span></code></pre></div>
<pre><code>## [1] 0.9500042</code></pre>
<p>In mathematical terms, the derivation of this confidence is as follows:</p>
<p>Let <span class="math inline">\(X_1,X_2,...,X_n\)</span> be an iid sequence of random variables, each with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. The central limit theorem tells us that
<span class="math display">\[
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\overset{approx}{\sim}\textsf{Norm}(0,1)
\]</span></p>
<p>If the significance level is <span class="math inline">\(0\leq \alpha \leq 1\)</span>, then the confidence level is <span class="math inline">\(1-\alpha\)</span>. Yes <span class="math inline">\(\alpha\)</span> is the same as the significance level in hypothesis testing. Thus
<span class="math display">\[
\mbox{P}\left(-z_{\alpha/2}\leq {\bar{X}-\mu\over \sigma/\sqrt{n}} \leq z_{\alpha/2}\right)=1-\alpha
\]</span></p>
<p>where <span class="math inline">\(z_{\alpha/2}\)</span> is such that <span class="math inline">\(\mbox{P}(Z\geq z_{\alpha/2})=\alpha/2\)</span>, where <span class="math inline">\(Z\sim \textsf{Norm}(0,1)\)</span>, see Figure @ref(fig:dens221-fig).</p>
<div class="figure">
<img src="22-Confidence-Intervals_files/figure-html/dens221-fig-1.png" alt="The pdf of a standard normal distribution showing idea of how to develop a confidence interval." width="672" />
<p class="caption">
(#fig:dens221-fig)The pdf of a standard normal distribution showing idea of how to develop a confidence interval.
</p>
</div>
<p>So, we know that <span class="math inline">\((1-\alpha)*100\%\)</span> of the time, <span class="math inline">\({\bar{X}-\mu\over \sigma/\sqrt{n}}\)</span> will be between <span class="math inline">\(-z_{\alpha/2}\)</span> and <span class="math inline">\(z_{\alpha/2}\)</span>.</p>
<p>By rearranging the expression above and solving for <span class="math inline">\(\mu\)</span>, we get:
<span class="math display">\[
\mbox{P}\left(\bar{X}-z_{\alpha/2}{\sigma\over\sqrt{n}}\leq \mu \leq \bar{X}+z_{\alpha/2}{\sigma\over\sqrt{n}}\right)=1-\alpha
\]</span></p>
<p>Be careful with the interpretation of this expression. As a reminder <span class="math inline">\(\bar{X}\)</span> is the random variable here. The population mean, <span class="math inline">\(\mu\)</span>, is NOT a variable. It is an unknown parameter. Thus, the above expression is NOT a probabilistic statement about <span class="math inline">\(\mu\)</span>, but rather about the random variable <span class="math inline">\(\bar{X}\)</span>.</p>
<p>Nonetheless, the above expression gives us a nice interval for “reasonable” values of <span class="math inline">\(\mu\)</span> given a particular sample.</p>
<p>A <span class="math inline">\((1-\alpha)*100\%\)</span> <em>confidence interval for the mean</em> is given by:
<span class="math display">\[
\mu\in\left(\bar{x}\pm z_{\alpha/2}{\sigma\over\sqrt{n}}\right)
\]</span></p>
<p>Notice in this equation we are using the lower case <span class="math inline">\(\bar{x}\)</span>, the sample mean, and thus nothing is random in the interval. Thus we will not use probabilistic statements about confidence intervals when we calculate numerical values from data for the upper and/or lower limits.</p>
<p>In most applications, the most common value of <span class="math inline">\(\alpha\)</span> is 0.05. In that case, to construct a 95% confidence interval, we would need to find <span class="math inline">\(z_{0.025}\)</span> which can be found quickly with <code>qnorm()</code>:</p>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb602-1"><a href="#cb602-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="dv">1</span><span class="fl">-0.05</span><span class="sc">/</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb604-1"><a href="#cb604-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(.<span class="dv">975</span>)</span></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<div id="unknown-variance" class="section level4" number="22.2.2.1">
<h4><span class="header-section-number">22.2.2.1</span> Unknown Variance</h4>
<p>When inferring about the population mean, we usually will have to estimate the underlying standard deviation as well. This introduces an extra level of uncertainty. We found that while <span class="math inline">\({\bar{X}-\mu\over\sigma/\sqrt{n}}\)</span> has an approximate normal distribution, <span class="math inline">\({\bar{X}-\mu\over S/\sqrt{n}}\)</span> follows the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. This adds the additional assumption that the parent population, the distribution of <span class="math inline">\(X\)</span>, must be normal.</p>
<p>Thus, when <span class="math inline">\(\sigma\)</span> is unknown, a <span class="math inline">\((1-\alpha)*100\%\)</span> confidence interval for the mean is given by:
<span class="math display">\[
\mu\in\left(\bar{x}\pm t_{\alpha/2,n-1}{s\over\sqrt{n}}\right)
\]</span></p>
<p>Similar to the case above, <span class="math inline">\(t_{\alpha/2,n-1}\)</span> can be found using the <code>qt()</code> function in <code>R</code>.</p>
<p>In practice, if <span class="math inline">\(X\)</span> is close to symmetrical and unimodal, we can relax the assumption of normality. Always look at your sample data. Outliers or skewness can be causes of concern. You can always run other methods that don’t require the assumption of normality and compare results.</p>
<p>For large sample sizes, the choice of using the normal distribution or the <span class="math inline">\(t\)</span> distribution is irrelevant since they are close to each other. The <span class="math inline">\(t\)</span> distribution requires you to use the degrees of freedom so be careful.</p>
</div>
</div>
<div id="body-temperature-example" class="section level3" number="22.2.3">
<h3><span class="header-section-number">22.2.3</span> Body Temperature Example</h3>
<blockquote>
<p><em>Example</em>:<br />
Find a 95% confidence interval for the body temperature data from last lesson.</p>
</blockquote>
<p>We need the mean, standard deviation, and sample size from this data. The following <code>R</code> code calculates the confidence interval, make sure you can follow the code.</p>
<div class="sourceCode" id="cb606"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb606-1"><a href="#cb606-1" aria-hidden="true" tabindex="-1"></a>temperature <span class="sc">%&gt;%</span></span>
<span id="cb606-2"><a href="#cb606-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">favstats</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>.) <span class="sc">%&gt;%</span></span>
<span id="cb606-3"><a href="#cb606-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(mean,sd,n) <span class="sc">%&gt;%</span></span>
<span id="cb606-4"><a href="#cb606-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">lower_bound=</span>mean<span class="sc">-</span><span class="fu">qt</span>(<span class="fl">0.975</span>,<span class="dv">129</span>)<span class="sc">*</span>sd<span class="sc">/</span><span class="fu">sqrt</span>(n),</span>
<span id="cb606-5"><a href="#cb606-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">upper_bound=</span>mean<span class="sc">+</span><span class="fu">qt</span>(<span class="fl">0.975</span>,<span class="dv">129</span>)<span class="sc">*</span>sd<span class="sc">/</span><span class="fu">sqrt</span>(n))</span></code></pre></div>
<pre><code>##   lower_bound upper_bound
## 1      98.122    98.37646</code></pre>
<p>The 95% confidence interval for <span class="math inline">\(\mu\)</span> is <span class="math inline">\((98.12,98.38)\)</span>. We are 95% <em>confident</em> that <span class="math inline">\(\mu\)</span>, the average human body temperature, is in this interval. Alternatively and equally relevant, we could say that 95% of similarly constructed intervals will contain the true mean, <span class="math inline">\(\mu\)</span>. It is important to understand the use of the word confident and not the word probability.</p>
<p>There is a link between hypothesis testing and confidence intervals. Remember when we used this data in a hypothesis test, the null hypothesis was <span class="math inline">\(H_0\)</span>: The average body temperature is 98.6 <span class="math inline">\(\mu = 98.6\)</span>. This null hypothesized value is not in the interval, so we could reject the null hypothesis with this confidence interval.</p>
<p>We could also use <code>R</code> to find the confidence interval and conduct the hypothesis test. Read about the function <code>t_test()</code> in the help menu to determine why we used the <code>mu</code> option.</p>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb608-1"><a href="#cb608-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t_test</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>temperature,<span class="at">mu=</span><span class="fl">98.6</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  temperature
## t = -5.4548, df = 129, p-value = 2.411e-07
## alternative hypothesis: true mean is not equal to 98.6
## 95 percent confidence interval:
##  98.12200 98.37646
## sample estimates:
## mean of x 
##  98.24923</code></pre>
<p>Or if you just want the interval:</p>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="#cb610-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">t_test</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>temperature,<span class="at">mu=</span><span class="fl">98.6</span>))</span></code></pre></div>
<pre><code>##   mean of x  lower    upper level
## 1  98.24923 98.122 98.37646  0.95</code></pre>
<p>In reviewing the hypothesis test for a single mean, you can see how this confidence interval was formed by <em>inverting</em> the test statistic. As a reminder, the following equation inverts the test statistic.</p>
<p><span class="math display">\[
\mbox{P}\left(\bar{X}-z_{\alpha/2}{\sigma\over\sqrt{n}}\leq \mu \leq \bar{X}+z_{\alpha/2}{\sigma\over\sqrt{n}}\right)=1-\alpha
\]</span></p>
</div>
<div id="one-sided-intervals" class="section level3" number="22.2.4">
<h3><span class="header-section-number">22.2.4</span> One-sided Intervals</h3>
<p>If you remember the hypothesis test for temperature in the central limit theorem lesson, you may be crying foul. That was a one-sided hypothesis test and we just conducted a two-sided test. So far, we have discussed only “two-sided” intervals. These intervals have an upper and lower bound. Typically, <span class="math inline">\(\alpha\)</span> is apportioned equally between the two tails. (Thus, we look for <span class="math inline">\(z_{\alpha/2}\)</span>.)</p>
<p>In “one-sided” intervals, we only bound the interval on one side. We construct one-sided intervals when we are concerned with whether a parameter exceeds or stays below some threshold. Building a one-sided interval is similar to building two-sided intervals, except rather than dividing <span class="math inline">\(\alpha\)</span> into two, you simply apportion all of <span class="math inline">\(\alpha\)</span> to the relevant side. The difficult part is to determine if we need an upper bound or lower bound.</p>
<p>For the body temperature study, the alternative hypothesis was that the mean was less than 98.6. In our confidence interval, we want to find the largest value the mean could be and thus we want the upper bound. We are trying to reject the hypothesis by showing an alternative that is smaller than the null hypothesized value. Finding the lower limit does not help us since the confidence interval indicates an interval that starts at the lower value and is unbounded above. Let’s just make up some numbers; suppose the lower confidence bound is 97.5. All we know is the true average temperature is this value or greater. This is not helpful. However, if we find an upper confidence bound and the value is 98.1, we know the true average temperature is most likely no larger than this value. This is much more helpful.</p>
<p>Repeating the analysis with this in mind.</p>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="#cb612-1" aria-hidden="true" tabindex="-1"></a>temperature <span class="sc">%&gt;%</span></span>
<span id="cb612-2"><a href="#cb612-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">favstats</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>.) <span class="sc">%&gt;%</span></span>
<span id="cb612-3"><a href="#cb612-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(mean,sd,n) <span class="sc">%&gt;%</span></span>
<span id="cb612-4"><a href="#cb612-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">upper_bound=</span>mean<span class="sc">+</span><span class="fu">qt</span>(<span class="fl">0.95</span>,<span class="dv">129</span>)<span class="sc">*</span>sd<span class="sc">/</span><span class="fu">sqrt</span>(n))</span></code></pre></div>
<pre><code>##   upper_bound
## 1    98.35577</code></pre>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="#cb614-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">t_test</span>(<span class="sc">~</span>temperature,<span class="at">data=</span>temperature,<span class="at">alternative=</span><span class="st">&quot;less&quot;</span>))</span></code></pre></div>
<pre><code>##   mean of x lower    upper level
## 1  98.24923  -Inf 98.35577  0.95</code></pre>
<p>Notice the upper bound in the one-sided interval is smaller than the upper bound in the two-sided interval since all 0.05 is going into the upper tail.</p>
</div>
</div>
<div id="confidence-intervals-for-two-proportions" class="section level2" number="22.3">
<h2><span class="header-section-number">22.3</span> Confidence intervals for two proportions</h2>
<p>In hypothesis testing we had several examples of two proportions. We tested these problems with a permutation test or using a hypergeometric. In our chapters and homework, we have not presented the hypothesis test for two proportions using the asymptotic normal distribution, the central limit theorem. So in this chapter we will present three methods of answering our research question, a permutation test, a hypothesis test using the normal distribution, and a confidence interval.</p>
<p>Earlier this book, in fact in the first chapter, we encountered an experiment that examined whether implanting a stent in the brain of a patient at risk for a stroke helps reduce the risk of a stroke. The results from the first 30 days of this study, which included 451 patients, are summarized in the <code>R</code> code below. These results are surprising! The point estimate suggests that patients who received stents may have a <strong>higher</strong> risk of stroke: <span class="math inline">\(p_{trmt} - p_{control} = 0.090\)</span>.</p>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="#cb616-1" aria-hidden="true" tabindex="-1"></a>stent <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/stent_study.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb617-1"><a href="#cb617-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>group<span class="sc">+</span>outcome30,<span class="at">data=</span>stent,<span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##          outcome30
## group     no_event stroke Total
##   control      214     13   227
##   trmt         191     33   224
##   Total        405     46   451</code></pre>
<div class="sourceCode" id="cb619"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb619-1"><a href="#cb619-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(outcome30<span class="sc">~</span>group,<span class="at">data=</span>stent,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>##           group
## outcome30     control       trmt
##   no_event 0.94273128 0.85267857
##   stroke   0.05726872 0.14732143
##   Total    1.00000000 1.00000000</code></pre>
<div class="sourceCode" id="cb621"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb621-1"><a href="#cb621-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">diffprop</span>(outcome30<span class="sc">~</span>group,<span class="at">data=</span>stent)</span>
<span id="cb621-2"><a href="#cb621-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>##    diffprop 
## -0.09005271</code></pre>
<p>Notice that because <code>R</code> uses the variables by names in alphabetic order we have <span class="math inline">\(p_{control} - p_{trmt} = - 0.090\)</span>. This is not a problem. We could fix this by changing the variables to factors.</p>
<div id="permutation-test-for-two-proportions" class="section level3" number="22.3.1">
<h3><span class="header-section-number">22.3.1</span> Permutation test for two proportions</h3>
<p>We start with the null hypothesis which is two-sided since we don’t know if the treatment is harmful or beneficial.</p>
<p><span class="math inline">\(H_0\)</span>: The treatment and outcome are independent. <span class="math inline">\(p_{control} - p_{trmt} = 0\)</span> or <span class="math inline">\(p_{control} = p_{trmt}\)</span>.<br />
<span class="math inline">\(H_A\)</span>: The treatment and outcome are dependent <span class="math inline">\(p_{control} \neq p_{trmt}\)</span>.</p>
<p>We will use <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<p>The test statistic is the difference in proportions of patients with stroke in the control and treatment groups.</p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb623-1"><a href="#cb623-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">diffprop</span>(outcome30<span class="sc">~</span>group,<span class="at">data=</span>stent)</span>
<span id="cb623-2"><a href="#cb623-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>##    diffprop 
## -0.09005271</code></pre>
<p>To calculate the p-value, we will shuffle the treatment and control labels because under the null hypothesis, there is no difference.</p>
<div class="sourceCode" id="cb625"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb625-1"><a href="#cb625-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2027</span>)</span>
<span id="cb625-2"><a href="#cb625-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">diffprop</span>(outcome30<span class="sc">~</span><span class="fu">shuffle</span>(group),<span class="at">data=</span>stent)</span></code></pre></div>
<p>Figure @ref(fig:dens222-fig) a visual summary of the distribution of the test statistics generated under the null hypothesis, the sampling distribution.</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb626-1"><a href="#cb626-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb626-2"><a href="#cb626-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dhistogram</span>(<span class="sc">~</span>diffprop,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb626-3"><a href="#cb626-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span>obs ) <span class="sc">%&gt;%</span></span>
<span id="cb626-4"><a href="#cb626-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb626-5"><a href="#cb626-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Sampling distribution of randomization test&quot;</span>,</span>
<span id="cb626-6"><a href="#cb626-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Difference in proportions&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="22-Confidence-Intervals_files/figure-html/dens222-fig-1.png" alt="Sampling distribution of the difference in proportions." width="672" />
<p class="caption">
(#fig:dens222-fig)Sampling distribution of the difference in proportions.
</p>
</div>
<p>We next calculate the p-value. We will calculate it as if it were a one-sided test and then double the result to account for the fact that we would reject with a similar value in the opposite tail. Note that the <code>prop1()</code> includes the observed value in the calculation of the p-value.</p>
<div class="sourceCode" id="cb627"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb627-1"><a href="#cb627-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">prop1</span>(<span class="sc">~</span>(diffprop<span class="sc">&lt;=</span>obs),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##  prop_TRUE 
## 0.00259974</code></pre>
<p>Based on the data, if there were no difference between the treatment and control groups, the probability of the observed differences in proportion of strokes being - 0.09 or more extreme is 0.0026. This is too unlikely, so we reject that there is no difference between control and stroke groups.</p>
</div>
<div id="hypothesis-test-for-two-proportions-using-normal-model" class="section level3" number="22.3.2">
<h3><span class="header-section-number">22.3.2</span> Hypothesis test for two proportions using normal model</h3>
<p>We must check two conditions before applying the normal model to a generic test of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>. First, the sampling distribution for each sample proportion must be nearly normal, and secondly, the samples must be independent. Under these two conditions, the sampling distribution of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> may be well approximated using the normal model.</p>
<p>The hypotheses are the same as above.</p>
<div id="conditions-for-the-sampling-distribution-of-hatp_1---hatp_2-to-be-normal" class="section level4" number="22.3.2.1">
<h4><span class="header-section-number">22.3.2.1</span> Conditions for the sampling distribution of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> to be normal</h4>
<p>The difference <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> tends to follow a normal model when</p>
<ol style="list-style-type: lower-alpha">
<li>each proportion separately follows a normal model, and<br />
</li>
<li>the two samples are independent of each other</li>
</ol>
</div>
<div id="standard-error" class="section level4" number="22.3.2.2">
<h4><span class="header-section-number">22.3.2.2</span> Standard error</h4>
<p>For our research question the conditions must be verified. Because each group is a simple random sample from less than 10% of the population, the observations are independent, both within the samples and between the samples. The success-failure condition also holds for each sample, at least 10 in each cell is the easiest way to think about it. Because all conditions are met, the normal model can be used for the point estimate of the difference in proportion of strokes</p>
<p><span class="math display">\[p_{control} - p_{trmt} = 0.05726872 - 0.14732143 = - 0.090\]</span>
The standard error of the difference in sample proportions is
<span class="math display">\[ SE_{\hat{p}_1 - \hat{p}_2}
    = \sqrt{SE_{\hat{p}_1}^2 + SE_{\hat{p}_2}^2}\]</span>
<span class="math display">\[  = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}\]</span>
where <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span> represent the population proportions, and <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> represent the sample sizes.</p>
<p>The calculation of the standard error for our problem must be done carefully. Remember in hypothesis testing, we assume the null hypothesis is true; this means the proportions of strokes must be the same.</p>
<p><span class="math display">\[SE = \sqrt{\frac{p(1-p)}{n_{control}} + \frac{p(1-p)}{n_{trmt}}}\]</span>
We don’t know the stroke incidence rate, <span class="math inline">\(p\)</span>, but we can obtain a good estimate of it by <strong>pooling</strong> the results of both samples:
<span class="math display">\[\hat{p} = \frac{\text{# of successes}}{\text{# of cases}} = \frac{13 + 33}{451} = 0.102\]</span>
This is called the <em>pooled estimate</em> of the sample proportion, and we use it to compute the standard error when the null hypothesis is that <span class="math inline">\(p_{control} = p_{trmt}\)</span>.</p>
<p><span class="math display">\[SE \approx \sqrt{\frac{\hat{p}(1-\hat{p})}{n_{control}} + \frac{\hat{p}(1-\hat{p})}{n_{trmt}}}\]</span></p>
<p><span class="math display">\[SE \approx \sqrt{\frac{0.102(1-0.102)}{227} + \frac{0.102(1-0.102)}{224}} = 0.0285\]</span></p>
<p>The test statistic is
<span class="math display">\[Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{-.09 - 0}{0.0285} = - 3.16  \]</span></p>
<p>The p-value is</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="#cb629-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">3.16</span>)</span></code></pre></div>
<pre><code>## [1] 0.001577691</code></pre>
<p>Which is close to what we got with permutation test. This should not surprise us as the sampling distribution under the permutation test looked normal.</p>
<p>Figure @ref(fig:dens223-fig) plots the empirical sampling distribution from the permutation test again with a normal density curve overlayed.</p>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb631-1"><a href="#cb631-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb631-2"><a href="#cb631-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dhistogram</span>(<span class="sc">~</span>diffprop,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb631-3"><a href="#cb631-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span>obs ) <span class="sc">%&gt;%</span></span>
<span id="cb631-4"><a href="#cb631-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dist</span>(<span class="st">&quot;norm&quot;</span>,<span class="at">sd=</span><span class="fl">0.0285</span>,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb631-5"><a href="#cb631-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb631-6"><a href="#cb631-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Sampling distribution of randomization test&quot;</span>,</span>
<span id="cb631-7"><a href="#cb631-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">subtitle=</span><span class="st">&quot;Reference normal distribution in red&quot;</span>,</span>
<span id="cb631-8"><a href="#cb631-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Difference in proportions&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="22-Confidence-Intervals_files/figure-html/dens223-fig-1.png" alt="The sampling distribution of the randomization test with a normal distribution plotted in red." width="672" />
<p class="caption">
(#fig:dens223-fig)The sampling distribution of the randomization test with a normal distribution plotted in red.
</p>
</div>
</div>
</div>
<div id="confidence-interval-for-two-proportions-using-normal-model" class="section level3" number="22.3.3">
<h3><span class="header-section-number">22.3.3</span> Confidence interval for two proportions using normal model</h3>
<p>The conditions for applying the normal model have already been verified, so we can proceed to the construction of the confidence interval. Remember the form of the confidence interval is</p>
<p><span class="math display">\[\text{point estimate} \ \pm\ z^{\star}SE\]</span></p>
<p>Our point estimate is -0.09. The standard error is different since we can’t assume the proportion of strokes are equal. We will estimate the standard error from</p>
<p><span class="math display">\[SE    = \sqrt{\frac{p_{control}(1-p_{control})}{n_{control}} + \frac{p_{trmt}(1-p_{trmt})}{n_{trmt}}}\]</span></p>
<p><span class="math display">\[SE \approx \sqrt{\frac{0.057(1-0.057)}{227} + \frac{0.15(1-0.15)}{224}} = 0.0284\]</span></p>
<p>It is close to the pooled value because of the nearly equal sample sizes.</p>
<p>The critical value is found from the normal quantile.</p>
<div class="sourceCode" id="cb632"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb632-1"><a href="#cb632-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(.<span class="dv">975</span>)</span></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<p>The 95% confidence interval is</p>
<p><span class="math display">\[ - 0.09 \ \pm\ 1.96 \times  0.0284 \quad \to \quad (-0.146,- 0.034)\]</span>
We are 95% confident that the difference in proportions of strokes in the control and treatment groups is between -0.146 and -0.034. Since this does not include zero, we are confident they are different. This supports the hypothesis tests. This confidence interval is not an accurate method for smaller samples sizes. This is because the actual coverage rate, the percentage of intervals that contain the true population parameter, will not be the nominal coverage rate. This means it is not true that 95% of similarly constructed 95% confidence intervals will contain the true parameter. This because the pooled estimate of the standard error is not accurate for small sample sizes. For the example above, the sample sizes are large and the performance of the method should be adequate.</p>
<p>Of course, <code>R</code> has a built in function to calculate the hypothesis test and confidence interval for two proportions.</p>
<div class="sourceCode" id="cb634"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb634-1"><a href="#cb634-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop_test</span>(outcome30<span class="sc">~</span>group,<span class="at">data=</span>stent)</span></code></pre></div>
<pre><code>## 
##  2-sample test for equality of proportions with continuity correction
## 
## data:  tally(outcome30 ~ group)
## X-squared = 9.0233, df = 1, p-value = 0.002666
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  0.03022922 0.14987619
## sample estimates:
##    prop 1    prop 2 
## 0.9427313 0.8526786</code></pre>
<p>The p-value is a little different from the one we calculated and closer to the randomization test, which is an approximation of the exact permutation test, because a correction factor was applied. Read online about this correction to learn more. We run the code below with the correction factor off and get the same p-value as we calculated above. The confidence interval is a little different because the function used <em>no stroke</em> as its success event, but since zero is not in the interval, we get the same conclusion.</p>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="#cb636-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop_test</span>(outcome30<span class="sc">~</span>group,<span class="at">data=</span>stent,<span class="at">correct=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  2-sample test for equality of proportions without continuity
##  correction
## 
## data:  tally(outcome30 ~ group)
## X-squared = 9.9823, df = 1, p-value = 0.001581
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  0.03466401 0.14544140
## sample estimates:
##    prop 1    prop 2 
## 0.9427313 0.8526786</code></pre>
<p>Essentially, confidence intervals and hypothesis tests serve similar purposes, but answer slightly different questions. A confidence interval gives you a range of feasible values of a parameter given a particular sample. A hypothesis test tells you whether a specific value is feasible given a sample. Sometimes you can informally conduct a hypothesis test simply by building an interval and observing whether the hypothesized value is contained in the interval. The disadvantage to this approach is that it does not yield a specific <span class="math inline">\(p\)</span>-value. The disadvantage of the hypothesis test is that it does not give a range of values for the test statistic.</p>
<p>As with hypothesis tests, confidence intervals are imperfect. About 1-in-20 properly constructed 95% confidence intervals will fail to capture the parameter of interest. This is a similar idea to our Type 1 error.</p>
</div>
</div>
<div id="changing-the-confidence-level" class="section level2" number="22.4">
<h2><span class="header-section-number">22.4</span> Changing the confidence level</h2>
<p>Suppose we want to consider confidence intervals where the confidence level is somewhat higher than 95%; perhaps we would like a confidence level of 99%. Think back to the analogy about trying to catch a fish: if we want to be more sure that we will catch the fish, we should use a wider net. To create a 99% confidence level, we must also widen our 95% interval. On the other hand, if we want an interval with lower confidence, such as 90%, we could make our original 95% interval slightly slimmer.</p>
<p>The 95% confidence interval structure provides guidance in how to make intervals with new confidence levels. Below is a general 95% confidence interval for a point estimate that comes from a nearly normal distribution:</p>
<p><span class="math display">\[\text{point estimate}\ \pm\ 1.96\times SE \]</span></p>
<p>There are three components to this interval: the point estimate, “1.96”, and the standard error. The choice of <span class="math inline">\(1.96\times SE\)</span>, which is also called <strong>margin of error</strong>, was based on capturing 95% of the data since the estimate is within 1.96 standard errors of the true value about 95% of the time. The choice of 1.96 corresponds to a 95% confidence level.</p>
<blockquote>
<p><strong>Exercise</strong>:
If <span class="math inline">\(X\)</span> is a normally distributed random variable, how often will <span class="math inline">\(X\)</span> be within 2.58 standard deviations of the mean?<a href="#fn87" class="footnote-ref" id="fnref87"><sup>87</sup></a></p>
</blockquote>
<p>To create a 99% confidence interval, change 1.96 in the 95% confidence interval formula to be <span class="math inline">\(2.58\)</span>.</p>
<p>The normal approximation is crucial to the precision of these confidence intervals. We will learn a method called the <strong>bootstrap</strong> that will allow us to find confidence intervals without the assumption of normality.</p>
</div>
<div id="interpreting-confidence-intervals" class="section level2" number="22.5">
<h2><span class="header-section-number">22.5</span> Interpreting confidence intervals</h2>
<p>A careful eye might have observed the somewhat awkward language used to describe confidence intervals.</p>
<blockquote>
<p>Correct interpretation:<br />
We are XX% confident that the population parameter is between…</p>
</blockquote>
<p><strong>Incorrect</strong> language might try to describe the confidence interval as capturing the population parameter with a certain probability. This is one of the most common errors: while it might be useful to think of it as a probability, the confidence level only quantifies how plausible it is that the parameter is in the interval.</p>
<p>Another especially important consideration of confidence intervals is that they <strong>only try to capture the population parameter</strong>. Our intervals say nothing about the confidence of capturing individual observations, a proportion of the observations, or about capturing point estimates. Confidence intervals only attempt to capture population parameters.</p>
</div>
<div id="homework-problems-21" class="section level2" number="22.6">
<h2><span class="header-section-number">22.6</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Chronic illness</li>
</ol>
<p>In 2013, the Pew Research Foundation reported that “45% of U.S. adults report that they live with one or more chronic conditions”.<a href="#fn88" class="footnote-ref" id="fnref88"><sup>88</sup></a> However, this value was based on a sample, so it may not be a perfect estimate for the population parameter of interest on its own. The study reported a standard error of about 1.2%, and a normal model may reasonably be used in this setting.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a 95% confidence interval for the proportion of U.S. adults who live with one or more chronic conditions. Also interpret the confidence interval in the context of the study.<br />
</li>
<li>Create a 99% confidence interval for the proportion of U.S. adults who live with one or more chronic conditions. Also interpret the confidence interval in the context of the study.<br />
</li>
<li>Identify each of the following statements as true or false. Provide an explanation to justify each of your answers.</li>
</ol>
<ul>
<li>We can say with certainty that the confidence interval from part a contains the true percentage of U.S. adults who suffer from a chronic illness.</li>
<li>If we repeated this study 1,000 times and constructed a 95% confidence interval for each study, then approximately 950 of those confidence intervals would contain the true fraction of U.S. adults who suffer from chronic illnesses.</li>
<li>The poll provides statistically significant evidence (at the <span class="math inline">\(\alpha = 0.05\)</span> level) that the percentage of U.S. adults who suffer from chronic illnesses is not 50%.</li>
<li>Since the standard error is 1.2%, only 1.2% of people in the study communicated uncertainty about their answer.</li>
<li>Suppose the researchers had formed a one-sided hypothesis, they believed that the true proportion is less than 50%. We could find an equivalent one-sided 95% confidence interval by taking the upper bound of our two-sided 95% confidence interval.</li>
</ul>
<div style="page-break-after: always;"></div>
<ol start="2" style="list-style-type: decimal">
<li>Vegetarian college students</li>
</ol>
<p>Suppose that 8% of college students are vegetarians. Determine if the following statements are true or false, and explain your reasoning.</p>
<ol style="list-style-type: lower-alpha">
<li>The distribution of the sample proportions of vegetarians in random samples of size 60 is approximately normal since <span class="math inline">\(n \ge 30\)</span>.</li>
<li>The distribution of the sample proportions of vegetarian college students in random samples of size 50 is right skewed.</li>
<li>A random sample of 125 college students where 12% are vegetarians would be considered unusual.</li>
<li>A random sample of 250 college students where 12% are vegetarians would be considered unusual.</li>
<li>The standard error would be reduced by one-half if we increased the sample size from 125 to~250.</li>
<li>A 99% confidence will be wider than a 95% because to have a higher confidence level requires a wider interval.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Orange tabbies</li>
</ol>
<p>Suppose that 90% of orange tabby cats are male. Determine if the following statements are true or false, and explain your reasoning.<br />
a. The distribution of sample proportions of random samples of size 30 is left skewed.<br />
b. Using a sample size that is 4 times as large will reduce the standard error of the sample proportion by one-half.<br />
c. The distribution of sample proportions of random samples of size 140 is approximately normal.</p>
<ol start="4" style="list-style-type: decimal">
<li>Working backwards</li>
</ol>
<p>A 90% confidence interval for a population mean is (65,77). The population distribution is approximately normal and the population standard deviation is unknown. This confidence interval is based on a simple random sample of 25 observations. Calculate the sample mean, the margin of error, and the sample standard deviation.</p>
<ol start="5" style="list-style-type: decimal">
<li>Find the p-value</li>
</ol>
<p>An independent random sample is selected from an approximately normal population with an unknown standard deviation. Find the p-value for the given set of hypotheses and <span class="math inline">\(T\)</span> test statistic. Also determine if the null hypothesis would be rejected at <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_{A}: \mu &gt; \mu_{0}\)</span>, <span class="math inline">\(n = 11\)</span>, <span class="math inline">\(T = 1.91\)</span><br />
</li>
<li><span class="math inline">\(H_{A}: \mu &lt; \mu_{0}\)</span>, <span class="math inline">\(n = 17\)</span>, <span class="math inline">\(T = - 3.45\)</span><br />
</li>
<li><span class="math inline">\(H_{A}: \mu \ne \mu_{0}\)</span>, <span class="math inline">\(n = 7\)</span>, <span class="math inline">\(T = 0.83\)</span><br />
</li>
<li><span class="math inline">\(H_{A}: \mu &gt; \mu_{0}\)</span>, <span class="math inline">\(n = 28\)</span>, <span class="math inline">\(T = 2.13\)</span></li>
</ol>
<div style="page-break-after: always;"></div>
<ol start="6" style="list-style-type: decimal">
<li>Sleep habits of New Yorkers</li>
</ol>
<p>New York is known as “the city that never sleeps”. A random sample of 25 New Yorkers were asked how much sleep they get per night. Statistical summaries of these data are shown below. Do these data provide strong evidence that New Yorkers sleep less than 8 hours a night on average?</p>
<p><span class="math display">\[
\begin{array}{ccccc} &amp; &amp; &amp;\\
\hline
n   &amp; \bar{x}   &amp; s     &amp; min   &amp; max \\
\hline
25  &amp; 7.73      &amp; 0.77  &amp; 6.17  &amp; 9.78 \\
  \hline
\end{array}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Write the hypotheses in symbols and in words.<br />
</li>
<li>Check conditions, then calculate the test statistic, <span class="math inline">\(T\)</span>, and the associated degrees of freedom.<br />
</li>
<li>Find and interpret the p-value in this context.<br />
</li>
<li>What is the conclusion of the hypothesis test?<br />
</li>
<li>Construct a 95% confidence interval that corresponded to this hypothesis test, would you expect 8 hours to be in the interval?</li>
</ol>
<ol start="7" style="list-style-type: decimal">
<li>Vegetarian college students II</li>
</ol>
<p>From problem 2 part c, suppose that it has been reported that 8% of college students are vegetarians. We think USAFA is not typical because of their fitness and health awareness, we think there are more vegetarians. We collect a random sample of 125 cadets and find 12% claimed they are vegetarians. Is there enough evidence to claim that USAFA cadets are different?</p>
<ol style="list-style-type: lower-alpha">
<li>Use <code>binom.test()</code> to conduct the hypothesis test and find a confidence interval.</li>
<li>Use <code>prop.test()</code> with <code>correct=FALSE</code> to conduct the hypothesis test and find a confidence interval.</li>
<li>Use <code>prop.test()</code> with <code>correct=TRUE</code> to conduct the hypothesis test and find a confidence interval.</li>
<li>Which test should you use?</li>
</ol>
<!--chapter:end:22-Confidence-Intervals.Rmd-->
</div>
</div>
<div id="BOOT" class="section level1" number="23">
<h1><span class="header-section-number">23</span> Bootstrap</h1>
<div id="objectives-21" class="section level2" number="23.1">
<h2><span class="header-section-number">23.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Use the bootstrap to estimate the standard error, the standard deviation, of the sample statistic.<br />
</li>
<li>Using bootstrap methods, obtain and interpret a confidence interval for an unknown parameter, based on a random sample.<br />
</li>
<li>Describe the advantages, disadvantages, and assumptions behind using bootstrapping for confidence intervals.</li>
</ol>
</div>
<div id="confidence-intervals" class="section level2" number="23.2">
<h2><span class="header-section-number">23.2</span> Confidence intervals</h2>
<p>In the last chapter, we introduced the concept of confidence intervals. As a reminder, confidence intervals are used to describe uncertainty around an estimate of a parameter. A confidence interval can be interpreted as a range of feasible values for an unknown parameter, given a representative sample of the population.</p>
<p>Recall the four general steps of building a confidence interval:</p>
<ol style="list-style-type: decimal">
<li><p>Identify the parameter you would like to estimate.</p></li>
<li><p>Identify a good estimate for that parameter.</p></li>
<li><p>Determine the distribution of your estimate or a function of your estimate.</p></li>
<li><p>Use this distribution to obtain a range of feasible values (confidence interval) for the parameter.</p></li>
</ol>
<p>We previously used the central limit theorem to determine the distribution of our estimate. This lesson, we will build <em>bootstrap distribution</em>s of sample estimates.</p>
</div>
<div id="bootstrapping" class="section level2" number="23.3">
<h2><span class="header-section-number">23.3</span> Bootstrapping</h2>
<p>In many contexts, the sampling distribution of a sample statistic is either unknown or subject to assumptions. For example, suppose we wanted to obtain a 95% confidence interval on the <em>median</em> of a population. The central limit theorem does not apply to the median; we don’t know its distribution.</p>
<p>The theory required to quantify the uncertainty of the sample median is complex. In an ideal world, we would sample data from the population again and recompute the median with this new sample. Then we could do it again. And again. And so on until we get enough median estimates that we have a good sense of the precision of our original estimate. This is an ideal world where sampling data is free or extremely cheap. That is rarely the case, which poses a challenge to this “resample from the population” approach.</p>
<p>However, we can sample from the sample. <em>Bootstrapping</em> allows us to simulate the sampling distribution by <strong>resampling</strong> from the sample. Suppose <span class="math inline">\(x_1,x_2,...,x_n\)</span> is an iid random sample from the population. First we define the empirical distribution function of <span class="math inline">\(X\)</span> by assigning an equal probability to each <span class="math inline">\(x_i\)</span>. Then, we sample from this empirical probability mass function. In practice, this simply means sampling from your original sample <em>with replacement</em>. Thus we are treating our sample as a discrete uniform random variable.</p>
<p>The general procedure for bootstrapping is to sample with replacement from your original sample, calculate and record the sample statistic for that bootstrapped sample, then repeat the process many times. The collection of sample statistics comprises a <em>bootstrap distribution</em> of the sample statistic. Generally, this procedure works quite well, provided that the sample is representative of the population. Otherwise, any bias or misrepresentation is simply amplified throughout the bootstrap process. Further, for very small sample sizes, bootstrap distributions become “choppy” and hard to interpret. Thus in small sample cases, we must use permutation or mathematical methods to determine the sampling distribution.</p>
<p>Once you have completed the procedure, the bootstrap distribution can be used to build a confidence interval for the population parameter or estimate the standard error. We are not using the bootstrap to find p-values.</p>
</div>
<div id="bootstrap-example" class="section level2" number="23.4">
<h2><span class="header-section-number">23.4</span> Bootstrap example</h2>
<p>To help us understand the bootstrap, let’s use an example of a single mean. We would like to estimate the mean height of students at a local college. We collect a sample of size 50 (stored in vector <code>heights</code> below).</p>
<blockquote>
<p><strong>Exercise</strong>
Using both a traditional method, via the CLT or the t-distribution, and the bootstrap method, find 95% confidence intervals for <span class="math inline">\(\mu\)</span>. Compare the two intervals.</p>
</blockquote>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="#cb638-1" aria-hidden="true" tabindex="-1"></a>heights<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fl">62.0</span>,<span class="fl">73.8</span>,<span class="fl">59.8</span>,<span class="fl">66.9</span>,<span class="fl">75.6</span>,<span class="fl">63.3</span>,<span class="fl">64.0</span>,<span class="fl">63.1</span>,<span class="fl">65.0</span>,<span class="fl">67.2</span>,<span class="fl">73.0</span>,</span>
<span id="cb638-2"><a href="#cb638-2" aria-hidden="true" tabindex="-1"></a>     <span class="fl">62.3</span>,<span class="fl">60.8</span>,<span class="fl">65.7</span>,<span class="fl">60.8</span>,<span class="fl">65.8</span>,<span class="fl">63.3</span>,<span class="fl">54.9</span>,<span class="fl">67.8</span>,<span class="fl">65.1</span>,<span class="fl">74.8</span>,<span class="fl">75.0</span>,</span>
<span id="cb638-3"><a href="#cb638-3" aria-hidden="true" tabindex="-1"></a>     <span class="fl">77.8</span>,<span class="fl">73.7</span>,<span class="fl">74.3</span>,<span class="fl">68.4</span>,<span class="fl">77.5</span>,<span class="fl">77.9</span>,<span class="fl">66.5</span>,<span class="fl">65.5</span>,<span class="fl">71.7</span>,<span class="fl">75.9</span>,<span class="fl">81.7</span>,</span>
<span id="cb638-4"><a href="#cb638-4" aria-hidden="true" tabindex="-1"></a>     <span class="fl">76.5</span>,<span class="fl">77.8</span>,<span class="fl">75.0</span>,<span class="fl">64.6</span>,<span class="fl">59.4</span>,<span class="fl">60.7</span>,<span class="fl">69.2</span>,<span class="fl">78.2</span>,<span class="fl">65.7</span>,<span class="fl">69.6</span>,<span class="fl">80.0</span>,</span>
<span id="cb638-5"><a href="#cb638-5" aria-hidden="true" tabindex="-1"></a>     <span class="fl">67.6</span>,<span class="fl">73.0</span>,<span class="fl">65.3</span>,<span class="fl">67.6</span>,<span class="fl">66.2</span>,<span class="fl">69.6</span>)</span></code></pre></div>
<p>Let’s look at the data; Figures @ref(fig:box231-fig) and @ref(fig:dens231-fig).</p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="#cb639-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_boxplot</span>(<span class="sc">~</span>heights) <span class="sc">%&gt;%</span></span>
<span id="cb639-2"><a href="#cb639-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb639-3"><a href="#cb639-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">y=</span><span class="st">&quot;Heights (in)&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/box231-fig-1.png" alt="Boxplot of heights of local college students." width="672" />
<p class="caption">
(#fig:box231-fig)Boxplot of heights of local college students.
</p>
</div>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="#cb640-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_density</span>(<span class="sc">~</span>heights,<span class="at">fill=</span><span class="st">&quot;lightgrey&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb640-2"><a href="#cb640-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb640-3"><a href="#cb640-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Heights (in)&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/dens231-fig-1.png" alt="Density plot of heights of local college students." width="672" />
<p class="caption">
(#fig:dens231-fig)Density plot of heights of local college students.
</p>
</div>
<p>It looks bimodal since there are probably both men and women in this sample and thus we have two different population distributions of heights.</p>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb641-1"><a href="#cb641-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(<span class="sc">~</span>heights)</span></code></pre></div>
<pre><code>##   min   Q1 median     Q3  max   mean       sd  n missing
##  54.9 64.7   67.6 74.675 81.7 68.938 6.345588 50       0</code></pre>
<div id="using-traditional-mathematically-methods" class="section level3" number="23.4.1">
<h3><span class="header-section-number">23.4.1</span> Using traditional mathematically methods</h3>
<p>The data comes from less that 10% of the population so we feel good about the assumption of independence. However, the data is bimodal and clearly does not come from a normal distribution. The sample size is larger, so this may help us. We will use the t-distribution and compare with the answer from the CLT then compare with the bootstrap.</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb643-1"><a href="#cb643-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">t_test</span>(<span class="sc">~</span>heights))</span></code></pre></div>
<pre><code>##   mean of x   lower   upper level
## 1    68.938 67.1346 70.7414  0.95</code></pre>
<p>We can also calculate by hand.</p>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb645-1"><a href="#cb645-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Using t</span></span>
<span id="cb645-2"><a href="#cb645-2" aria-hidden="true" tabindex="-1"></a>xbar<span class="ot">&lt;-</span><span class="fu">mean</span>(heights)</span>
<span id="cb645-3"><a href="#cb645-3" aria-hidden="true" tabindex="-1"></a>sd<span class="ot">&lt;-</span><span class="fu">sd</span>(heights)</span>
<span id="cb645-4"><a href="#cb645-4" aria-hidden="true" tabindex="-1"></a>n<span class="ot">&lt;-</span><span class="fu">length</span>(heights)</span>
<span id="cb645-5"><a href="#cb645-5" aria-hidden="true" tabindex="-1"></a>tval<span class="ot">&lt;-</span><span class="fu">qt</span>(<span class="fl">0.975</span>,n<span class="dv">-1</span>)</span>
<span id="cb645-6"><a href="#cb645-6" aria-hidden="true" tabindex="-1"></a>xbar<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>tval<span class="sc">*</span>sd<span class="sc">/</span><span class="fu">sqrt</span>(n)</span></code></pre></div>
<pre><code>## [1] 67.1346 70.7414</code></pre>
<p>If we want to use the <code>tidyverse</code>, we must convert to a <code>dataframe</code>.</p>
<div class="sourceCode" id="cb647"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb647-1"><a href="#cb647-1" aria-hidden="true" tabindex="-1"></a>heights <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">height=</span>heights)</span></code></pre></div>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="#cb648-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(heights)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 1
##   height
##    &lt;dbl&gt;
## 1   62  
## 2   73.8
## 3   59.8
## 4   66.9
## 5   75.6
## 6   63.3</code></pre>
<div class="sourceCode" id="cb650"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb650-1"><a href="#cb650-1" aria-hidden="true" tabindex="-1"></a>heights <span class="sc">%&gt;%</span></span>
<span id="cb650-2"><a href="#cb650-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean=</span><span class="fu">mean</span>(height),<span class="at">stand_dev=</span><span class="fu">sd</span>(height),<span class="at">n=</span><span class="fu">n</span>(),</span>
<span id="cb650-3"><a href="#cb650-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">ci=</span>mean<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">qt</span>(<span class="fl">0.975</span>,n<span class="dv">-1</span>)<span class="sc">*</span>stand_dev<span class="sc">/</span><span class="fu">sqrt</span>(n))</span></code></pre></div>
<pre><code>## # A tibble: 2 x 4
##    mean stand_dev     n    ci
##   &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;
## 1  68.9      6.35    50  67.1
## 2  68.9      6.35    50  70.7</code></pre>
<p>Using the CLT we have</p>
<div class="sourceCode" id="cb652"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb652-1"><a href="#cb652-1" aria-hidden="true" tabindex="-1"></a>heights <span class="sc">%&gt;%</span></span>
<span id="cb652-2"><a href="#cb652-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean=</span><span class="fu">mean</span>(height),<span class="at">stand_dev=</span><span class="fu">sd</span>(height),<span class="at">n=</span><span class="fu">n</span>(),</span>
<span id="cb652-3"><a href="#cb652-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">ci=</span>mean<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">qnorm</span>(<span class="fl">0.975</span>)<span class="sc">*</span>stand_dev<span class="sc">/</span><span class="fu">sqrt</span>(n))</span></code></pre></div>
<pre><code>## # A tibble: 2 x 4
##    mean stand_dev     n    ci
##   &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;
## 1  68.9      6.35    50  67.2
## 2  68.9      6.35    50  70.7</code></pre>
<p>This is not much different from the results using the <span class="math inline">\(t\)</span> distribution.</p>
</div>
<div id="bootstrap" class="section level3" number="23.4.2">
<h3><span class="header-section-number">23.4.2</span> Bootstrap</h3>
<p>The idea behind the bootstrap is that we will get an estimate of the distribution of the statistic of interest by sampling the original data with replacement. We must sample under the same regime as the original data was collected. In <code>R</code>, we will use the <code>resample()</code> function from the <strong>mosaic</strong> package. There are entire packages dedicated to resampling such as <strong>boot</strong> and this is a great deal of information about these types of packages online.</p>
<p>When applied to a dataframe, the <code>resample()</code> function samples rows with replacement to produce a new data
frame with the same number of rows as the original, but some rows will be duplicated and others missing.</p>
<p>To illustrate, let’s use <code>resample()</code> on the first 10 positive integers.</p>
<div class="sourceCode" id="cb654"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb654-1"><a href="#cb654-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">305</span>)</span>
<span id="cb654-2"><a href="#cb654-2" aria-hidden="true" tabindex="-1"></a><span class="fu">resample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>##  [1] 8 7 8 1 4 4 2 2 6 9</code></pre>
<p>Notice that 8, 4 and 2 appeared at least twice. The number 3 did not appear. This is a single bootstrap replicate of the data.</p>
<p>We then calculate a point estimate on the bootstrap replicate. We repeat this process a large number of times, 1000 or maybe even 10000. The collection of the point estimates is called the bootstrap distribution. For the sample mean, ideally, the bootstrap distribution should be unimodal, roughly symmetric, and centered at the original estimate.</p>
<p>Here we go with our problem.</p>
<div class="sourceCode" id="cb656"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb656-1"><a href="#cb656-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2115</span>)</span>
<span id="cb656-2"><a href="#cb656-2" aria-hidden="true" tabindex="-1"></a>boot_results<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">mean</span>(<span class="sc">~</span>height,<span class="at">data=</span><span class="fu">resample</span>(heights))</span></code></pre></div>
<p>The first few rows of the results are:</p>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="#cb657-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(boot_results)</span></code></pre></div>
<pre><code>##     mean
## 1 68.390
## 2 68.048
## 3 67.732
## 4 68.534
## 5 70.980
## 6 68.424</code></pre>
<p>The <code>do()</code> function by default gives the column name to the last function used, in this case <em>mean</em>. This is an unfortunate name as it can cause us some confusion.</p>
<p>Figure @ref(fig:boot231-fig) is a plot of the bootstrap sampling distribution.</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="#cb659-1" aria-hidden="true" tabindex="-1"></a>boot_results <span class="sc">%&gt;%</span></span>
<span id="cb659-2"><a href="#cb659-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>mean,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb659-3"><a href="#cb659-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> <span class="fl">68.938</span>) <span class="sc">%&gt;%</span></span>
<span id="cb659-4"><a href="#cb659-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(theme_classic) <span class="sc">%&gt;%</span></span>
<span id="cb659-5"><a href="#cb659-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Sample mean&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/boot231-fig-1.png" alt="The sampling distribution approximated using a bootstrap distribution." width="672" />
<p class="caption">
(#fig:boot231-fig)The sampling distribution approximated using a bootstrap distribution.
</p>
</div>
<p>And a summary of the bootstrap distribution:</p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb660-1"><a href="#cb660-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(<span class="sc">~</span>mean,<span class="at">data=</span>boot_results)</span></code></pre></div>
<pre><code>##     min      Q1 median    Q3  max     mean        sd    n missing
##  65.684 68.3915 68.976 69.55 72.3 68.96724 0.9040555 1000       0</code></pre>
<p>Now there are two ways we could go from here to calculate a confidence interval. The first is called the percentile method where we go into the bootstrap distribution and find the appropriate quantiles. The second is call the t interval with bootstrap error. In this second method you construct a confidence interval like you would using the CLT except you use the bootstrap estimate of standard error.</p>
<div id="bootstrap-percentile" class="section level4" number="23.4.2.1">
<h4><span class="header-section-number">23.4.2.1</span> Bootstrap percentile</h4>
<p>The function <code>cdata()</code> makes this easy for us.</p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb662-1"><a href="#cb662-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>mean,<span class="at">data=</span>boot_results,<span class="at">p=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##        lower   upper central.p
## 2.5% 67.2197 70.7964      0.95</code></pre>
<p>Or we can use the <code>qdata()</code>.</p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="#cb664-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qdata</span>(<span class="sc">~</span>mean,<span class="at">data=</span>boot_results,<span class="at">p=</span><span class="fu">c</span>(<span class="fl">0.025</span>,<span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##    2.5%   97.5% 
## 67.2197 70.7964</code></pre>
</div>
<div id="t-interval-with-bootstrap-standard-error" class="section level4" number="23.4.2.2">
<h4><span class="header-section-number">23.4.2.2</span> t interval with bootstrap standard error</h4>
<p>Since the bootstrap distribution looks like a <span class="math inline">\(t\)</span> distribution, we can use a <span class="math inline">\(t\)</span> interval with the bootstrap standard error. The standard deviation of the bootstrap distribution is the standard error of the sample mean. We will not have to divide by <span class="math inline">\(\sqrt{n}\)</span> since we are dealing with the distribution of the mean directly.</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="#cb666-1" aria-hidden="true" tabindex="-1"></a>xbar<span class="ot">&lt;-</span><span class="fu">mean</span>(boot_results<span class="sc">$</span>mean)</span>
<span id="cb666-2"><a href="#cb666-2" aria-hidden="true" tabindex="-1"></a>SE<span class="ot">&lt;-</span><span class="fu">sd</span>(boot_results<span class="sc">$</span>mean)</span>
<span id="cb666-3"><a href="#cb666-3" aria-hidden="true" tabindex="-1"></a>xbar<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">qt</span>(.<span class="dv">975</span>,<span class="dv">49</span>)<span class="sc">*</span>SE</span></code></pre></div>
<pre><code>## [1] 67.15047 70.78401</code></pre>
<p>You could of course use <code>tidyverse</code> but we must change the column name.</p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="#cb668-1" aria-hidden="true" tabindex="-1"></a>boot_results <span class="sc">%&gt;%</span></span>
<span id="cb668-2"><a href="#cb668-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">stat=</span>mean) <span class="sc">%&gt;%</span></span>
<span id="cb668-3"><a href="#cb668-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean=</span><span class="fu">mean</span>(stat),<span class="at">stand_dev=</span><span class="fu">sd</span>(stat),<span class="at">ci=</span>mean<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">qt</span>(<span class="fl">0.975</span>,<span class="dv">49</span>)<span class="sc">*</span>stand_dev)</span></code></pre></div>
<pre><code>##       mean stand_dev       ci
## 1 68.96724 0.9040555 67.15047
## 2 68.96724 0.9040555 70.78401</code></pre>
<p>Of course there is a function to make this easier for us.</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="#cb670-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(boot_results, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">&quot;percentile&quot;</span>, <span class="st">&quot;stderr&quot;</span>))</span></code></pre></div>
<pre><code>##   name    lower    upper level     method estimate margin.of.error df
## 1 mean 67.21970 70.79640  0.95 percentile   68.938              NA NA
## 2 mean 67.15047 70.78401  0.95     stderr   68.938        1.816768 49</code></pre>
<p>The three intervals are very similar.</p>
</div>
</div>
</div>
<div id="non-standard-sample-statistics" class="section level2" number="23.5">
<h2><span class="header-section-number">23.5</span> Non-standard sample statistics</h2>
<p>One of the huge advantages of simulation-based methods is the ability to build confidence intervals for parameters whose estimates don’t have known sampling distributions or the distributions are difficult to derive.</p>
<div id="example-median" class="section level3" number="23.5.1">
<h3><span class="header-section-number">23.5.1</span> Example median</h3>
<p>Consider the height data again, we would like to know the median student height and use a confidence interval for the estimate. However, we have no idea of the sampling distribution of the median. We can use bootstrapping to obtain an empirical distribution of the median.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Find a 90% confidence interval for the median height of the students at a local college.</p>
</blockquote>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb672-1"><a href="#cb672-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">427</span>)</span>
<span id="cb672-2"><a href="#cb672-2" aria-hidden="true" tabindex="-1"></a>boot_results<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">median</span>(<span class="sc">~</span>height,<span class="at">data=</span><span class="fu">resample</span>(heights))</span></code></pre></div>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="#cb673-1" aria-hidden="true" tabindex="-1"></a>boot_results <span class="sc">%&gt;%</span></span>
<span id="cb673-2"><a href="#cb673-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>median,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb673-3"><a href="#cb673-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> <span class="fl">67.6</span>) <span class="sc">%&gt;%</span></span>
<span id="cb673-4"><a href="#cb673-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(theme_classic) <span class="sc">%&gt;%</span></span>
<span id="cb673-5"><a href="#cb673-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Sample median&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/boot232-fig-1.png" alt="The sampling distribution approximated using a bootstrap distribution." width="672" />
<p class="caption">
(#fig:boot232-fig)The sampling distribution approximated using a bootstrap distribution.
</p>
</div>
<p>From Figure @ref(fig:boot232-fig), the bootstrap sampling distribution is not symmetrical so we may not want to use the t interval approach. We will still calculate the confidence interval based on both approaches to compare the results.</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb674-1"><a href="#cb674-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>median,<span class="at">data=</span>boot_results,<span class="at">p=</span><span class="fl">0.90</span>)</span></code></pre></div>
<pre><code>##    lower upper central.p
## 5%  65.8 70.65       0.9</code></pre>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb676-1"><a href="#cb676-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(boot_results, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">&quot;percentile&quot;</span>, <span class="st">&quot;stderr&quot;</span>),<span class="at">level=</span><span class="fl">0.9</span>)</span></code></pre></div>
<pre><code>##     name   lower   upper level     method estimate margin.of.error
## 1 median 65.8000 70.6500   0.9 percentile     67.6              NA
## 2 median 65.4648 70.1297   0.9     stderr     67.6        2.332455</code></pre>
<p>There is a little difference between these two methods but not as large as we may have expected.</p>
</div>
<div id="summary-bootstrap" class="section level3" number="23.5.2">
<h3><span class="header-section-number">23.5.2</span> Summary bootstrap</h3>
<p>The key idea behind the bootstrap is that we estimate the population with the sample, this is called the <em>plug in principle</em>, if something is unknown then substitute an estimate of it. We can then generate new samples from this population estimate. The bootstrap does not improve the accuracy of the original estimate, in fact the bootstrap distribution is centered on the original sample estimate. Instead we only get information about the variability of the sample estimate. Some people are suspicious that we are using the data over and over. But remember we are just getting estimates of variability. In traditional statistics, when we calculate the sample standard deviation, we are using sample mean. Thus we are using the data twice. Always think of the bootstrap as providing a way to find the variability in an estimate.</p>
</div>
</div>
<div id="confidence-interval-for-difference-in-means" class="section level2" number="23.6">
<h2><span class="header-section-number">23.6</span> Confidence interval for difference in means</h2>
<p>To bring all the ideas we have learned so far in this block we will work an example of testing for a difference of two means. In our opinion, the easiest method to understand is the permutation test and the most difficult is the one based on the mathematical derivation, because of the assumptions necessary to get a mathematical solution for the sampling distribution. We will also introduce how to use the bootstrap to get a confidence interval.</p>
<div id="health-evaluation-and-linkage-of-primary-care" class="section level3" number="23.6.1">
<h3><span class="header-section-number">23.6.1</span> Health evaluation and linkage of primary care</h3>
<p>The HELP study was a clinical trial for adult inpatients recruited from a detoxification unit. Patients with no primary care physician were randomized to receive a multidisciplinary assessment and a brief motivational intervention or usual care, with the goal of linking them to primary medical care.</p>
<p>We are interested if there is a difference between male and female ages.</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="#cb678-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;HELPrct&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="#cb679-1" aria-hidden="true" tabindex="-1"></a>HELP_sub <span class="ot">&lt;-</span> HELPrct <span class="sc">%&gt;%</span></span>
<span id="cb679-2"><a href="#cb679-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(age,sex)</span></code></pre></div>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="#cb680-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(age<span class="sc">~</span>sex,<span class="at">data=</span>HELP_sub)</span></code></pre></div>
<pre><code>##      sex min Q1 median   Q3 max     mean       sd   n missing
## 1 female  21 31     35 40.5  58 36.25234 7.584858 107       0
## 2   male  19 30     35 40.0  60 35.46821 7.750110 346       0</code></pre>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="#cb682-1" aria-hidden="true" tabindex="-1"></a>HELP_sub <span class="sc">%&gt;%</span></span>
<span id="cb682-2"><a href="#cb682-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_boxplot</span>(age<span class="sc">~</span>sex) <span class="sc">%&gt;%</span></span>
<span id="cb682-3"><a href="#cb682-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb682-4"><a href="#cb682-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Gender&quot;</span>,<span class="at">y=</span><span class="st">&quot;Age (years)&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/box232-fig-1.png" alt="The distribution of age in the HELP study by gender." width="672" />
<p class="caption">
(#fig:box232-fig)The distribution of age in the HELP study by gender.
</p>
</div>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb683-1"><a href="#cb683-1" aria-hidden="true" tabindex="-1"></a>HELP_sub <span class="sc">%&gt;%</span></span>
<span id="cb683-2"><a href="#cb683-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dhistogram</span>(<span class="sc">~</span>age<span class="sc">|</span>sex,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb683-3"><a href="#cb683-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb683-4"><a href="#cb683-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Age&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/hist232-fig-1.png" alt="The distribution of age in the HELP study by gender." width="672" />
<p class="caption">
(#fig:hist232-fig)The distribution of age in the HELP study by gender.
</p>
</div>
<p>Figures @ref(fig:box232-fig) and @ref(fig:hist232-fig) indicate there might be a slight difference in the means, but is it statistically significant?</p>
</div>
<div id="permutation-test" class="section level3" number="23.6.2">
<h3><span class="header-section-number">23.6.2</span> Permutation test</h3>
<p>The permutation test is ideally suited for a hypothesis test. So we will conduct this first and then see if we can generate a confidence interval.</p>
<p>The hypotheses are:</p>
<p><span class="math inline">\(H_0\)</span>: There is no difference in average age for men and women in the detoxification unit. In statistical notation: <span class="math inline">\(\mu_{male} - \mu_{female} = 0\)</span>, where <span class="math inline">\(\mu_{female}\)</span> represents female inpatients and <span class="math inline">\(\mu_{male}\)</span> represents the male inpatients.<br />
<span class="math inline">\(H_A\)</span>: There is some difference in average age for men and women in the detoxification unit (<span class="math inline">\(\mu_{male} - \mu_{female} \neq 0\)</span>).</p>
<p>Let’s perform a randomization, permutation, test.</p>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="#cb684-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(age<span class="sc">~</span>sex,<span class="at">data=</span>HELP_sub)</span></code></pre></div>
<pre><code>##      sex min Q1 median   Q3 max     mean       sd   n missing
## 1 female  21 31     35 40.5  58 36.25234 7.584858 107       0
## 2   male  19 30     35 40.0  60 35.46821 7.750110 346       0</code></pre>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="#cb686-1" aria-hidden="true" tabindex="-1"></a>obs_stat<span class="ot">&lt;-</span><span class="fu">diffmean</span>(age<span class="sc">~</span>sex,<span class="at">data=</span>HELP_sub)</span>
<span id="cb686-2"><a href="#cb686-2" aria-hidden="true" tabindex="-1"></a>obs_stat</span></code></pre></div>
<pre><code>##   diffmean 
## -0.7841284</code></pre>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb688-1"><a href="#cb688-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb688-2"><a href="#cb688-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">10000</span>)<span class="sc">*</span><span class="fu">diffmean</span>(age<span class="sc">~</span><span class="fu">shuffle</span>(sex),<span class="at">data=</span>HELP_sub)</span></code></pre></div>
<div class="sourceCode" id="cb689"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb689-1"><a href="#cb689-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(<span class="sc">~</span>diffmean,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##        min         Q1     median     Q3      max        mean        sd     n
##  -3.378154 -0.5638809 0.01120955 0.5863 3.486224 0.009350908 0.8492454 10000
##  missing
##        0</code></pre>
<p>The sampling distribution is centered on the null value of 0, more or less, and the standard deviation is 0.849. This is an estimate of the variability of the difference in mean ages.</p>
<div class="sourceCode" id="cb691"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb691-1"><a href="#cb691-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb691-2"><a href="#cb691-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>diffmean,<span class="at">color=</span><span class="st">&quot;black&quot;</span>,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb691-3"><a href="#cb691-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept=</span>obs_stat,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb691-4"><a href="#cb691-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb691-5"><a href="#cb691-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Difference of means&quot;</span>,<span class="at">title=</span><span class="st">&quot;Sampling distribution of difference of two means&quot;</span>,</span>
<span id="cb691-6"><a href="#cb691-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">subtitle=</span><span class="st">&quot;Null assumes equal means&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/hist233-fig-1.png" alt="The approximate sampling distribution of the difference of means from a bootstrap process." width="672" />
<p class="caption">
(#fig:hist233-fig)The approximate sampling distribution of the difference of means from a bootstrap process.
</p>
</div>
<p>Our test statistic does not appear to be too extreme, Figure @ref(fig:hist233-fig).</p>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="#cb692-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">prop1</span>(<span class="sc">~</span>(diffmean <span class="sc">&lt;=</span> obs_stat),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>## prop_TRUE 
## 0.3523648</code></pre>
<p>Based on this p-value, we would fail to reject the null hypothesis.</p>
<p>Now to construct a confidence interval we have to be careful and think about this. The object <code>results</code> has the distribution of difference in means assuming there is no difference. To get a confidence interval, we want to center this difference on the observed difference in means and not on zero.</p>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb694-1"><a href="#cb694-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>(diffmean<span class="sc">+</span>obs_stat),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##          lower     upper central.p
## 2.5% -2.449246 0.8789368      0.95</code></pre>
<p>We are 95% confident that the true difference in mean ages between female and male participants in the study is between -2.45 and 0.88. Since 0 in in the confidence interval, we would fail to reject the null hypothesis.</p>
<p>We are assuming that the test statistic can be transformed. It turns out that the percentile method is transformation invariant so we can do the transform of shifting the null distribution by the observed value.</p>
</div>
<div id="traditional-mathematical-methods" class="section level3" number="23.6.3">
<h3><span class="header-section-number">23.6.3</span> Traditional mathematical methods</h3>
<p>Using the CLT or the <span class="math inline">\(t\)</span> distribution becomes difficult because we have to find a way to calculate the standard error. There have been many proposed methods, you are welcome to research them, but we will only present a couple of ideas in this section. Let’s summarize the process for both hypothesis testing and confidence intervals in the case of the difference of two means using the <span class="math inline">\(t\)</span> distribution.</p>
</div>
<div id="hypothesis-tests" class="section level3" number="23.6.4">
<h3><span class="header-section-number">23.6.4</span> Hypothesis tests</h3>
<p>When applying the <span class="math inline">\(t\)</span> distribution for a hypothesis test, we proceed as follows:<br />
1. Write appropriate hypotheses.<br />
2. Verify conditions for using the <span class="math inline">\(t\)</span> distribution.<br />
For a difference of means when the data are not paired: each sample mean must separately satisfy the one-sample conditions for the <span class="math inline">\(t\)</span> distribution, and the data in each group must also be independent. Just like in the one-sample case, slight skewness will not be a problem for larger sample sizes. We can have moderate skewness and be fine if our sample is 30 or more. We can have extreme skewness if our sample is 60 or more.<br />
3. Compute the point estimate of interest, the standard error, and the degrees of freedom.<br />
4. Compute the T score and p-value.<br />
5. Make a conclusion based on the p-value, and write a conclusion in context and in plain language so anyone can understand the result.</p>
<p>We added the extra step of checking the assumptions.</p>
</div>
<div id="confidence-intervals-1" class="section level3" number="23.6.5">
<h3><span class="header-section-number">23.6.5</span> Confidence intervals</h3>
<p>Similarly, the following is how we generally computed a confidence interval using a <span class="math inline">\(t\)</span> distribution:<br />
1. Verify conditions for using the <span class="math inline">\(t\)</span> distribution. (See above.)<br />
2. Compute the point estimate of interest, the standard error, the degrees of freedom, and <span class="math inline">\(t^{\star}_{df}\)</span>.<br />
3. Calculate the confidence interval using the general formula, point estimate <span class="math inline">\(\pm\ t_{df}^{\star} SE\)</span>.<br />
4. Put the conclusions in context and in plain language so even non-statisticians can understand the results.</p>
<p>If the assumptions above are met, each sample mean can itself be modeled using a <span class="math inline">\(t\)</span> distribution and if the samples are independent, then the sample difference of two means, <span class="math inline">\(\bar{x}_1 - \bar{x}_2\)</span>, can be modeled using the <span class="math inline">\(t\)</span> distribution and the standard error
<span class="math display">\[SE_{\bar{x}_{1} - \bar{x}_{2}} = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}\]</span></p>
<p>To calculate the degrees of freedom, use statistical software or conservatively use the smaller of <span class="math inline">\(n_1 - 1\)</span> and <span class="math inline">\(n_2 - 1\)</span>.</p>
<div id="results" class="section level4" number="23.6.5.1">
<h4><span class="header-section-number">23.6.5.1</span> Results</h4>
<p>Back to our study, the men and women were independent of each other. Additionally, the distributions in each population don’t show any clear deviations from normality, some slight skewness but the sample size reduces this concern, Figure @ref(fig:qq231-fig). Finally, within each group we also need independence. If they represent less that 10% of the population, we are good to go on this. This condition might be difficult to verify.</p>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="#cb696-1" aria-hidden="true" tabindex="-1"></a>HELP_sub <span class="sc">%&gt;%</span></span>
<span id="cb696-2"><a href="#cb696-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_qq</span>(<span class="sc">~</span>age<span class="sc">|</span>sex) <span class="sc">%&gt;%</span></span>
<span id="cb696-3"><a href="#cb696-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_qqline</span>(<span class="sc">~</span>age<span class="sc">|</span>sex) <span class="sc">%&gt;%</span></span>
<span id="cb696-4"><a href="#cb696-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/qq231-fig-1.png" alt="The quantile-quantile plots to check normality assumption." width="672" />
<p class="caption">
(#fig:qq231-fig)The quantile-quantile plots to check normality assumption.
</p>
</div>
<p>The distribution of males tends to have longer tails than a normal and the female distribution is skewed to the right. The sample sizes are large enough that this does not worry us.</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb697-1"><a href="#cb697-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(age<span class="sc">~</span>sex,<span class="at">data=</span>HELP_sub)</span></code></pre></div>
<pre><code>##      sex min Q1 median   Q3 max     mean       sd   n missing
## 1 female  21 31     35 40.5  58 36.25234 7.584858 107       0
## 2   male  19 30     35 40.0  60 35.46821 7.750110 346       0</code></pre>
<p>Let’s find the confidence interval first.</p>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb699-1"><a href="#cb699-1" aria-hidden="true" tabindex="-1"></a>(<span class="fl">35.47-36.25</span>)<span class="sc">+</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span><span class="fu">qt</span>(.<span class="dv">975</span>,<span class="dv">106</span>)<span class="sc">*</span><span class="fu">sqrt</span>(<span class="fl">7.58</span><span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">107</span><span class="fl">+7.75</span><span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">346</span>)</span></code></pre></div>
<pre><code>## [1] -2.4512328  0.8912328</code></pre>
<p>This result is very close to what we got with the permutation test.</p>
<p>Now let’s find the p-value for the hypothesis test.</p>
<p>The test statistic is:
<span class="math display">\[T = \frac{\text{point estimate} - \text{null value}}{SE}\]</span></p>
<p><span class="math display">\[ = \frac{(35.47 - 36.25) - 0}{\sqrt{\left( \frac{7.58^2}{107}+ \frac{7.75^2}{346}\right)}} = - 0.92976 \]</span>
We use the smaller of <span class="math inline">\(n_1-1\)</span> and <span class="math inline">\(n_2-1\)</span> as the degrees of freedom: <span class="math inline">\(df=106\)</span>.</p>
<p>The p-value is:</p>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb701-1"><a href="#cb701-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pt</span>(<span class="sc">-</span><span class="fl">0.92976</span>,<span class="dv">106</span>)</span></code></pre></div>
<pre><code>## [1] 0.3546079</code></pre>
<p>Of course, there is a function that does this for us.</p>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb703-1"><a href="#cb703-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t_test</span>(age<span class="sc">~</span>sex,<span class="at">data=</span>HELP_sub)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  age by sex
## t = 0.92976, df = 179.74, p-value = 0.3537
## alternative hypothesis: true difference in means between group female and group male is not equal to 0
## 95 percent confidence interval:
##  -0.8800365  2.4482932
## sample estimates:
## mean in group female   mean in group male 
##             36.25234             35.46821</code></pre>
<p>Notice that the degrees of freedom are not an integer, this is because it is a weighted average of the two different samples sizes and standard deviations. This method is called the Satterwaite approximation.</p>
</div>
<div id="pooled-standard-deviation" class="section level4" number="23.6.5.2">
<h4><span class="header-section-number">23.6.5.2</span> Pooled standard deviation</h4>
<p>Occasionally, two populations will have standard deviations that are so similar that they can be treated as identical. This is an assumption of equal variance in each group. For example, historical data or a well-understood biological mechanism may justify this strong assumption. In such cases, we can make the <span class="math inline">\(t\)</span> distribution approach slightly more precise by using a pooled standard deviation.</p>
<p>The <strong>pooled standard deviation</strong> of two groups is a way to use data from both samples to better estimate the standard deviation and standard error. If <span class="math inline">\(s_1^{}\)</span> and <span class="math inline">\(s_2^{}\)</span> are the standard deviations of groups 1 and 2 and there are good reasons to believe that the population standard deviations are equal, then we can obtain an improved estimate of the group variances by pooling their data:</p>
<p><span class="math display">\[ s_{pooled}^2 = \frac{s_1^2\times (n_1-1) + s_2^2\times (n_2-1)}{n_1 + n_2 - 2}\]</span></p>
<p>where <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> are the sample sizes, as before. To use this new statistic, we substitute <span class="math inline">\(s_{pooled}^2\)</span> in place of <span class="math inline">\(s_1^2\)</span> and <span class="math inline">\(s_2^2\)</span> in the standard error formula, and we use an updated formula for the degrees of freedom:
<span class="math display">\[df = n_1 + n_2 - 2\]</span></p>
<p>The benefits of pooling the standard deviation are realized through obtaining a better estimate of the standard deviation for each group and using a larger degrees of freedom parameter for the <span class="math inline">\(t\)</span> distribution. Both of these changes may permit a more accurate model of the sampling distribution of <span class="math inline">\(\bar{x}_1 - \bar{x}_2\)</span>.</p>
<blockquote>
<p><strong>Caution</strong><br />
Pooling standard deviations should be done only after careful research</p>
</blockquote>
<p>A pooled standard deviation is only appropriate when background research indicates the population standard deviations are nearly equal. When the sample size is large and the condition may be adequately checked with data, the benefits of pooling the standard deviations greatly diminishes.</p>
<p>In <code>R</code> we can before the difference of two means with equal variance using <code>var.equal</code>.</p>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb705-1"><a href="#cb705-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t_test</span>(age<span class="sc">~</span>sex,<span class="at">data=</span>HELP_sub,<span class="at">var.equal=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  age by sex
## t = 0.91923, df = 451, p-value = 0.3585
## alternative hypothesis: true difference in means between group female and group male is not equal to 0
## 95 percent confidence interval:
##  -0.8922735  2.4605303
## sample estimates:
## mean in group female   mean in group male 
##             36.25234             35.46821</code></pre>
<p>Since our sample sizes were so large, this did not have a big impact on the results.</p>
</div>
</div>
<div id="bootstrap-1" class="section level3" number="23.6.6">
<h3><span class="header-section-number">23.6.6</span> Bootstrap</h3>
<p>Finally, we will construct a confidence interval through the use of the bootstrap distribution. In this problem we have to be careful and sample within each group. Compare the following two sets of samples.</p>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb707-1"><a href="#cb707-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(age <span class="sc">~</span> sex, <span class="at">data =</span> <span class="fu">resample</span>(HELP_sub))</span></code></pre></div>
<pre><code>##      sex min Q1 median    Q3 max     mean       sd   n missing
## 1 female  21 30     33 38.75  50 34.64706 6.267387 102       0
## 2   male  19 29     33 39.00  59 34.74359 7.833066 351       0</code></pre>
<p>and</p>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb709-1"><a href="#cb709-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(age <span class="sc">~</span> sex, <span class="at">data =</span> <span class="fu">resample</span>(HELP_sub,<span class="at">groups=</span>sex))</span></code></pre></div>
<pre><code>##      sex min Q1 median   Q3 max     mean       sd   n missing
## 1 female  22 31     34 39.5  57 35.60748 6.901951 107       0
## 2   male  20 31     35 41.0  60 35.94798 8.039227 346       0</code></pre>
<p>Notice in the second line of code, we are keeping the samples the same size within the <code>sex</code> variable.</p>
<p>Let’s get our bootstrap distribution.</p>
<div class="sourceCode" id="cb711"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb711-1"><a href="#cb711-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2527</span>)</span>
<span id="cb711-2"><a href="#cb711-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">1000</span>) <span class="sc">*</span> <span class="fu">diffmean</span>(age <span class="sc">~</span> sex, <span class="at">data =</span> <span class="fu">resample</span>(HELP_sub, <span class="at">groups =</span> sex))</span></code></pre></div>
<p>Figure @ref(fig:boot235-fig) is our sampling distribution from the bootstrap.</p>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb712-1"><a href="#cb712-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb712-2"><a href="#cb712-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>diffmean,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb712-3"><a href="#cb712-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(theme_classic) <span class="sc">%&gt;%</span></span>
<span id="cb712-4"><a href="#cb712-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Difference in means&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="23-Bootstrap_files/figure-html/boot235-fig-1.png" alt="Sampling distribution of the difference in means." width="672" />
<p class="caption">
(#fig:boot235-fig)Sampling distribution of the difference in means.
</p>
</div>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb713-1"><a href="#cb713-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>( <span class="sc">~</span> diffmean, <span class="at">p =</span> <span class="fl">0.95</span>, <span class="at">data =</span> results)</span></code></pre></div>
<pre><code>##          lower     upper central.p
## 2.5% -2.394406 0.8563786      0.95</code></pre>
<p>Again, similar results.</p>
</div>
</div>
<div id="frequently-asked-questions" class="section level2" number="23.7">
<h2><span class="header-section-number">23.7</span> Frequently asked questions</h2>
<ol style="list-style-type: decimal">
<li>There are more types of bootstrap techniques, right?</li>
</ol>
<p>Yes! There are many excellent bootstrap techniques. We have only chosen to present two bootstrap techniques that could be explained in a single lesson and that are also reasonably reliable. There are many adjustments that can be made to speed up and improve accuracy. Packages such as <strong>resample</strong> and <strong>boot</strong> are more appropriate for these situations.</p>
<ol start="2" style="list-style-type: decimal">
<li>I’ve heard the percentile bootstrap is very robust.</li>
</ol>
<p>It is a <strong>commonly</strong> held belief that the percentile bootstrap is a robust bootstrap method. That is false. The percentile method is one of the least reliable bootstrap methods. However, it is easy to use and understand and can give a first attempt at a solution before more accurate methods are used.</p>
<ol start="3" style="list-style-type: decimal">
<li>I should use 1000 replicates in my bootstrap and permutation tests.</li>
</ol>
<p>The randomization and bootstrap distributions involve a random component from the sampling process and thus p-values and confidence intervals computed from the same data will vary. The amount of this <strong>Monte Carlo</strong> variability depends on the number of replicates used to create the randomization or bootstrap distribution. It is important that we not use too few as this will introduce too much random noise into p-value and confidence interval calculations. But each replicate costs time, and the marginal gain for each additional replicate decreases as the number of replicates increases. There is little reason to use millions of replicates (unless the goal is to estimate
very small p-values). We generally use roughly 1000 for routine or preliminary work and increase this to 10,000
when we want to reduce the effects of Monte Carlo variability.</p>
</div>
<div id="homework-problems-22" class="section level2" number="23.8">
<h2><span class="header-section-number">23.8</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Poker<br />
An aspiring poker player recorded her winnings and losses over 50 evenings of play, the data is in the <code>data</code> folder in the file <code>poker.csv</code>. The poker player would like to better understand the volatility in her long term play.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Load the data and plot a histogram.<br />
</li>
<li>Find the summary statistics.<br />
</li>
<li><em>Mean absolute deviation</em> or <em>MAD</em> is a more intuitive measure of spread than variance. It directly measures the average distance from the mean. It is found by the formula:
<span class="math display">\[mad = \sum_{i=1}^{n}\frac{\left| x_{i} - \bar{x} \right|}{n}\]</span>
Write a function and find the <em>MAD</em> of the data.<br />
</li>
<li>Find the bootstrap distribution of the <em>MAD</em> using 1000 replicates.<br />
</li>
<li>Plot a histogram of the bootstrap distribution.<br />
</li>
<li>Report a 95% confidence interval on the MAD.<br />
</li>
<li>ADVANCED: Do you think sample MAD is an unbiased estimator of population MAD? Why or why not?</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Bootstrap hypothesis testing</li>
</ol>
<p>Bootstrap hypothesis testing is relatively undeveloped, and is generally not as accurate as permutation testing. Therefore in general avoid it. But for our problem in the reading above, it may work. We will sample in a way that is consistent with the null hypothesis, then calculate a p-value as a tail probability like we do in permutation tests. This example does not generalize well to other applications like relative risk, correlation, regression, or categorical data.</p>
<ol style="list-style-type: lower-alpha">
<li>Using the <code>HELPrct</code> data, the null hypothesis requires the means of each group to be equal. Pick one group to adjust, either <code>male</code> or <code>female</code>. First zero the mean of the selected group by subtracting the sample mean of this group from data points only in this group. Then add the sample mean of the other group to each data point in the selected group. Store in a new object called <code>HELP_null</code>. set, store the observed value of the difference of means for male and female.</li>
<li>The null hypothesis requires the means of each group to be equal. Pick one group to adjust, either <code>male</code> or <code>female</code>. First zero the mean of the selected group by subtracting the sample mean of this group from data points only in this group. Then add the sample mean of the other group to each data point in the selected group. Store in a new object called <code>HELP_null</code>.<br />
</li>
<li>Run <code>favstats()</code> to check that the means are equal.<br />
</li>
<li>On this new adjusted data set, generate a bootstrap distribution of the difference in sample means.<br />
</li>
<li>Plot the bootstrap distribution and a line at the observed difference in sample means.<br />
</li>
<li>Find a p-value.<br />
</li>
<li>How does the p-value compare with those in the reading.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Paired data</li>
</ol>
<p>Are textbooks actually cheaper online? Here we compare the price of textbooks at the University of California, Los Angeles’ (UCLA’s) bookstore and prices at Amazon.com. Seventy-three UCLA courses were randomly sampled in Spring 2010, representing less than 10% of all UCLA courses. When a class had multiple books, only the most expensive text was considered.</p>
<p>The data is in the file <code>textbooks.csv</code> under the data folder.</p>
<p>Each textbook has two corresponding prices in the data set: one for the UCLA bookstore and one for Amazon. Therefore, each textbook price from the UCLA bookstore has a natural correspondence with a textbook price from Amazon. When two sets of observations have this special correspondence, they are said to be <strong>paired</strong>.</p>
<p>To analyze paired data, it is often useful to look at the difference in outcomes of each pair of observations. In <code>textbooks</code>, we look at the difference in prices, which is represented as the <code>diff</code> variable. It is important that we always subtract using a consistent order; here Amazon prices are always subtracted from UCLA prices.</p>
<ol style="list-style-type: lower-alpha">
<li>Is this data tidy? Explain.<br />
</li>
<li>Make a scatterplot of the UCLA price versus the Amazon price. Add a 45 degree line to the plot.<br />
</li>
<li>Make a histogram of the differences in price.</li>
</ol>
<p>The hypotheses are:<br />
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{diff}=0\)</span>. There is no difference in the average textbook price.<br />
<span class="math inline">\(H_A\)</span>: <span class="math inline">\(\mu_{diff} \neq 0\)</span>. There is a difference in average prices.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>To use a <span class="math inline">\(t\)</span> distribution, the variable <code>diff</code> has to independent and normally distributed. Since the 73 books represent less than 10% of the population, the assumption that the random sample is independent is reasonable. Check normality using <code>qqnorsim()</code> from the <strong>openintro</strong> package. It generates 8 qq plots of simulated normal data that you can use to judge the <code>diff</code> variable.<br />
</li>
<li>Run a <span class="math inline">\(t\)</span> test on the <code>diff</code> variable. Report the p-value and conclusion.<br />
</li>
<li>Create a bootstrap distribution and generate a 95% confidence interval on the mean of the differences, the <code>diff</code> column.<br />
</li>
<li>If there is really no differences between book sources, the variable <code>more</code> is a binomial and under the null the probably of success is <span class="math inline">\(\pi = 0.5\)</span>. Run a hypothesis test using the variable <code>more</code>.<br />
</li>
<li>Could you use a permutation test on this example? Explain.</li>
</ol>
<!--chapter:end:23-Bootstrap.Rmd-->
</div>
</div>
<div id="ADDTESTS" class="section level1" number="24">
<h1><span class="header-section-number">24</span> Additional Hypothesis Tests</h1>
<div id="objectives-22" class="section level2" number="24.1">
<h2><span class="header-section-number">24.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Conduct and interpret a hypothesis test for equality of two or more means using both permutation and the <span class="math inline">\(F\)</span> distribution.<br />
</li>
<li>Conduct and interpret a goodness of fit test using both Pearson’s chi-squared and randomization to evaluate the independence between two categorical variables.<br />
</li>
<li>Conduct and interpret a hypothesis test for the equality of two variances.<br />
</li>
<li>Know and check assumptions for the tests in the reading.</li>
</ol>
</div>
<div id="introduction-2" class="section level2" number="24.2">
<h2><span class="header-section-number">24.2</span> Introduction</h2>
<p>The purpose of this chapter is to put all we learned in this block into perspective and then to also add a couple of new tests to demonstrate other statistical tests.</p>
<p>Remember that we have been using data to answer research questions. So far we can do this with hypothesis tests or confidence intervals. There is a close link between these two methods. The key ideas have been to generate a single number metric to use in answering our research question and then to obtain the sampling distribution of this metric.</p>
<p>In obtaining the sampling distribution we used randomization as an approximation to permutation exact tests, probability models, mathematical models, and the bootstrap. Each of these had different assumptions and different areas where they could be applied. In some cases, several methods can be applied to the problem to get a sense of the robustness to the different assumptions. For example, if you run a randomization test and a test using the CLT and they both give you similar results, you can feel better about your decision.</p>
<p>Finding a single number metric to answer our research question can be difficult. For example, in the homework for last chapter, we wanted to determine if the prices of books at a campus bookstore were different from Amazon’s prices. The metric we decided to use was the mean of the differences in prices. But is this the best way to answer the question? This metric has been used historically because of the need to use the <span class="math inline">\(t\)</span> distribution. However, there are other ways in which the prices of books can differ. Jack Welch was the CEO of GE for years and he made the claim that customers don’t care about average but they do care about variability. The average temperature setting of your GE refrigerator could be off and you would adapt. However if the temperature had great variability, then you would be upset. So maybe metrics that incorporate variability might be good. In our bootstrap notes, we looked at the ages of males and females in the HELP study. In using a randomization permutation test, we assumed there was no difference in the distribution of ages between males and females. However, in the alternative we measured the difference in the distributions using only means. The means of these two populations could be equal but the distributions differ in other ways, for example variability. We could conduct a separate test for variances but we have to be careful about multiple comparisons because in that case the Type 1 error is inflated.</p>
<p>We also learned that the use of the information in the data impacts the power of the test. In the golf ball example, when we used range as our metric, we did not have the same power as looking at the differences from expected values under the null hypothesis. There is some mathematical theory that leads to better estimators, they are called likelihood ratio tests, but this is beyond the scope of the book. What you can do is create a simulation where you simulate data from the alternative hypothesis and then measure the power. This will give you a sense of the quality of your metric. We only briefly looked at measuring power an earlier chapter and will not go further into this idea in this chapter.</p>
<p>We will finish this block by examining problems with two variables. In the first case they will both be categorical but at least one of the categorical variables has more than two levels. In the second case, we will examine two variables where one is numeric and the other categorical. The categorical variable has more than two levels.</p>
</div>
<div id="categorical-data-1" class="section level2" number="24.3">
<h2><span class="header-section-number">24.3</span> Categorical data</h2>
<p>It is worth spending some time on common approaches to categorical data that you may come across. We have already dealt with categorical data to some extent in this course. We have performed hypothesis tests and built confidence intervals for <span class="math inline">\(\pi\)</span>, the population proportion of “success” in binary cases (for example, support for a local measure in a vote). This problem had a single variable. Also, the golf ball example involved counts of four types of golf ball. This is considered categorical data because each observation is characterized by a qualitative value (number on the ball). The data are summarized by counting how many balls in a sample belong to each type. This again was a single variable.</p>
<p>In another scenario, suppose we are presented with two qualitative variables and would like to know if they are independent. For example, we have discussed methods for determining whether a coin could be fair. What if we wanted to know whether flipping the coin during the day or night changes the fairness of the coin? In this case, we have two categorical variables with two levels each: result of coin flip (heads vs tails) and time of day (day vs night). We have solved this type of problem by looking at a difference in probabilities of success using randomization and mathematically derived solutions, CLT. We also used a hypergeometric distribution to obtain an exact p-value.</p>
<p>We will next explore a scenario that involves categorical data with two variables but where at least one variable has more than two levels. However, note that we are only merely scratching the surface in our studies. You could take an entire course on statistical methods for categorical data. This book is giving you a solid foundation to learn more advanced methods.</p>
<div id="help-example" class="section level3" number="24.3.1">
<h3><span class="header-section-number">24.3.1</span> HELP example</h3>
<p>Let’s return to Health Evaluation and Linkage to Primary Care data set, <code>HELPrct</code> in the <strong>mosaicData</strong> package. Previously, we looked at the differences in ages between males and females, let’s now do the same thing for the variable <code>substance</code>, the primary substance of abuse.</p>
<p>There are three substances: alcohol, cocaine, and heroin. We’d like to know if there is evidence that the proportions of use differ for men and for women. In our data set, we observe modest differences.</p>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb715-1"><a href="#cb715-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>( substance <span class="sc">~</span> sex, <span class="at">data =</span> HELPrct,</span>
<span id="cb715-2"><a href="#cb715-2" aria-hidden="true" tabindex="-1"></a><span class="at">format=</span><span class="st">&quot;prop&quot;</span>, <span class="at">margins =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##          sex
## substance    female      male
##   alcohol 0.3364486 0.4075145
##   cocaine 0.3831776 0.3208092
##   heroin  0.2803738 0.2716763
##   Total   1.0000000 1.0000000</code></pre>
<p>But we need a test statistic to test if there is a difference in substance of abuse between males and females.</p>
</div>
<div id="test-statistic" class="section level3" number="24.3.2">
<h3><span class="header-section-number">24.3.2</span> Test statistic</h3>
<p>To help us develop and understand a test statistic, let’s simplify and use a simple theoretical example.</p>
<p>Suppose we have a 2 x 2 contingency table like the one below.
<span class="math display">\[
\begin{array}{lcc}
&amp; \mbox{Response 1} &amp; \mbox{Response 2} \\
\mbox{Group 1} &amp; n_{11} &amp; n_{12} \\
\mbox{Group 2} &amp; n_{21} &amp; n_{22}
\end{array}
\]</span></p>
<p>If our null hypothesis is that the two variables are independent, a classical test statistic used is the Pearson chi-squared test statistic (<span class="math inline">\(X^2\)</span>). This is similar to the one we used in our golf ball example. Let <span class="math inline">\(e_{ij}\)</span> be the expected count in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column under the null hypothesis, then the test statistic is:
<span class="math display">\[
X^2=\sum_{i=1}^2 \sum_{j=1}^2 {(n_{ij}-e_{ij})^2\over e_{ij}}
\]</span></p>
<p>But how do we find <span class="math inline">\(e_{ij}\)</span>? What do we expect the count to be under <span class="math inline">\(H_0\)</span>? To find this, we recognize that under <span class="math inline">\(H_0\)</span> (independence), a joint probability is equal to the product of the marginal probabilities. Let <span class="math inline">\(\pi_{ij}\)</span> be the probability of an outcome appearing in row <span class="math inline">\(i\)</span> and column <span class="math inline">\(j\)</span>. In the absence of any other information, our best guess at <span class="math inline">\(\pi_{ij}\)</span> is <span class="math inline">\(\hat{\pi}_{ij}={n_{ij}\over n}\)</span>, where <span class="math inline">\(n\)</span> is the total sample size. But under the null hypothesis we have the assumption of independence, thus <span class="math inline">\(\pi_{ij}=\pi_{i+}\pi_{+j}\)</span> where <span class="math inline">\(\pi_{i+}\)</span> represents the total probability of ending up in row <span class="math inline">\(i\)</span> and <span class="math inline">\(\pi_{+j}\)</span> represents the total probability of ending up in column <span class="math inline">\(j\)</span>. Note that <span class="math inline">\(\pi_{i+}\)</span> is estimated by <span class="math inline">\(\hat{\pi}_{i+}\)</span> and
<span class="math display">\[
\hat{\pi}_{i+}={n_{i+}\over n}
\]</span>
Thus for our simple 2 x 2 example, we have:</p>
<p><span class="math display">\[
\hat{\pi}_{i+}={n_{i+}\over n}={n_{i1}+n_{i2}\over n}
\]</span></p>
<p>And for Group 1 we would have:</p>
<p><span class="math display">\[
\hat{\pi}_{1+}={n_{1+}\over n}={n_{11}+n_{12}\over n}
\]</span></p>
<p>So, under <span class="math inline">\(H_0\)</span>, our best guess for <span class="math inline">\(\pi_{ij}\)</span> is:
<span class="math display">\[
\hat{\pi}_{ij}=\hat{\pi}_{i+}\hat{\pi}_{+j}={n_{i+}\over n}{n_{+j}\over n} = {n_{i1}+n_{i2}\over n}{n_{1j}+n_{2j}\over n}
\]</span></p>
<p>Continuing, under <span class="math inline">\(H_0\)</span> the expected cell count is:</p>
<p><span class="math display">\[
e_{ij}=n\hat{\pi}_{ij}=n{n_{i+}\over n}{n_{+j}\over n}={n_{i+}n_{+j}\over n}
\]</span></p>
<p>This may look too abstract, so let’s break it down with an example, totally made up by the way.</p>
<p>Suppose we flip a coin 40 times during the day and 40 times at night and obtain the results below.
<span class="math display">\[
\begin{array}{lcc}
&amp; \mbox{Heads} &amp; \mbox{Tails} \\
\mbox{Day} &amp; 22 &amp; 18 \\
\mbox{Night} &amp; 17 &amp; 23
\end{array}
\]</span></p>
<p>To find the Pearson chi-squared (<span class="math inline">\(X^2\)</span>), we need to figure out the expected value under <span class="math inline">\(H_0\)</span>. Recall that under <span class="math inline">\(H_0\)</span> the two variables are independent. It’s helpful to add the row and column totals prior to finding expected counts:</p>
<p><span class="math display">\[
\begin{array}{lccc}
&amp; \mbox{Heads} &amp; \mbox{Tails} &amp; \mbox{Row Total}\\
\mbox{Day} &amp; 22 &amp; 18  &amp; 40\\
\mbox{Night} &amp; 17 &amp; 23 &amp; 40 \\
\mbox{Column Total} &amp; 39 &amp; 41 &amp; 80
\end{array}
\]</span></p>
<p>Thus under independence, expected count is equal to the row sum multiplied by the column sum divided by the overall sum. So,</p>
<p><span class="math display">\[
e_{11} = {40*39\over 80}= 19.5
\]</span></p>
<p>Continuing in this fashion yields the following table of expected counts:</p>
<p><span class="math display">\[
\begin{array}{lcc}
&amp; \mbox{Heads} &amp; \mbox{Tails} \\
\mbox{Day} &amp; 19.5 &amp; 20.5 \\
\mbox{Night} &amp; 19.5 &amp; 20.5
\end{array}
\]</span></p>
<p>Now we can find <span class="math inline">\(X^2\)</span>:
<span class="math display">\[
X^2= {(22-19.5)^2\over 19.5}+{(17-19.5)^2\over 19.5}+{(18-20.5)^2\over 20.5}+{(23-20.5)^2\over 20.5}
\]</span></p>
<p>As you can probably tell, <span class="math inline">\(X^2\)</span> is essentially comparing the observed counts with the expected counts under <span class="math inline">\(H_0\)</span>. The larger the difference between observed and expected, the larger the value of <span class="math inline">\(X^2\)</span>. It is normalized by dividing by the expected counts since more data in a cell leads to a larger contribution to the sum. Under <span class="math inline">\(H_0\)</span>, this statistic follows the chi-squared distribution with <span class="math inline">\((R-1)(C-1)\)</span>, in this case 1, degrees of freedom (<span class="math inline">\(R\)</span> is the number of rows and <span class="math inline">\(C\)</span> is the number of columns).</p>
<div id="p-value" class="section level4" number="24.3.2.1">
<h4><span class="header-section-number">24.3.2.1</span> p-value</h4>
<p>To find the Pearson chi-squared statistic (<span class="math inline">\(X^2\)</span>) and corresponding p-value from the chi-squared distribution in <code>R</code> use the following code:</p>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb717-1"><a href="#cb717-1" aria-hidden="true" tabindex="-1"></a>e<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fl">19.5</span>,<span class="fl">19.5</span>,<span class="fl">20.5</span>,<span class="fl">20.5</span>)</span>
<span id="cb717-2"><a href="#cb717-2" aria-hidden="true" tabindex="-1"></a>o<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="dv">22</span>,<span class="dv">17</span>,<span class="dv">18</span>,<span class="dv">23</span>)</span>
<span id="cb717-3"><a href="#cb717-3" aria-hidden="true" tabindex="-1"></a>x2<span class="ot">&lt;-</span><span class="fu">sum</span>(((o<span class="sc">-</span>e)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>e)</span>
<span id="cb717-4"><a href="#cb717-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb717-5"><a href="#cb717-5" aria-hidden="true" tabindex="-1"></a>x2</span></code></pre></div>
<pre><code>## [1] 1.250782</code></pre>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="#cb719-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pchisq</span>(x2,<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 0.2634032</code></pre>
<p>Note that the chi-squared test statistic is a sum of squared differences. Thus its distribution, a chi-squared, is skewed right and bounded on the left at zero. A departure from the null hypothesis means a value further in the right tail of the distribution. This is why we use one minus the CDF in the calculation of the p-value.</p>
<p>Again, the <span class="math inline">\(p\)</span>-value suggests there is not enough evidence to say these two variables are dependent.</p>
<p>Of course there is a built in function in <code>R</code> that will make the calculations easier. It is <code>chisq.test()</code>.</p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="#cb721-1" aria-hidden="true" tabindex="-1"></a>coin <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">time =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;Day&quot;</span>,<span class="dv">40</span>),<span class="fu">rep</span>(<span class="st">&quot;Night&quot;</span>,<span class="dv">40</span>)),</span>
<span id="cb721-2"><a href="#cb721-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">result =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Heads&quot;</span>,<span class="st">&quot;Tails&quot;</span>),<span class="fu">c</span>(<span class="dv">22</span>,<span class="dv">18</span>)),<span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Heads&quot;</span>,<span class="st">&quot;Tails&quot;</span>),<span class="fu">c</span>(<span class="dv">17</span>,<span class="dv">23</span>))))</span></code></pre></div>
<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb722-1"><a href="#cb722-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>time<span class="sc">+</span>result,<span class="at">data=</span>coin)</span></code></pre></div>
<pre><code>##        result
## time    Heads Tails
##   Day      22    18
##   Night    17    23</code></pre>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb724-1"><a href="#cb724-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(<span class="fu">tally</span>(<span class="sc">~</span>time<span class="sc">+</span>result,<span class="at">data=</span>coin),<span class="at">correct =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tally(~time + result, data = coin)
## X-squared = 1.2508, df = 1, p-value = 0.2634</code></pre>
<p>If you just want the test statistic, which we will for permutation tests, then use:</p>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb726-1"><a href="#cb726-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq</span>(<span class="sc">~</span>time<span class="sc">+</span>result,<span class="at">data=</span>coin)</span></code></pre></div>
<pre><code>## X.squared 
##  1.250782</code></pre>
</div>
</div>
<div id="extension-to-larger-tables" class="section level3" number="24.3.3">
<h3><span class="header-section-number">24.3.3</span> Extension to larger tables</h3>
<p>The advantage of using the Pearson chi-squared is that it can be extended to larger <strong>contingency tables</strong>, the name given to these tables of multiple categorical variables. Suppose we are comparing two categorical variables, one with <span class="math inline">\(r\)</span> levels and the other with <span class="math inline">\(c\)</span> levels. Then,
<span class="math display">\[
X^2=\sum_{i=1}^r \sum_{j=1}^c {(n_{ij}-e_{ij})^2\over e_{ij}}
\]</span></p>
<p>Under the null hypothesis of independence, the <span class="math inline">\(X^2\)</span> test statistic follows the chi-squared distribution with <span class="math inline">\((r-1)(c-1)\)</span> degrees of freedom.</p>
<div id="assumptions" class="section level4" number="24.3.3.1">
<h4><span class="header-section-number">24.3.3.1</span> Assumptions</h4>
<p>Note that to use this test statistic, the expected cell counts must be reasonably large. In fact, no <span class="math inline">\(e_{ij}\)</span> should be less than 1 and no more than 20% of the <span class="math inline">\(e_{ij}\)</span>’s should be less than 5. If this occurs, you should combine cells or look for a different test.</p>
</div>
</div>
<div id="permutation-test-1" class="section level3" number="24.3.4">
<h3><span class="header-section-number">24.3.4</span> Permutation test</h3>
<p>We will complete our analysis of the HELP data first using a randomization, approximate permutation, test.</p>
<p>First let’s write the hypotheses:</p>
<p><span class="math inline">\(H_0\)</span>: The variables sex and substance are independent.<br />
<span class="math inline">\(H_a\)</span>: The variables sex and substance are dependent.</p>
<p>We will use the chi-squared test statistic as our test statistic. We could use a different test statistic such as using the absolute value function instead of the square function but then we would need to write a custom function.</p>
<p>First, let’s get the observed value for the test statistic:</p>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb728-1"><a href="#cb728-1" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> <span class="fu">chisq</span>(substance<span class="sc">~</span>sex,<span class="at">data=</span>HELPrct)</span>
<span id="cb728-2"><a href="#cb728-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>## X.squared 
##  2.026361</code></pre>
<p>Next we will use a permutation randomization process to find the sampling distribution of our test statistics.</p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="#cb730-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2720</span>)</span>
<span id="cb730-2"><a href="#cb730-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">chisq</span>(substance<span class="sc">~</span><span class="fu">shuffle</span>(sex),<span class="at">data=</span>HELPrct)</span></code></pre></div>
<p>Figure @ref(fig:hist241-fig) is a visual summary of the results which helps us to gain some intuition about the p-value. We also plot the theoretical chi-squared distribution as a dark blue overlay.</p>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="#cb731-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb731-2"><a href="#cb731-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dhistogram</span>(<span class="sc">~</span>X.squared,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb731-3"><a href="#cb731-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> obs,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb731-4"><a href="#cb731-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb731-5"><a href="#cb731-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dist</span>(<span class="st">&quot;chisq&quot;</span>,<span class="at">df=</span><span class="dv">2</span>,<span class="at">color=</span><span class="st">&quot;darkblue&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb731-6"><a href="#cb731-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Sampling distribution of chi-squared test statistic&quot;</span>,</span>
<span id="cb731-7"><a href="#cb731-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">subtitle=</span><span class="st">&quot;For the variables sex and substance in the HELPrct data set&quot;</span>,</span>
<span id="cb731-8"><a href="#cb731-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Test statistic&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="24-Additional-Hypothesis-Tests_files/figure-html/hist241-fig-1.png" alt="Sampling distribution of chi-squared statistic from randomization test." width="672" />
<p class="caption">
(#fig:hist241-fig)Sampling distribution of chi-squared statistic from randomization test.
</p>
</div>
<p>We find the p-value using <code>prop1()</code>.</p>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb732-1"><a href="#cb732-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop1</span>((<span class="sc">~</span>X.squared<span class="sc">&gt;=</span>obs),<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>## prop_TRUE 
## 0.3536464</code></pre>
<p>We don’t double this value because the chi-squared is a one sided test due to the fact that we squared the differences.</p>
<p>Based on this p-value, we fail to reject the hypothesis that the variables are independent.</p>
</div>
<div id="chi-squared-test" class="section level3" number="24.3.5">
<h3><span class="header-section-number">24.3.5</span> Chi-squared test</h3>
<p>We will jump straight to using the function <code>chisq.test()</code>.</p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="#cb734-1" aria-hidden="true" tabindex="-1"></a><span class="fu">chisq.test</span>(<span class="fu">tally</span>(substance<span class="sc">~</span>sex,<span class="at">data=</span>HELPrct))</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tally(substance ~ sex, data = HELPrct)
## X-squared = 2.0264, df = 2, p-value = 0.3631</code></pre>
<p>We get a p-value very close to the one from the randomization permutation test. Remember in the randomization test we shuffled the variable <code>sex</code> over many replications and calculated a value for the test statistic for each replication. We did this shuffling because the null hypothesis assumed independence of the two variables. This process led to an empirical estimate of the sampling distribution, the gray histogram in the previous graph. In this section, under the null hypothesis and the appropriate assumptions, the sampling distribution is a chi-squared, the blue line in the previous graph. We used it to calculate the p-value directly.</p>
<p>Notice that if the null hypothesis is true the test statistic has the minimum value of zero. We can’t use a bootstrap confidence interval on this problem because zero will never be in the interval. It can only be on the edge of an interval.</p>
</div>
</div>
<div id="numerical-data-2" class="section level2" number="24.4">
<h2><span class="header-section-number">24.4</span> Numerical data</h2>
<p>Sometimes we want to compare means across many groups. In this case we have two variables where one is continuous and the other categorical. We might initially think to do pairwise comparisons, two sample t-tests, as a solution; for example, if there were three groups, we might be tempted to compare the first mean with the second, then with the third, and then finally compare the second and third means for a total of three comparisons. However, this strategy can be treacherous. If we have many groups and do many comparisons, it is likely that we will eventually find a difference just by chance, even if there is no difference in the populations.</p>
<p>In this section, we will learn a new method called <strong>analysis of variance</strong> (ANOVA) and a new test statistic called <span class="math inline">\(F\)</span>. ANOVA uses a single hypothesis test to check whether the means across many groups are equal. The hypotheses are:</p>
<p><span class="math inline">\(H_0\)</span>: The mean outcome is the same across all groups. In statistical notation, <span class="math inline">\(\mu_1 = \mu_2 = \cdots = \mu_k\)</span> where <span class="math inline">\(\mu_i\)</span> represents the mean of the outcome for observations in category <span class="math inline">\(i\)</span>.<br />
<span class="math inline">\(H_A\)</span>: At least one mean is different.</p>
<p>Generally we must check three conditions on the data before performing ANOVA with the <span class="math inline">\(F\)</span> distribution:</p>
<ol style="list-style-type: lower-roman">
<li>the observations are independent within and across groups,<br />
</li>
<li>the data within each group are nearly normal, and<br />
</li>
<li>the variability across the groups is about equal.</li>
</ol>
<p>When these three conditions are met, we may perform an ANOVA to determine whether the data provide strong evidence against the null hypothesis that all the <span class="math inline">\(\mu_i\)</span> are equal.</p>
<div id="mlb-batting-performance" class="section level3" number="24.4.1">
<h3><span class="header-section-number">24.4.1</span> MLB batting performance</h3>
<p>We would like to discern whether there are real differences between the batting performance of baseball players according to their position: outfielder (<code>OF</code>), infielder (<code>IF</code>), designated hitter (<code>DH</code>), and catcher (<code>C</code>). We will use a data set <code>mlbbat10</code> from the <strong>openintro</strong> package but we saved it is in the file <code>mlb_obp.csv</code> which has been modified from the original data set to include only those with more than 200 at bats. The batting performance will be measured with the on-base percentage. The on-base percentage roughly represents the fraction of the time a player successfully gets on base or hits a home run.</p>
<p>Read the data into <code>R</code>.</p>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="#cb736-1" aria-hidden="true" tabindex="-1"></a>mlb_obp <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/mlb_obp.csv&quot;</span>)</span></code></pre></div>
<p>Let’s review our data:</p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="#cb737-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(mlb_obp)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##       name     class levels   n missing
## 1 position character      4 327       0
##                                    distribution
## 1 IF (47.1%), OF (36.7%), C (11.9%) ...        
## 
## quantitative variables:  
##      name   class   min    Q1 median     Q3   max     mean         sd   n
## ...1  obp numeric 0.174 0.309  0.331 0.3545 0.437 0.332159 0.03570249 327
##      missing
## ...1       0</code></pre>
<p>Next change the variable <code>position</code> to a factor to give us greater control.</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="#cb739-1" aria-hidden="true" tabindex="-1"></a>mlb_obp <span class="ot">&lt;-</span> mlb_obp <span class="sc">%&gt;%</span></span>
<span id="cb739-2"><a href="#cb739-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">position=</span><span class="fu">as.factor</span>(position))</span></code></pre></div>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="#cb740-1" aria-hidden="true" tabindex="-1"></a><span class="fu">favstats</span>(obp<span class="sc">~</span>position,<span class="at">data=</span>mlb_obp)</span></code></pre></div>
<pre><code>##   position   min      Q1 median      Q3   max      mean         sd   n missing
## 1        C 0.219 0.30000 0.3180 0.35700 0.405 0.3226154 0.04513175  39       0
## 2       DH 0.287 0.31625 0.3525 0.36950 0.412 0.3477857 0.03603669  14       0
## 3       IF 0.174 0.30800 0.3270 0.35275 0.437 0.3315260 0.03709504 154       0
## 4       OF 0.265 0.31475 0.3345 0.35300 0.411 0.3342500 0.02944394 120       0</code></pre>
<p>The means for each group are pretty close to each other.</p>
<blockquote>
<p><strong>Exercise</strong>:
The null hypothesis under consideration is the following: <span class="math inline">\(\mu_{OF} = \mu_{IF} = \mu_{DH} = \mu_{C}\)</span>.
Write the null and corresponding alternative hypotheses in plain language.<a href="#fn89" class="footnote-ref" id="fnref89"><sup>89</sup></a></p>
</blockquote>
<p>If we have all the data for the 2010 season, why do we need a hypothesis test? What is the population of interest?</p>
<p>If we are only making decisions or claims about the 2010 season, we do not need hypothesis testing. We can just use summary statistics. However, if we want to generalize to other years or other leagues, then we would need a hypothesis test.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Construct side-by-side boxplots.</p>
</blockquote>
<p>Figure @ref(fig:box241-fig) is the side-by-side boxplots.</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="#cb742-1" aria-hidden="true" tabindex="-1"></a>mlb_obp <span class="sc">%&gt;%</span></span>
<span id="cb742-2"><a href="#cb742-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_boxplot</span>(obp<span class="sc">~</span>position) <span class="sc">%&gt;%</span></span>
<span id="cb742-3"><a href="#cb742-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Position Played&quot;</span>,<span class="at">y=</span><span class="st">&quot;On Base Percentage&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb742-4"><a href="#cb742-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb742-5"><a href="#cb742-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Comparison of OBP for different positions&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="24-Additional-Hypothesis-Tests_files/figure-html/box241-fig-1.png" alt="Boxplots of on base percentage by position played." width="672" />
<p class="caption">
(#fig:box241-fig)Boxplots of on base percentage by position played.
</p>
</div>
<p>The largest difference between the sample means is between the designated hitter and the catcher positions. Consider again the original hypotheses:</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{OF} = \mu_{IF} = \mu_{DH} = \mu_{C}\)</span><br />
<span class="math inline">\(H_A\)</span>: The average on-base percentage (<span class="math inline">\(\mu_i\)</span>) varies across some (or all) groups.</p>
<p>Why might it be inappropriate to run the test by simply estimating whether the difference of <span class="math inline">\(\mu_{DH}\)</span> and <span class="math inline">\(\mu_{C}\)</span> is statistically significant at a 0.05 significance level? The primary issue here is that we are inspecting the data before picking the groups that will be compared. It is inappropriate to examine all data by eye (informal testing) and only afterwards decide which parts to formally test. This is called <strong>data snooping</strong> or <strong>data fishing</strong>. Naturally we would pick the groups with the large differences for the formal test, leading to an inflation in the Type 1 Error rate. To understand this better, let’s consider a slightly different problem.</p>
<p>Suppose we are to measure the aptitude for students in 20 classes in a large elementary school at the beginning of the year. In this school, all students are randomly assigned to classrooms, so any differences we observe between the classes at the start of the year are completely due to chance. However, with so many groups, we will probably observe a few groups that look rather different from each other. If we select only these classes that look so different, we will probably make the wrong conclusion that the assignment wasn’t random. While we might only formally test differences for a few pairs of classes, we informally evaluated the other classes by eye before choosing the most extreme cases for a comparison.</p>
<p>In the next section we will learn how to use the <span class="math inline">\(F\)</span> statistic and ANOVA to test whether observed differences in means could have happened just by chance even if there was no difference in the respective population means.</p>
</div>
<div id="analysis-of-variance-anova-and-the-f-test" class="section level3" number="24.4.2">
<h3><span class="header-section-number">24.4.2</span> Analysis of variance (ANOVA) and the F test</h3>
<p>The method of analysis of variance in this context focuses on answering one question: is the variability in the sample means so large that it seems unlikely to be from chance alone? This question is different from earlier testing procedures since we will <em>simultaneously</em> consider many groups, and evaluate whether their sample means differ more than we would expect from natural variation. We call this variability the <strong>mean square between groups</strong> (<span class="math inline">\(MSG\)</span>), and it has an associated degrees of freedom, <span class="math inline">\(df_{G}=k-1\)</span> when there are <span class="math inline">\(k\)</span> groups. The <span class="math inline">\(MSG\)</span> can be thought of as a scaled variance formula for means. If the null hypothesis is true, any variation in the sample means is due to chance and shouldn’t be too large. We typically use software to find <span class="math inline">\(MSG\)</span>, however, the derivation follows. Let <span class="math inline">\(\bar{x}\)</span> represent the mean of outcomes across all groups. Then the mean square between groups is computed as<br />
<span class="math display">\[
MSG = \frac{1}{df_{G}}SSG = \frac{1}{k-1}\sum_{i=1}^{k} n_{i}\left(\bar{x}_{i} - \bar{x}\right)^2
\]</span></p>
<p>where <span class="math inline">\(SSG\)</span> is called the <strong>sum of squares between groups</strong> and <span class="math inline">\(n_{i}\)</span> is the sample size of group <span class="math inline">\(i\)</span>.</p>
<p>The mean square between the groups is, on its own, quite useless in a hypothesis test. We need a benchmark value for how much variability should be expected among the sample means if the null hypothesis is true. To this end, we compute a pooled variance estimate, often abbreviated as the <strong>mean square error</strong> (<span class="math inline">\(MSE\)</span>), which has an associated degrees of freedom value <span class="math inline">\(df_E=n-k\)</span>. It is helpful to think of <span class="math inline">\(MSE\)</span> as a measure of the variability within the groups. To find <span class="math inline">\(MSE\)</span>, let <span class="math inline">\(\bar{x}\)</span> represent the mean of outcomes across all groups. Then the <strong>sum of squares total</strong> (<span class="math inline">\(SST\)</span>)} is computed as
<span class="math inline">\(SST = \sum_{i=1}^{n} \left(x_{i} - \bar{x}\right)^2\)</span>,
where the sum is over all observations in the data set. Then we compute the <strong>sum of squared errors</strong> (<span class="math inline">\(SSE\)</span>) in one of two equivalent ways:</p>
<p><span class="math display">\[
SSE = SST - SSG = (n_1-1)s_1^2 + (n_2-1)s_2^2 + \cdots + (n_k-1)s_k^2
\]</span></p>
<p>where <span class="math inline">\(s_i^2\)</span> is the sample variance (square of the standard deviation) of the residuals in group <span class="math inline">\(i\)</span>. Then the <span class="math inline">\(MSE\)</span> is the standardized form of <span class="math inline">\(SSE\)</span>: <span class="math inline">\(MSE = \frac{1}{df_{E}}SSE\)</span>.</p>
<p>When the null hypothesis is true, any differences among the sample means are only due to chance, and the <span class="math inline">\(MSG\)</span> and <span class="math inline">\(MSE\)</span> should be about equal. As a test statistic for ANOVA, we examine the fraction of <span class="math inline">\(MSG\)</span> and <span class="math inline">\(MSE\)</span>:</p>
<p><span class="math display">\[F = \frac{MSG}{MSE}\]</span></p>
<p>The <span class="math inline">\(MSG\)</span> represents a measure of the between-group variability, and <span class="math inline">\(MSE\)</span> measures the variability within each of the groups. Using a permutation test, we could look at the difference in the mean squared errors as a test statistic instead of the ratio.</p>
<p>We can use the <span class="math inline">\(F\)</span> statistic to evaluate the hypotheses in what is called an <strong>F test</strong>. A p-value can be computed from the <span class="math inline">\(F\)</span> statistic using an <span class="math inline">\(F\)</span> distribution, which has two associated parameters: <span class="math inline">\(df_{1}\)</span> and <span class="math inline">\(df_{2}\)</span>. For the <span class="math inline">\(F\)</span> statistic in ANOVA, <span class="math inline">\(df_{1} = df_{G}\)</span> and <span class="math inline">\(df_{2}= df_{E}\)</span>. The <span class="math inline">\(F\)</span> is really a ratio of chi-squared distributions.</p>
<p>The larger the observed variability in the sample means (<span class="math inline">\(MSG\)</span>) relative to the within-group observations (<span class="math inline">\(MSE\)</span>), the larger <span class="math inline">\(F\)</span> will be and the stronger the evidence against the null hypothesis. Because larger values of <span class="math inline">\(F\)</span> represent stronger evidence against the null hypothesis, we use the upper tail of the distribution to compute a p-value.</p>
<blockquote>
<p><strong>The <span class="math inline">\(F\)</span> statistic and the <span class="math inline">\(F\)</span> test</strong><br />
Analysis of variance (ANOVA) is used to test whether the mean outcome differs across 2 or more groups. ANOVA uses a test statistic <span class="math inline">\(F\)</span>, which represents a standardized ratio of variability in the sample means relative to the variability within the groups. If <span class="math inline">\(H_0\)</span> is true and the model assumptions are satisfied, the statistic <span class="math inline">\(F\)</span> follows an <span class="math inline">\(F\)</span> distribution with parameters <span class="math inline">\(df_{1}=k-1\)</span> and <span class="math inline">\(df_{2}=n-k\)</span>. The upper tail of the <span class="math inline">\(F\)</span> distribution is used to represent the p-value.</p>
</blockquote>
<div id="anova" class="section level4" number="24.4.2.1">
<h4><span class="header-section-number">24.4.2.1</span> ANOVA</h4>
<p>We will use <code>R</code> to perform the calculations for the ANOVA. But let’s check our assumptions first.</p>
<p>There are three conditions we must check for an ANOVA analysis: all observations must be independent, the data in each group must be nearly normal, and the variance within each group must be approximately equal.</p>
<blockquote>
<p><strong>Independence</strong><br />
If the data are a simple random sample from less than 10% of the population, this condition is reasonable. For processes and experiments, carefully consider whether the data may be independent (e.g. no pairing). In our MLB data, the data were not sampled. However, there are not obvious reasons why independence would not hold for most or all observations. This is a bit of hand waving but remember independence is difficult to assess.</p>
</blockquote>
<blockquote>
<p><strong>Approximately normal</strong><br />
As with one- and two-sample testing for means, the normality assumption is especially important when the sample size is quite small. The normal probability plots for each group of the MLB data are shown below; there is some deviation from normality for infielders, but this isn’t a substantial concern since there are over 150 observations in that group and the outliers are not extreme. Sometimes in ANOVA there are so many groups or so few observations per group that checking normality for each group isn’t reasonable. One solution is to combine the groups into one set of data. First calculate the <strong>residuals</strong> of the baseball data, which are calculated by taking the observed values and subtracting the corresponding group means. For example, an outfielder with OBP of 0.435 would have a residual of <span class="math inline">\(0.435 - \bar{x}_{OF} = 0.082\)</span>. Then to check the normality condition, create a normal probability plot using all the residuals simultaneously.</p>
</blockquote>
<p>Figure @ref(fig:qq241-fig) is the quantile-quantile plot to assess the normality assumption.</p>
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb743-1"><a href="#cb743-1" aria-hidden="true" tabindex="-1"></a>mlb_obp <span class="sc">%&gt;%</span></span>
<span id="cb743-2"><a href="#cb743-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_qq</span>(<span class="sc">~</span>obp<span class="sc">|</span>position) <span class="sc">%&gt;%</span></span>
<span id="cb743-3"><a href="#cb743-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_qqline</span>() <span class="sc">%&gt;%</span></span>
<span id="cb743-4"><a href="#cb743-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="24-Additional-Hypothesis-Tests_files/figure-html/qq241-fig-1.png" alt="Quantile-quantile plot for two-sample test of means." width="672" />
<p class="caption">
(#fig:qq241-fig)Quantile-quantile plot for two-sample test of means.
</p>
</div>
<blockquote>
<p><strong>Constant variance</strong><br />
The last assumption is that the variance in the groups is about equal from one group to the next. This assumption can be checked by examining a side-by-side box plot of the outcomes across the groups which we did previously. In this case, the variability is similar in the four groups but not identical. We also see in the output of <code>favstats</code> that the standard deviation varies a bit from one group to the next. Whether these differences are from natural variation is unclear, so we should report this uncertainty of meeting this assumption when the final results are reported. The permutation test does not have this assumption and can be used as a check on the results from the ANOVA.</p>
</blockquote>
<p>In summary, independence is always important to an ANOVA analysis. The normality condition is very important when the sample sizes for each group are relatively small. The constant variance condition is especially important when the sample sizes differ between groups.</p>
<p>Let’s write the hypotheses again.</p>
<p><span class="math inline">\(H_0\)</span>: The average on-base percentage is equal across the four positions.<br />
<span class="math inline">\(H_A\)</span>: The average on-base percentage varies across some (or all) groups.</p>
<p>The test statistic is the ratio of the between means variance and the pooled within group variance.</p>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb744-1"><a href="#cb744-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">aov</span>(obp<span class="sc">~</span>position,<span class="at">data=</span>mlb_obp))</span></code></pre></div>
<pre><code>##              Df Sum Sq  Mean Sq F value Pr(&gt;F)
## position      3 0.0076 0.002519   1.994  0.115
## Residuals   323 0.4080 0.001263</code></pre>
<p>The table contains all the information we need. It has the degrees of freedom, mean squared errors, test statistic, and p-value. The test statistic is 1.994, <span class="math inline">\(\frac{0.002519}{0.001263}=1.994\)</span>. The p-value is larger than 0.05, indicating the evidence is not strong enough to reject the null hypothesis at a significance level of 0.05. That is, the data do not provide strong evidence that the average on-base percentage varies by player’s primary field position.</p>
<p>The calculation of the p-value is</p>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="#cb746-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pf</span>(<span class="fl">1.994</span>,<span class="dv">3</span>,<span class="dv">323</span>,<span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.1147443</code></pre>
<p>Figure @ref(fig:dens242-fig) is a plot of the <span class="math inline">\(F\)</span> distribution.</p>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb748-1"><a href="#cb748-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;f&quot;</span>,<span class="at">df1=</span><span class="dv">3</span>,<span class="at">df2=</span><span class="dv">323</span>) <span class="sc">%&gt;%</span></span>
<span id="cb748-2"><a href="#cb748-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> <span class="fl">1.994</span>,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb748-3"><a href="#cb748-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb748-4"><a href="#cb748-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;F distribution&quot;</span>,<span class="at">x=</span><span class="st">&quot;F value&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="24-Additional-Hypothesis-Tests_files/figure-html/dens242-fig-1.png" alt="The F distribution" width="672" />
<p class="caption">
(#fig:dens242-fig)The F distribution
</p>
</div>
</div>
<div id="permutation-test-2" class="section level4" number="24.4.2.2">
<h4><span class="header-section-number">24.4.2.2</span> Permutation test</h4>
<p>We can repeat the same analysis using a permutation test. We will first run it using a ratio of variances and then for interest as a difference in variances.</p>
<p>We need a way to extract the mean squared errors from the output. There is a package called <strong>broom</strong> and within it a function called <code>tidy()</code> that cleans up output from functions and makes them into data frames.</p>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb749-1"><a href="#cb749-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span></code></pre></div>
<div class="sourceCode" id="cb750"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb750-1"><a href="#cb750-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aov</span>(obp<span class="sc">~</span>position,<span class="at">data=</span>mlb_obp) <span class="sc">%&gt;%</span></span>
<span id="cb750-2"><a href="#cb750-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 2 x 6
##   term         df   sumsq  meansq statistic p.value
##   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 position      3 0.00756 0.00252      1.99   0.115
## 2 Residuals   323 0.408   0.00126     NA     NA</code></pre>
<p>Let’s summarize the values in the <code>meansq</code> column and develop our test statistic, we could just pull the statistic but we want to be able to generate a difference test statistic as well.</p>
<div class="sourceCode" id="cb752"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb752-1"><a href="#cb752-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aov</span>(obp<span class="sc">~</span>position,<span class="at">data=</span>mlb_obp) <span class="sc">%&gt;%</span></span>
<span id="cb752-2"><a href="#cb752-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb752-3"><a href="#cb752-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">stat=</span>meansq[<span class="dv">1</span>]<span class="sc">/</span>meansq[<span class="dv">2</span>]) </span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  1.99</code></pre>
<p>Now we are ready. First get our test statistic using <code>pull()</code>.</p>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb754-1"><a href="#cb754-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">aov</span>(obp<span class="sc">~</span>position,<span class="at">data=</span>mlb_obp) <span class="sc">%&gt;%</span></span>
<span id="cb754-2"><a href="#cb754-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb754-3"><a href="#cb754-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">stat=</span>meansq[<span class="dv">1</span>]<span class="sc">/</span>meansq[<span class="dv">2</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb754-4"><a href="#cb754-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>()</span>
<span id="cb754-5"><a href="#cb754-5" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>## [1] 1.994349</code></pre>
<p>Let’s put our test statistic into a function to include shuffling the <code>position</code> variable.</p>
<div class="sourceCode" id="cb756"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb756-1"><a href="#cb756-1" aria-hidden="true" tabindex="-1"></a>f_stat <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb756-2"><a href="#cb756-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aov</span>(obp<span class="sc">~</span><span class="fu">shuffle</span>(position),<span class="at">data=</span>x) <span class="sc">%&gt;%</span></span>
<span id="cb756-3"><a href="#cb756-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb756-4"><a href="#cb756-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">stat=</span>meansq[<span class="dv">1</span>]<span class="sc">/</span>meansq[<span class="dv">2</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb756-5"><a href="#cb756-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>()</span>
<span id="cb756-6"><a href="#cb756-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb757-1"><a href="#cb757-1" aria-hidden="true" tabindex="-1"></a><span class="fu">f_stat</span>(mlb_obp)</span></code></pre></div>
<pre><code>## [1] 0.4160649</code></pre>
<p>Next we run the randomization test using the <code>do()</code> function. There is an easier way to do all of this work with the <strong>purrr</strong> package but we will continue with the work we have started.</p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="#cb759-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5321</span>)</span>
<span id="cb759-2"><a href="#cb759-2" aria-hidden="true" tabindex="-1"></a>results<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span>(<span class="fu">f_stat</span>(mlb_obp))</span></code></pre></div>
<p>That was slow in executing because we are using <strong>tidyverse</strong> functions that are slow.</p>
<p>Figure @ref(fig:hist243-fig) is a plot of the sampling distribution from the randomization test.</p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb760-1"><a href="#cb760-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb760-2"><a href="#cb760-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dhistogram</span>(<span class="sc">~</span>result,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb760-3"><a href="#cb760-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dist</span>(<span class="st">&quot;f&quot;</span>,<span class="at">df1=</span><span class="dv">3</span>,<span class="at">df2=</span><span class="dv">323</span>,<span class="at">color=</span><span class="st">&quot;darkblue&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb760-4"><a href="#cb760-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> <span class="fl">1.994</span>,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb760-5"><a href="#cb760-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb760-6"><a href="#cb760-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Randomization test sampling distribution&quot;</span>,</span>
<span id="cb760-7"><a href="#cb760-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">subtitle=</span><span class="st">&quot;F distribution is overlayed in blue&quot;</span>,</span>
<span id="cb760-8"><a href="#cb760-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Test statistic&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="24-Additional-Hypothesis-Tests_files/figure-html/hist243-fig-1.png" alt="The sampling distribution of the randomization test statistic." width="672" />
<p class="caption">
(#fig:hist243-fig)The sampling distribution of the randomization test statistic.
</p>
</div>
<p>The p-value is</p>
<div class="sourceCode" id="cb761"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb761-1"><a href="#cb761-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop1</span>(<span class="sc">~</span>(result<span class="sc">&gt;=</span>obs),results)</span></code></pre></div>
<pre><code>## prop_TRUE 
## 0.0959041</code></pre>
<p>This is a similar p-value from the ANOVA output.</p>
<p>Now let’s repeat the analysis but use the difference in variance as our test statistic.</p>
<div class="sourceCode" id="cb763"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb763-1"><a href="#cb763-1" aria-hidden="true" tabindex="-1"></a>f_stat2 <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb763-2"><a href="#cb763-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aov</span>(obp<span class="sc">~</span><span class="fu">shuffle</span>(position),<span class="at">data=</span>x) <span class="sc">%&gt;%</span></span>
<span id="cb763-3"><a href="#cb763-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb763-4"><a href="#cb763-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">stat=</span>meansq[<span class="dv">1</span>]<span class="sc">-</span>meansq[<span class="dv">2</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb763-5"><a href="#cb763-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(stat)</span>
<span id="cb763-6"><a href="#cb763-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb764-1"><a href="#cb764-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5321</span>)</span>
<span id="cb764-2"><a href="#cb764-2" aria-hidden="true" tabindex="-1"></a>results<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span>(<span class="fu">f_stat2</span>(mlb_obp))</span></code></pre></div>
<p>Figure @ref(fig:hist244-fig) is the plot of the sampling distribution of the difference in variance.</p>
<div class="sourceCode" id="cb765"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb765-1"><a href="#cb765-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb765-2"><a href="#cb765-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_dhistogram</span>(<span class="sc">~</span>result,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb765-3"><a href="#cb765-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.001255972</span>,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb765-4"><a href="#cb765-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb765-5"><a href="#cb765-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Randomization test sampling distribution&quot;</span>,</span>
<span id="cb765-6"><a href="#cb765-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">subtitle=</span><span class="st">&quot;Test statistic is the difference in variances&quot;</span>,</span>
<span id="cb765-7"><a href="#cb765-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Test statistic&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="24-Additional-Hypothesis-Tests_files/figure-html/hist244-fig-1.png" alt="The sampling distribution of the difference in variance randomization test statistic." width="672" />
<p class="caption">
(#fig:hist244-fig)The sampling distribution of the difference in variance randomization test statistic.
</p>
</div>
<p>We need the observed value to find a p-value.</p>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="#cb766-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">aov</span>(obp<span class="sc">~</span>position,<span class="at">data=</span>mlb_obp) <span class="sc">%&gt;%</span></span>
<span id="cb766-2"><a href="#cb766-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb766-3"><a href="#cb766-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">stat=</span>meansq[<span class="dv">1</span>]<span class="sc">-</span>meansq[<span class="dv">2</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb766-4"><a href="#cb766-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(stat)</span>
<span id="cb766-5"><a href="#cb766-5" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>## [1] 0.001255972</code></pre>
<p>The p-value is</p>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb768-1"><a href="#cb768-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop1</span>(<span class="sc">~</span>(result<span class="sc">&gt;=</span>obs),results)</span></code></pre></div>
<pre><code>## prop_TRUE 
## 0.0959041</code></pre>
<p>Again a similar p-value.</p>
<p>If we reject in the ANOVA test, we know there is a difference in at least one mean but we don’t know which ones. How would you approach answering that question, which means are different?</p>
</div>
</div>
</div>
<div id="homework-problems-23" class="section level2" number="24.5">
<h2><span class="header-section-number">24.5</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Golf balls</li>
</ol>
<p>Repeat the analysis of the golf ball problem from earlier in the book.</p>
<ol style="list-style-type: lower-alpha">
<li>Load the data and tally the data into a table. The data is in <code>golf_balls.csv</code>.<br />
</li>
<li>Using the function <code>chisq.test()</code>, conduct a hypothesis test of equally likely distribution of balls. You may have to read the help menu.<br />
</li>
<li>Repeat part b. but assume balls with the numbers 1 and 2 occur 30% of the time and balls with 3 and 4 occur 20%.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Bootstrap hypothesis testing</li>
</ol>
<p>Repeat the analysis of the MLB data from the reading but this time generate a bootstrap distribution of the <span class="math inline">\(F\)</span> statistic.</p>
<ol start="3" style="list-style-type: decimal">
<li>Test of variance</li>
</ol>
<p>We have not performed a test of variance so we will create our own.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Using the MLB from the reading, subset on <code>IF</code> and <code>OF</code>.</p></li>
<li><p>Create a side-by-side boxplot.</p></li>
</ol>
<p>The hypotheses are:<br />
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\sigma^2_{IF}=\sigma^2_{OF}\)</span>. There is no difference in the variance of on base percentage for infielders and outfielders.<br />
<span class="math inline">\(H_A\)</span>: <span class="math inline">\(\sigma^2_{IF}\neq \sigma^2_{OF}\)</span>. There is a difference in variances.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Use the differences in sample standard deviations as your test statistic. Using a permutation test, find the p-value and discuss your decision.<br />
</li>
<li>Create a bootstrap distribution of the differences in sample standard deviations, and report a 95% confidence interval. Compare with part d.</li>
</ol>
<!--chapter:end:24-Additional-Hypothesis-Tests.Rmd-->
</div>
</div>
<div id="part-predictive-statistical-modeling" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Predictive Statistical Modeling</h1>
</div>
<div id="CS4" class="section level1" number="25">
<h1><span class="header-section-number">25</span> Case Study</h1>
<div id="objectives-23" class="section level2" number="25.1">
<h2><span class="header-section-number">25.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Using <code>R</code>, generate a linear regression model and use it to produce a prediction model.<br />
</li>
<li>Using plots, check the assumptions of a linear regression model.</li>
</ol>
</div>
<div id="introduction-to-linear-regression" class="section level2" number="25.2">
<h2><span class="header-section-number">25.2</span> Introduction to linear regression</h2>
<p>Linear regression is often one of the first methods taught in a machine learning course. It is an excellent tool with a wide range of applications. It can be used solely to predict an outcome of interest, a prediction model, and/or be used for inference. In this book, we will mainly focus on its use for inference. Even so, this treatment barely scratches the surface of what can be done. There are entire courses devoted to the interpretation of linear regression models.</p>
<p>When used as a predictive model, linear regression fits into the category of a function approximation method. The parameters of the model, function, are fit using an objective, loss, function and optimization procedure. For linear regression in this book, the loss function will be sum of squared errors which leads to closed form solution using differentiation. In machine learning courses you will learn about different types of loss functions to include penalized or regularized versions as well as different optimization engines. For software such as <code>tidymodels</code> in <code>R</code> or <code>scitkit-learn</code> in <code>python</code>, you will specify the loss function and optimization engine directly.</p>
</div>
<div id="case-study-introduction" class="section level2" number="25.3">
<h2><span class="header-section-number">25.3</span> Case study introduction</h2>
<p>The Human Freedom Index is a report that attempts to summarize the idea of “freedom” through a bunch of different variables for many countries around the globe. It serves as a rough objective measure for the relationships between the different types of freedom - whether it’s political, religious, economical or personal freedom - and other social and economic circumstances. The Human Freedom Index is an annually co-published report by the Cato Institute, the Fraser Institute, and the Liberales Institut at the Friedrich Naumann Foundation for Freedom.</p>
<p>In this case study, you’ll be analyzing data from Human Freedom Index reports from 2008-2016. Your aim will be to summarize a few of the relationships within the data both graphically and numerically in order to find which variables can help tell a story about freedom. This will be done using the tool of regression.</p>
<p>Again, like our previous case studies, this chapter will introduce many of the ideas of the block. Don’t worry if they seem difficult and you feel overwhelmed a bit, we will come back to the ideas in the following chapters.</p>
<div id="load-packages" class="section level3" number="25.3.1">
<h3><span class="header-section-number">25.3.1</span> Load packages</h3>
<p>Let’s load the packages.</p>
<div class="sourceCode" id="cb770"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb770-1"><a href="#cb770-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb770-2"><a href="#cb770-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mosaic)</span></code></pre></div>
</div>
<div id="the-data-and-exploratory-analysis" class="section level3" number="25.3.2">
<h3><span class="header-section-number">25.3.2</span> The data and exploratory analysis</h3>
<p>The data we’re working with is in the file called <code>hfi.csv</code> under the <code>data</code> folder. The name <code>hfi</code> is
short for Human Freedom Index.</p>
<blockquote>
<p><strong>Exercise</strong><br />
Read the data into <code>R</code>. What are the dimensions of the dataset?</p>
</blockquote>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb771-1"><a href="#cb771-1" aria-hidden="true" tabindex="-1"></a>hfi<span class="ot">&lt;-</span><span class="fu">tibble</span>(<span class="fu">read_csv</span>(<span class="st">&quot;data/hfi.csv&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb772"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb772-1"><a href="#cb772-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(hfi)</span></code></pre></div>
<pre><code>## [1] 1458  123</code></pre>
<p>There are 1458 observations and 123 variables in the data frame.</p>
<blockquote>
<p><strong>Exercise</strong><br />
Create summaries of the first 10 variables in the data. We just don’t want a large printout.</p>
</blockquote>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="#cb774-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(hfi[,<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>])</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##        name     class levels    n missing
## 1  ISO_code character    162 1458       0
## 2 countries character    162 1458       0
## 3    region character     10 1458       0
##                                    distribution
## 1 AGO (0.6%), ALB (0.6%), ARE (0.6%) ...       
## 2 Albania (0.6%), Algeria (0.6%) ...           
## 3 Sub-Saharan Africa (25.9%) ...               
## 
## quantitative variables:  
##                            name   class  min          Q1      median
## ...1                       year numeric 2008 2010.000000 2012.000000
## ...2          pf_rol_procedural numeric    0    4.133333    5.300000
## ...3               pf_rol_civil numeric    0    4.549550    5.300000
## ...4            pf_rol_criminal numeric    0    3.789724    4.575189
## ...5                     pf_rol numeric    0    4.131746    4.910797
## ...6             pf_ss_homicide numeric    0    6.386978    8.638278
## ...7 pf_ss_disappearances_disap numeric    0   10.000000   10.000000
##               Q3         max        mean       sd    n missing
## ...1 2014.000000 2016.000000 2012.000000 2.582875 1458       0
## ...2    7.389499    9.700000    5.589355 2.080957  880     578
## ...3    6.410975    8.773533    5.474770 1.428494  880     578
## ...4    6.400000    8.719848    5.044070 1.724886  880     578
## ...5    6.513178    8.723094    5.309641 1.529310 1378      80
## ...6    9.454402    9.926568    7.412980 2.832947 1378      80
## ...7   10.000000   10.000000    8.341855 3.225902 1369      89</code></pre>
<blockquote>
<p><strong>Exercise</strong><br />
Create a scatter plot to display the relationship between the personal freedom score, <code>pf_score</code>, as the response and <code>pf_expression_control</code> as the predictor. Does the relationship look linear?</p>
</blockquote>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb776-1"><a href="#cb776-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_lm</span>(pf_score<span class="sc">~</span>pf_expression_control,<span class="at">data=</span>hfi,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb776-2"><a href="#cb776-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb776-3"><a href="#cb776-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(<span class="at">alpha=</span><span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb776-4"><a href="#cb776-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Personal freedom score versus Expression control&quot;</span>,</span>
<span id="cb776-5"><a href="#cb776-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Political pressures and controls on media&quot;</span>,</span>
<span id="cb776-6"><a href="#cb776-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">y=</span><span class="st">&quot;Personal freedom score&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="25-Linear-Regression-Case-Study_files/figure-html/scat251-fig-1.png" alt="A scatterplot of personal freedom versus expression control using the ggformula package." width="672" />
<p class="caption">
(#fig:scat251-fig)A scatterplot of personal freedom versus expression control using the ggformula package.
</p>
</div>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb777-1"><a href="#cb777-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hfi,<span class="fu">aes</span>(<span class="at">x=</span>pf_expression_control,<span class="at">y=</span>pf_score))<span class="sc">+</span></span>
<span id="cb777-2"><a href="#cb777-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha=</span><span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb777-3"><a href="#cb777-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb777-4"><a href="#cb777-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_lm</span>(<span class="at">color=</span><span class="st">&quot;black&quot;</span>)<span class="sc">+</span></span>
<span id="cb777-5"><a href="#cb777-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Personal freedom score versus Expression control&quot;</span>,</span>
<span id="cb777-6"><a href="#cb777-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Political pressures and controls on media&quot;</span>,</span>
<span id="cb777-7"><a href="#cb777-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">y=</span><span class="st">&quot;Personal freedom score&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="25-Linear-Regression-Case-Study_files/figure-html/scat252-fig-1.png" alt="A scatterplot of personal freedom versus expression control using the ggplot2 package." width="672" />
<p class="caption">
(#fig:scat252-fig)A scatterplot of personal freedom versus expression control using the ggplot2 package.
</p>
</div>
<p>Figures @ref(fig:scat251-fig) and @ref(fig:scat252-fig) are both scatterplots, we included both to demonstrate both the <strong>ggformula</strong> and <strong>ggplot2</strong> packages. In these figures, the relationship does look linear. Although, we should be uncomfortable using the model at the end points. That is because there are less points at the edge and and linear estimation has larger variance at the endpoints, the predictions at the endpoints is more suspect.</p>
<blockquote>
<p><strong>Exercise</strong><br />
The relationship looks linear, quantify the strength of the
relationship with the correlation coefficient.</p>
</blockquote>
<div class="sourceCode" id="cb778"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb778-1"><a href="#cb778-1" aria-hidden="true" tabindex="-1"></a>hfi <span class="sc">%&gt;%</span></span>
<span id="cb778-2"><a href="#cb778-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">cor</span>(pf_expression_control, pf_score, <span class="at">use =</span> <span class="st">&quot;complete.obs&quot;</span>))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   `cor(pf_expression_control, pf_score, use = &quot;complete.obs&quot;)`
##                                                          &lt;dbl&gt;
## 1                                                        0.796</code></pre>
<p>The sample correlation coefficient, indicates a strong positive linear relationship between the variables.</p>
<p>Note that we set the <code>use</code> argument to “complete.obs” since there are some observations with missing values, <code>NA</code>.</p>
</div>
</div>
<div id="sum-of-squared-residuals" class="section level2" number="25.4">
<h2><span class="header-section-number">25.4</span> Sum of squared residuals</h2>
<p>In this section, you will use an interactive function to investigate what we mean by “sum
of squared residuals”. You will need to run this function in your console. Running the function also requires that the <code>hfi</code> data set is loaded in your environment, which we did above.</p>
<p>Think back to the way that we described the distribution of a single variable. Recall that we discussed characteristics such as center, spread, and shape. It’s also useful to be able to describe the relationship of two numerical variables, such as <code>pf_expression_control</code> and <code>pf_score</code> above.</p>
<blockquote>
<p><strong>Exercise</strong><br />
Looking at your scatterplot above, describe the relationship between these two variables. Make sure to discuss the form, direction, and strength of the relationship as well as any unusual observations.</p>
</blockquote>
<p>We would say that there is a strong positive linear relationship between the two variables.</p>
<p>Just as you’ve used the mean and standard deviation to summarize a single variable, you can summarize the relationship between these two variables by finding the
line that best follows their association. Use the following interactive function to select the line that you think does the best job of going through the cloud of points.</p>
<p>First we must remove missing values from the data set and to make the visualization easier, we will just randomly sample 30 of the data points. We included <code>hf_score</code> because we will need it later.</p>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="#cb780-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4011</span>)</span>
<span id="cb780-2"><a href="#cb780-2" aria-hidden="true" tabindex="-1"></a>hfi_sub <span class="ot">&lt;-</span> hfi <span class="sc">%&gt;%</span></span>
<span id="cb780-3"><a href="#cb780-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(pf_expression_control,pf_score,hf_score) <span class="sc">%&gt;%</span></span>
<span id="cb780-4"><a href="#cb780-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">drop_na</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-5"><a href="#cb780-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(pf_expression_control) <span class="sc">%&gt;%</span></span>
<span id="cb780-6"><a href="#cb780-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">n=</span><span class="dv">1</span>)</span></code></pre></div>
<p>We used the function <code>slice_sample()</code> to ensure we have unique values of <code>pf_expression_control</code> in our sample.</p>
<blockquote>
<p><strong>Exercise</strong><br />
In your <code>R</code> console, run the code above to create the object <code>hfi_sub</code>. You are going to have to load packages and read in the <code>hfi</code> data set. Then execute the next lines of code. Pick two locations in the plot to create a line. Record the sum of squares.</p>
</blockquote>
<p>First, run this code chunk to create a function <code>plot_ss()</code> that you will use next.</p>
<div class="sourceCode" id="cb781"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb781-1"><a href="#cb781-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to create plot and residuals.</span></span>
<span id="cb781-2"><a href="#cb781-2" aria-hidden="true" tabindex="-1"></a>plot_ss <span class="ot">&lt;-</span> <span class="cf">function</span> (x, y, data, <span class="at">showSquares =</span> <span class="cn">FALSE</span>, <span class="at">leastSquares =</span> <span class="cn">FALSE</span>) </span>
<span id="cb781-3"><a href="#cb781-3" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb781-4"><a href="#cb781-4" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">eval</span>(<span class="fu">substitute</span>(x), data)</span>
<span id="cb781-5"><a href="#cb781-5" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">eval</span>(<span class="fu">substitute</span>(y), data)</span>
<span id="cb781-6"><a href="#cb781-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">asp =</span> <span class="dv">1</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb781-7"><a href="#cb781-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (leastSquares) {</span>
<span id="cb781-8"><a href="#cb781-8" aria-hidden="true" tabindex="-1"></a>        m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb781-9"><a href="#cb781-9" aria-hidden="true" tabindex="-1"></a>        y.hat <span class="ot">&lt;-</span> m1<span class="sc">$</span>fit</span>
<span id="cb781-10"><a href="#cb781-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb781-11"><a href="#cb781-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> {</span>
<span id="cb781-12"><a href="#cb781-12" aria-hidden="true" tabindex="-1"></a>        <span class="fu">cat</span>(<span class="st">&quot;Click two points to make a line.&quot;</span>)</span>
<span id="cb781-13"><a href="#cb781-13" aria-hidden="true" tabindex="-1"></a>        pt1 <span class="ot">&lt;-</span> <span class="fu">locator</span>(<span class="dv">1</span>)</span>
<span id="cb781-14"><a href="#cb781-14" aria-hidden="true" tabindex="-1"></a>        <span class="fu">points</span>(pt1<span class="sc">$</span>x, pt1<span class="sc">$</span>y, <span class="at">pch =</span> <span class="dv">4</span>)</span>
<span id="cb781-15"><a href="#cb781-15" aria-hidden="true" tabindex="-1"></a>        pt2 <span class="ot">&lt;-</span> <span class="fu">locator</span>(<span class="dv">1</span>)</span>
<span id="cb781-16"><a href="#cb781-16" aria-hidden="true" tabindex="-1"></a>        <span class="fu">points</span>(pt2<span class="sc">$</span>x, pt2<span class="sc">$</span>y, <span class="at">pch =</span> <span class="dv">4</span>)</span>
<span id="cb781-17"><a href="#cb781-17" aria-hidden="true" tabindex="-1"></a>        pts <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(pt1<span class="sc">$</span>x, pt2<span class="sc">$</span>x), <span class="at">y =</span> <span class="fu">c</span>(pt1<span class="sc">$</span>y, pt2<span class="sc">$</span>y))</span>
<span id="cb781-18"><a href="#cb781-18" aria-hidden="true" tabindex="-1"></a>        m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> pts)</span>
<span id="cb781-19"><a href="#cb781-19" aria-hidden="true" tabindex="-1"></a>        y.hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(m1, <span class="at">newdata =</span> <span class="fu">data.frame</span>(x))</span>
<span id="cb781-20"><a href="#cb781-20" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb781-21"><a href="#cb781-21" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">&lt;-</span> y <span class="sc">-</span> y.hat</span>
<span id="cb781-22"><a href="#cb781-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>(m1)</span>
<span id="cb781-23"><a href="#cb781-23" aria-hidden="true" tabindex="-1"></a>    oSide <span class="ot">&lt;-</span> x <span class="sc">-</span> r</span>
<span id="cb781-24"><a href="#cb781-24" aria-hidden="true" tabindex="-1"></a>    LLim <span class="ot">&lt;-</span> <span class="fu">par</span>()<span class="sc">$</span>usr[<span class="dv">1</span>]</span>
<span id="cb781-25"><a href="#cb781-25" aria-hidden="true" tabindex="-1"></a>    RLim <span class="ot">&lt;-</span> <span class="fu">par</span>()<span class="sc">$</span>usr[<span class="dv">2</span>]</span>
<span id="cb781-26"><a href="#cb781-26" aria-hidden="true" tabindex="-1"></a>    oSide[oSide <span class="sc">&lt;</span> LLim <span class="sc">|</span> oSide <span class="sc">&gt;</span> RLim] <span class="ot">&lt;-</span> <span class="fu">c</span>(x <span class="sc">+</span> r)[oSide <span class="sc">&lt;</span> LLim <span class="sc">|</span> </span>
<span id="cb781-27"><a href="#cb781-27" aria-hidden="true" tabindex="-1"></a>        oSide <span class="sc">&gt;</span> RLim]</span>
<span id="cb781-28"><a href="#cb781-28" aria-hidden="true" tabindex="-1"></a>    n <span class="ot">&lt;-</span> <span class="fu">length</span>(y.hat)</span>
<span id="cb781-29"><a href="#cb781-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n) {</span>
<span id="cb781-30"><a href="#cb781-30" aria-hidden="true" tabindex="-1"></a>        <span class="fu">lines</span>(<span class="fu">rep</span>(x[i], <span class="dv">2</span>), <span class="fu">c</span>(y[i], y.hat[i]), <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb781-31"><a href="#cb781-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (showSquares) {</span>
<span id="cb781-32"><a href="#cb781-32" aria-hidden="true" tabindex="-1"></a>            <span class="fu">lines</span>(<span class="fu">rep</span>(oSide[i], <span class="dv">2</span>), <span class="fu">c</span>(y[i], y.hat[i]), <span class="at">lty =</span> <span class="dv">3</span>, </span>
<span id="cb781-33"><a href="#cb781-33" aria-hidden="true" tabindex="-1"></a>                <span class="at">col =</span> <span class="st">&quot;orange&quot;</span>)</span>
<span id="cb781-34"><a href="#cb781-34" aria-hidden="true" tabindex="-1"></a>            <span class="fu">lines</span>(<span class="fu">c</span>(oSide[i], x[i]), <span class="fu">rep</span>(y.hat[i], <span class="dv">2</span>), <span class="at">lty =</span> <span class="dv">3</span>, </span>
<span id="cb781-35"><a href="#cb781-35" aria-hidden="true" tabindex="-1"></a>                <span class="at">col =</span> <span class="st">&quot;orange&quot;</span>)</span>
<span id="cb781-36"><a href="#cb781-36" aria-hidden="true" tabindex="-1"></a>            <span class="fu">lines</span>(<span class="fu">c</span>(oSide[i], x[i]), <span class="fu">rep</span>(y[i], <span class="dv">2</span>), <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&quot;orange&quot;</span>)</span>
<span id="cb781-37"><a href="#cb781-37" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb781-38"><a href="#cb781-38" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb781-39"><a href="#cb781-39" aria-hidden="true" tabindex="-1"></a>    SS <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">sum</span>(r<span class="sc">^</span><span class="dv">2</span>), <span class="dv">3</span>)</span>
<span id="cb781-40"><a href="#cb781-40" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\r</span><span class="st">                                &quot;</span>)</span>
<span id="cb781-41"><a href="#cb781-41" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(m1)</span>
<span id="cb781-42"><a href="#cb781-42" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">&quot;Sum of Squares: &quot;</span>, SS)</span>
<span id="cb781-43"><a href="#cb781-43" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Next run the next code chunk that for us resulted in Figure @ref(fig:plotss-expression-score). You will have to pick to points on the plot that you think gives the best line.</p>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb782-1"><a href="#cb782-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ss</span>(<span class="at">x =</span> pf_expression_control, <span class="at">y =</span> pf_score, <span class="at">data =</span> hfi_sub)</span></code></pre></div>
<div class="figure">
<img src="25-Linear-Regression-Case-Study_files/figure-html/plotss-expression-score-1.png" alt="Plot of selected line and the associated residuals." width="672" />
<p class="caption">
(#fig:plotss-expression-score)Plot of selected line and the associated residuals.
</p>
</div>
<pre><code>## Click two points to make a line.
                                
## Call:
## lm(formula = y ~ x, data = pts)
## 
## Coefficients:
## (Intercept)            x  
##      5.0272       0.4199  
## 
## Sum of Squares:  19.121</code></pre>
<p>Once you’ve picked your two locations, the line you specified will be shown in black and the residuals in blue. Residuals are the difference between the observed values and the values predicted by the line:</p>
<p><span class="math display">\[
  e_i = y_i - \hat{y}_i
\]</span></p>
<p>The most common way to do linear regression is to select the line that minimizes the sum of squared residuals. To visualize the squared residuals, you can rerun
the plot command and add the argument <code>showSquares = TRUE</code>.</p>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb784-1"><a href="#cb784-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ss</span>(<span class="at">x =</span> pf_expression_control, <span class="at">y =</span> pf_score, <span class="at">data =</span> hfi_sub, <span class="at">showSquares =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Note that the output from the <code>plot_ss</code> function provides you with the slope and intercept of your line as well as the sum of squares.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Using <code>plot_ss</code>, choose a line that does a good job of minimizing the sum of squares. Run the function several times. What was the smallest sum of squares that you got?</p>
</blockquote>
</div>
<div id="the-linear-model" class="section level2" number="25.5">
<h2><span class="header-section-number">25.5</span> The linear model</h2>
<p>It is rather cumbersome to try to get the correct least squares line, i.e. the line that minimizes the sum of squared residuals, through trial and error. Instead, you can use the <code>lm()</code> function in <code>R</code> to fit the linear model (a.k.a.
regression line).</p>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb785-1"><a href="#cb785-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(pf_score <span class="sc">~</span> pf_expression_control, <span class="at">data =</span> hfi_sub)</span></code></pre></div>
<p>The first argument in the function <code>lm</code> is a formula that takes the form <code>y ~ x</code>. Here it can be read that we want to make a linear model of <code>pf_score</code> as a function of <code>pf_expression_control</code>. The second argument specifies
that <code>R</code> should look in the <code>hfi_sub</code> data frame to find the two variables. This should be familiar to us since we have been doing this when we used the <strong>mosaic</strong> package.</p>
<p>The output of <code>lm</code> is an object that contains all of the information we need about the linear model that was just fit. We can access this information using the <code>summary()</code> function.</p>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb786-1"><a href="#cb786-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = pf_score ~ pf_expression_control, data = hfi_sub)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.7559 -0.4512  0.1838  0.5369  1.2510 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            5.02721    0.23186  21.682  &lt; 2e-16 ***
## pf_expression_control  0.41988    0.04312   9.736 1.26e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7288 on 36 degrees of freedom
## Multiple R-squared:  0.7248, Adjusted R-squared:  0.7171 
## F-statistic:  94.8 on 1 and 36 DF,  p-value: 1.262e-11</code></pre>
<p>Let’s consider this output piece by piece. First, the formula used to describe the model is shown at the top. After the formula you find the five-number summary of the residuals. The “Coefficients” table shown next is key; its first
column displays the linear model’s y-intercept and the coefficient of <code>pf_expression_control</code>. With this table, we can write down the least squares regression line for the
linear model:</p>
<p><span class="math display">\[
  \hat{\text{pf_score}} = 5.02721 + 0.41988 \times \text{pf_expression_control}
\]</span></p>
<p>At least these are the values we got on our machine using the <em>seed</em> provided. Yours may differ slightly. One last piece of information we will discuss from the summary output is the <code>Multiple R-squared</code>, or more simply, <span class="math inline">\(R^2\)</span>. The <span class="math inline">\(R^2\)</span> value represents the proportion of variability in the response variable that is explained by the explanatory variable. For this model, 72.48% of the variability in <code>pf_score</code> is explained by <code>pr_expression_control</code>.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Fit a new model that uses <code>pf_expression_control</code> to predict <code>hf_score</code>, or the total human freedom score. Using the estimates from the <code>R</code> output, write the equation of the regression line. What does the slope tell us in the context of the relationship between human freedom and the amount of political pressure on media content?</p>
</blockquote>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb788-1"><a href="#cb788-1" aria-hidden="true" tabindex="-1"></a>m2<span class="ot">&lt;-</span><span class="fu">lm</span>(hf_score <span class="sc">~</span> pf_expression_control, <span class="at">data =</span> hfi_sub)</span></code></pre></div>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb789-1"><a href="#cb789-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = hf_score ~ pf_expression_control, data = hfi_sub)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.5151 -0.5776  0.2340  0.4622  1.0633 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            5.45660    0.21585  25.279  &lt; 2e-16 ***
## pf_expression_control  0.30707    0.04015   7.649 4.72e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6785 on 36 degrees of freedom
## Multiple R-squared:  0.6191, Adjusted R-squared:  0.6085 
## F-statistic:  58.5 on 1 and 36 DF,  p-value: 4.718e-09</code></pre>
<p><span class="math display">\[
  \hat{\text{hf_score}} = 5.45660 + 0.30707 \times \text{pf_expression_control}
\]</span>
As the political pressure increases by one unit, the <strong>average</strong> human freedom score increases by 0.307.</p>
</div>
<div id="prediction-and-prediction-errors" class="section level2" number="25.6">
<h2><span class="header-section-number">25.6</span> Prediction and prediction errors</h2>
<p>Let’s create a scatterplot with the least squares line for <code>m1</code>, our first model, laid on top, Figure @ref(fig:reg-with-line).</p>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb791-1"><a href="#cb791-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> hfi_sub, <span class="fu">aes</span>(<span class="at">x =</span> pf_expression_control, <span class="at">y =</span> pf_score)) <span class="sc">+</span></span>
<span id="cb791-2"><a href="#cb791-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb791-3"><a href="#cb791-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  geom_lm(color=&quot;black&quot;) +</span></span>
<span id="cb791-4"><a href="#cb791-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb791-5"><a href="#cb791-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb791-6"><a href="#cb791-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">&quot;Personal freedom score versus Expression control&quot;</span>,</span>
<span id="cb791-7"><a href="#cb791-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;Political pressures and controls on media&quot;</span>,</span>
<span id="cb791-8"><a href="#cb791-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">y=</span><span class="st">&quot;Personal freedom score&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="25-Linear-Regression-Case-Study_files/figure-html/reg-with-line-1.png" alt="Scatterplot of personal expression control and personal freedom score." width="672" />
<p class="caption">
(#fig:reg-with-line)Scatterplot of personal expression control and personal freedom score.
</p>
</div>
<p>Here, we are literally adding a layer on top of our plot. The <code>stat_smooth()</code> function creates the line by fitting a linear model, we could use <code>geom_lm()</code> as well. It can also show us the standard error <code>se</code>
associated with our line, but we’ll suppress that for now.</p>
<p>This line can be used to predict <span class="math inline">\(y\)</span> at any value of <span class="math inline">\(x\)</span>. When predictions are made for values of <span class="math inline">\(x\)</span> that are beyond the range of the observed data, it is referred to as <em>extrapolation</em> and is not usually recommended. However,
predictions made within the range of the data are more reliable. They’re also used to compute the residuals.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
If someone saw the least squares regression line and not the actual data, how would they predict a country’s personal freedom score for one with a 6.75 rating for <code>pf_expression_control</code>? Is this an overestimate or an underestimate, and by how much? In other words, what is the residual for this prediction?</p>
</blockquote>
<p>To predict, we will use the predict function, but we have to send the new data as a data frame.</p>
<div class="sourceCode" id="cb792"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb792-1"><a href="#cb792-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(m1,<span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">pf_expression_control=</span><span class="fl">6.75</span>))</span></code></pre></div>
<pre><code>##        1 
## 7.861402</code></pre>
<p>We thus predict a value of 7.86 for the average <code>pf_score</code>.</p>
<p>The observed value is 8.628272.</p>
<div class="sourceCode" id="cb794"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb794-1"><a href="#cb794-1" aria-hidden="true" tabindex="-1"></a>hfi_sub <span class="sc">%&gt;%</span></span>
<span id="cb794-2"><a href="#cb794-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(pf_expression_control<span class="sc">==</span><span class="fl">6.75</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
## # Groups:   pf_expression_control [1]
##   pf_expression_control pf_score hf_score
##                   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1                  6.75     8.63     8.25</code></pre>
<p>The residual is:</p>
<div class="sourceCode" id="cb796"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb796-1"><a href="#cb796-1" aria-hidden="true" tabindex="-1"></a><span class="fl">8.628272</span> <span class="sc">-</span> <span class="fl">7.861402</span></span></code></pre></div>
<pre><code>## [1] 0.76687</code></pre>
<p>We underestimated the actual value.</p>
<p>Another way to do this is to use the <strong>broom</strong> package.</p>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb798-1"><a href="#cb798-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span></code></pre></div>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb799-1"><a href="#cb799-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(m1) <span class="sc">%&gt;%</span></span>
<span id="cb799-2"><a href="#cb799-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">filter</span>(pf_expression_control<span class="sc">==</span><span class="fl">6.75</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 8
##   pf_score pf_expression_control .fitted .resid   .hat .sigma .cooksd .std.resid
##      &lt;dbl&gt;                 &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;
## 1     8.63                  6.75    7.86  0.767 0.0421  0.727  0.0254       1.08</code></pre>
</div>
<div id="model-diagnostics" class="section level2" number="25.7">
<h2><span class="header-section-number">25.7</span> Model diagnostics</h2>
<p>To assess whether the linear model is reliable, we need to check for</p>
<ol style="list-style-type: decimal">
<li>linearity,<br />
</li>
<li>independence,</li>
<li>nearly normal residuals, and<br />
</li>
<li>constant variability.</li>
</ol>
<p><strong>Linearity</strong>: You already checked if the relationship between <code>pf_score</code> and <code>pf_expression_control</code> is linear using a scatterplot. We should also verify this condition with a plot of the residuals vs. fitted (predicted) values, Figure @ref(fig:residuals).</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb801-1"><a href="#cb801-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> m1, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span></span>
<span id="cb801-2"><a href="#cb801-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb801-3"><a href="#cb801-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb801-4"><a href="#cb801-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Fitted values&quot;</span>,<span class="at">y=</span><span class="st">&quot;Residuals&quot;</span>,<span class="at">title=</span><span class="st">&quot;Residual analysis&quot;</span>) <span class="sc">+</span></span>
<span id="cb801-5"><a href="#cb801-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure">
<img src="25-Linear-Regression-Case-Study_files/figure-html/residuals-1.png" alt="Scatterplot of residuals and fitted values used to assess the assumptions of linearity and constant variance." width="672" />
<p class="caption">
(#fig:residuals)Scatterplot of residuals and fitted values used to assess the assumptions of linearity and constant variance.
</p>
</div>
<p>Notice here that <code>m1</code> can also serve as a data set because stored within it are the fitted values (<span class="math inline">\(\hat{y}\)</span>) and the residuals. Also note that we’re getting more sophisticated with the code in Figure @ref(fig:residuals). After creating the scatterplot on the first layer (first line of code), we overlay a horizontal dashed line at <span class="math inline">\(y = 0\)</span> (to help us check whether residuals are distributed around 0), and we also rename the axis labels to be more informative and add a title.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Is there any apparent pattern in the residuals plot? What does this indicate about the linearity of the relationship between the two variables?</p>
</blockquote>
<p>The width is constant and there is no trend in the data. The linearity assumption is not bad.</p>
<p><strong>Independence</strong>: This is difficult to check with residuals and depends on how the data was collected.</p>
<p><strong>Nearly normal residuals</strong>: To check this condition, we can look at a histogram, Figure @ref(fig:hist-res).</p>
<div class="sourceCode" id="cb802"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb802-1"><a href="#cb802-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> m1, <span class="fu">aes</span>(<span class="at">x =</span> .resid)) <span class="sc">+</span></span>
<span id="cb802-2"><a href="#cb802-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> .<span class="dv">4</span>,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb802-3"><a href="#cb802-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Residuals&quot;</span>) <span class="sc">+</span></span>
<span id="cb802-4"><a href="#cb802-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure">
<img src="25-Linear-Regression-Case-Study_files/figure-html/hist-res-1.png" alt="Histogram of residuals from linear regression model." width="672" />
<p class="caption">
(#fig:hist-res)Histogram of residuals from linear regression model.
</p>
</div>
<p>or a normal probability plot of the residuals, @ref(fig:qq-res).</p>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb803-1"><a href="#cb803-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> m1, <span class="fu">aes</span>(<span class="at">sample =</span> .resid)) <span class="sc">+</span></span>
<span id="cb803-2"><a href="#cb803-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb803-3"><a href="#cb803-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb803-4"><a href="#cb803-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>,<span class="at">intercept =</span> <span class="dv">0</span>)</span></code></pre></div>
<div class="figure">
<img src="25-Linear-Regression-Case-Study_files/figure-html/qq-res-1.png" alt="The quantile-quantile residual plot used to assess the normality assumption." width="672" />
<p class="caption">
(#fig:qq-res)The quantile-quantile residual plot used to assess the normality assumption.
</p>
</div>
<p>Note that the syntax for making a normal probability plot is a bit different than what you’re used to seeing: we set <code>sample</code> equal to the residuals instead of <code>x</code>, and we set a statistical method <code>qq</code>, which stands for “quantile-quantile”,
another name commonly used for normal probability plots.</p>
<p>It is a little difficult at first to understand how the <code>qq</code> plot indicated that the distribution was skewed to the left. The points indicate the quantile from the sample, standardized to have mean zero and standard deviation one, plotted against the same quantiles from a standard normal. It the sample matched a standard normal the points would align on the 45-degree line. From the plot, we see that as the theoretical quantile get larger, further from zero, the sample do not. That is why the trajectory of the points in the upper right looks flat, below the 45-degree line. Thus the distribution is compressed on the right making it skewed to the left.</p>
<blockquote>
<p><strong>Exercise</strong>:
Based on the histogram and the normal probability plot, does the nearly normal residuals condition appear to be met?</p>
</blockquote>
<p>No, the sample is small but it appears the residual are skewed to the left.</p>
<p><strong>Constant variability</strong>:</p>
<blockquote>
<p><strong>Exercise</strong>:
Based on the residuals vs. fitted plot, does the constant variability condition appear to be met?</p>
</blockquote>
<p>Yes, the width of the plot seems constant.</p>
</div>
<div id="brief-summary" class="section level2" number="25.8">
<h2><span class="header-section-number">25.8</span> Brief summary</h2>
<p>This case study introduced simple linear regression. We look at the criteria to find a best fit linear line between two variables. We also used <code>R</code> to fit the line. We examined the output from <code>R</code> and used it to explain and predict with our model. In the remainder of this block we will develop these ideas further and extend to multiple predictors and binary outcomes. This is a perfect introduction for Math 378.</p>
</div>
<div id="homework-problems-24" class="section level2" number="25.9">
<h2><span class="header-section-number">25.9</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>HFI</li>
</ol>
<p>Choose another freedom variable and a variable you think would strongly correlate with it. The <strong>openintro</strong> package contains the data set <code>hfi</code>. Type <code>?openintro::hfi</code> in the Console window in <code>RStudio</code> to learn more about the variables.</p>
<ol style="list-style-type: lower-alpha">
<li>Produce a scatterplot of the two variables.<br />
</li>
<li>Quantify the strength of the relationship with the correlation coefficient.<br />
</li>
<li>Fit a linear model. At a glance, does there seem to be a linear relationship?<br />
</li>
<li>How does this relationship compare to the relationship between <code>pf_expression_control</code> and <code>pf_score</code>? Use the <span class="math inline">\(R^2\)</span> values from the two model summaries to compare. Does your independent variable seem to predict your dependent one better? Why or why not?<br />
</li>
<li>Display the model diagnostics for the regression model analyzing this relationship.<br />
</li>
<li>Predict the response from your explanatory variable for a value between the median and third quartile. Is this an overestimate or an underestimate, and by how much? In other words, what is the residual for this prediction?</li>
</ol>
<!--chapter:end:25-Linear-Regression-Case-Study.Rmd-->
</div>
</div>
<div id="LRBASICS" class="section level1" number="26">
<h1><span class="header-section-number">26</span> Linear Regression Basics</h1>
<div id="objectives-24" class="section level2" number="26.1">
<h2><span class="header-section-number">26.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Obtain parameter estimates of a simple linear regression model given a sample of data.<br />
</li>
<li>Interpret the coefficients of a simple linear regression.<br />
</li>
<li>Create a scatterplot with a regression line.<br />
</li>
<li>Explain and check the assumptions of linear regression.<br />
</li>
<li>Use and be able to explain all new terms.</li>
</ol>
</div>
<div id="linear-regression-models" class="section level2" number="26.2">
<h2><span class="header-section-number">26.2</span> Linear regression models</h2>
<p>The rest of this block will serve as a brief introduction to linear models. In general, a model estimates the relationship between one variable (a <strong>response</strong>) and one or more other variables (<strong>predictors</strong>). Models typically serve two purposes: <em>prediction</em> and <em>inference</em>. A model allows us to predict the value of a response given particular values of predictors. Also, a model allows us to make inferences about the relationship between the response and the predictors.</p>
<p>Not all models are used or built on the same principles. Some models are better for inference and others are better for prediction. Some models are better for qualitative responses and others are better for quantitative responses. Also, many models require making assumptions about the nature of the relationship between variables. If these assumptions are violated, the model loses usefulness. In a machine learning course, a wide array of models are discussed but most of which are used for the purpose of prediction.</p>
<p>In this block, we will focus on <em>linear models</em> and the use of linear regression to produce and evaluate the model. Linear regression is a very powerful statistical technique. Many people have some familiarity with regression just from reading the news, where graphs with straight lines are overlaid on scatterplots, much like we did in the last lesson. Linear models can be used for prediction or to evaluate whether there is a linear relationship between two numerical variables.</p>
<p>Suppose we were interested in exploring the relationship between one response variable (<span class="math inline">\(Y\)</span>) and one predictor variable (<span class="math inline">\(X\)</span>). We can postulate a linear relationship between the two:
<span class="math display">\[
Y=\beta_0+\beta_1 X
\]</span></p>
<p>A linear model can be expanded to include multiple predictor variables:
<span class="math display">\[
Y=\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_pX_p
\]</span></p>
<p>This model is often referred to as a <strong>linear regression</strong> model. (When there is only one predictor variable, we often refer to it as a <strong>simple linear regression</strong> model.) The <span class="math inline">\(\beta_j\)</span> terms are referred to as <strong>coefficients</strong>. Note that the coefficients are <strong>parameters</strong> and thus represented as Greek letters. We typically don’t know the true values of <span class="math inline">\(\beta_j\)</span>, so we have to estimate them with samples from the population of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, our data. Estimating these parameters and using them for prediction and inference will be the majority of the work of this last block.</p>
<p>We consider the models above to be linear models because they are linear in the <strong>parameters</strong>. This means that the following model is also a linear model:</p>
<p><span class="math display">\[
Y=\beta_0+\beta_1 X^2
\]</span></p>
<p>Technically, we can write the parameters as a vector and the explanatory variables as a matrix. The response will then be an inner product of this vector and matrix and thus a linear combination.</p>
<p>Even if we expect two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to share a linear relationship, we don’t expect it to be perfect. There will be some scatter around the estimated line. For example, consider the head length and total length of 104 brushtail possums from Australia. The data is in the file <code>possum.csv</code> in the <code>data</code> folder.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Read in the data from <code>data/possum.csv</code> and look at the first few rows of data.</p>
</blockquote>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb804-1"><a href="#cb804-1" aria-hidden="true" tabindex="-1"></a>possum<span class="ot">&lt;-</span><span class="fu">read_csv</span>(<span class="st">&quot;data/possum.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb805-1"><a href="#cb805-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(possum)</span></code></pre></div>
<pre><code>## Rows: 104
## Columns: 8
## $ site    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~
## $ pop     &lt;chr&gt; &quot;Vic&quot;, &quot;Vic&quot;, &quot;Vic&quot;, &quot;Vic&quot;, &quot;Vic&quot;, &quot;Vic&quot;, &quot;Vic&quot;, &quot;Vic&quot;, &quot;Vic&quot;,~
## $ sex     &lt;chr&gt; &quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m~
## $ age     &lt;dbl&gt; 8, 6, 6, 6, 2, 1, 2, 6, 9, 6, 9, 5, 5, 3, 5, 4, 1, 2, 5, 4, 3,~
## $ head_l  &lt;dbl&gt; 94.1, 92.5, 94.0, 93.2, 91.5, 93.1, 95.3, 94.8, 93.4, 91.8, 93~
## $ skull_w &lt;dbl&gt; 60.4, 57.6, 60.0, 57.1, 56.3, 54.8, 58.2, 57.6, 56.3, 58.0, 57~
## $ total_l &lt;dbl&gt; 89.0, 91.5, 95.5, 92.0, 85.5, 90.5, 89.5, 91.0, 91.5, 89.5, 89~
## $ tail_l  &lt;dbl&gt; 36.0, 36.5, 39.0, 38.0, 36.0, 35.5, 36.0, 37.0, 37.0, 37.5, 39~</code></pre>
<div class="sourceCode" id="cb807"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb807-1"><a href="#cb807-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(possum)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 8
##    site pop   sex     age head_l skull_w total_l tail_l
##   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1     1 Vic   m         8   94.1    60.4    89     36  
## 2     1 Vic   f         6   92.5    57.6    91.5   36.5
## 3     1 Vic   f         6   94      60      95.5   39  
## 4     1 Vic   f         6   93.2    57.1    92     38  
## 5     1 Vic   f         2   91.5    56.3    85.5   36  
## 6     1 Vic   f         1   93.1    54.8    90.5   35.5</code></pre>
<p>We think the head and total length variables are linearly associated. Possums with an above average total length also tend to have above average head lengths. To visualize this data, we will use a scatterplot. We have used scatterplots multiple times in this book. Scatterplots are a graphical technique to present two numerical variables simultaneously. Such plots permit the relationship between the variables to be examined with ease. The following figure shows a scatterplot for the head length and total length of the possums. Each point represents a single possum from the data.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Create a scatterplot of head length and total length.</p>
</blockquote>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb809-1"><a href="#cb809-1" aria-hidden="true" tabindex="-1"></a>possum <span class="sc">%&gt;%</span></span>
<span id="cb809-2"><a href="#cb809-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(head_l<span class="sc">~</span>total_l) <span class="sc">%&gt;%</span></span>
<span id="cb809-3"><a href="#cb809-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Total Length (cm)&quot;</span>,<span class="at">y=</span><span class="st">&quot;Head Length (mm)&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb809-4"><a href="#cb809-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>())</span></code></pre></div>
<div class="figure">
<img src="26-Linear-Regression-Basics_files/figure-html/scat261-fig-1.png" alt="A scatterplot of possum total length and head length." width="672" />
<p class="caption">
(#fig:scat261-fig)A scatterplot of possum total length and head length.
</p>
</div>
<p>From Figure @ref(fig:scat261-fig), we see that the relationship is not perfectly linear; however, it could be helpful to partially explain the connection between these variables with a straight line. Since some longer possums will have shorter heads and some shorter possums will have longer heads, there is no straight line that can go through all the data points. We expect some deviation from the linear fit. This deviation is represented by random variable <span class="math inline">\(e\)</span> (this is not the Euler number), which we refer to as an error term or residual:</p>
<p><span class="math display">\[
Y=\beta_0+\beta_1X+e
\]</span></p>
<p>For our problem, <span class="math inline">\(Y\)</span> is head length and <span class="math inline">\(X\)</span> is total length.</p>
<p>In general we have:</p>
<p><span class="math display">\[ \text{Data} = \text{Fit} + \text{Residual} \]</span></p>
<p>and what will change in our modeling process is how we specify the <span class="math inline">\(\text{Fit}\)</span>.</p>
<p>The error term is assumed to follow a normal distribution with mean 0 and constant standard deviation <span class="math inline">\(\sigma\)</span>. Note: the assumption of normality is only for inference using the <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> distributions and we can relax this assumption by using a bootstrap. Among other things, these assumptions imply that a linear model should only be used when the response variable is continuous in nature. There are other approaches for non-continuous response variables (for example logistic regression).</p>
<div id="estimation-1" class="section level3" number="26.2.1">
<h3><span class="header-section-number">26.2.1</span> Estimation</h3>
<p>We want to describe the relationship between the head length and total length variables in the possum data set using a line. In this example, we will use the total length as the predictor variable, <span class="math inline">\(x\)</span>, to predict a possum’s head length, <span class="math inline">\(y\)</span>. Just as a side note, the choice of the predictor and response are not arbitrary. The response is typically what we want to predict or in the case of experiments is the causal result of the predictor(s).</p>
<p>In the possum data we have <span class="math inline">\(n = 104\)</span> observations: <span class="math inline">\((x_1,y_1), (x_2,y_2),...,(x_{104},y_{104})\)</span>. Then for each observation the implied linear model is:</p>
<p><span class="math display">\[
y_i=\beta_0+\beta x_i + e_i
\]</span></p>
<p>We could fit the linear relationship by eye like we did in the case study and obtain estimates of the slope and intercept but this is too ad hoc.<a href="#fn90" class="footnote-ref" id="fnref90"><sup>90</sup></a> So, given a set of data like the <code>possum</code>, how do we actually obtain estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>? What is the <strong>best</strong> fit line?</p>
<p>We begin by thinking about what we mean by ``best’’. Mathematically, we want a line that has small residuals. There are multiple methods, but the most common is the <em>method of least squares</em>. In this method, our goal is to find the values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> that minimize the squared vertical distance between the points and the resulting line, the <strong>residuals</strong>. See @ref(fig:resid1-fig) for a visual representation involving only four observations from <em>made up</em> data.</p>
<div class="figure">
<img src="26-Linear-Regression-Basics_files/figure-html/resid1-fig-1.png" alt="An illustration of the least squares method." width="672" />
<p class="caption">
(#fig:resid1-fig)An illustration of the least squares method.
</p>
</div>
<p>Our criterion for best is the estimates of slope and intercept that minimize the sum of the squared residuals:</p>
<p><span class="math display">\[e_{1}^2 + e_{2}^2 + \dots + e_{n}^2\]</span></p>
<p>The following are three possible reasons to choose the least squares criterion over other criteria such as the sum of the absolute value of residuals:</p>
<ol style="list-style-type: lower-roman">
<li>It is the most commonly used method.<br />
</li>
<li>Computing a line based on least squares was much easier by hand when computers were not available.<br />
</li>
<li>In many applications, a residual twice as large as another residual is more than twice as bad. For example, being off by 4 is usually more than twice as bad as being off by 2. Squaring the residuals accounts for this discrepancy.</li>
</ol>
<p>The first two reasons are largely for tradition and convenience; the last reason explains why least squares is typically helpful.<a href="#fn91" class="footnote-ref" id="fnref91"><sup>91</sup></a></p>
<p>So, we need to find <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> that minimize the expression, observed minus expected:
<span class="math display">\[
\sum_{i=1}^n (y_i-\beta_0-\beta_1 x_i)^2
\]</span></p>
<p>Using calculus-based optimization yields the following estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>:</p>
<p><span class="math display">\[
\hat{\beta}_0=\bar{y}-\hat{\beta}_1\bar{x}
\]</span></p>
<p>Notice that this implies that the line will always go through the point <span class="math inline">\(\left(\bar{x},\bar{y} \right)\)</span>. As a reminder <span class="math inline">\(\bar{x}\)</span> is the sample mean of the explanatory variable and <span class="math inline">\(\bar{y}\)</span> is the sample mean of the response.</p>
<p>And</p>
<p><span class="math display">\[
\hat{\beta}_1 = {\sum x_i y_i - n\bar{x}\bar{y} \over \sum x_i^2 -n\bar{x}^2}
\]</span></p>
<p>A more intuitive formula for the slope and one that links <strong>correlation</strong> to linear regression is:</p>
<p><span class="math display">\[
\hat{\beta}_1 = \frac{s_y}{s_x} R
\]</span></p>
<p>where <span class="math inline">\(R\)</span> is the correlation between the two variables, and <span class="math inline">\(s_x\)</span> and <span class="math inline">\(s_y\)</span> are the sample standard deviations of the explanatory variable and response, respectively. Thus the slope is proportional to the correlation.</p>
<p>You may also be interested in estimating <span class="math inline">\(\sigma\)</span>, the standard deviation of the error:
<span class="math display">\[
\hat{\sigma}=\sqrt{{1\over n-2} \sum_{i=1}^n \hat{e}_i^2}
\]</span></p>
<p>where <span class="math inline">\(\hat{e}_i\)</span> is the observed <span class="math inline">\(i\)</span>th <strong>residual</strong> (<span class="math inline">\(\hat{e}_i=y_i-\hat{\beta}_0-\hat{\beta}_1x_i\)</span>). This estimate is based only on the assumption of constant variance.</p>
</div>
<div id="possum-example" class="section level3" number="26.2.2">
<h3><span class="header-section-number">26.2.2</span> Possum example</h3>
<p>We will let <code>R</code> do the heavy work of minimizing the sum of squares. The function is <code>lm()</code> as we learned in the case study. This function needs a formula and data for input. The formula notation should be easy for us since we have worked with formulas so much in the <strong>mosaic</strong> package.</p>
<p>First create the model:</p>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb810-1"><a href="#cb810-1" aria-hidden="true" tabindex="-1"></a>poss_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(head_l<span class="sc">~</span>total_l,<span class="at">data=</span>possum)</span></code></pre></div>
<p>The output of the model object is minimal with just the estimated slope and intercept.</p>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb811-1"><a href="#cb811-1" aria-hidden="true" tabindex="-1"></a>poss_mod</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = head_l ~ total_l, data = possum)
## 
## Coefficients:
## (Intercept)      total_l  
##     42.7098       0.5729</code></pre>
<p>We can get more information using the <code>summary()</code> function:</p>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb813-1"><a href="#cb813-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(poss_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = head_l ~ total_l, data = possum)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.1877 -1.5340 -0.3345  1.2788  7.3968 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 42.70979    5.17281   8.257 5.66e-13 ***
## total_l      0.57290    0.05933   9.657 4.68e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.595 on 102 degrees of freedom
## Multiple R-squared:  0.4776, Adjusted R-squared:  0.4725 
## F-statistic: 93.26 on 1 and 102 DF,  p-value: 4.681e-16</code></pre>
<p>The model object, <code>poss_mod</code>, contains much more information. Using the function <code>names()</code> function on the model objects, gives you a list of other quantities available, such as residuals.</p>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb815-1"><a href="#cb815-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(poss_mod)</span></code></pre></div>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;</code></pre>
<p>Figure @ref(fig:scat262-fig) is a plot the data points and least squares line together.</p>
<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb817-1"><a href="#cb817-1" aria-hidden="true" tabindex="-1"></a>possum <span class="sc">%&gt;%</span></span>
<span id="cb817-2"><a href="#cb817-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>( head_l <span class="sc">~</span> total_l) <span class="sc">%&gt;%</span></span>
<span id="cb817-3"><a href="#cb817-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_lm</span>(<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb817-4"><a href="#cb817-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Total Length (cm)&quot;</span>,<span class="at">y=</span><span class="st">&quot;Head Length (mm)&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb817-5"><a href="#cb817-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Possum data including regression line&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb817-6"><a href="#cb817-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) </span></code></pre></div>
<div class="figure">
<img src="26-Linear-Regression-Basics_files/figure-html/scat262-fig-1.png" alt="A scatterplot of possum total length and head length including a regression line." width="672" />
<p class="caption">
(#fig:scat262-fig)A scatterplot of possum total length and head length including a regression line.
</p>
</div>
</div>
<div id="interpretation" class="section level3" number="26.2.3">
<h3><span class="header-section-number">26.2.3</span> Interpretation</h3>
<p>Interpreting parameters in a regression model is often one of the most important steps in the analysis. The intercept term, <span class="math inline">\(\beta_0\)</span>, is usually uninteresting. It represents the <strong>average</strong> value of the response when the predictor is 0. Unless we center our predictor variable around 0, the actual value of the intercept is usually not important; it typically just gives the slope more flexibility to fit the data. The slope term, <span class="math inline">\(\beta_1\)</span> represents the <strong>average</strong> increase in the response variable per unit increase in the predictor variable. We keep using the word <strong>average</strong> in our discussion. With the assumption of a mean of 0 for the residuals, which least squares ensures with a line going through the point <span class="math inline">\(\left(\bar{x},\bar{y} \right)\)</span>, the output of the model is the expected or average response for the given input. Mathematically we have:</p>
<p><span class="math display">\[
E(Y|X=x)=E(\beta_0+\beta_1x+e) = E(\beta_0+\beta_1x)+E(e)=\beta_0+\beta_1x
\]</span></p>
<p>Predicting a value of the response variable simply becomes a matter of substituting the value of the predictor variable into the estimated regression equation. Again, it is important to note that for a given value of <span class="math inline">\(x\)</span>, the predicted response, <span class="math inline">\(\hat{y}\)</span> is what we expect the average value of <span class="math inline">\(y\)</span> to be given that specific value of the predictor.</p>
<blockquote>
<p><strong>Exercise</strong>: The slope and intercept estimates for the possum data are 0.5729 and 42.7098. What do these numbers really mean, interpret them?</p>
</blockquote>
<p>Interpreting the slope parameter is helpful in almost any application. For each additional 1 cm of total length of a possum, we would expect the possum’s head to be 0.5729 mm longer on average. Note that a longer total length corresponds to longer head because the slope coefficient is positive. We must be cautious in this interpretation: while there is a real association, we cannot interpret a causal connection between the variables because these data are observational. That is, increasing a possum’s total length may not cause the possum’s head to be longer.</p>
<p>The estimated intercept <span class="math inline">\(b_0=42.7\)</span> describes the average head length of a possum with zero total length! The meaning of the intercept is irrelevant to this application since a possum can not practically have a total length of 0.</p>
<p>Earlier we noted a relationship between the slope estimate and the correlation coefficient estimate.</p>
<blockquote>
<p><strong>Exercise</strong>
Find the slope from the correlation and standard deviations.</p>
</blockquote>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb818-1"><a href="#cb818-1" aria-hidden="true" tabindex="-1"></a>possum <span class="sc">%&gt;%</span></span>
<span id="cb818-2"><a href="#cb818-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">correlation=</span><span class="fu">cor</span>(head_l,total_l),<span class="at">sd_head=</span><span class="fu">sd</span>(head_l),</span>
<span id="cb818-3"><a href="#cb818-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">sd_total=</span><span class="fu">sd</span>(total_l),<span class="at">slope=</span>correlation<span class="sc">*</span>sd_head<span class="sc">/</span>sd_total)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##   correlation sd_head sd_total slope
##         &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
## 1       0.691    3.57     4.31 0.573</code></pre>
</div>
<div id="extrapolation-is-dangerous" class="section level3" number="26.2.4">
<h3><span class="header-section-number">26.2.4</span> Extrapolation is dangerous</h3>
<blockquote>
<p>“When those blizzards hit the East Coast this winter, it proved to my satisfaction that global warming was a fraud. That snow was freezing cold. But in an alarming trend, temperatures this spring have risen. Consider this: On February <span class="math inline">\(6^{th}\)</span> it was 10 degrees. Today it hit almost 80. At this rate, by August it will be 220 degrees. So clearly folks the climate debate rages on.”
<em>Stephen Colbert</em>
April 6th, 2010<a href="#fn92" class="footnote-ref" id="fnref92"><sup>92</sup></a></p>
</blockquote>
<p>Linear models can be used to approximate the relationship between two variables and are built on an observed random sample. These models have real limitations as linear regression is simply a modeling framework. The truth is almost always much more complex than our simple line. <em>Extrapolation</em> occurs when one tries to make a prediction of a response given a value of the predictor that is outside the range of values used to build the model. We only have information about the relationship between two variables in the region around our observed data. We do not know how the data outside of our limited window will behave. Be careful about extrapolating.</p>
</div>
<div id="reading-computer-output" class="section level3" number="26.2.5">
<h3><span class="header-section-number">26.2.5</span> Reading computer output</h3>
<p>We stored the results of our linear regression model for the possum data in the object <code>poss_mod</code> but it provided only the bare minimum of information. We can get more information using the function <code>summary()</code>.</p>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb820-1"><a href="#cb820-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(poss_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = head_l ~ total_l, data = possum)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.1877 -1.5340 -0.3345  1.2788  7.3968 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 42.70979    5.17281   8.257 5.66e-13 ***
## total_l      0.57290    0.05933   9.657 4.68e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.595 on 102 degrees of freedom
## Multiple R-squared:  0.4776, Adjusted R-squared:  0.4725 
## F-statistic: 93.26 on 1 and 102 DF,  p-value: 4.681e-16</code></pre>
<p>The first line repeats the model formula. The second line is a descriptive summary of the residuals, plots of the residuals are more useful than this summary. We then have a table of the model fit. The first column of numbers provides estimates for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, respectively. For the next columns, we’ll describe the meaning of the columns using the second row, which corresponds to information about the slope estimate. Again, the first column provides the point estimate for <span class="math inline">\(\beta_1\)</span>. The second column is a standard error for this point estimate. The third column is a <span class="math inline">\(t\)</span> test statistic for the null hypothesis that <span class="math inline">\(\beta_1 = 0\)</span>: <span class="math inline">\(T=9.657\)</span>. The last column is the p-value for the <span class="math inline">\(t\)</span> test statistic for the null hypothesis <span class="math inline">\(\beta_1=0\)</span> and a two-sided alternative hypothesis. We will get into more of these details in the next chapters.</p>
<p>The row with the residual standard error is an estimate of the unexplained variance. The next rows give a summary of the model fit and we will discuss in the next chapters.</p>
<p>In the <code>tidyverse</code> we may want to have the table above in a <code>tibble</code>. The <strong>broom</strong> package, which we have seen before, helps with this effort.</p>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb822-1"><a href="#cb822-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span></code></pre></div>
<div class="sourceCode" id="cb823"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb823-1"><a href="#cb823-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(poss_mod)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   42.7      5.17        8.26 5.66e-13
## 2 total_l        0.573    0.0593      9.66 4.68e-16</code></pre>
<blockquote>
<p><strong>Exercise</strong>:<br />
The <code>cars</code> dataset (built-in to <code>R</code>) contains 50 observations of 2 variables. The data give the speed of cars (in mph) and the corresponding distance (in feet) that it took to stop. Attempt to answer the following questions.</p>
</blockquote>
<ol style="list-style-type: lower-alpha">
<li>Build a simple linear regression model fitting distance against speed.</li>
</ol>
<div class="sourceCode" id="cb825"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb825-1"><a href="#cb825-1" aria-hidden="true" tabindex="-1"></a>cars_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(dist<span class="sc">~</span>speed,<span class="at">data=</span>cars)</span>
<span id="cb825-2"><a href="#cb825-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cars_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = dist ~ speed, data = cars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -29.069  -9.525  -2.272   9.215  43.201 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -17.5791     6.7584  -2.601   0.0123 *  
## speed         3.9324     0.4155   9.464 1.49e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15.38 on 48 degrees of freedom
## Multiple R-squared:  0.6511, Adjusted R-squared:  0.6438 
## F-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12</code></pre>
<p>Figure @ref(fig:scat263-fig) is a scatterplot of the <code>cars</code> data set.</p>
<div class="sourceCode" id="cb827"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb827-1"><a href="#cb827-1" aria-hidden="true" tabindex="-1"></a>cars <span class="sc">%&gt;%</span></span>
<span id="cb827-2"><a href="#cb827-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(dist<span class="sc">~</span>speed) <span class="sc">%&gt;%</span></span>
<span id="cb827-3"><a href="#cb827-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_lm</span>() <span class="sc">%&gt;%</span></span>
<span id="cb827-4"><a href="#cb827-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Speed (mph)&quot;</span>,<span class="at">y=</span><span class="st">&quot;Stopping distance (ft)&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb827-5"><a href="#cb827-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="26-Linear-Regression-Basics_files/figure-html/scat263-fig-1.png" alt="A scatterplot of speed and stopping distance." width="672" />
<p class="caption">
(#fig:scat263-fig)A scatterplot of speed and stopping distance.
</p>
</div>
<p>As expected, it appears that for larger speeds, stopping distance is greater.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Report and interpret the estimated model coefficients.</li>
</ol>
<p>The estimated intercept term, <span class="math inline">\(\hat{\beta}_0\)</span> is equal to -17.6. This estimate doesn’t have a helpful interpretation. Technically, it is the estimated average stopping distance for speed 0. However, “stopping distance” doesn’t make sense when a car has no speed. Also, a negative stopping distance doesn’t make sense. Furthermore, a speed of 0 is outside of the observed speeds in the data set, so even if a speed of 0 made sense, it is outside the scope of this data and thus an extrapolation.</p>
<p>The estimated slope term, <span class="math inline">\(\hat{\beta}_1\)</span> is equal to 3.9. This means that for an increase of one mph, we expect stopping distance to increase by 3.9 feet, on average.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Report the estimated common standard deviation of the residuals.</li>
</ol>
<p>The estimated standard deviation of the error (residual), <span class="math inline">\(\hat{\sigma}\)</span> is equal to 15.4.</p>
</div>
<div id="assumptions-1" class="section level3" number="26.2.6">
<h3><span class="header-section-number">26.2.6</span> Assumptions</h3>
<p>Anytime we build a model, there are assumptions behind it that, if violated, could invalidate the conclusions of the model. In the description of simple linear regression, we briefly mentioned these assumptions. Next chapter, we will discuss how to validate these assumptions.</p>
<p><strong>Fit</strong>. When we build a simple linear regression, we assume that the relationship between the response and the predictor is as we specify in the fit formula. This in simple linear regression is often just a linear relationship. Suppose two variables are non-linearly related, see @ref(fig:resid2-fig). While we could build a linear regression model between the two, the resulting model would not be very useful. If we built a model with the fit formulated as a quadratic, a similar plot of the residuals would look flat. We will discuss this more in a later chapter.</p>
<div class="figure">
<img src="26-Linear-Regression-Basics_files/figure-html/resid2-fig-1.png" alt="An example of non-linear relationship between two variables fitted with a linear regression line." width="672" />
<p class="caption">
(#fig:resid2-fig)An example of non-linear relationship between two variables fitted with a linear regression line.
</p>
</div>
<p><strong>Independent Observations</strong>. Another assumption is that all observations in a data set are independent of one another. A common way this assumption is violated is by using time as the predictor variable. For example, suppose we were interested in how an individual’s weight changes over time. While it may be tempting to plot this and fit a regression line through the data, the resulting model is inappropriate, as simple linear regression assumes that each observation is independent. Figure @ref(fig:resid3-fig) shows correlated data fitted with a linear regression line.</p>
<div class="figure">
<img src="26-Linear-Regression-Basics_files/figure-html/resid3-fig-1.png" alt="A scatterplot of correlated data fit using a linear regression model with the assumption of independence." width="672" />
<p class="caption">
(#fig:resid3-fig)A scatterplot of correlated data fit using a linear regression model with the assumption of independence.
</p>
</div>
<p><strong>Constant Error Variance</strong>. In simple linear regression, we assume that the residuals come from a normal distribution with mean 0 and constant standard deviation <span class="math inline">\(\sigma\)</span>. Violation of this assumption is usually manifested as a “megaphone” pattern in the scatterplot. Specifically, as the value of the predictor increases, the variance in the response also increases, resulting in greater spread for larger values of the predictor.</p>
<p><strong>Normality of Errors</strong>. Again, we assume that the residuals are normally distributed. Normality of residuals is not easy to see graphically, so we have to use other diagnostics to check this assumption.</p>
<p>The last three assumptions are important not necessarily for estimating the relationship, but for <em>inferring</em> about the relationship. In future chapters, we will discuss how to use a model for prediction, and how to build a confidence/prediction interval around a prediction. Also, we will discuss inference about the coefficient estimates in a model. Violation of one of the last three assumptions will impact our ability to conduct inference about the population parameters.</p>
</div>
<div id="residual-plots" class="section level3" number="26.2.7">
<h3><span class="header-section-number">26.2.7</span> Residual plots</h3>
<p>One purpose of residual plots is to identify characteristics or patterns still apparent in data after fitting a model. These can help to evaluate the assumptions.</p>
<p>Figure @ref(fig:resid4-fig) shows three scatterplots with linear models in the first row and residual plots in the second row.</p>
<div class="figure">
<img src="26-Linear-Regression-Basics_files/figure-html/resid4-fig-1.png" alt="Residual plots and associated scatterplots." width="672" />
<p class="caption">
(#fig:resid4-fig)Residual plots and associated scatterplots.
</p>
</div>
<p>In the first data set (first column), the residuals show no obvious patterns. The residuals appear to be scattered randomly around the dashed line that represents 0.</p>
<p>The second data set shows a pattern in the residuals. There is some curvature in the scatterplot, which is more obvious in the residual plot. We should not use a straight line to model these data. Instead, a more advanced technique should be used.</p>
<p>In the last plot the spread, variance of the data, seems to increase as the explanatory variable increases. We can see this clearly in the residual plot. To make inference using the <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> distribution would require a transformation to equalize the variance.</p>
</div>
<div id="summary-1" class="section level3" number="26.2.8">
<h3><span class="header-section-number">26.2.8</span> Summary</h3>
<p>We have introduced the ideas of linear regression in this lesson. There are many new terms as well as new <code>R</code> functions to learn. We will continue to use these ideas in the remainder of this block of material. Next we will learn about inference and prediction.</p>
</div>
</div>
<div id="homework-problems-25" class="section level2" number="26.3">
<h2><span class="header-section-number">26.3</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Nutrition at Starbucks</li>
</ol>
<p>In the <code>data</code> folder is a file named <code>starbucks.csv</code>. Use it to answer the questions below.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a scatterplot of number of calories and amount of carbohydrates.<br />
</li>
<li>Describe the relationship in the graph.<br />
</li>
<li>In this scenario, what are the explanatory and response variables?<br />
</li>
<li>Why might we want to fit a regression line to these data?<br />
</li>
<li>Create a scatterplot of number of calories and amount of carbohydrates with the regression line included.<br />
</li>
<li>Using ’lm()` fit a least squares line to the data.<br />
</li>
<li>Report and interpret the slope coefficient.<br />
</li>
<li>For a menu item with 51 g of carbs, what is the estimated calorie count?<br />
</li>
<li>Could we use the model for a menu item with 100 g of carbs?<br />
</li>
<li>Does the assumption of constant variance seem reasonable for this problem?<br />
</li>
<li>Verify that the line passes through the mean carb and mean calories, do this mathematically.<br />
</li>
<li>What is the estimate of the standard deviation of the residuals? How could you use this information?</li>
</ol>
<!--chapter:end:26-Linear-Regression-Basics.Rmd-->
</div>
</div>
<div id="LRINF" class="section level1" number="27">
<h1><span class="header-section-number">27</span> Linear Regression Inference</h1>
<div id="objectives-25" class="section level2" number="27.1">
<h2><span class="header-section-number">27.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Given a simple linear regression model, conduct inference on the coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.<br />
</li>
<li>Given a simple linear regression model, calculate the predicted response for a given value of the predictor.<br />
</li>
<li>Build and interpret confidence and prediction intervals for values of the response variable.</li>
</ol>
</div>
<div id="introduction-3" class="section level2" number="27.2">
<h2><span class="header-section-number">27.2</span> Introduction</h2>
<p>In this chapter we discuss uncertainty in the estimates of the slope and y-intercept for a regression line. This will allow us to perform inference and predictions. Just as we identified standard errors for point estimates in previous chapters, we first discuss standard errors for these new estimates. This chapter is a classical chapter in the sense that we will be using the normal distribution. We will assume that the errors are normally distributed with constant variance. Later in the book, we will relax these assumptions.</p>
<div id="regression" class="section level3" number="27.2.1">
<h3><span class="header-section-number">27.2.1</span> Regression</h3>
<p>Last chapter, we introduced linear models using the simple linear regression model:
<span class="math display">\[
Y=\beta_0+\beta_1X+e
\]</span></p>
<p>where now we assume the error term follows a normal distribution with mean 0 and constant standard deviation <span class="math inline">\(\sigma\)</span>. Using the method of least squares, which does not require the assumption of normality, we obtain estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>:
<span class="math display">\[
\hat{\beta}_1 = {\sum x_i y_i - n\bar{x}\bar{y} \over \sum x_i^2 -n\bar{x}^2}
\]</span>
<span class="math display">\[
\hat{\beta}_0=\bar{y}-\hat{\beta}_1\bar{x}
\]</span></p>
<p>If we assume a probability distribution for the errors, we could also find point estimates using maximum likelihood methods. This will not be discussed in this book.</p>
<p>Using these estimates, for a given value of the predictor, <span class="math inline">\(x_*\)</span>, we can obtain a prediction of the response variable. Here we are using the subscript <span class="math inline">\(_*\)</span> to denote a new value for the explanatory variable. The resulting prediction, which we will denote <span class="math inline">\(\hat{Y}_*\)</span>, is the <strong>average</strong> or <strong>expected value</strong> of the response given predictor value <span class="math inline">\(x_*\)</span>:</p>
<p><span class="math display">\[
\hat{Y}_*=\hat{\beta}_0+\hat{\beta}_1x_*
\]</span></p>
<p>The reason this model returns the expected value of the response at the given value of the predictor is because the error term has an expected value of zero. As a review of the properties of expectation as well as last chapter, we have:</p>
<p><span class="math display">\[
E(Y|X=x)=E(\beta_0+\beta_1x+e)=Y=\beta_0+\beta_1x+E(e)=\beta_0+\beta_1x
\]</span>
because <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(x\)</span> are constants.</p>
<p>It should be abundantly clear by now that <span class="math inline">\(\hat{Y}_*\)</span>, <span class="math inline">\(\hat{\beta}_0\)</span>, and <span class="math inline">\(\hat{\beta}_1\)</span> are <strong><em>estimators</em></strong>. Being estimators, they are dependent on our random sample, our data. If we collect a new random sample from the same population, we will get new estimates from these estimators. Thus, we can think of <span class="math inline">\(\hat{Y}_*\)</span>, <span class="math inline">\(\hat{\beta}_0\)</span>, and <span class="math inline">\(\hat{\beta}_1\)</span> as <strong>random variables</strong>. Like all random variables, they have distributions. We can use the distribution of an estimator to build confidence intervals and conduct hypothesis tests about the true values of the parameter it is intended to estimate. The estimators based on least squares are unbiased, their distributions are centered around the actual values of <span class="math inline">\(Y\)</span>, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, respectively.</p>
</div>
<div id="review-of-assumptions" class="section level3" number="27.2.2">
<h3><span class="header-section-number">27.2.2</span> Review of assumptions</h3>
<p>We will review the assumptions of the least squares model because they are important for inference. Refer to Figure @ref(fig:assump271-fig), which plots the linear regression in the top row and the residuals in the second row. We generally assume the following:</p>
<ol style="list-style-type: decimal">
<li><strong>Fit</strong>. The data should show a linear trend. If there is a nonlinear trend, a transformation of the explanatory variable or a more advanced regression method should be applied. When looking at the residual plot, if the trend is linear, we should see a spread of points that are flat. The left column of Figure @ref(fig:assump271-fig) is an example of a nonlinear relationship. The top plot is the regression plot and we can see what looks like a quadratic relationship instead of a linear one. The residual plot, the plot in the lower left corner of Figure @ref(fig:assump271-fig), also exhibits this non-linear trend.<br />
</li>
<li><strong>Nearly normal residuals</strong>. Generally the residuals must be nearly normal to use a <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> for inference. When this assumption is found to be unreasonable, it is usually because of <strong>outliers</strong> or concerns about <strong>influential</strong> points. An example of non-normal residuals is shown in the second column of Figure @ref(fig:assump271-fig). A <strong>qq</strong> plot is also useful as a diagnostic tool as we have seen. We can still use the <strong>bootstrap</strong> as an inference tool if the normality assumption is unreasonable.<br />
</li>
<li><strong>Constant variability</strong>. The variability of points around the least squares line remains roughly constant. An example of non-constant variability is shown in the third panel of Figure @ref(fig:assump271-fig). The constant variability assumption is needed for the <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> distributions. It is not required for the bootstrap method.<br />
</li>
<li><strong>Independent observations</strong>. Be cautious about applying regression to data collected sequentially in what is called a <strong>time series</strong>. Such data may have an underlying structure that should be considered in a model and analysis. An example of a time series where independence is violated is shown in the fourth panel of Figure @ref(fig:assump271-fig). More advanced methods are required for time series data even including using a bootstrap.</li>
</ol>
<p>In a later chapter we will explore more regression diagnostics.</p>
<div class="figure">
<img src="27-Regression-Inference_files/figure-html/assump271-fig-1.png" alt="Plots of linear regression and residual to illustrate the assumptions of the model." width="672" />
<p class="caption">
(#fig:assump271-fig)Plots of linear regression and residual to illustrate the assumptions of the model.
</p>
</div>
</div>
<div id="distribution-of-our-estimators" class="section level3" number="27.2.3">
<h3><span class="header-section-number">27.2.3</span> Distribution of our estimators</h3>
<p>With the assumption that the error term is normally distributed, we can find the distributions of our estimates, which turn out to be normal:</p>
<p><span class="math display">\[
\hat{\beta}_0\sim N\left(\beta_0, \sigma\sqrt{{1\over n}+{\bar{x}^2\over \sum (x_i-\bar{x})^2}}\right)
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_1\sim N\left(\beta_1, {\sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}\right)
\]</span></p>
<p><span class="math display">\[
\hat{Y}_* \sim N\left(\beta_0+\beta_1x_*, \sigma\sqrt{{1\over n}+{(x_*-\bar{x})^2\over \sum (x_i-\bar{x})^2}}\right)
\]</span></p>
<p>Notice that all three of these are unbiased, the expected value is equal to the parameter being estimated. Looking at the variance of the slope estimate we can see that is a function of the underlying unexplained variance, <span class="math inline">\(\sigma^2\)</span> and the data. The denominator is increased by having a larger spread in the explanatory variable. The slope of the estimated line is more stable, less variable, if the independent variable has high variance. That is interesting. If you are designing an experiment, this gives you insight in how to select the range of values for your explanatory variable.</p>
</div>
</div>
<div id="inference" class="section level2" number="27.3">
<h2><span class="header-section-number">27.3</span> Inference</h2>
<p>Now that we know how the coefficient estimates and the average predicted values behave, we can perform inference on their true values. Let’s take <span class="math inline">\(\hat{\beta}_1\)</span> for demonstration:</p>
<p><span class="math display">\[
\hat{\beta}_1\sim N\left(\beta_1, {\sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}\right)
\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[
{\hat{\beta}_1-\beta_1 \over {\sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}\sim N\left(0, 1\right)
\]</span></p>
<p>However, note that the expression on the left depends on error standard deviation, <span class="math inline">\(\sigma\)</span>. In reality, we will not know this value and will have to estimate it with</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{{1\over n-2} \sum_{i=1}^n \hat{e}_i^2}
\]</span></p>
<p>where <span class="math inline">\(\hat{e}_i\)</span> is the observed <span class="math inline">\(i\)</span>th <strong>residual</strong> (<span class="math inline">\(\hat{e}_i=y_i-\hat{\beta}_0-\hat{\beta}_1x_i\)</span>).</p>
<p>As we learned in the last block, if we replace population standard deviation (<span class="math inline">\(\sigma\)</span>) with an estimation, the resulting random variable no longer has the standard normal distribution. In fact, it can be shown that</p>
<p><span class="math display">\[
{\hat{\beta}_1-\beta_1 \over {\hat \sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}\sim \textsf{t}\left(n-2\right)
\]</span>
We only have <span class="math inline">\(n-2\)</span> degrees of freedom because in the estimation of <span class="math inline">\(\sigma^2\)</span> we had to estimate two parameters, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p>We can use this information to build a <span class="math inline">\((1-\alpha)*100\%\)</span> confidence interval for <span class="math inline">\(\beta_1\)</span>. First, we recognize that</p>
<p><span class="math display">\[
\mbox{P}\left(-t_{\alpha/2,n-2} \leq {\hat{\beta}_1-\beta_1 \over {\hat \sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}\leq t_{\alpha/2,n-2} \right) = 1-\alpha
\]</span></p>
<p>Solving the expression inside the probability statement for <span class="math inline">\(\beta_1\)</span> yields a confidence interval of</p>
<p><span class="math display">\[
\beta_1 \in \left(\hat{\beta_1} \pm t_{\alpha/2,n-2}{\hat \sigma \over \sqrt{\sum(x_i-\bar{x})^2}}\right)
\]</span></p>
<p>We can also evaluate the null hypothesis <span class="math inline">\(H_0: \beta_1 =\beta^*_1\)</span>. If the true value of <span class="math inline">\(\beta_1\)</span> were <span class="math inline">\(\beta^*_1\)</span>, then the estimated <span class="math inline">\(\hat{\beta_1}\)</span> should be around that value. In fact, if <span class="math inline">\(H_0\)</span> were true, the value</p>
<p><span class="math display">\[
{\hat{\beta}_1-\beta^*_1 \over {\hat \sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}
\]</span></p>
<p>has the <span class="math inline">\(\textsf{t}\)</span> distribution with <span class="math inline">\(n-2\)</span> degrees of freedom. Thus, once we collect a sample and obtain the observed <span class="math inline">\(\hat{\beta_1}\)</span> and <span class="math inline">\(\hat \sigma\)</span>, we can calculate this quantity and determine whether it is far enough from zero to reject <span class="math inline">\(H_0\)</span>.</p>
<p>Similarly, we can use the distribution of <span class="math inline">\(\hat \beta_0\)</span> to build a confidence interval or conduct a hypothesis test on <span class="math inline">\(\beta_0\)</span>, but we usually don’t. This has to do with the interpretation of <span class="math inline">\(\beta_0\)</span>.</p>
<div id="starbucks" class="section level3" number="27.3.1">
<h3><span class="header-section-number">27.3.1</span> Starbucks</h3>
<p>That was a great deal of mathematics and theory. Let’s put it to use on the example from Starbucks. In the file <code>data/starbucks.csv</code> we have nutritional facts for several Starbucks’ food items. We used this data in the homework for last chapter. We will use this data again to illustrate the ideas we have introduced in this section.</p>
<p>Read in the data.</p>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb828-1"><a href="#cb828-1" aria-hidden="true" tabindex="-1"></a>starbucks <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/starbucks.csv&quot;</span>)  <span class="sc">%&gt;%</span></span>
<span id="cb828-2"><a href="#cb828-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">type=</span><span class="fu">factor</span>(type))</span></code></pre></div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Summarize and explore the data.</p>
</blockquote>
<p>Let’s look at a summary of the data.</p>
<div class="sourceCode" id="cb829"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb829-1"><a href="#cb829-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(starbucks)</span></code></pre></div>
<pre><code>## Rows: 77
## Columns: 7
## $ item     &lt;chr&gt; &quot;8-Grain Roll&quot;, &quot;Apple Bran Muffin&quot;, &quot;Apple Fritter&quot;, &quot;Banana~
## $ calories &lt;dbl&gt; 350, 350, 420, 490, 130, 370, 460, 370, 310, 420, 380, 320, 3~
## $ fat      &lt;dbl&gt; 8, 9, 20, 19, 6, 14, 22, 14, 18, 25, 17, 12, 17, 21, 5, 18, 1~
## $ carb     &lt;dbl&gt; 67, 64, 59, 75, 17, 47, 61, 55, 32, 39, 51, 53, 34, 57, 52, 7~
## $ fiber    &lt;dbl&gt; 5, 7, 0, 4, 0, 5, 2, 0, 0, 0, 2, 3, 2, 2, 3, 3, 2, 3, 0, 2, 0~
## $ protein  &lt;dbl&gt; 10, 6, 5, 7, 0, 6, 7, 6, 5, 7, 4, 6, 5, 5, 12, 7, 8, 6, 0, 10~
## $ type     &lt;fct&gt; bakery, bakery, bakery, bakery, bakery, bakery, bakery, baker~</code></pre>
<div class="sourceCode" id="cb831"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb831-1"><a href="#cb831-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(starbucks)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##   name     class levels  n missing
## 1 item character     77 77       0
## 2 type    factor      7 77       0
##                                    distribution
## 1 8-Grain Roll (1.3%) ...                      
## 2 bakery (53.2%), petite (11.7%) ...           
## 
## quantitative variables:  
##          name   class min  Q1 median  Q3 max       mean         sd  n missing
## ...1 calories numeric  80 300    350 420 500 338.831169 105.368701 77       0
## ...2      fat numeric   0   9     13  18  28  13.766234   7.095488 77       0
## ...3     carb numeric  16  31     45  59  80  44.870130  16.551634 77       0
## ...4    fiber numeric   0   0      2   4   7   2.220779   2.112764 77       0
## ...5  protein numeric   0   5      7  15  34   9.480519   8.079556 77       0</code></pre>
<p>Let’s predict calories from the carbohydrate content.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Create a scatterplot of calories and carbohydrate, carbs, content.</p>
</blockquote>
<p>Figure @ref(fig:scat271-fig) is the scatterplot.</p>
<div class="sourceCode" id="cb833"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb833-1"><a href="#cb833-1" aria-hidden="true" tabindex="-1"></a>starbucks <span class="sc">%&gt;%</span></span>
<span id="cb833-2"><a href="#cb833-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(calories<span class="sc">~</span>carb) <span class="sc">%&gt;%</span></span>
<span id="cb833-3"><a href="#cb833-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Carbohydrates&quot;</span>,<span class="at">y=</span><span class="st">&quot;Calories&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb833-4"><a href="#cb833-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>())</span></code></pre></div>
<div class="figure">
<img src="27-Regression-Inference_files/figure-html/scat271-fig-1.png" alt="Scatterplot of calories and carbohydrate content in Starbucks' products." width="672" />
<p class="caption">
(#fig:scat271-fig)Scatterplot of calories and carbohydrate content in Starbucks’ products.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Use <code>R</code> to fit a linear regression model by regressing <code>calories</code> on <code>carb</code>.</p>
</blockquote>
<p>The results of fitting a linear least squares model is stored in the <code>star_mod</code> object.</p>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb834-1"><a href="#cb834-1" aria-hidden="true" tabindex="-1"></a>star_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> calories <span class="sc">~</span> carb, <span class="at">data =</span> starbucks)</span></code></pre></div>
<div class="sourceCode" id="cb835"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb835-1"><a href="#cb835-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(star_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = calories ~ carb, data = starbucks)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -151.962  -70.556   -0.636   54.908  179.444 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 146.0204    25.9186   5.634 2.93e-07 ***
## carb          4.2971     0.5424   7.923 1.67e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 78.26 on 75 degrees of freedom
## Multiple R-squared:  0.4556, Adjusted R-squared:  0.4484 
## F-statistic: 62.77 on 1 and 75 DF,  p-value: 1.673e-11</code></pre>
<div id="hypothesis-test" class="section level4" number="27.3.1.1">
<h4><span class="header-section-number">27.3.1.1</span> Hypothesis test</h4>
<p>In the second row of the <strong>Coefficients</strong> portion of the table we have our point estimate, standard error, test statistic, and p-value for the slope.</p>
<p>The hypotheses for this output is<br />
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_1 = 0\)</span>. The true linear model has slope zero. The carb content has no impact on the the calorie content.<br />
<span class="math inline">\(H_A\)</span>: <span class="math inline">\(\beta_1 \neq 0\)</span>. The true linear model has a slope different than zero. The higher the carb content, the greater the average calorie content or vice-versa.</p>
<p>Our estimate of the slope is 4.297 with a standard error of 0.5424. Just for demonstration purposes, we will use <code>R</code> to calculate the test statistic and p-value as a series of steps. The test statistic under the null hypothesis is:</p>
<p><span class="math display">\[
{\hat{\beta}_1-0 \over {\hat \sigma \over \sqrt{ \sum (x_i-\bar{x})^2}}}
\]</span>
The denominator is the standard error of the estimate. The estimate of the residual standard deviation is reported in the last line as 78.26. But it is just the square root of the sum of squared residuals divided by the degrees of freedom.</p>
<div class="sourceCode" id="cb837"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb837-1"><a href="#cb837-1" aria-hidden="true" tabindex="-1"></a>sighat<span class="ot">&lt;-</span><span class="fu">sqrt</span>(<span class="fu">sum</span>((star_mod<span class="sc">$</span>residuals)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">75</span>)</span>
<span id="cb837-2"><a href="#cb837-2" aria-hidden="true" tabindex="-1"></a>sighat</span></code></pre></div>
<pre><code>## [1] 78.25956</code></pre>
<p>The standard error of the slope estimate is, and confirmed in the table:</p>
<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb839-1"><a href="#cb839-1" aria-hidden="true" tabindex="-1"></a>std_er<span class="ot">&lt;-</span>sighat<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">sum</span>((starbucks<span class="sc">$</span>carb<span class="sc">-</span><span class="fu">mean</span>(starbucks<span class="sc">$</span>carb))<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb839-2"><a href="#cb839-2" aria-hidden="true" tabindex="-1"></a>std_er</span></code></pre></div>
<pre><code>## [1] 0.5423626</code></pre>
<p>The test statistic is</p>
<div class="sourceCode" id="cb841"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb841-1"><a href="#cb841-1" aria-hidden="true" tabindex="-1"></a>(<span class="fl">4.2971</span><span class="dv">-0</span>)<span class="sc">/</span>std_er</span></code></pre></div>
<pre><code>## [1] 7.922928</code></pre>
<p>And the p-value</p>
<div class="sourceCode" id="cb843"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb843-1"><a href="#cb843-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pt</span>((<span class="fl">4.2971</span><span class="dv">-0</span>)<span class="sc">/</span>std_er,<span class="dv">73</span>,<span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 1.965319e-11</code></pre>
<p>This is slightly different from the table value because of the precision of the computer and the small p-value.</p>
<p>We reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span> because the data provide strong evidence that the true slope parameter is greater than zero.</p>
<p>The computer software uses zero in the null hypothesis, if you wanted to test another value of the slope then you would have to do the calculations step by step like we did above.</p>
<p>By the way, this was not a <code>tidy</code> way to do the calculation. The <strong>broom</strong> package makes it easier to use <code>tidy</code> ideas on the regression model. We used these ideas in the last chapter.</p>
<p>As a reminder:</p>
<div class="sourceCode" id="cb845"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb845-1"><a href="#cb845-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span></code></pre></div>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb846-1"><a href="#cb846-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(star_mod) </span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   146.      25.9        5.63 2.93e- 7
## 2 carb            4.30     0.542      7.92 1.67e-11</code></pre>
<p>And step by step:</p>
<div class="sourceCode" id="cb848"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb848-1"><a href="#cb848-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(star_mod) <span class="sc">%&gt;%</span></span>
<span id="cb848-2"><a href="#cb848-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(term<span class="sc">==</span><span class="st">&quot;carb&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb848-3"><a href="#cb848-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">test_stat=</span>(estimate<span class="dv">-0</span>)<span class="sc">/</span>std.error,<span class="at">p_value=</span><span class="dv">2</span><span class="sc">*</span><span class="fu">pt</span>(test_stat,<span class="at">df=</span><span class="dv">73</span>,<span class="at">lower.tail =</span> <span class="cn">FALSE</span>))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   test_stat  p_value
##       &lt;dbl&gt;    &lt;dbl&gt;
## 1      7.92 1.97e-11</code></pre>
</div>
<div id="confidence-interval-1" class="section level4" number="27.3.1.2">
<h4><span class="header-section-number">27.3.1.2</span> Confidence interval</h4>
<p>We could calculate the confidence interval from the point estimate, standard error, and critical value but we will let <code>R</code> do it for us.</p>
<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb850-1"><a href="#cb850-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(star_mod)</span></code></pre></div>
<pre><code>##                 2.5 %     97.5 %
## (Intercept) 94.387896 197.652967
## carb         3.216643   5.377526</code></pre>
<p>This confidence interval does not contain the value 0. This suggests that a value of 0 is probably not feasible for <span class="math inline">\(\beta_1\)</span>.</p>
<p>In the end, we would declare that carbohydrate and calorie content of Starbucks’ menu items are linearly correlated. However, we DID NOT prove causation. We simply showed that the two variables are correlated.</p>
</div>
</div>
</div>
<div id="inference-on-predictions" class="section level2" number="27.4">
<h2><span class="header-section-number">27.4</span> Inference on Predictions</h2>
<p>Similarly, we can take advantage of the distribution of <span class="math inline">\(\hat Y_*\)</span> to build a confidence interval on <span class="math inline">\(Y_*\)</span> (the average value of <span class="math inline">\(Y\)</span> at some value <span class="math inline">\(x_*\)</span>):</p>
<p><span class="math display">\[
Y_*\in \left(\hat Y_* \pm t_{\alpha/2,n-2}\hat \sigma \sqrt{{1\over n}+{(x_*-\bar{x})^2\over \sum (x_i-\bar{x})^2}} \right)
\]</span></p>
<p>There are a couple of things to point out about the above. First, note that the width of the confidence interval is dependent on how far <span class="math inline">\(x_*\)</span> is from the average value of <span class="math inline">\(x\)</span>. The further we are from the center of the data, the wider the interval will be.</p>
<p>Second, note that this in an interval on <span class="math inline">\(Y_*\)</span> the <strong><em>average</em></strong> value of <span class="math inline">\(Y\)</span> at <span class="math inline">\(x_*\)</span>. If we want to build an interval for a single observation of <span class="math inline">\(Y\)</span> (<span class="math inline">\(Y_{new}\)</span>), we will need to build a <em>prediction</em> interval, which is considerably wider than a confidence interval on <span class="math inline">\(Y_*\)</span>:</p>
<p><span class="math display">\[
Y_{new}\in \left(\hat Y_* \pm t_{\alpha/2,n-2}\hat \sigma \sqrt{1+{1\over n}+{(x_*-\bar{x})^2\over \sum (x_i-\bar{x})^2}} \right)
\]</span></p>
<div id="starbucks-1" class="section level3" number="27.4.1">
<h3><span class="header-section-number">27.4.1</span> Starbucks</h3>
<p>Continuing with the <code>Starbucks</code> example. In plotting the data, we can have <code>R</code> plot the confidence and prediction bands, Figure @ref(fig:ci271-fig). We will observe the width of both of these intervals increase as we move away from the center of the data and also that prediction intervals are wider than the confidence interval.</p>
<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb852-1"><a href="#cb852-1" aria-hidden="true" tabindex="-1"></a>starbucks <span class="sc">%&gt;%</span></span>
<span id="cb852-2"><a href="#cb852-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(calories<span class="sc">~</span>carb) <span class="sc">%&gt;%</span></span>
<span id="cb852-3"><a href="#cb852-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Carbohydrates&quot;</span>,<span class="at">y=</span><span class="st">&quot;Calories&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb852-4"><a href="#cb852-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_lm</span>(<span class="at">stat=</span><span class="st">&quot;lm&quot;</span>,<span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb852-5"><a href="#cb852-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_lm</span>(<span class="at">stat=</span><span class="st">&quot;lm&quot;</span>,<span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb852-6"><a href="#cb852-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>())</span></code></pre></div>
<div class="figure">
<img src="27-Regression-Inference_files/figure-html/ci271-fig-1.png" alt="Confidence and predictions bands for linear regression model of calories and carbs in Starbucks' products." width="672" />
<p class="caption">
(#fig:ci271-fig)Confidence and predictions bands for linear regression model of calories and carbs in Starbucks’ products.
</p>
</div>
<p>We have not done diagnostics yet and it may be that using a linear regression model for this data may not be appropriate. But for the sake of learning we will continue. To find these confidence intervals we need a value for <code>carb</code> so let’s use 60 and 70.</p>
<p>We create a data frame with the new values of <code>carb</code> in it. Then we will use the <code>predict</code> function to find the confidence interval. Using the option <code>interval</code> set to <code>confidence</code> will return a confidence interval for the average calorie content for each value in the new data frame.</p>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb853-1"><a href="#cb853-1" aria-hidden="true" tabindex="-1"></a>new_carb <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">carb=</span><span class="fu">c</span>(<span class="dv">60</span>,<span class="dv">70</span>))</span>
<span id="cb853-2"><a href="#cb853-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(star_mod, <span class="at">newdata =</span> new_carb, <span class="at">interval =</span> <span class="st">&#39;confidence&#39;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 403.8455 379.7027 427.9883
## 2 446.8163 414.3687 479.2640</code></pre>
<p>Or using the <strong>broom</strong> package.</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb855-1"><a href="#cb855-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(star_mod,<span class="at">newdata=</span>new_carb,<span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 4
##    carb .fitted .lower .upper
##   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1    60    404.   380.   428.
## 2    70    447.   414.   479.</code></pre>
<p>As an example, we are 95% confident that the average calories in a Starbucks’ menu item with 60 grams of carbs is between 379.7 and 428.0.</p>
<blockquote>
<p><strong>Exercise</strong>:
Give the 95% confidence interval of average calories for 70 grams of carbohydrates.</p>
</blockquote>
<p>We are 95% confident that the average calories in a Starbucks’ menu item with 70 grams carbs is between 414.4 and 479.3.</p>
<p>For the prediction interval, we simply need to change the option in <code>interval</code>:</p>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb857-1"><a href="#cb857-1" aria-hidden="true" tabindex="-1"></a>new_carb <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">carb=</span><span class="fu">c</span>(<span class="dv">60</span>,<span class="dv">70</span>))</span>
<span id="cb857-2"><a href="#cb857-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(star_mod, <span class="at">newdata =</span> new_carb, <span class="at">interval =</span> <span class="st">&#39;prediction&#39;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 403.8455 246.0862 561.6048
## 2 446.8163 287.5744 606.0582</code></pre>
<p>We are 95% confident the next Starbucks’ menu item that has 60 grams of carbs will have a calorie content between 246 and 561. Notice how prediction intervals are wider since they are intervals on individual observations and not an averages.</p>
<blockquote>
<p><strong>Exercise</strong>:
Give the 90% prediction interval of average calories for 70 grams of carbohydrates.</p>
</blockquote>
<p>We changed the confidence level. Since we are less confident, the interval will be narrower than the 95% prediction interval we just calculated.</p>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb859-1"><a href="#cb859-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(star_mod, <span class="at">newdata =</span> new_carb, <span class="at">level=</span><span class="fl">0.9</span>, <span class="at">interval =</span> <span class="st">&#39;prediction&#39;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 403.8455 271.9565 535.7345
## 2 446.8163 313.6879 579.9448</code></pre>
<p>We are 90% confident the next Starbucks’ menu item that has 70 grams of carbs will have a calorie content between 313.7 and 579.9.</p>
</div>
<div id="summary-2" class="section level3" number="27.4.2">
<h3><span class="header-section-number">27.4.2</span> Summary</h3>
<p>This chapter has introduced the process of inference for a simple linear regression model. We tested the slope estimate as well as generated confidence intervals for average and individual predicted values.</p>
</div>
</div>
<div id="homework-problems-26" class="section level2" number="27.5">
<h2><span class="header-section-number">27.5</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li><p>In the chapter reading, we noticed that the 95% prediction interval was much wider than the 95% confidence interval. In words, explain why this is.</p></li>
<li><p>Beer and blood alcohol content</p></li>
</ol>
<p>Many people believe that gender, weight, drinking habits, and many other factors are much more important in predicting blood alcohol content (BAC) than simply considering the number of drinks a person consumed. Here we examine data from sixteen student volunteers at Ohio State University who each drank a randomly assigned number of cans of beer. These students were evenly divided between men and women, and they differed in weight and drinking habits. Thirty minutes later, a police officer measured their blood alcohol content (BAC) in grams of alcohol per deciliter of blood. The data is in the <code>bac.csv</code> file under the <code>data</code> folder.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a scatterplot for cans of beer and blood alcohol level.<br />
</li>
<li>Describe the relationship between the number of cans of beer and BAC.<br />
</li>
<li>Write the equation of the regression line. Interpret the slope and intercept in context.<br />
</li>
<li>Do the data provide strong evidence that drinking more cans of beer is associated with an increase in blood alcohol? State the null and alternative hypotheses, report the p-value, and state your conclusion.<br />
</li>
<li>Build a 95% confidence interval for the slope and interpret it in the context of your hypothesis test from part d.<br />
</li>
<li>Suppose we visit a bar, ask people how many drinks they have had, and also take their BAC. Do you think the relationship between number of drinks and BAC would be as strong as the relationship found in the Ohio State study?<br />
</li>
<li>Predict the average BAC after two beers and build a 90% confidence interval around that prediction.<br />
</li>
<li>Repeat except build a 90% prediction interval and interpret.<br />
</li>
<li>Plot the data points with a regression line, confidence band, and prediction band.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Suppose I build a regression fitting a response variable to one predictor variable. I build a 95% confidence interval on <span class="math inline">\(\beta_1\)</span> and find that it contains 0, meaning that a slope of 0 is feasible. Does this mean that the response and the predictor are independent?</li>
</ol>
<!--chapter:end:27-Regression-Inference.Rmd-->
</div>
</div>
<div id="LRDIAG" class="section level1" number="28">
<h1><span class="header-section-number">28</span> Regression Diagnostics</h1>
<div id="objectives-26" class="section level2" number="28.1">
<h2><span class="header-section-number">28.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Obtain and interpret <span class="math inline">\(R\)</span>-squared and the <span class="math inline">\(F\)</span>-statistic.<br />
</li>
<li>Use <code>R</code> to evaluate the assumptions of a linear model.<br />
</li>
<li>Identify and explain outliers and leverage points.</li>
</ol>
</div>
<div id="introduction-4" class="section level2" number="28.2">
<h2><span class="header-section-number">28.2</span> Introduction</h2>
<p>Over the last two chapters, we have detailed simple linear regression. First, we described the model and its underlying assumptions. Next, we obtained parameter estimates using the method of least squares. Finally, we obtained the distributions of parameter estimates and used that information to conduct inference on parameters and predictions. Implementation was relatively straightforward; once we obtained the expressions of interest, we used <code>R</code> to find parameters estimates, interval estimates, etc. In this chapter we will explore more tools to assess the quality of our simple linear regression model. Some of these tools will generalize when we move to multiple predictors.</p>
</div>
<div id="assessing-our-model---understanding-the-output-from-lm" class="section level2" number="28.3">
<h2><span class="header-section-number">28.3</span> Assessing our model - understanding the output from <code>lm</code></h2>
<p>There is more that we can do with the output from the <code>lm()</code> function than just estimating parameters and predicting responses. There are metrics that allow us to assess the fit of our model. To explore some of these ideas let’s use the Starbucks example again.</p>
<p>First load the data:</p>
<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb861-1"><a href="#cb861-1" aria-hidden="true" tabindex="-1"></a>starbucks <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/starbucks.csv&quot;</span>)</span></code></pre></div>
<p>Next build and summarize the model:</p>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb862-1"><a href="#cb862-1" aria-hidden="true" tabindex="-1"></a>star_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(calories<span class="sc">~</span>carb,<span class="at">data=</span>starbucks)</span></code></pre></div>
<div class="sourceCode" id="cb863"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb863-1"><a href="#cb863-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(star_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = calories ~ carb, data = starbucks)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -151.962  -70.556   -0.636   54.908  179.444 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 146.0204    25.9186   5.634 2.93e-07 ***
## carb          4.2971     0.5424   7.923 1.67e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 78.26 on 75 degrees of freedom
## Multiple R-squared:  0.4556, Adjusted R-squared:  0.4484 
## F-statistic: 62.77 on 1 and 75 DF,  p-value: 1.673e-11</code></pre>
<p>You may have noticed some other information that appeared in the summary of our model. We discussed the output in a previous chapter but let’s go a little more in depth.</p>
<div id="residual-standard-error" class="section level3" number="28.3.1">
<h3><span class="header-section-number">28.3.1</span> Residual Standard Error</h3>
<p>The “residual standard error” is the estimate of <span class="math inline">\(\sigma\)</span>, the unexplained variance in our response. In our example, this turned out to be 78.26. If the assumptions of normality and constant variance are valid, we would expect the majority, 68%, of the observed values at a given input to be within <span class="math inline">\(\pm 78.26\)</span> of the mean value.</p>
<p>If we want to extract just this value from the model object, first recognize that <code>summary(my.model)</code> is a list with several components:</p>
<div class="sourceCode" id="cb865"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb865-1"><a href="#cb865-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(<span class="fu">summary</span>(star_mod))</span></code></pre></div>
<pre><code>##  [1] &quot;call&quot;          &quot;terms&quot;         &quot;residuals&quot;     &quot;coefficients&quot; 
##  [5] &quot;aliased&quot;       &quot;sigma&quot;         &quot;df&quot;            &quot;r.squared&quot;    
##  [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot;    &quot;cov.unscaled&quot;</code></pre>
<p>As expected, the <code>sigma</code> component shows the estimated value of <span class="math inline">\(\sigma\)</span>.</p>
<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb867-1"><a href="#cb867-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(star_mod)<span class="sc">$</span>sigma</span></code></pre></div>
<pre><code>## [1] 78.25956</code></pre>
<p>Again, this value is smaller the closer the points are to the regression fit. It is a measure of unexplained variance in the response variable.</p>
</div>
<div id="r-squared" class="section level3" number="28.3.2">
<h3><span class="header-section-number">28.3.2</span> R-squared</h3>
<p>Another quantity that appears is <span class="math inline">\(R\)</span>-squared, also know as the coefficient of determination. <span class="math inline">\(R\)</span>-squared is one measure of goodness of fit. Essentially <span class="math inline">\(R\)</span>-squared is a ratio of variance (in the response) explained by the model to overall variance of the response. It helps to describe the decomposition of variance:</p>
<p><span class="math display">\[
\underbrace{\sum_{i=1}^n (y_i-\bar{y})^2}_{SS_{\text{Total}}} = \underbrace{\sum_{i=1}^n (\hat{y}_i-\bar y)^2}_{SS_{\text{Regression}}}+\underbrace{\sum_{i=1}^n(y_i-\hat{y}_i)^2}_{SS_{\text{Error}}}
\]</span></p>
<p>In other words, the overall variation in <span class="math inline">\(y\)</span> can be separated into two parts: variation due to the linear relationship between <span class="math inline">\(y\)</span> and the predictor variable(s), called <span class="math inline">\(SS_\text{Regression}\)</span>, and residual variation (due to random scatter or perhaps a poorly chosen model), called <span class="math inline">\(SS_\text{Error}\)</span>. Note: <span class="math inline">\(SS_\text{Error}\)</span> is used to estimate residual standard error in the previous section.<a href="#fn93" class="footnote-ref" id="fnref93"><sup>93</sup></a></p>
<p><span class="math inline">\(R\)</span>-squared simply measures the ratio between <span class="math inline">\(SS_\text{Regression}\)</span> and <span class="math inline">\(SS_\text{Total}\)</span>. A common definition of <span class="math inline">\(R\)</span>-squared is the proportion of overall variation in the response that is explained by the linear model. <span class="math inline">\(R\)</span>-squared can be between 0 and 1. Values of <span class="math inline">\(R\)</span>-squared close to 1 indicate a tight fit (little scatter) around the estimated regression line. Value close to 0 indicate the opposite (large remaining scatter).</p>
<p>We can obtain <span class="math inline">\(R\)</span>-squared “by hand” or by using the output of the <code>lm()</code> function:</p>
<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb869-1"><a href="#cb869-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(star_mod)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.4556237</code></pre>
<p>For simple linear regression, <span class="math inline">\(R\)</span>-squared is related to <strong>correlation</strong>. We can compute the correlation using a formula, just as we did with the sample mean and standard deviation. However, this formula is rather complex,<a href="#fn94" class="footnote-ref" id="fnref94"><sup>94</sup></a> so we let <code>R</code> do the heavy lifting for us.</p>
<div class="sourceCode" id="cb871"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb871-1"><a href="#cb871-1" aria-hidden="true" tabindex="-1"></a>starbucks <span class="sc">%&gt;%</span></span>
<span id="cb871-2"><a href="#cb871-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">correlation=</span><span class="fu">cor</span>(carb,calories),<span class="at">correlation_squared=</span>correlation<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   correlation correlation_squared
##         &lt;dbl&gt;               &lt;dbl&gt;
## 1       0.675               0.456</code></pre>
<p>As a review, Figure @ref(fig:cor-fig) below shows eight plots and their corresponding correlations. Only when the relationship is perfectly linear is the correlation either -1 or 1. If the relationship is strong and positive, the correlation will be near +1. If it is strong and negative, it will be near -1. If there is no apparent linear relationship between the variables, then the correlation will be near zero.</p>
<div class="figure">
<img src="28-Regression-Diagnostics_files/figure-html/cor-fig-1.png" alt="Scatterplots demonstrating different correlations." width="672" />
<p class="caption">
(#fig:cor-fig)Scatterplots demonstrating different correlations.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong><br />
If a linear model has a very strong negative relationship with a correlation of -0.97, how much of the variation in the response is explained by the explanatory variable?<a href="#fn95" class="footnote-ref" id="fnref95"><sup>95</sup></a></p>
</blockquote>
<p>Note that one of the components of <code>summary(lm())</code> function is <code>adj.r.squared</code>. This is a value of <span class="math inline">\(R\)</span>-squared adjusted for number of predictors. This idea is covered more in depth in a machine learning course.</p>
</div>
<div id="f-statistic" class="section level3" number="28.3.3">
<h3><span class="header-section-number">28.3.3</span> F-Statistic</h3>
<p>Another quantity that appears in the summary of the model is the <span class="math inline">\(F\)</span>-statistic. This value evaluates the null hypothesis that all of the non-intercept coefficients are equal to 0. Rejecting this hypothesis implies that the model is useful in the sense that at least one of the predictors shares a significant linear relationship with the response.</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_1 = \beta_2 = \dots = \beta_p = 0\)</span><br />
<span class="math inline">\(H_a\)</span>: At least one coefficient not equal to 0.</p>
<p>where <span class="math inline">\(p\)</span> is the number of predictors in the model. Just like in ANOVA, this is a simultaneous test of all coefficients and does not inform us which one(s) are different from 0.</p>
<p>The <span class="math inline">\(F\)</span>-statistic is given by
<span class="math display">\[
{n-p-1 \over p}{\sum (\hat{y}_i-\bar{y})^2\over \sum e_i^2}
\]</span></p>
<p>Under the null hypothesis, the <span class="math inline">\(F\)</span>-statistic follows the <span class="math inline">\(F\)</span> distribution with parameters <span class="math inline">\(p\)</span> and <span class="math inline">\(n-p-1\)</span>.</p>
<p>In our example, the <span class="math inline">\(F\)</span>-statistic is redundant since there is only one predictor. In fact, the <span class="math inline">\(p\)</span>-value associated with the <span class="math inline">\(F\)</span>-statistic is equal to the <span class="math inline">\(p\)</span>-value associated with the estimate of <span class="math inline">\(\beta_1\)</span>. However, when we move to cases with more predictor variables, we may be interested in the <span class="math inline">\(F\)</span>-statistic.</p>
<div class="sourceCode" id="cb873"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb873-1"><a href="#cb873-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(star_mod)<span class="sc">$</span>fstatistic</span></code></pre></div>
<pre><code>##    value    numdf    dendf 
## 62.77234  1.00000 75.00000</code></pre>
</div>
</div>
<div id="regression-diagnostics" class="section level2" number="28.4">
<h2><span class="header-section-number">28.4</span> Regression diagnostics</h2>
<p>Finally, we can use the <code>lm</code> object to check the assumptions of the model. We have discussed the assumptions before but in this chapter we will use <code>R</code> to generate visual checks. There are also numeric diagnostic measures.</p>
<p>There are several potential problems with a regression model:</p>
<ol style="list-style-type: decimal">
<li><strong>Assumptions about the error structure</strong>. We assume:<br />
</li>
</ol>
<ul>
<li>the errors are normally distributed<br />
</li>
<li>the errors are independent<br />
</li>
<li>the errors have constant variance, <strong>homoskedastic</strong></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Assumptions about the fit</strong>. We assume that fit of the model is correct. For a simple linear regression, this means that fit specified by the formula in <code>lm</code> is correct.</p></li>
<li><p><strong>Problems with outliers and leverage points</strong>. In this case a small number of points in the data could have an unusually large impact on the parameter estimates. These points may give a mistaken sense that our model has a great fit or conversely that there is not relationship between the variables.</p></li>
<li><p><strong>Missing predictors</strong>. We can potentially improve the fit and predictive performance of our model by including other predictors. We will spend one chapter on this topic, but machine learning courses devote more time to discussing how to build these more complex models. In the case of multivariate linear regression, many of the diagnostic tools discussed next will also be applicable.</p></li>
</ol>
<div id="residual-plots-1" class="section level3" number="28.4.1">
<h3><span class="header-section-number">28.4.1</span> Residual plots</h3>
<p>The assumptions about the error structure can be checked with residual plots. We have already done this, but let’s review again and provide a little more depth.</p>
<p>Applying the <code>plot()</code> function to an “lm” object provides several graphs that allow us to visually evaluate a linear model’s assumptions. There are actually six plots (selected by the <code>which</code> option) available:</p>
<ul>
<li>a plot of residuals against fitted values,<br />
</li>
<li>a Scale-Location plot of <span class="math inline">\(\sqrt(| \text{residuals} |)\)</span> against fitted values,<br />
</li>
<li>a Normal Q-Q plot,<br />
</li>
<li>a plot of Cook’s distances versus row labels,<br />
</li>
<li>a plot of residuals against leverages,<br />
</li>
<li>and a plot of Cook’s distances against leverage/(1-leverage).</li>
</ul>
<p>By default, the first three and the fifth are provided by applying <code>plot()</code> to an “lm” object. To obtain all four at once, simply use <code>plot(my.model)</code> at the command line, Figure @ref(fig:diag281-fig).</p>
<div class="sourceCode" id="cb875"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb875-1"><a href="#cb875-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(star_mod)</span></code></pre></div>
<div class="figure">
<img src="28-Regression-Diagnostics_files/figure-html/diag281-fig-1.png" alt="Regression diagnostic plots." width="50%" /><img src="28-Regression-Diagnostics_files/figure-html/diag281-fig-2.png" alt="Regression diagnostic plots." width="50%" /><img src="28-Regression-Diagnostics_files/figure-html/diag281-fig-3.png" alt="Regression diagnostic plots." width="50%" /><img src="28-Regression-Diagnostics_files/figure-html/diag281-fig-4.png" alt="Regression diagnostic plots." width="50%" />
<p class="caption">
(#fig:diag281-fig)Regression diagnostic plots.
</p>
</div>
<p>However, it’s best to walk through each of these four plots in our Starbucks example.</p>
</div>
<div id="residuals-vs-fitted" class="section level3" number="28.4.2">
<h3><span class="header-section-number">28.4.2</span> Residuals vs Fitted</h3>
<p>By providing a number in the <code>which</code> option, we can select the plot we want, Figure @ref(fig:diag282-fig) is the first diagnostic plot.</p>
<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb876-1"><a href="#cb876-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(star_mod,<span class="at">which =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure">
<img src="28-Regression-Diagnostics_files/figure-html/diag282-fig-1.png" alt="A diagnostic residual plot." width="672" />
<p class="caption">
(#fig:diag282-fig)A diagnostic residual plot.
</p>
</div>
<p>This plot assesses linearity of the model and homoscedasticity (constant variance). The red line is a smoothed estimate of the fitted values versus the residuals. Ideally, the red line should coincide with the dashed horizontal line and the residuals should be centered around this dashed line. This would indicate that a linear fit is appropriate. Furthermore, the scatter around the dashed line should be relatively constant across the plot, homoscedasticity. In this case, it looks like there is some minor concern over linearity and non-constant error variance. We noted this earlier with the cluster of points in the lower left hand corner of the scatterplot.</p>
<p>Note: the points that are labeled are points with a high residual value. They are extreme. We will discuss outliers and leverage points shortly.</p>
</div>
<div id="normal-q-q-plot" class="section level3" number="28.4.3">
<h3><span class="header-section-number">28.4.3</span> Normal Q-Q Plot</h3>
<p>As it’s name suggests, this plot evaluates the normality of the residuals. We have seen and used this plot several times in this book. Remember if the number of data points is small, this plot has a greatly reduced effectiveness.</p>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb877-1"><a href="#cb877-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(star_mod,<span class="at">which =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure">
<img src="28-Regression-Diagnostics_files/figure-html/diag283-fig-1.png" alt="The quantile-quantile plot for checking normality." width="672" />
<p class="caption">
(#fig:diag283-fig)The quantile-quantile plot for checking normality.
</p>
</div>
<p>Along the <span class="math inline">\(y\)</span>-axis are the actual standardized residuals. Along the <span class="math inline">\(x\)</span>-axis is where those points should be if the residuals were actually normally distributed. Ideally, the dots should fall along the diagonal dashed line. In Figure @ref(fig:diag283-fig), it appears there is some skewness to the right or just longer tails than a normal distribution. We can tell this because for the smaller residuals, they don’t increase as they should to match a normal distribution, the points are above the line. This is concerning.</p>
</div>
<div id="scale-location-plot" class="section level3" number="28.4.4">
<h3><span class="header-section-number">28.4.4</span> Scale-Location Plot</h3>
<p>The scale-location plot is a better indicator of non-constant error variance. It is a plot of fitted values versus square root of the absolute value of the standardized residuals. A standardized residual is the residual divided by its standard deviation</p>
<p><span class="math display">\[
e^{&#39;}_i=\frac{e_i}{s}
\]</span></p>
<p>This plot illustrates the spread of the residuals over the entire range of the predictor. We are using fitted values because this will generalize well if we have more than one predictor.</p>
<div class="sourceCode" id="cb878"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb878-1"><a href="#cb878-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(star_mod,<span class="at">which=</span><span class="dv">3</span>)</span></code></pre></div>
<div class="figure">
<img src="28-Regression-Diagnostics_files/figure-html/diag284-fig-1.png" alt="A scale-location diagnostic residual plot." width="672" />
<p class="caption">
(#fig:diag284-fig)A scale-location diagnostic residual plot.
</p>
</div>
<p>A straight horizontal red line indicates constant error variance. In this case, Figure @ref(fig:diag284-fig), there is some indication error variance is higher for lower carb counts.</p>
</div>
</div>
<div id="outliers-and-leverage" class="section level2" number="28.5">
<h2><span class="header-section-number">28.5</span> Outliers and leverage</h2>
<p>Before discussing the last plot, we need to spend some time discussing outliers. Outliers in regression are observations that fall far from the “cloud” of points. These points are especially important because they can have a strong influence on the least squares line.</p>
<p>In regression, there are two types of outliers:<br />
- An outlier in the response variable is one that is not predicted well by the model. This could either be a problem with the data or the model. The residuals for this outlier will be large in absolute value.<br />
- An outlier in the explanatory variable. These are typically called <strong>leverage points</strong> because they can have a undue impact on the parameter estimates. With multiple predictors, we can have a leverage point when we have an unusual combination of the predictors.</p>
<p>An outlier is a <strong>influential point</strong> if it drastically alters the regression output. For example by causing large changes in the estimated slope or hypothesis p-values, if it is omitted.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
There are six plots shown in Figure @ref(fig:resid282-fig) along with the least squares line and residual plots. For each scatterplot and residual plot pair, identify any obvious outliers and note how they influence the least squares line. Recall that an outlier is any point that doesn’t appear to belong with the vast majority of the other points.</p>
</blockquote>
<div class="figure">
<img src="28-Regression-Diagnostics_files/figure-html/resid282-fig-1.png" alt="Examples of outliers and leverage points." width="672" />
<p class="caption">
(#fig:resid282-fig)Examples of outliers and leverage points.
</p>
</div>
<ol style="list-style-type: decimal">
<li>There is one outlier far from the other points, though it only appears to slightly influence the line. This is an outlier in the response and will have a large residual in magnitude.<br />
</li>
<li>There is one outlier on the right, though it is quite close to the least squares line, which suggests it wasn’t very influential although it is a leverage point.<br />
</li>
<li>There is one point far away from the cloud, and this leverage point appears to pull the least squares line up on the right; examine how the line around the primary cloud doesn’t appear to fit very well. This point has a high influence on the estimated slope.<br />
</li>
<li>There is a primary cloud and then a small secondary cloud of four outliers. The secondary cloud appears to be influencing the line somewhat strongly, making the least square line fit poorly almost everywhere. There might be an interesting explanation for the dual clouds, which is something that could be investigated.<br />
</li>
<li>There is no obvious trend in the main cloud of points and the outlier on the right appears to largely control the slope of the least squares line. This point is an outlier in both the response and predictor. It is a highly influential point.<br />
</li>
<li>There is one outlier in both the response and predictor, thus a leverage point, far from the cloud, however, it falls quite close to the least squares line and does not appear to be very influential.</li>
</ol>
<p>Examining the residual plots in Figure @ref(fig:resid282-fig), you will probably find that there is some trend in the main clouds of (3) and (4). In these cases, the outliers influenced the slope of the least squares lines. In (5), data with no clear trend were assigned a line with a large trend simply due to one outlier!</p>
<blockquote>
<p>Leverage<br />
Points that fall horizontally away from the center of the cloud tend to pull harder on the line, so we call them points with <strong>high leverage</strong>.</p>
</blockquote>
<p>Points that fall horizontally far from the line are points of high leverage; these points can strongly influence the slope of the least squares line. If one of these high leverage points does appear to actually invoke its influence on the slope of the line – as in cases (3), (4), and (5) – then we call it an <strong>influential point</strong>. Usually we can say a point is influential if, had we fitted the line without it, the influential point would have been unusually far from the least squares line. Leverage can be calculated from what is called the <strong>hat matrix</strong>, the actual mathematics is beyond the scope of this book.</p>
<p>A point can be an outlier but not a leverage point as we have already discussed. It is tempting to remove outliers from your data set. Don’t do this without a very good reason. Models that ignore exceptional (and interesting) cases often perform poorly. For instance, if a financial firm ignored the largest market swings – the ``outliers’’ – they would soon go bankrupt by making poorly thought-out investments.</p>
<div id="residuals-vs-leverage-plot" class="section level3" number="28.5.1">
<h3><span class="header-section-number">28.5.1</span> Residuals vs Leverage Plot</h3>
<p>The residuals vs leverage plot is a good way to identify influential observations. Sometimes, influential observations are representative of the population, but they could also indicate an error in recording data, or an otherwise unrepresentative outlier. It could be worth looking into these cases.</p>
<div class="sourceCode" id="cb879"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb879-1"><a href="#cb879-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(star_mod,<span class="dv">5</span>)</span></code></pre></div>
<div class="figure">
<img src="28-Regression-Diagnostics_files/figure-html/diag286-fig-1.png" alt="Diagnostic plots for Starbucks regression model." width="672" />
<p class="caption">
(#fig:diag286-fig)Diagnostic plots for Starbucks regression model.
</p>
</div>
<p>Figure @ref(fig:diag286-fig) helps us to find influential cases, those leverage points that impact the estimated slope. Unlike the other plots, patterns are not relevant. We watch out for outlying values at the upper right corner or at the lower right corner. Those spots are the places where cases can be influential against a regression line. Look for cases outside of a dashed line, Cook’s distance. In our particular plot, a dotted line for Cook’s distance was outside the bounds of the plot and thus did not come into play. When cases are outside of the Cook’s distance (meaning they have high Cook’s distance scores), the cases are influential to the regression results. The regression results will be altered if we exclude those cases. In this example, there are no points that tend to have undue influence.</p>
</div>
<div id="what-if-our-assumptions-are-violated" class="section level3" number="28.5.2">
<h3><span class="header-section-number">28.5.2</span> What If Our Assumptions Are Violated</h3>
<p>If the assumptions of the model are violated and/or we have influential points, a linear regression model with normality assumptions is not appropriate. Sometimes it is appropriate to transform the data (either response or predictor), so that the assumptions are met on the transformed data. Other times, it is appropriate to explore other models. There are entire courses on regression where blocks of material are devoted to diagnostics and transformations to reduce the impact of violations of assumptions. We will not go into these methods in this book. Instead, when confronted with clear violated assumptions, we will use resampling as a possible solution. We will learn about this in the next chapter because it does not assume normality in the residuals. This is a limited solution, but as this is an introductory text, this is an excellent first step.</p>
</div>
</div>
<div id="homework-problems-27" class="section level2" number="28.6">
<h2><span class="header-section-number">28.6</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Identify relationships</li>
</ol>
<p>For each of the six plots in Figure @ref(fig:hw1), identify the strength of the relationship (e.g. weak, moderate, or strong) in the data and whether fitting a linear model would be reasonable. When we ask about the strength of the relationship, we mean:</p>
<ul>
<li>is there a relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> and</li>
<li>does that relationship explain most of the variance?</li>
</ul>
<div class="figure">
<img src="figures/association1.png" alt="Homework problem 1." width="33%" /><img src="figures/association2.png" alt="Homework problem 1." width="33%" /><img src="figures/association3.png" alt="Homework problem 1." width="33%" /><img src="figures/association4.png" alt="Homework problem 1." width="33%" /><img src="figures/association5.png" alt="Homework problem 1." width="33%" /><img src="figures/association6.png" alt="Homework problem 1." width="33%" />
<p class="caption">
(#fig:hw1)Homework problem 1.
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Beer and blood alcohol content</li>
</ol>
<p>We will use the blood alcohol content data again. As a reminder this is the description of the data: <em>Many people believe that gender, weight, drinking habits, and many other factors are much more important in predicting blood alcohol content (BAC) than simply considering the number of drinks a person consumed. Here we examine data from sixteen student volunteers at Ohio State University who each drank a randomly assigned number of cans of beer. These students were evenly divided between men and women, and they differed in weight and drinking habits. Thirty minutes later, a police officer measured their blood alcohol content (BAC) in grams of alcohol per deciliter of blood.</em></p>
<p>The data is in the <code>bac.csv</code> file under the <code>data</code> folder.</p>
<ol style="list-style-type: lower-alpha">
<li>Obtain and interpret <span class="math inline">\(R\)</span>-squared for this model.<br />
</li>
<li>Evaluate the assumptions of this model. Do we have anything to be concerned about?</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Outliers</li>
</ol>
<p>Identify the outliers in the scatterplots shown in Figure @ref(fig:hw3) and determine what type of outliers they are. Explain your reasoning.</p>
<div class="figure">
<img src="figures/outInf1.png" alt="Homework problem 3." width="33%" /><img src="figures/outLev1.png" alt="Homework problem 3." width="33%" /><img src="figures/outOut1.png" alt="Homework problem 3." width="33%" /><img src="figures/outInf2.png" alt="Homework problem 3." width="33%" /><img src="figures/outInf3.png" alt="Homework problem 3." width="33%" /><img src="figures/outOut2.png" alt="Homework problem 3." width="33%" />
<p class="caption">
(#fig:hw3)Homework problem 3.
</p>
</div>
<!--chapter:end:28-Regression-Diagnostics.Rmd-->
</div>
</div>
<div id="LRSIM" class="section level1" number="29">
<h1><span class="header-section-number">29</span> Simulation Based Linear Regression</h1>
<div id="objectives-27" class="section level2" number="29.1">
<h2><span class="header-section-number">29.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Using the bootstrap, generate confidence intervals and estimates of standard error for parameter estimates from a linear regression model.<br />
</li>
<li>Generate and interpret bootstrap confidence intervals for predicted values.<br />
</li>
<li>Generate bootstrap samples from sampling rows of the data or sampling residuals. Explain why you might prefer one over the other.<br />
</li>
<li>Interpret regression coefficients for a linear model with a categorical explanatory variable.</li>
</ol>
</div>
<div id="introduction-5" class="section level2" number="29.2">
<h2><span class="header-section-number">29.2</span> Introduction</h2>
<p>In the last couple of chapters we examined how to perform inference for a simple linear regression model assuming the errors were independent normally distributed random variables. We examined diagnostic tools to check assumptions and look for outliers. In this chapter we will use the <strong>bootstrap</strong> to create confidence and prediction intervals.</p>
<p>There are at least two ways we can consider creating a bootstrap distribution for a linear model. We can easily fit a linear model to a resampled data set. But in some situations this may have undesirable features. Influential observations, for example, will appear duplicated in some resamples and be missing entirely from other resamples.</p>
<p>Another option is to use “residual resampling”. In residual resampling, the new data set has all of the predictor values from the original data set and a new response is created by adding to the fitted function a resampled residual.</p>
<p>In summary, suppose we have <span class="math inline">\(n\)</span> observations, each with <span class="math inline">\(Y\)</span> and some number of <span class="math inline">\(X\)</span>’s, with each observation stored as a row in a data set. The two basic procedures when bootstrapping regression are:<br />
a. bootstrap observations, and<br />
b. bootstrap residuals.<br />
The latter is a special case of a more general rule: sample <span class="math inline">\(Y\)</span> from its estimated conditional distribution given <span class="math inline">\(X\)</span>.</p>
<p>In bootstrapping observations, we sample with replacement from the rows of the data; each <span class="math inline">\(Y\)</span> comes with the corresponding <span class="math inline">\(X\)</span>’s. In any bootstrap sample some observations may be repeated multiple times, and others not included. This is the same idea we used before when we used the bootstrap for hypothesis testing.</p>
<p>In bootstrapping residuals, we fit the regression model, compute predicted values <span class="math inline">\(\hat{Y}_i\)</span> and residuals <span class="math inline">\(e_i = Y_i - \hat{Y}_i\)</span>, then create a bootstrap sample using the same <span class="math inline">\(X\)</span> values as in the original data, but with new <span class="math inline">\(Y\)</span> values obtained using the prediction plus a random residual, <span class="math inline">\(Y^{*}_i = \hat{Y}_i + e^{*}_i\)</span>, where the residuals <span class="math inline">\(e^{*}_i\)</span> are sampled randomly with replacement from the original residuals. We still have the chance of selecting a large residual from an outlier, but if it paired with an <span class="math inline">\(x\)</span> value near <span class="math inline">\(\bar{x}\)</span>, it will have little leverage.</p>
<p>Bootstrapping residuals corresponds to a designed experiment, where the <span class="math inline">\(x\)</span> values are fixed and only <span class="math inline">\(Y\)</span> is random. If we bootstrap observations, then essentially both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are sampled. By the principle of sampling the way the data were drawn, the second method implies that both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are random.</p>
</div>
<div id="confidence-intervals-for-parameters" class="section level2" number="29.3">
<h2><span class="header-section-number">29.3</span> Confidence intervals for parameters</h2>
<p>To build a confidence interval for the slope parameter, we will resample the data or residuals and generate a new regression model. This process does not assume normality of the residuals. We will use functions from the <strong>mosaic</strong> package to complete this work. However, know that <strong>tidymodels</strong> and <strong>purrr</strong> are more sophisticated tools for doing this work.</p>
<div id="resampling" class="section level3" number="29.3.1">
<h3><span class="header-section-number">29.3.1</span> Resampling</h3>
<p>To make this ideas more salient, let’s use the Starbucks example again.</p>
<p>First read the data into <code>R</code>:</p>
<div class="sourceCode" id="cb880"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb880-1"><a href="#cb880-1" aria-hidden="true" tabindex="-1"></a>starbucks <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/starbucks.csv&quot;</span>)</span></code></pre></div>
<p>Build the model:</p>
<div class="sourceCode" id="cb881"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb881-1"><a href="#cb881-1" aria-hidden="true" tabindex="-1"></a>star_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(calories<span class="sc">~</span>carb,<span class="at">data=</span>starbucks)</span></code></pre></div>
<p>Let’s see the output of the model:</p>
<div class="sourceCode" id="cb882"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb882-1"><a href="#cb882-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(star_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = calories ~ carb, data = starbucks)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -151.962  -70.556   -0.636   54.908  179.444 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 146.0204    25.9186   5.634 2.93e-07 ***
## carb          4.2971     0.5424   7.923 1.67e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 78.26 on 75 degrees of freedom
## Multiple R-squared:  0.4556, Adjusted R-squared:  0.4484 
## F-statistic: 62.77 on 1 and 75 DF,  p-value: 1.673e-11</code></pre>
<p>In preparation for resampling, let’s see how <code>do()</code> treats a linear model object.</p>
<div class="sourceCode" id="cb884"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb884-1"><a href="#cb884-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">401</span>)</span>
<span id="cb884-2"><a href="#cb884-2" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">1</span>)<span class="sc">*</span>star_mod</span>
<span id="cb884-3"><a href="#cb884-3" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>##   Intercept     carb    sigma r.squared        F numdf dendf .row .index
## 1  146.0204 4.297084 78.25956 0.4556237 62.77234     1    75    1      1</code></pre>
<p>Nice. To resample the data we use <code>do()</code> with <code>resample()</code>. This will sample the rows, what we were referring to above as the first method.</p>
<div class="sourceCode" id="cb886"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb886-1"><a href="#cb886-1" aria-hidden="true" tabindex="-1"></a><span class="fu">do</span>(<span class="dv">2</span>)<span class="sc">*</span><span class="fu">lm</span>(calories<span class="sc">~</span>carb,<span class="at">data=</span><span class="fu">resample</span>(starbucks))</span></code></pre></div>
<pre><code>##   Intercept     carb    sigma r.squared        F numdf dendf .row .index
## 1  145.6345 4.089065 73.32243 0.4980692 74.42299     1    75    1      1
## 2  160.0193 3.828742 66.81016 0.4298148 56.53621     1    75    1      2</code></pre>
<p>Perfect, we are ready to scale up.</p>
<div class="sourceCode" id="cb888"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb888-1"><a href="#cb888-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">532</span>)</span>
<span id="cb888-2"><a href="#cb888-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">lm</span>(calories<span class="sc">~</span>carb,<span class="at">data=</span><span class="fu">resample</span>(starbucks))</span></code></pre></div>
<p>Now let’s look at the first 6 rows of <code>results</code>.</p>
<div class="sourceCode" id="cb889"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb889-1"><a href="#cb889-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##   Intercept     carb    sigma r.squared        F numdf dendf .row .index
## 1  154.7670 4.176327 78.94717 0.4127581 52.71568     1    75    1      1
## 2  166.8589 3.807697 72.09482 0.4032196 50.67437     1    75    1      2
## 3  105.3658 4.899956 77.62517 0.5310212 84.92195     1    75    1      3
## 4  227.4138 2.805156 79.97902 0.2467094 24.56317     1    75    1      4
## 5  194.9190 3.457191 83.74624 0.2670279 27.32313     1    75    1      5
## 6  183.1159 3.549460 73.90153 0.3931691 48.59292     1    75    1      6</code></pre>
<p>If we plot all the slopes, the red lines in Figure @ref(fig:slope291-fig), we get a sense of the variability in the estimated slope and intercept. This also gives us an idea of the width of the confidence interval on the estimated mean response. We plotted the confidence interval in a gray shade and we can see it matches the red shaded region of the bootstrap slopes. We can see that the confidence interval will be wider at the extreme values of the predictor.</p>
<div class="sourceCode" id="cb891"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb891-1"><a href="#cb891-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(starbucks, <span class="fu">aes</span>(<span class="at">x=</span>carb, <span class="at">y=</span>calories)) <span class="sc">+</span></span>
<span id="cb891-2"><a href="#cb891-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">data =</span> results,</span>
<span id="cb891-3"><a href="#cb891-3" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">slope =</span>  carb, <span class="at">intercept =</span> Intercept), </span>
<span id="cb891-4"><a href="#cb891-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">alpha =</span> <span class="fl">0.01</span>,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb891-5"><a href="#cb891-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb891-6"><a href="#cb891-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb891-7"><a href="#cb891-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Carbohydrates (g)&quot;</span>,<span class="at">y=</span><span class="st">&quot;Calories&quot;</span>,<span class="at">title=</span><span class="st">&quot;Bootstrap Slopes&quot;</span>,<span class="at">subtitle =</span><span class="st">&quot;1000 Slopes&quot;</span>) <span class="sc">+</span></span>
<span id="cb891-8"><a href="#cb891-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_lm</span>(<span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/slope291-fig-1.png" alt="Plot of slopes from resampled regression." width="672" />
<p class="caption">
(#fig:slope291-fig)Plot of slopes from resampled regression.
</p>
</div>
<p>With all this data in <code>results</code>, we can generate confidence intervals for the slope, <span class="math inline">\(R\)</span>-squared (<span class="math inline">\(R^2\)</span>), and the <span class="math inline">\(F\)</span> statistic. Figure @ref(fig:hist291-fig) is a histogram of slope values from resampling.</p>
<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb892-1"><a href="#cb892-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb892-2"><a href="#cb892-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>carb,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb892-3"><a href="#cb892-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> obs<span class="sc">$</span>carb,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb892-4"><a href="#cb892-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb892-5"><a href="#cb892-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Carbohydrate regression slope.&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/hist291-fig-1.png" alt="Histogram of slopes from resampled regression." width="672" />
<p class="caption">
(#fig:hist291-fig)Histogram of slopes from resampled regression.
</p>
</div>
<p>The confidence interval is found using <code>cdata()</code>.</p>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb893-1"><a href="#cb893-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>carb,<span class="at">data=</span>results,<span class="at">p=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##         lower    upper central.p
## 2.5% 3.166546 5.377743      0.95</code></pre>
<p>We are 95% confident that the true slope is between 3.17 and 5.37. As a reminder, using the normality assumption we had a 95% confidence interval of <span class="math inline">\((3.21,5.38)\)</span>:</p>
<div class="sourceCode" id="cb895"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb895-1"><a href="#cb895-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(star_mod)</span></code></pre></div>
<pre><code>##                 2.5 %     97.5 %
## (Intercept) 94.387896 197.652967
## carb         3.216643   5.377526</code></pre>
<p>The bootstrap confidence interval for <span class="math inline">\(R^2\)</span> is:</p>
<div class="sourceCode" id="cb897"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb897-1"><a href="#cb897-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>r.squared,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##          lower     upper central.p
## 2.5% 0.2837033 0.6234751      0.95</code></pre>
<p>And the bootstrap sampling distribution of <span class="math inline">\(R^2\)</span> is displayed in Figure @ref(fig:hist292-fig).</p>
<p>(ref:ref291) A histogram of the <span class="math inline">\(R^2\)</span> values from resampled regression.</p>
<div class="sourceCode" id="cb899"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb899-1"><a href="#cb899-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb899-2"><a href="#cb899-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>r.squared,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb899-3"><a href="#cb899-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> obs<span class="sc">$</span>r.squared,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb899-4"><a href="#cb899-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb899-5"><a href="#cb899-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">y=</span><span class="st">&quot;&quot;</span>,<span class="at">x=</span><span class="fu">expression</span>(R<span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/hist292-fig-1.png" alt="(ref:ref291)" width="672" />
<p class="caption">
(#fig:hist292-fig)(ref:ref291)
</p>
</div>
<p>This is nice work. So powerful.</p>
<p>Let’s see how we could accomplish this same work using the <strong>infer</strong> package.</p>
<div class="sourceCode" id="cb900"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb900-1"><a href="#cb900-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(infer)</span></code></pre></div>
<p>To check that we can use this package, let’s find the slope estimate.</p>
<div class="sourceCode" id="cb901"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb901-1"><a href="#cb901-1" aria-hidden="true" tabindex="-1"></a>slope_estimate <span class="ot">&lt;-</span> starbucks <span class="sc">%&gt;%</span></span>
<span id="cb901-2"><a href="#cb901-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">specify</span>(calories <span class="sc">~</span> carb) <span class="sc">%&gt;%</span></span>
<span id="cb901-3"><a href="#cb901-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat=</span><span class="st">&quot;slope&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb902"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb902-1"><a href="#cb902-1" aria-hidden="true" tabindex="-1"></a>slope_estimate</span></code></pre></div>
<pre><code>## Response: calories (numeric)
## Explanatory: carb (numeric)
## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  4.30</code></pre>
<p>Good, let’s get the bootstrap sampling distribution of the regression slope.</p>
<div class="sourceCode" id="cb904"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb904-1"><a href="#cb904-1" aria-hidden="true" tabindex="-1"></a>results2 <span class="ot">&lt;-</span> starbucks <span class="sc">%&gt;%</span></span>
<span id="cb904-2"><a href="#cb904-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">specify</span>(calories<span class="sc">~</span>carb) <span class="sc">%&gt;%</span></span>
<span id="cb904-3"><a href="#cb904-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps=</span><span class="dv">1000</span>,<span class="at">type=</span><span class="st">&quot;bootstrap&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb904-4"><a href="#cb904-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat=</span><span class="st">&quot;slope&quot;</span>)</span>
<span id="cb904-5"><a href="#cb904-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results2)</span></code></pre></div>
<pre><code>## Response: calories (numeric)
## Explanatory: carb (numeric)
## # A tibble: 6 x 2
##   replicate  stat
##       &lt;int&gt; &lt;dbl&gt;
## 1         1  3.75
## 2         2  5.43
## 3         3  3.76
## 4         4  4.69
## 5         5  4.38
## 6         6  3.63</code></pre>
<p>Next the confidence interval.</p>
<div class="sourceCode" id="cb906"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb906-1"><a href="#cb906-1" aria-hidden="true" tabindex="-1"></a>slope_ci<span class="ot">&lt;-</span>results2 <span class="sc">%&gt;%</span></span>
<span id="cb906-2"><a href="#cb906-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">get_confidence_interval</span>(<span class="at">level=</span><span class="fl">0.95</span>)</span>
<span id="cb906-3"><a href="#cb906-3" aria-hidden="true" tabindex="-1"></a>slope_ci</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1     3.14     5.26</code></pre>
<p>This matches the work we have already done. Finally, let’s visualize the results, Figure @ref(fig:infer291-fig).</p>
<div class="sourceCode" id="cb908"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb908-1"><a href="#cb908-1" aria-hidden="true" tabindex="-1"></a>results2 <span class="sc">%&gt;%</span></span>
<span id="cb908-2"><a href="#cb908-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">visualize</span>() <span class="sc">+</span></span>
<span id="cb908-3"><a href="#cb908-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">shade_confidence_interval</span>(slope_ci,<span class="at">color=</span><span class="st">&quot;blue&quot;</span>,<span class="at">fill=</span><span class="st">&quot;lightblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb908-4"><a href="#cb908-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> slope_estimate<span class="sc">$</span>stat,<span class="at">color=</span><span class="st">&quot;black&quot;</span>,<span class="at">size=</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb908-5"><a href="#cb908-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Estimated Slope&quot;</span>) <span class="sc">+</span></span>
<span id="cb908-6"><a href="#cb908-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/infer291-fig-1.png" alt="Sampling distribution of the slope using resampling. (Black line is estimate slope from original data and blue lines are the confidence bounds.)" width="672" />
<p class="caption">
(#fig:infer291-fig)Sampling distribution of the slope using resampling. (Black line is estimate slope from original data and blue lines are the confidence bounds.)
</p>
</div>
</div>
<div id="resample-residuals" class="section level3" number="29.3.2">
<h3><span class="header-section-number">29.3.2</span> Resample residuals</h3>
<p>We could also resample the residuals instead of the data. This makes a stronger assumption that the linear model is appropriate. However, it guarantees that every <span class="math inline">\(X\)</span> value is in the resample data frame. In the <code>lm</code> function, we send the model instead of the data to resample the residuals. Since <code>R</code> is an object oriented programming language, in sending a model object to the <code>resample()</code> function, the code automatically resample from the residuals.</p>
<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb909-1"><a href="#cb909-1" aria-hidden="true" tabindex="-1"></a>results_resid <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">lm</span>( calories<span class="sc">~</span>carb, <span class="at">data =</span> <span class="fu">resample</span>(star_mod)) <span class="co"># resampled residuals</span></span>
<span id="cb909-2"><a href="#cb909-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results_resid)</span></code></pre></div>
<pre><code>##   Intercept     carb    sigma r.squared        F numdf dendf .row .index
## 1  151.9999 4.356740 73.07024 0.4967052 74.01804     1    75    1      1
## 2  101.6226 5.280410 82.24346 0.5336627 85.82779     1    75    1      2
## 3  152.4453 4.346918 82.64249 0.4344055 57.60383     1    75    1      3
## 4  159.1311 3.846912 84.42784 0.3656236 43.22634     1    75    1      4
## 5  167.9957 3.981328 67.50240 0.4912807 72.42905     1    75    1      5
## 6  198.5458 3.239953 86.11143 0.2821237 29.47482     1    75    1      6</code></pre>
<p>Next a plot of the bootstrap sampling distribution, Figure @ref(fig:hist293-fig).</p>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb911-1"><a href="#cb911-1" aria-hidden="true" tabindex="-1"></a>results_resid <span class="sc">%&gt;%</span></span>
<span id="cb911-2"><a href="#cb911-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>carb,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb911-3"><a href="#cb911-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> obs<span class="sc">$</span>carb,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb911-4"><a href="#cb911-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb911-5"><a href="#cb911-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">x=</span><span class="st">&quot;Estimated slope of carbs&quot;</span>,<span class="at">y=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/hist293-fig-1.png" alt="Histogram of estimated regression slope using resampling from residuals." width="672" />
<p class="caption">
(#fig:hist293-fig)Histogram of estimated regression slope using resampling from residuals.
</p>
</div>
<p>And finally the confidence interval for the slope.</p>
<div class="sourceCode" id="cb912"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb912-1"><a href="#cb912-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>carb,<span class="at">data=</span>results_resid)</span></code></pre></div>
<pre><code>##        lower    upper central.p
## 2.5% 3.24622 5.323031      0.95</code></pre>
<p>Similar to the previous bootstrap confidence interval just a little narrower.</p>
</div>
</div>
<div id="confidence-intervals-for-prediction" class="section level2" number="29.4">
<h2><span class="header-section-number">29.4</span> Confidence intervals for prediction</h2>
<p>We now want to generate a confidence interval for the average calories from 60 grams of carbohydrates.</p>
<p>Using the normal assumption, we had</p>
<div class="sourceCode" id="cb914"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb914-1"><a href="#cb914-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(star_mod,<span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">carb=</span><span class="dv">60</span>),<span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 403.8455 379.7027 427.9883</code></pre>
<p>We have all the bootstrap slope and intercept estimates in the <code>results</code> object. We can use <code>tidyverse</code> functions to find the confidence interval by predicting the response for each of these slope and intercept estimate.</p>
<div class="sourceCode" id="cb916"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb916-1"><a href="#cb916-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##   Intercept     carb    sigma r.squared        F numdf dendf .row .index
## 1  154.7670 4.176327 78.94717 0.4127581 52.71568     1    75    1      1
## 2  166.8589 3.807697 72.09482 0.4032196 50.67437     1    75    1      2
## 3  105.3658 4.899956 77.62517 0.5310212 84.92195     1    75    1      3
## 4  227.4138 2.805156 79.97902 0.2467094 24.56317     1    75    1      4
## 5  194.9190 3.457191 83.74624 0.2670279 27.32313     1    75    1      5
## 6  183.1159 3.549460 73.90153 0.3931691 48.59292     1    75    1      6</code></pre>
<div class="sourceCode" id="cb918"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb918-1"><a href="#cb918-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb918-2"><a href="#cb918-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pred=</span>Intercept<span class="sc">+</span>carb<span class="sc">*</span><span class="dv">60</span>) <span class="sc">%&gt;%</span></span>
<span id="cb918-3"><a href="#cb918-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cdata</span>(<span class="sc">~</span>pred,<span class="at">data=</span>.)</span></code></pre></div>
<pre><code>##         lower    upper central.p
## 2.5% 385.2706 423.6689      0.95</code></pre>
<p>This is similar to the interval we found last chapter. We are 95% confident that the average calorie content for a menu item with 60 grams of carbohydrates is between 380.8 and 425.7.</p>
<div id="prediction-interval" class="section level3" number="29.4.1">
<h3><span class="header-section-number">29.4.1</span> Prediction interval</h3>
<p>The prediction interval is more difficult to perform with a bootstrap. We would have to account for the variability of the slope but also the residual variability since this is an individual observation. We can’t just add the residual to the predicted value. Remember the variance of a sum of independent variables is the sum of the variances. But here we have standard deviations and we can’t just add them.</p>
<p>Let’s look at what would happen if we try. First as a reminder, the prediction interval at 60 grams of <code>carb</code> using the assumption of normally distributed errors from last lesson is:</p>
<div class="sourceCode" id="cb920"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb920-1"><a href="#cb920-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(star_mod,<span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">carb=</span><span class="dv">60</span>),<span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 403.8455 246.0862 561.6048</code></pre>
<p>If we are generating a bootstrap of size 1000, we will resample from the residuals 1000 times.</p>
<div class="sourceCode" id="cb922"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb922-1"><a href="#cb922-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb922-2"><a href="#cb922-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pred=</span>Intercept<span class="sc">+</span>carb<span class="sc">*</span><span class="dv">60</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb922-3"><a href="#cb922-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cbind</span>(<span class="at">resid=</span><span class="fu">sample</span>(star_mod<span class="sc">$</span>residuals,<span class="at">size=</span><span class="dv">1000</span>,<span class="at">replace =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb922-4"><a href="#cb922-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pred_ind=</span>pred<span class="sc">+</span>resid) <span class="sc">%&gt;%</span></span>
<span id="cb922-5"><a href="#cb922-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cdata</span>(<span class="sc">~</span>pred_ind,<span class="at">data=</span>.)</span></code></pre></div>
<pre><code>##         lower    upper central.p
## 2.5% 277.4886 577.0957      0.95</code></pre>
<p>This prediction interval appears to be biased. Thus generating a prediction interval is beyond the scope of this book.</p>
</div>
</div>
<div id="categorical-predictor" class="section level2" number="29.5">
<h2><span class="header-section-number">29.5</span> Categorical predictor</h2>
<p>We want to finish up simple linear regression by discussing a categorical predictor. It somewhat changes the interpretation of the regression model.</p>
<p>Thus far, we have only discussed regression in the context of a quantitative, continuous, response AND a quantitative, continuous, predictor. We can build linear models with categorical predictor variables as well.</p>
<p>In the case of a binary covariate, nothing about the linear model changes. The two levels of the binary covariate are typically coded as 1 and 0, and the model is built, evaluated and interpreted in an analogous fashion as before. The difference between the continuous predictor and categorical is that there are only two values the predictor can take and the regression model will simply predict the average value of the response within each value of the predictor.</p>
<p>In the case of a categorical covariate with <span class="math inline">\(k\)</span> levels, where <span class="math inline">\(k&gt;2\)</span>, we need to include <span class="math inline">\(k-1\)</span> <em>dummy variables</em> in the model. Each of these dummy variables takes the value 0 or 1. For example, if a covariate has <span class="math inline">\(k=3\)</span> categories or levels (say A, B or C), we create two dummy variables, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, each of which can only take values 1 or 0. We arbitrarily state that if <span class="math inline">\(X_1=1\)</span>, it represents the covariate has the value A. Likewise if <span class="math inline">\(X_2=1\)</span>, then we state that the covariate takes the value B. If both <span class="math inline">\(X_1=0\)</span> and <span class="math inline">\(X_2=0\)</span>, this is known as the reference category, and in this case the covariate takes the value C. The arrangement of the levels of the categorical covariate are arbitrary and can be adjusted by the user. This coding of the covariate into dummy variables is called <strong>contrasts</strong> and again is typically taught in a more advanced course on linear models.</p>
<p>In the case <span class="math inline">\(k=3\)</span>, the linear model is <span class="math inline">\(Y=\beta_0 + \beta_1X_1 + \beta_2X_2+e\)</span>.</p>
<p>When the covariate takes the value A, <span class="math inline">\(\mbox{E}(Y|X=A)=\beta_0 + \beta_1\)</span>.</p>
<p>When the covariate takes the value B, <span class="math inline">\(\mbox{E}(Y|X=B)=\beta_0 + \beta_2\)</span>.</p>
<p>When the covariate takes the value C, <span class="math inline">\(\mbox{E}(Y|X=C)=\beta_0\)</span>.</p>
<p>Based on this, think about how you would interpret the coefficients <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\beta_2\)</span>.</p>
<div id="lending-club" class="section level3" number="29.5.1">
<h3><span class="header-section-number">29.5.1</span> Lending Club</h3>
<p>Let’s do an example with some data.</p>
<p>The Lending Club data set represents thousands of loans made through the Lending Club platform, which is a platform that allows individuals to lend to other individuals. Of course, not all loans are created equal. Someone who is essentially a sure bet to pay back a loan will have an easier time getting a loan with a low interest rate than someone who appears to be riskier. And for people who are very risky? They may not even get a loan offer, or they may not have accepted the loan offer due to a high interest rate. It is important to keep that last part in mind, since this data set only represents loans actually made, i.e. do not mistake this data for loan applications! The data set is <code>loans.csv</code> from the <code>data</code> folder.</p>
<div class="sourceCode" id="cb924"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb924-1"><a href="#cb924-1" aria-hidden="true" tabindex="-1"></a>loans <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/loans.csv&quot;</span>)</span></code></pre></div>
<p>Let’s look at the size of the data:</p>
<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb925-1"><a href="#cb925-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(loans)</span></code></pre></div>
<pre><code>## [1] 10000    55</code></pre>
<p>This is a big data set. For educational purposes, we will sample 100 points from the original data. We only need the variables <code>interest_rate</code> and <code>homeownership</code>. First let’s break down the <code>homeownership</code> variable.</p>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb927-1"><a href="#cb927-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>homeownership,<span class="at">data=</span>loans,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>## homeownership
## MORTGAGE      OWN     RENT 
##   0.4789   0.1353   0.3858</code></pre>
<p>We want to sample the data so that each level of home ownership has the same proportion as the original, a stratified sample.</p>
<div class="sourceCode" id="cb929"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb929-1"><a href="#cb929-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">905</span>)</span>
<span id="cb929-2"><a href="#cb929-2" aria-hidden="true" tabindex="-1"></a>loans100 <span class="ot">&lt;-</span> loans <span class="sc">%&gt;%</span></span>
<span id="cb929-3"><a href="#cb929-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(interest_rate,homeownership) <span class="sc">%&gt;%</span></span>
<span id="cb929-4"><a href="#cb929-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">homeownership=</span><span class="fu">factor</span>(homeownership)) <span class="sc">%&gt;%</span></span>
<span id="cb929-5"><a href="#cb929-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(homeownership) <span class="sc">%&gt;%</span></span>
<span id="cb929-6"><a href="#cb929-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">prop=</span><span class="fl">0.01</span>) <span class="sc">%&gt;%</span></span>
<span id="cb929-7"><a href="#cb929-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span></code></pre></div>
<div class="sourceCode" id="cb930"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb930-1"><a href="#cb930-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(loans100)</span></code></pre></div>
<pre><code>## [1] 98  2</code></pre>
<p>Not quite a 100 observations, but we preserved the proportion of homeownership.</p>
<div class="sourceCode" id="cb932"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb932-1"><a href="#cb932-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>homeownership,<span class="at">data=</span>loans100,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>## homeownership
##  MORTGAGE       OWN      RENT 
## 0.4795918 0.1326531 0.3877551</code></pre>
<p>Let’s look at the data with a boxplot, Figure @ref(fig:box291-fig).</p>
<div class="sourceCode" id="cb934"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb934-1"><a href="#cb934-1" aria-hidden="true" tabindex="-1"></a>loans100 <span class="sc">%&gt;%</span></span>
<span id="cb934-2"><a href="#cb934-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_boxplot</span>(interest_rate<span class="sc">~</span>homeownership) <span class="sc">%&gt;%</span></span>
<span id="cb934-3"><a href="#cb934-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb934-4"><a href="#cb934-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Lending Club&quot;</span>,<span class="at">x=</span><span class="st">&quot;Homeownership&quot;</span>,<span class="at">y=</span><span class="st">&quot;Interest Rate&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/box291-fig-1.png" alt="Boxplot of loan interest rates from the Lending Club based on homeownership status." width="672" />
<p class="caption">
(#fig:box291-fig)Boxplot of loan interest rates from the Lending Club based on homeownership status.
</p>
</div>
<p>It appears that there is some evidence that home ownership impacts the interest rate. We can build a linear model to explore whether this difference in significant. We can use the <code>lm()</code> function in <code>R</code>, but in order to include a categorical predictor, we need to make sure that variable is stored as a “factor” type. If it is not, we’ll need to convert it.</p>
<div class="sourceCode" id="cb935"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb935-1"><a href="#cb935-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(loans100)</span></code></pre></div>
<pre><code>## tibble [98 x 2] (S3: tbl_df/tbl/data.frame)
##  $ interest_rate: num [1:98] 19.03 9.44 6.07 7.96 10.9 ...
##  $ homeownership: Factor w/ 3 levels &quot;MORTGAGE&quot;,&quot;OWN&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Now we can build the model:</p>
<div class="sourceCode" id="cb937"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb937-1"><a href="#cb937-1" aria-hidden="true" tabindex="-1"></a>loan_mod<span class="ot">&lt;-</span><span class="fu">lm</span>(interest_rate <span class="sc">~</span> homeownership,<span class="at">data=</span>loans100)</span>
<span id="cb937-2"><a href="#cb937-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(loan_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = interest_rate ~ homeownership, data = loans100)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.5442 -3.1472  0.1628  2.1228 12.9658 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        10.4972     0.5889  17.825  &lt; 2e-16 ***
## homeownershipOWN    2.6135     1.2652   2.066  0.04158 *  
## homeownershipRENT   2.3570     0.8808   2.676  0.00878 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.037 on 95 degrees of freedom
## Multiple R-squared:  0.08517,    Adjusted R-squared:  0.06591 
## F-statistic: 4.422 on 2 and 95 DF,  p-value: 0.01458</code></pre>
<p>Note that by default, <code>R</code> set the <code>MORTGAGE</code> level as the reference category. This is because it is first value when sorted alphabetically. You can control this by changing the order of the factor levels. The package <strong>forcats</strong> helps with this effort.</p>
<p>How would we interpret this output? Since <code>MORTGAGE</code> is the reference category, the intercept is effectively the estimated, average, interest rate for home owners with a mortgage.</p>
<div class="sourceCode" id="cb939"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb939-1"><a href="#cb939-1" aria-hidden="true" tabindex="-1"></a>loans100 <span class="sc">%&gt;%</span></span>
<span id="cb939-2"><a href="#cb939-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(homeownership <span class="sc">==</span> <span class="st">&quot;MORTGAGE&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb939-3"><a href="#cb939-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">average=</span><span class="fu">mean</span>(interest_rate))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   average
##     &lt;dbl&gt;
## 1    10.5</code></pre>
<p>The other terms represent the expected difference in average interest rates for the ownership types.</p>
<div class="sourceCode" id="cb941"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb941-1"><a href="#cb941-1" aria-hidden="true" tabindex="-1"></a>loans100 <span class="sc">%&gt;%</span></span>
<span id="cb941-2"><a href="#cb941-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(homeownership) <span class="sc">%&gt;%</span></span>
<span id="cb941-3"><a href="#cb941-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">average=</span><span class="fu">mean</span>(interest_rate),<span class="at">std_dev=</span><span class="fu">sd</span>(interest_rate))</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   homeownership average std_dev
##   &lt;fct&gt;           &lt;dbl&gt;   &lt;dbl&gt;
## 1 MORTGAGE         10.5    3.44
## 2 OWN              13.1    2.89
## 3 RENT             12.9    4.94</code></pre>
<p>Specifically, on average, loan interest rates for home owners who own their home is 2.61 percentage points higher than those with a mortgage. Those who rent is 2.36 percent higher on average. The highest interest rate is for those who own their own home. This seems odd but it is interesting.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Using the coefficient from the regression model, how do we find the difference in average interest rates between home owners and renters?</p>
</blockquote>
<p>The first coefficient
<span class="math display">\[\beta_\text{homeownershipOWN} = \mu_\text{OWN} - \mu_\text{MORTGAGE}\]</span><br />
and <span class="math display">\[\beta_\text{homeownershipRENT} = \mu_\text{RENT} - \mu_\text{MORTGAGE}.\]</span>
Thus <span class="math display">\[\mu_\text{OWN} -\mu_\text{RENT} = \beta_\text{homeownershipOWN} - \beta_\text{homeownershipRENT},\]</span> the difference in coefficients.</p>
<p>The model is not fitting a line to the data but just estimating average with the coefficients representing difference from the reference level.</p>
<p>The <code>Std.Error</code>, <code>t value</code>, and <code>Pr(&gt;|t|)</code> values can be used to conduct inference about the respective estimates. Both p-values are significant. This is similar to the ANOVA analysis we conducted last block except that hypothesis test was simultaneously testing all coefficients and here we are testing them pairwise.</p>
</div>
<div id="bootstrap-2" class="section level3" number="29.5.2">
<h3><span class="header-section-number">29.5.2</span> Bootstrap</h3>
<p>From the boxplots, the biggest difference in means is between home owners and those with a mortgage. However, in the regression output there is no p-value to test the difference between owners and renters. An easy solution would be to change the reference level but what if you had many levels? How would you know which ones to test? In the next section we will look at multiple comparisons but before then we can use the bootstrap to help us.</p>
<p>Let’s bootstrap the regression.</p>
<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb943-1"><a href="#cb943-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">532</span>)</span>
<span id="cb943-2"><a href="#cb943-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">lm</span>(interest_rate <span class="sc">~</span> homeownership,<span class="at">data=</span><span class="fu">resample</span>(loans100))</span></code></pre></div>
<div class="sourceCode" id="cb944"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb944-1"><a href="#cb944-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##   Intercept homeownershipOWN homeownershipRENT    sigma  r.squared        F
## 1   9.98300         2.088250          2.110000 3.832758 0.07223701 3.698421
## 2  11.04875         3.868250          1.449750 3.421090 0.11065485 5.910085
## 3  10.52865         3.200096          2.065557 3.958047 0.08231134 4.260474
## 4  11.10000         2.572000          2.163000 4.752496 0.05494338 2.761539
## 5  10.52939         2.459703          1.214033 4.157461 0.03970813 1.964128
## 6  10.08280         4.100533          2.531745 3.650730 0.16435823 9.342539
##   numdf dendf .row .index
## 1     2    95    1      1
## 2     2    95    1      2
## 3     2    95    1      3
## 4     2    95    1      4
## 5     2    95    1      5
## 6     2    95    1      6</code></pre>
<p>We of course can generate a confidence interval on either of the coefficients in the <code>results</code> object.</p>
<div class="sourceCode" id="cb946"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb946-1"><a href="#cb946-1" aria-hidden="true" tabindex="-1"></a>obs<span class="ot">&lt;-</span><span class="fu">do</span>(<span class="dv">1</span>)<span class="sc">*</span>loan_mod</span>
<span id="cb946-2"><a href="#cb946-2" aria-hidden="true" tabindex="-1"></a>obs</span></code></pre></div>
<pre><code>##   Intercept homeownershipOWN homeownershipRENT    sigma  r.squared        F
## 1  10.49723         2.613535          2.356976 4.037396 0.08516582 4.421978
##   numdf dendf .row .index
## 1     2    95    1      1</code></pre>
<p>Figure @ref(fig:hist297-fig) is a histogram of the estimated coefficient for those that own their home.</p>
<div class="sourceCode" id="cb948"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb948-1"><a href="#cb948-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb948-2"><a href="#cb948-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>homeownershipOWN,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color=</span><span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb948-3"><a href="#cb948-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_vline</span>(<span class="at">xintercept =</span> obs<span class="sc">$</span>homeownershipOWN,<span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb948-4"><a href="#cb948-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb948-5"><a href="#cb948-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">y=</span><span class="st">&quot;&quot;</span>,<span class="at">x=</span><span class="st">&quot;Homeownership (Own).&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided.</code></pre>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/hist297-fig-1.png" alt="Distribution of estimated regression coefficent for homeownership." width="672" />
<p class="caption">
(#fig:hist297-fig)Distribution of estimated regression coefficent for homeownership.
</p>
</div>
<div class="sourceCode" id="cb950"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb950-1"><a href="#cb950-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>homeownershipOWN,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##          lower    upper central.p
## 2.5% 0.7674164 4.489259      0.95</code></pre>
<p>Which is similar to the results assuming normality.</p>
<div class="sourceCode" id="cb952"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb952-1"><a href="#cb952-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(loan_mod)</span></code></pre></div>
<pre><code>##                       2.5 %    97.5 %
## (Intercept)       9.3280904 11.666378
## homeownershipOWN  0.1018118  5.125259
## homeownershipRENT 0.6083964  4.105557</code></pre>
<p>However, we want a confidence interval for the difference between home owners and renters.</p>
<div class="sourceCode" id="cb954"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb954-1"><a href="#cb954-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb954-2"><a href="#cb954-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">own_rent=</span>homeownershipOWN <span class="sc">-</span> homeownershipRENT) <span class="sc">%&gt;%</span></span>
<span id="cb954-3"><a href="#cb954-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cdata</span>(<span class="sc">~</span>own_rent,<span class="at">data=</span>.)</span></code></pre></div>
<pre><code>##          lower    upper central.p
## 2.5% -1.943183 2.536296      0.95</code></pre>
<p>Done! From this interval we can infer that home owners that own their home and those that rent do not have significantly different interest rates.</p>
</div>
<div id="anova-table" class="section level3" number="29.5.3">
<h3><span class="header-section-number">29.5.3</span> ANOVA Table</h3>
<p>As a reminder, we could also report the results of loans analysis using an <em>analysis of variance</em>, or ANOVA, table.</p>
<div class="sourceCode" id="cb956"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb956-1"><a href="#cb956-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(loan_mod)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: interest_rate
##               Df  Sum Sq Mean Sq F value  Pr(&gt;F)  
## homeownership  2  144.16  72.081   4.422 0.01458 *
## Residuals     95 1548.55  16.301                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This table lays out how the variation between observations is broken down. This is a simultaneous test of equality of the three means. Using the <span class="math inline">\(F\)</span>-statistic, we would reject the null hypothesis of no differences in mean response across levels of the categorical variable. Notice it is the same p-value reported for the <span class="math inline">\(F\)</span> distribution in the regression summary.</p>
</div>
<div id="pairwise-comparisons" class="section level3" number="29.5.4">
<h3><span class="header-section-number">29.5.4</span> Pairwise Comparisons</h3>
<p>The ANOVA table above (along with the summary of the linear model output before that) merely tells you whether any difference exists in the mean response across the levels of the categorical predictor. It does not tell you where that difference lies. In the case of using regression we can compare <code>MORTGAGE</code> to the other two levels but can’t conduct a hypothesis of <code>OWN</code> vs <code>RENT</code>. In order to make all pairwise comparisons, we need another tool. A common one is the Tukey method. Essentially, the Tukey method conducts three hypothesis tests (each under the null of no difference in mean) but corrects the <span class="math inline">\(p\)</span>-values based on the understanding that we are conducting three simultaneous hypothesis tests with the same set of data and we don’t want to inflate the Type 1 error.</p>
<p>We can obtain these pairwise comparisons using the <code>TukeyHSD()</code> function in <code>R</code>. The “HSD” stands for “Honest Significant Differences”. This function requires an <code>anova</code> object, which is obtained by using the <code>aov()</code> function:</p>
<div class="sourceCode" id="cb958"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb958-1"><a href="#cb958-1" aria-hidden="true" tabindex="-1"></a><span class="fu">TukeyHSD</span>(<span class="fu">aov</span>(interest_rate<span class="sc">~</span>homeownership, <span class="at">data=</span>loans100))</span></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = interest_rate ~ homeownership, data = loans100)
## 
## $homeownership
##                     diff        lwr      upr     p adj
## OWN-MORTGAGE   2.6135352 -0.3988868 5.625957 0.1025289
## RENT-MORTGAGE  2.3569765  0.2598263 4.454127 0.0236346
## RENT-OWN      -0.2565587 -3.3453062 2.832189 0.9786730</code></pre>
<p>According to this output, only the average interest rate for those with a mortgage is different from renters.</p>
</div>
</div>
<div id="assumptions-2" class="section level2" number="29.6">
<h2><span class="header-section-number">29.6</span> Assumptions</h2>
<p>Keep in mind that ANOVA is a special case of a simple linear model. Therefore, all of the assumptions remain the same except for the linearity. The order of the levels is irrelevant and thus a line does not need to go through the three levels. In order to evaluate these assumptions, we would need to obtain the appropriate diagnostic plots.</p>
<div class="sourceCode" id="cb960"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb960-1"><a href="#cb960-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(loan_mod,<span class="dv">2</span>)</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/diag291-fig-1.png" alt="Q-Q normality plot." width="672" />
<p class="caption">
(#fig:diag291-fig)Q-Q normality plot.
</p>
</div>
<p>Figure @ref(fig:diag291-fig) shows that normality is suspect but we have a large sample size and thus we did not get much of a difference in results from the bootstrap which does not assume normality.</p>
<div class="sourceCode" id="cb961"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb961-1"><a href="#cb961-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(loan_mod,<span class="dv">3</span>)</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/diag292-fig-1.png" alt="Scale-location residual diagnostic plot." width="672" />
<p class="caption">
(#fig:diag292-fig)Scale-location residual diagnostic plot.
</p>
</div>
<p>The assumption of equal variance is also suspect, Figure @ref(fig:diag292-fig). The variance for the homeowners might be less than that for the other two.</p>
<div class="sourceCode" id="cb962"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb962-1"><a href="#cb962-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(loan_mod,<span class="dv">5</span>)</span></code></pre></div>
<div class="figure">
<img src="29-Simulation-Based-Linear-Regression_files/figure-html/diag293-fig-1.png" alt="Residual plot for outliers and leverage points." width="672" />
<p class="caption">
(#fig:diag293-fig)Residual plot for outliers and leverage points.
</p>
</div>
<p>We have three points that might be outliers but they are not too extreme, Figure @ref(fig:diag293-fig). In general, nothing in this plot is concerning to us.</p>
</div>
<div id="homework-problems-28" class="section level2" number="29.7">
<h2><span class="header-section-number">29.7</span> Homework Problems</h2>
<p>We will use the <code>loans</code> data set again to create linear models. Remember this data set represents thousands of loans made through the Lending Club platform, which is a platform that allows individuals to lend to other individuals.</p>
<ol style="list-style-type: decimal">
<li>Loans</li>
</ol>
<p>In this exercise we will examine the relationship between interest rate and loan amount.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data from <code>loans.csv</code> in the <code>data</code> folder.<br />
</li>
<li>Create a subset of data of 200 observations with the following three variables <code>interest_rate</code>, <code>loan_amount</code>, and <code>term</code>. Change <code>term</code> into a factor and use a stratified sample to keep the proportion of loan terms roughly the same as the original data.<br />
</li>
<li>Plot <code>interest_rate</code> versus <code>loan_amount</code>. We think <code>interest_rate</code> should be the response.<br />
</li>
<li>Fit a linear model to the data by regressing <code>interest_rate</code> on <code>loan_amount</code>. Is there a significant relationship between <code>interest_rate</code> and <code>loan_amount</code>?<br />
</li>
<li>Using the <span class="math inline">\(t\)</span> distribution:
<ol style="list-style-type: lower-roman">
<li>Find a 95% confidence interval for the slope.<br />
</li>
<li>Find and interpret a 90% confidence interval for a loan amount of $20000<br />
</li>
</ol></li>
<li>Repeat part e using a bootstrap.<br />
</li>
<li>Check the assumptions of linear regression.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Loans II</li>
</ol>
<p>Using the <code>loans</code> data set of 200 observations from the previous exercise, use the variable <code>term</code> to determine if there is a difference in interest rates for the two different loan lengths.</p>
<ol style="list-style-type: lower-alpha">
<li>Build a set of side-by-side boxplots that summarize interest rate by term. Describe the relationship you see. Note: You will have to convert the <code>term</code> variable to a factor prior to continuing.<br />
</li>
<li>Build a linear model fitting interest rate against term. Does there appear to be a significant difference in mean interest rates by term?<br />
</li>
<li>Write out the estimated linear model. In words, interpret the coefficient estimate.<br />
</li>
<li>Construct a bootstrap confidence interval on the coefficient.<br />
</li>
<li>Check model assumptions.</li>
</ol>
<!--chapter:end:29-Simulation-Based-Linear-Regression.Rmd-->
</div>
</div>
<div id="LRMULTI" class="section level1" number="30">
<h1><span class="header-section-number">30</span> Multiple Linear Regression</h1>
<div id="objectives-28" class="section level2" number="30.1">
<h2><span class="header-section-number">30.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Create and interpret a model with multiple predictors and check assumptions.<br />
</li>
<li>Generate and interpret confidence intervals for estimates.<br />
</li>
<li>Explain adjusted <span class="math inline">\(R^2\)</span> and multi-collinearity.<br />
</li>
<li>Interpret regression coefficients for a linear model with multiple predictors.<br />
</li>
<li>Build and interpret models with higher order terms.</li>
</ol>
</div>
<div id="introduction-to-multiple-regression" class="section level2" number="30.2">
<h2><span class="header-section-number">30.2</span> Introduction to multiple regression</h2>
<p>The principles of simple linear regression lay the foundation for more sophisticated regression methods used in a wide range of challenging settings. In our last two chapters, we will explore multiple regression, which introduces the possibility of more than one predictor.</p>
</div>
<div id="multiple-regression" class="section level2" number="30.3">
<h2><span class="header-section-number">30.3</span> Multiple regression</h2>
<p>Multiple regression extends simple two-variable regression to the case that still has one response but many predictors (denoted <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, <span class="math inline">\(x_3\)</span>, …). The method is motivated by scenarios where many variables may be simultaneously connected to an output.</p>
<p>To explore and explain these ideas, we will consider Ebay auctions of a video game called <strong>Mario Kart</strong> for the Nintendo Wii. The outcome variable of interest is the total price of an auction, which is the highest bid plus the shipping cost. We will try to determine how total price is related to each characteristic in an auction while simultaneously controlling for other variables. For instance, with all other characteristics held constant, are longer auctions associated with higher or lower prices? And, on average, how much more do buyers tend to pay for additional Wii wheels (plastic steering wheels that attach to the Wii controller) in auctions? Multiple regression will help us answer these and other questions.</p>
<p>The data set is in the file <code>mariokart.csv</code> in the <code>data</code> folder. This data set includes results from 141 auctions.<a href="#fn96" class="footnote-ref" id="fnref96"><sup>96</sup></a> Ten observations from this data set are shown in the <code>R</code> code below. Note that we force the first column to be interpreted as a character string since it is the identification code for each sale and has no numeric meaning. Just as in the case of simple linear regression, multiple regression also allows for categorical variables with many levels. Although we do have this type of variable in this data set, we will leave the discussion of these types of variables in multiple regression for advanced regression or machine learning courses.</p>
<div class="sourceCode" id="cb963"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb963-1"><a href="#cb963-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="ot">&lt;-</span><span class="fu">read_csv</span>(<span class="st">&quot;data/mariokart.csv&quot;</span>, <span class="at">col_types =</span> <span class="fu">list</span>(<span class="fu">col_character</span>()))</span>
<span id="cb963-2"><a href="#cb963-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mariokart,<span class="at">n=</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 12
##    id        duration n_bids cond  start_pr ship_pr total_pr ship_sp seller_rate
##    &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;
##  1 15037742~        3     20 new       0.99    4        51.6 standa~        1580
##  2 26048337~        7     13 used      0.99    3.99     37.0 firstC~         365
##  3 32043234~        3     16 new       0.99    3.5      45.5 firstC~         998
##  4 28040522~        3     18 new       0.99    0        44   standa~           7
##  5 17039222~        1     20 new       0.01    0        71   media           820
##  6 36019515~        3     19 new       0.99    4        45   standa~      270144
##  7 12047772~        1     13 used      0.01    0        37.0 standa~        7284
##  8 30035550~        1     15 new       1       2.99     54.0 upsGro~        4858
##  9 20039206~        3     29 used      0.99    4        47   priori~          27
## 10 33036416~        7      8 used     20.0     4        50   firstC~         201
## # ... with 3 more variables: stock_photo &lt;chr&gt;, wheels &lt;dbl&gt;, title &lt;chr&gt;</code></pre>
<p>We are only interested in <code>total_pr</code>, <code>cond</code>, <code>stock_photo</code>, <code>duration</code>, and <code>wheels</code>. These variables are described in the following list:</p>
<ol style="list-style-type: decimal">
<li><code>total_pr</code>: final auction price plus shipping costs, in US dollars<br />
</li>
<li><code>cond</code>: a two-level categorical factor variable<br />
</li>
<li><code>stock_photo</code>: a two-level categorical factor variable<br />
</li>
<li><code>duration</code>: the length of the auction, in days, taking values from 1 to 10<br />
</li>
<li><code>wheels</code>: the number of Wii wheels included with the auction (a <strong>Wii wheel</strong> is a plastic racing wheel that holds the Wii controller and is an optional but helpful accessory for playing Mario Kart)</li>
</ol>
<div id="a-single-variable-model-for-the-mario-kart-data" class="section level3" number="30.3.1">
<h3><span class="header-section-number">30.3.1</span> A single-variable model for the Mario Kart data</h3>
<p>Let’s fit a linear regression model with the game’s condition as a predictor of auction price. Before we start let’s change <code>cond</code> and <code>stock_photo</code> into factors.</p>
<div class="sourceCode" id="cb965"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb965-1"><a href="#cb965-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="ot">&lt;-</span> mariokart <span class="sc">%&gt;%</span></span>
<span id="cb965-2"><a href="#cb965-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">cond=</span><span class="fu">factor</span>(cond),<span class="at">stock_photo=</span><span class="fu">factor</span>(stock_photo))</span></code></pre></div>
<p>Next let’s summarize the data.</p>
<div class="sourceCode" id="cb966"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb966-1"><a href="#cb966-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(mariokart)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##          name     class levels   n missing
## 1          id character    143 143       0
## 2        cond    factor      2 143       0
## 3     ship_sp character      8 143       0
## 4 stock_photo    factor      2 143       0
## 5       title character     80 142       1
##                                    distribution
## 1 110439174663 (0.7%) ...                      
## 2 used (58.7%), new (41.3%)                    
## 3 standard (23.1%), upsGround (21.7%) ...      
## 4 yes (73.4%), no (26.6%)                      
## 5  (%) ...                                     
## 
## quantitative variables:  
##             name   class   min      Q1 median      Q3       max         mean
## ...1    duration numeric  1.00   1.000    3.0    7.00     10.00     3.769231
## ...2      n_bids numeric  1.00  10.000   14.0   17.00     29.00    13.538462
## ...3    start_pr numeric  0.01   0.990    1.0   10.00     69.95     8.777203
## ...4     ship_pr numeric  0.00   0.000    3.0    4.00     25.51     3.143706
## ...5    total_pr numeric 28.98  41.175   46.5   53.99    326.51    49.880490
## ...6 seller_rate numeric  0.00 109.000  820.0 4858.00 270144.00 15898.419580
## ...7      wheels numeric  0.00   0.000    1.0    2.00      4.00     1.146853
##                sd   n missing
## ...1 2.585693e+00 143       0
## ...2 5.878786e+00 143       0
## ...3 1.506745e+01 143       0
## ...4 3.213179e+00 143       0
## ...5 2.568856e+01 143       0
## ...6 5.184032e+04 143       0
## ...7 8.471829e-01 143       0</code></pre>
<p>Finally, let’s plot the data.</p>
<div class="sourceCode" id="cb968"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb968-1"><a href="#cb968-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="sc">%&gt;%</span> </span>
<span id="cb968-2"><a href="#cb968-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_boxplot</span>(total_pr<span class="sc">~</span>cond) <span class="sc">%&gt;%</span></span>
<span id="cb968-3"><a href="#cb968-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb968-4"><a href="#cb968-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Ebay Auction Prices&quot;</span>,<span class="at">x=</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Total Price&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/box301-fig-1.png" alt="Total price of Mario Kart on Ebay for each condition." width="672" />
<p class="caption">
(#fig:box301-fig)Total price of Mario Kart on Ebay for each condition.
</p>
</div>
<p>We have several outliers that may impact our analysis, Figure @ref(fig:box301-fig).</p>
<p>Now let’s build the model.</p>
<div class="sourceCode" id="cb969"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb969-1"><a href="#cb969-1" aria-hidden="true" tabindex="-1"></a>mario_mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(total_pr<span class="sc">~</span>cond,<span class="at">data=</span>mariokart)</span></code></pre></div>
<div class="sourceCode" id="cb970"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb970-1"><a href="#cb970-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ cond, data = mariokart)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -18.168  -7.771  -3.148   1.857 279.362 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   53.771      3.329  16.153   &lt;2e-16 ***
## condused      -6.623      4.343  -1.525     0.13    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 25.57 on 141 degrees of freedom
## Multiple R-squared:  0.01622,    Adjusted R-squared:  0.009244 
## F-statistic: 2.325 on 1 and 141 DF,  p-value: 0.1296</code></pre>
<p>The model may be written as</p>
<p><span class="math display">\[
\hat{\text{totalprice}} = 53.771 - 6.623 \times \text{condused}
\]</span></p>
<p>A scatterplot for price versus game condition is shown in Figure @ref(fig:scat301-fig). Since the predictor is binary, the scatterplot is not appropriate but we will look at it for reference.</p>
<div class="sourceCode" id="cb972"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb972-1"><a href="#cb972-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="sc">%&gt;%</span></span>
<span id="cb972-2"><a href="#cb972-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(total_pr<span class="sc">~</span>cond) <span class="sc">%&gt;%</span></span>
<span id="cb972-3"><a href="#cb972-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_classic</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb972-4"><a href="#cb972-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Ebay Auction Prices&quot;</span>,<span class="at">x=</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Total Price&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/scat301-fig-1.png" alt="Scatterplot of total price of Mario Kart on Ebay versus condition." width="672" />
<p class="caption">
(#fig:scat301-fig)Scatterplot of total price of Mario Kart on Ebay versus condition.
</p>
</div>
<p>The largest outlier probably is significantly impacting the relationship in the model. If we find the mean and median for the two groups, we will see this.</p>
<div class="sourceCode" id="cb973"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb973-1"><a href="#cb973-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="sc">%&gt;%</span></span>
<span id="cb973-2"><a href="#cb973-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(cond) <span class="sc">%&gt;%</span></span>
<span id="cb973-3"><a href="#cb973-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">xbar=</span><span class="fu">mean</span>(total_pr), <span class="at">stand_dev=</span><span class="fu">sd</span>(total_pr),<span class="at">xmedian=</span><span class="fu">median</span>(total_pr))</span></code></pre></div>
<pre><code>## # A tibble: 2 x 4
##   cond   xbar stand_dev xmedian
##   &lt;fct&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 new    53.8      7.44    54.0
## 2 used   47.1     32.7     42.8</code></pre>
<p>It appears that <strong>used</strong> items have a right skewed distribution where their average is higher because of at least one of the outliers.</p>
<p>There are at least two outliers in the plot. Let’s gather more information about them.</p>
<div class="sourceCode" id="cb975"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb975-1"><a href="#cb975-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="sc">%&gt;%</span></span>
<span id="cb975-2"><a href="#cb975-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(total_pr <span class="sc">&gt;</span> <span class="dv">100</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 12
##   id         duration n_bids cond  start_pr ship_pr total_pr ship_sp seller_rate
##   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;
## 1 110439174~        7     22 used      1       25.5     327. parcel          115
## 2 130335427~        3     27 used      6.95     4       118. parcel           41
## # ... with 3 more variables: stock_photo &lt;fct&gt;, wheels &lt;dbl&gt;, title &lt;chr&gt;</code></pre>
<p>If you look at the variable <code>title</code> there were additional items in the sale for these two observations. Let’s remove those two outliers and run the model again. Note that the reason we are removing them is not because they are annoying us and messing up our model. It is because we don’t think they are representative of the population of interest. Figure @ref(fig:scat302-fig) is a boxplot of the data with the outliers dropped.</p>
<div class="sourceCode" id="cb977"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb977-1"><a href="#cb977-1" aria-hidden="true" tabindex="-1"></a>mariokart_new <span class="ot">&lt;-</span> mariokart <span class="sc">%&gt;%</span></span>
<span id="cb977-2"><a href="#cb977-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(total_pr <span class="sc">&lt;=</span> <span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb977-3"><a href="#cb977-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(total_pr,cond,stock_photo,duration,wheels)</span></code></pre></div>
<div class="sourceCode" id="cb978"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb978-1"><a href="#cb978-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mariokart_new)</span></code></pre></div>
<pre><code>##     total_pr       cond    stock_photo    duration          wheels     
##  Min.   :28.98   new :59   no : 36     Min.   : 1.000   Min.   :0.000  
##  1st Qu.:41.00   used:82   yes:105     1st Qu.: 1.000   1st Qu.:0.000  
##  Median :46.03                         Median : 3.000   Median :1.000  
##  Mean   :47.43                         Mean   : 3.752   Mean   :1.149  
##  3rd Qu.:53.99                         3rd Qu.: 7.000   3rd Qu.:2.000  
##  Max.   :75.00                         Max.   :10.000   Max.   :4.000</code></pre>
<div class="sourceCode" id="cb980"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb980-1"><a href="#cb980-1" aria-hidden="true" tabindex="-1"></a>mariokart_new <span class="sc">%&gt;%</span> </span>
<span id="cb980-2"><a href="#cb980-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_boxplot</span>(total_pr<span class="sc">~</span>cond) <span class="sc">%&gt;%</span></span>
<span id="cb980-3"><a href="#cb980-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb980-4"><a href="#cb980-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Ebay Auction Prices&quot;</span>,<span class="at">subtitle=</span><span class="st">&quot;Outliers removed&quot;</span>,<span class="at">x=</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Total Price&quot;</span>)</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/scat302-fig-1.png" alt="Boxplot of total price and condition with outliers removed." width="672" />
<p class="caption">
(#fig:scat302-fig)Boxplot of total price and condition with outliers removed.
</p>
</div>
<div class="sourceCode" id="cb981"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb981-1"><a href="#cb981-1" aria-hidden="true" tabindex="-1"></a>mario_mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(total_pr<span class="sc">~</span>cond,<span class="at">data=</span>mariokart_new)</span></code></pre></div>
<div class="sourceCode" id="cb982"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb982-1"><a href="#cb982-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ cond, data = mariokart_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.8911  -5.8311   0.1289   4.1289  22.1489 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  53.7707     0.9596  56.034  &lt; 2e-16 ***
## condused    -10.8996     1.2583  -8.662 1.06e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.371 on 139 degrees of freedom
## Multiple R-squared:  0.3506, Adjusted R-squared:  0.3459 
## F-statistic: 75.03 on 1 and 139 DF,  p-value: 1.056e-14</code></pre>
<p>Notice how much the residual standard error has decreased and likewise the <span class="math inline">\(R\)</span>-squared has increased.</p>
<p>The model may be written as:</p>
<p><span class="math display">\[
\hat{total price} = 53.771 - 10.90 \times condused
\]</span></p>
<p>Now we see that the average price for a used items is $10.90 less than the average of new items.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Does the linear model seem reasonable? Which assumptions should you check?</p>
</blockquote>
<p>The model does seem reasonable in the sense that the assumptions on the errors is plausible. The residuals indicate some skewness to the right which may be driven predominantly by the skewness in the new items, Figure @ref(fig:qq301-fig).</p>
<div class="sourceCode" id="cb984"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb984-1"><a href="#cb984-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mario_mod2,<span class="dv">2</span>)</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/qq301-fig-1.png" alt="Check of normality using quantile-quantile plot." width="672" />
<p class="caption">
(#fig:qq301-fig)Check of normality using quantile-quantile plot.
</p>
</div>
<p>The normality assumption is somewhat suspect but we have more than 100 data points so the short tails of the distribution are not a concern. The shape of this curve indicates a positive skew.</p>
<div class="sourceCode" id="cb985"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb985-1"><a href="#cb985-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mario_mod2,<span class="dv">3</span>)</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/diag301-fig-1.png" alt="Residual plot to assess equal variance assumption." width="672" />
<p class="caption">
(#fig:diag301-fig)Residual plot to assess equal variance assumption.
</p>
</div>
<p>From Figure @ref(fig:diag301-fig), equal variance seems reasonable.</p>
<div class="sourceCode" id="cb986"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb986-1"><a href="#cb986-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mario_mod2,<span class="dv">5</span>)</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/diag302-fig-1.png" alt="Residual plot for checking leverage points." width="672" />
<p class="caption">
(#fig:diag302-fig)Residual plot for checking leverage points.
</p>
</div>
<p>No high leverage points, Figure @ref(fig:diag302-fig).</p>
<p>No need to check linearity, we only have two different values for the explanatory variable.</p>
<blockquote>
<p><em>Example</em>: Interpretation<br />
Interpret the coefficient for the game’s condition in the model. Is this coefficient significantly different from 0?</p>
</blockquote>
<p>Note that <code>cond</code> is a two-level categorical variable and the reference level is <code>new</code>. So - 10.90 means that the model predicts an extra $10.90 on average for those games that are new versus those that are used. Examining the regression output, we can see that the p-value for <code>cond</code> is very close to zero, indicating there is strong evidence that the coefficient is different from zero when using this simple one-variable model.</p>
</div>
<div id="including-and-assessing-many-variables-in-a-model" class="section level3" number="30.3.2">
<h3><span class="header-section-number">30.3.2</span> Including and assessing many variables in a model</h3>
<p>Sometimes there are underlying structures or relationships between predictor variables. For instance, new games sold on Ebay tend to come with more Wii wheels, which may have led to higher prices for those auctions. We would like to fit a model that includes all potentially important variables simultaneously. This would help us evaluate the relationship between a predictor variable and the outcome while controlling for the potential influence of other variables. This is the strategy used in <strong>multiple regression</strong>. While we remain cautious about making any causal interpretations using multiple regression, such models are a common first step in providing evidence of a causal connection.</p>
<p>We want to construct a model that accounts for not only the game condition, but simultaneously accounts for three other variables: <code>stock_photo</code>, <code>duration</code>, and <code>wheels</code>. This model can be represented as:</p>
<p><span class="math display">\[
\widehat{\text{totalprice}}
    = \beta_0 + \beta_1 \times \text{cond} + \beta_2 \times \text{stockphoto}
    + \beta_3 \times  \text{duration} +
        \beta_4 \times  \text{wheels}
\]</span></p>
<p>or:</p>
<p><span class="math display">\[\begin{equation}
\hat{y}
    = \beta_0 + \beta_1 x_1 + \beta_2 x_2 +
        \beta_3 x_3 + \beta_4 x_4
  (\#eq:multilr)
\end{equation}\]</span></p>
<p>In Equation @ref(eq:multilr), <span class="math inline">\(y\)</span> represents the total price, <span class="math inline">\(x_1\)</span> indicates whether the game is new, <span class="math inline">\(x_2\)</span> indicates whether a stock photo was used, <span class="math inline">\(x_3\)</span> is the duration of the auction, and <span class="math inline">\(x_4\)</span> is the number of Wii wheels included with the game. Just as with the single predictor case, a multiple regression model may be missing important components or it might not precisely represent the relationship between the outcome and the available explanatory variables. While no model is perfect, we wish to explore the possibility that this model may fit the data reasonably well.</p>
<p>We estimate the parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, …, <span class="math inline">\(\beta_4\)</span> in the same way as we did in the case of a single predictor. We select <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span>, …, <span class="math inline">\(b_4\)</span> that minimize the sum of the squared residuals:</p>
<p><span class="math display">\[
\text{SSE} = e_1^2 + e_2^2 + \dots + e_{141}^2
    = \sum_{i=1}^{141} e_i^2
     = \sum_{i=1}^{141} \left(y_i - \hat{y}_i\right)^2
\]</span></p>
<p>In our problem, there are 141 residuals, one for each observation. We use a computer to minimize the sum and compute point estimates.</p>
<div class="sourceCode" id="cb987"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb987-1"><a href="#cb987-1" aria-hidden="true" tabindex="-1"></a>mario_mod_multi <span class="ot">&lt;-</span> <span class="fu">lm</span>(total_pr<span class="sc">~</span>., <span class="at">data=</span>mariokart_new)</span></code></pre></div>
<p>The formula <code>total_pr~.</code> uses a <em>dot</em>. This means we want to use all the predictors. We could have also used the following code:</p>
<div class="sourceCode" id="cb988"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb988-1"><a href="#cb988-1" aria-hidden="true" tabindex="-1"></a>mario_mod_multi <span class="ot">&lt;-</span> <span class="fu">lm</span>(total_pr<span class="sc">~</span>cond<span class="sc">+</span>stock_photo<span class="sc">+</span>duration<span class="sc">+</span>wheels, <span class="at">data=</span>mariokart_new)</span></code></pre></div>
<p>Recall, the <code>+</code> symbol does not mean to literally add the predictors together. It is not a mathematical operation but a formula operation that means to include the predictor.</p>
<p>You can view a summary of the model using the <code>summmary()</code> function.</p>
<div class="sourceCode" id="cb989"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb989-1"><a href="#cb989-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod_multi)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ ., data = mariokart_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.3788  -2.9854  -0.9654   2.6915  14.0346 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    41.34153    1.71167  24.153  &lt; 2e-16 ***
## condused       -5.13056    1.05112  -4.881 2.91e-06 ***
## stock_photoyes  1.08031    1.05682   1.022    0.308    
## duration       -0.02681    0.19041  -0.141    0.888    
## wheels          7.28518    0.55469  13.134  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.901 on 136 degrees of freedom
## Multiple R-squared:  0.719,  Adjusted R-squared:  0.7108 
## F-statistic: 87.01 on 4 and 136 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Which we can summarize in a tibble using the <strong>broom</strong> package.</p>
<table>
<caption>
(#tab:tab301)Multiple regression coefficients.
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
41.3415318
</td>
<td style="text-align:right;">
1.7116684
</td>
<td style="text-align:right;">
24.1527693
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
condused
</td>
<td style="text-align:right;">
-5.1305641
</td>
<td style="text-align:right;">
1.0511238
</td>
<td style="text-align:right;">
-4.8810276
</td>
<td style="text-align:right;">
0.0000029
</td>
</tr>
<tr>
<td style="text-align:left;">
stock_photoyes
</td>
<td style="text-align:right;">
1.0803108
</td>
<td style="text-align:right;">
1.0568238
</td>
<td style="text-align:right;">
1.0222241
</td>
<td style="text-align:right;">
0.3084897
</td>
</tr>
<tr>
<td style="text-align:left;">
duration
</td>
<td style="text-align:right;">
-0.0268075
</td>
<td style="text-align:right;">
0.1904122
</td>
<td style="text-align:right;">
-0.1407868
</td>
<td style="text-align:right;">
0.8882467
</td>
</tr>
<tr>
<td style="text-align:left;">
wheels
</td>
<td style="text-align:right;">
7.2851779
</td>
<td style="text-align:right;">
0.5546928
</td>
<td style="text-align:right;">
13.1337172
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
</tbody>
</table>
<p>Using this output, Table @ref(tab:tab301), we identify the point estimates <span class="math inline">\(b_i\)</span> of each <span class="math inline">\(\beta_i\)</span>, just as we did in the one-predictor case.</p>
<blockquote>
<p><strong>Multiple regression model</strong><br />
A multiple regression model is a linear model with many predictors.</p>
</blockquote>
<p>In general, we write the model as</p>
<p><span class="math display">\[
\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k %+ \epsilon
\]</span></p>
<p>when there are <span class="math inline">\(k\)</span> predictors. We often estimate the <span class="math inline">\(\beta_i\)</span> parameters using a computer.</p>
<blockquote>
<p><strong>Exercise</strong>:
Write out the the multiple regression model using the point estimates from regression output. How many predictors are there in this model?<a href="#fn97" class="footnote-ref" id="fnref97"><sup>97</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
What does <span class="math inline">\(\beta_4\)</span>, the coefficient of variable <span class="math inline">\(x_4\)</span> (Wii wheels), represent? What is the point estimate of <span class="math inline">\(\beta_4\)</span>?<a href="#fn98" class="footnote-ref" id="fnref98"><sup>98</sup></a></p>
</blockquote>
<blockquote>
<p><strong>Exercise</strong>:<br />
Compute the residual of the first observation in the dataframe using the regression equation.</p>
</blockquote>
<div class="sourceCode" id="cb991"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb991-1"><a href="#cb991-1" aria-hidden="true" tabindex="-1"></a>mario_mod_multi<span class="sc">$</span>residuals[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>##        1 
## 1.923402</code></pre>
<p>The <strong>broom</strong> package has a function <code>augment()</code> that will calculate the predicted and residuals.</p>
<div class="sourceCode" id="cb993"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb993-1"><a href="#cb993-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span></code></pre></div>
<div class="sourceCode" id="cb994"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb994-1"><a href="#cb994-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod_multi) <span class="sc">%&gt;%</span></span>
<span id="cb994-2"><a href="#cb994-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   total_pr cond  stock_photo duration wheels .fitted .resid   .hat .sigma
##      &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;          &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     51.6 new   yes                3      1    49.6   1.92 0.0215   4.92
## # ... with 2 more variables: .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt;</code></pre>
<p><span class="math inline">\(e_i = y_i - \hat{y_i} = 51.55 - 49.62 = 1.93\)</span></p>
<blockquote>
<p><em>Example</em>:<br />
We estimated a coefficient for <code>cond</code> as <span class="math inline">\(b_1 = - 10.90\)</span> with a standard error of <span class="math inline">\(SE_{b_1} = 1.26\)</span> when using simple linear regression. Why might there be a difference between that estimate and the one in the multiple regression setting?</p>
</blockquote>
<p>If we examined the data carefully, we would see that some predictors are correlated. For instance, when we estimated the connection of the outcome <code>total_pr</code> and predictor <code>cond</code> using simple linear regression, we were unable to control for other variables like the number of Wii wheels included in the auction. That model was biased by the confounding variable <code>wheels</code>. When we use both variables, this particular underlying and unintentional bias is reduced or eliminated (though bias from other confounding variables may still remain).</p>
<p>The previous example describes a common issue in multiple regression: correlation among predictor variables. We say the two predictor variables are <strong>collinear</strong> (pronounced as <strong>co-linear</strong>) when they are correlated, and this collinearity complicates model estimation. While it is impossible to prevent collinearity from arising in observational data, experiments are usually designed to prevent predictors from being collinear.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
The estimated value of the intercept is 41.34, and one might be tempted to make some interpretation of this coefficient, such as, it is the model’s predicted price when each of the variables take a value of zero: the game is new, the primary image is not a stock photo, the auction duration is zero days, and there are no wheels included. Is there any value gained by making this interpretation?<a href="#fn99" class="footnote-ref" id="fnref99"><sup>99</sup></a></p>
</blockquote>
</div>
<div id="inference-1" class="section level3" number="30.3.3">
<h3><span class="header-section-number">30.3.3</span> Inference</h3>
<p>From the printout of the model summary, we can see that both the <code>stock_photo</code> and <code>duration</code> variables are not significantly different from zero. Thus we may want to drop them from the model. In a machine learning course, you explore different ways to determine the best model.</p>
<p>Likewise, we could generate confidence intervals for the coefficients:</p>
<div class="sourceCode" id="cb996"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb996-1"><a href="#cb996-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mario_mod_multi)</span></code></pre></div>
<pre><code>##                     2.5 %     97.5 %
## (Intercept)    37.9566036 44.7264601
## condused       -7.2092253 -3.0519030
## stock_photoyes -1.0096225  3.1702442
## duration       -0.4033592  0.3497442
## wheels          6.1882392  8.3821165</code></pre>
<p>This confirms that the <code>stock_photo</code> and <code>duration</code> may not have an impact on total price.</p>
</div>
<div id="adjusted-r2-as-a-better-estimate-of-explained-variance" class="section level3" number="30.3.4">
<h3><span class="header-section-number">30.3.4</span> Adjusted <span class="math inline">\(R^2\)</span> as a better estimate of explained variance</h3>
<p>We first used <span class="math inline">\(R^2\)</span> in simple linear regression to determine the amount of variability, we used sum of squares and not mean squared errors, in the response that was explained by the model:
<span class="math display">\[
R^2 = 1 - \frac{\text{sum of squares of residuals}}{\text{sum of squares of the outcome}}
\]</span>
This equation remains valid in the multiple regression framework, but a small enhancement can often be even more informative.</p>
<blockquote>
<p><strong>Exercise</strong>:
The variance of the residuals for the model is <span class="math inline">\(4.901^2\)</span>, and the variance of the total price in all the auctions is 83.06. Estimate the <span class="math inline">\(R^2\)</span> for this model.<a href="#fn100" class="footnote-ref" id="fnref100"><sup>100</sup></a></p>
</blockquote>
<p>To get the <span class="math inline">\(R^2\)</span> we need the sum of squares and not variance, so we multiply by the appropriate degrees of freedom.</p>
<div class="sourceCode" id="cb998"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb998-1"><a href="#cb998-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span>(<span class="fl">24.0198</span><span class="sc">*</span><span class="dv">136</span>)<span class="sc">/</span>(<span class="fl">83.05864</span><span class="sc">*</span><span class="dv">140</span>)</span></code></pre></div>
<pre><code>## [1] 0.7190717</code></pre>
<div class="sourceCode" id="cb1000"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1000-1"><a href="#cb1000-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod_multi)<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.7190261</code></pre>
<p>This strategy for estimating <span class="math inline">\(R^2\)</span> is acceptable when there is just a single variable. However, it becomes less helpful when there are many variables. The regular <span class="math inline">\(R^2\)</span> is actually a biased estimate of the amount of variability explained by the model. To get a better estimate, we use the adjusted <span class="math inline">\(R^2\)</span>.</p>
<blockquote>
<p><strong>Adjusted <span class="math inline">\(\mathbf{R^2}\)</span> as a tool for model assessment</strong>:<br />
The adjusted <span class="math inline">\(\mathbf{R^2}\)</span> is computed as:
<span class="math display">\[
R_{adj}^{2} = 1-\frac{\text{sum of squares of residuals} / (n-k-1)}{\text{sum of squares of the outcome} / (n-1)}
\]</span>
where <span class="math inline">\(n\)</span> is the number of cases used to fit the model and <span class="math inline">\(k\)</span> is the number of predictor variables in the model.</p>
</blockquote>
<p>Because <span class="math inline">\(k\)</span> is never negative, the adjusted <span class="math inline">\(R^2\)</span> will be smaller – often times just a little smaller – than the unadjusted <span class="math inline">\(R^2\)</span>. The reasoning behind the adjusted <span class="math inline">\(R^2\)</span> lies in the <strong>degrees of freedom</strong> associated with each variance. <a href="#fn101" class="footnote-ref" id="fnref101"><sup>101</sup></a></p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Suppose you added another predictor to the model, but the variance of the errors didn’t go down. What would happen to the <span class="math inline">\(R^2\)</span>? What would happen to the adjusted <span class="math inline">\(R^2\)</span>?<a href="#fn102" class="footnote-ref" id="fnref102"><sup>102</sup></a></p>
</blockquote>
<p>Again, in a machine learning course, you will spend more time on how to select models. Using internal metrics of performance such as p-values or adjusted <span class="math inline">\(R\)</span> squared are one way but using external measures of predictive performance such as <strong>cross validation</strong> or <strong>hold out</strong> sets will be introduced.</p>
</div>
<div id="reduced-model" class="section level3" number="30.3.5">
<h3><span class="header-section-number">30.3.5</span> Reduced model</h3>
<p>Now let’s drop <code>duration</code> from the model and compare to our previous model:</p>
<div class="sourceCode" id="cb1002"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1002-1"><a href="#cb1002-1" aria-hidden="true" tabindex="-1"></a>mario_mod_multi2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(total_pr<span class="sc">~</span>cond<span class="sc">+</span>stock_photo<span class="sc">+</span>wheels, <span class="at">data=</span>mariokart_new)</span></code></pre></div>
<p>And the summary:</p>
<div class="sourceCode" id="cb1003"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1003-1"><a href="#cb1003-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod_multi2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ cond + stock_photo + wheels, data = mariokart_new)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -11.454  -2.959  -0.949   2.712  14.061 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     41.2245     1.4911  27.648  &lt; 2e-16 ***
## condused        -5.1763     0.9961  -5.196 7.21e-07 ***
## stock_photoyes   1.1177     1.0192   1.097    0.275    
## wheels           7.2984     0.5448  13.397  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.884 on 137 degrees of freedom
## Multiple R-squared:  0.719,  Adjusted R-squared:  0.7128 
## F-statistic: 116.8 on 3 and 137 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>As a reminder, the previous model summary is:</p>
<div class="sourceCode" id="cb1005"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1005-1"><a href="#cb1005-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod_multi)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ ., data = mariokart_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.3788  -2.9854  -0.9654   2.6915  14.0346 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    41.34153    1.71167  24.153  &lt; 2e-16 ***
## condused       -5.13056    1.05112  -4.881 2.91e-06 ***
## stock_photoyes  1.08031    1.05682   1.022    0.308    
## duration       -0.02681    0.19041  -0.141    0.888    
## wheels          7.28518    0.55469  13.134  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.901 on 136 degrees of freedom
## Multiple R-squared:  0.719,  Adjusted R-squared:  0.7108 
## F-statistic: 87.01 on 4 and 136 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Notice that the adjusted <span class="math inline">\(R^2\)</span> improved by dropping <code>duration</code>. Finally, let’s drop <code>stock_photo</code>.</p>
<div class="sourceCode" id="cb1007"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1007-1"><a href="#cb1007-1" aria-hidden="true" tabindex="-1"></a>mario_mod_multi3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(total_pr<span class="sc">~</span>cond<span class="sc">+</span>wheels, <span class="at">data=</span>mariokart_new)</span></code></pre></div>
<div class="sourceCode" id="cb1008"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1008-1"><a href="#cb1008-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod_multi3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = total_pr ~ cond + wheels, data = mariokart_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.0078  -3.0754  -0.8254   2.9822  14.1646 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  42.3698     1.0651  39.780  &lt; 2e-16 ***
## condused     -5.5848     0.9245  -6.041 1.35e-08 ***
## wheels        7.2328     0.5419  13.347  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.887 on 138 degrees of freedom
## Multiple R-squared:  0.7165, Adjusted R-squared:  0.7124 
## F-statistic: 174.4 on 2 and 138 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Though the adjusted <span class="math inline">\(R^2\)</span> dropped a little, it is only in the fourth decimal place and thus essentially the same value. We therefore will go with this model.</p>
</div>
<div id="confidence-and-prediction-intervals" class="section level3" number="30.3.6">
<h3><span class="header-section-number">30.3.6</span> Confidence and prediction intervals</h3>
<p>Let’s suppose we want to predict the average total price for a Mario Kart sale with 2 wheels and in new condition. We can again use the <code>predict()</code> function.</p>
<div class="sourceCode" id="cb1010"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1010-1"><a href="#cb1010-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mario_mod_multi3,<span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">cond=</span><span class="st">&quot;new&quot;</span>,<span class="at">wheels=</span><span class="dv">2</span>),<span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 56.83544 55.49789 58.17299</code></pre>
<p>We are 95% confident that the average price of a Mario Kart sale for a new item with 2 wheels will be between 55.50 and 58.17.</p>
<blockquote>
<p><strong>Exercise</strong>:
Find and interpret the prediction interval for a new Mario Kart with 2 wheels.</p>
</blockquote>
<div class="sourceCode" id="cb1012"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1012-1"><a href="#cb1012-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mario_mod_multi3,<span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">cond=</span><span class="st">&quot;new&quot;</span>,<span class="at">wheels=</span><span class="dv">2</span>),<span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 56.83544 47.07941 66.59147</code></pre>
<p>We are 95% confident that the price of a Mario Kart sale for a new item with 2 wheels will be between 47.07 and 66.59.</p>
</div>
<div id="diagnostics" class="section level3" number="30.3.7">
<h3><span class="header-section-number">30.3.7</span> Diagnostics</h3>
<p>The diagnostics for the model are similar to what we did in a previous lesson. Nothing in these plots gives us concern; however, there is one leverage point, Figure @ref(fig:diag305-fig).</p>
<div class="sourceCode" id="cb1014"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1014-1"><a href="#cb1014-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mario_mod_multi3)</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/diag305-fig-1.png" alt="Diagnostic residual plots for multiple regression model." width="50%" /><img src="30-Multiple-Regression_files/figure-html/diag305-fig-2.png" alt="Diagnostic residual plots for multiple regression model." width="50%" /><img src="30-Multiple-Regression_files/figure-html/diag305-fig-3.png" alt="Diagnostic residual plots for multiple regression model." width="50%" /><img src="30-Multiple-Regression_files/figure-html/diag305-fig-4.png" alt="Diagnostic residual plots for multiple regression model." width="50%" />
<p class="caption">
(#fig:diag305-fig)Diagnostic residual plots for multiple regression model.
</p>
</div>
</div>
</div>
<div id="interaction-and-higher-order-terms" class="section level2" number="30.4">
<h2><span class="header-section-number">30.4</span> Interaction and Higher Order Terms</h2>
<p>As a final short topic we want to explore <strong>feature engineering</strong>. Thus far we have not done any transformation to the predictors in the data set except maybe making categorical variables into factors. In data analysis competitions, such as Kaggle, feature engineering is often one of the most important steps. In a machine learning course, you will look at different tools but in this book we will look at simple transformations such as higher order terms and interactions.</p>
<p>To make this section more relevant, we are going to switch to a different data set. Load the library <strong>ISLR</strong>.</p>
<div class="sourceCode" id="cb1015"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1015-1"><a href="#cb1015-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span></code></pre></div>
<p>The data set of interest is <code>Credit</code>. Use the help menu to read about the variables. This is a simulated data set of credit card debt.</p>
<div class="sourceCode" id="cb1016"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1016-1"><a href="#cb1016-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(Credit)</span></code></pre></div>
<pre><code>## Rows: 400
## Columns: 12
## $ ID        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~
## $ Income    &lt;dbl&gt; 14.891, 106.025, 104.593, 148.924, 55.882, 80.180, 20.996, 7~
## $ Limit     &lt;int&gt; 3606, 6645, 7075, 9504, 4897, 8047, 3388, 7114, 3300, 6819, ~
## $ Rating    &lt;int&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589, 138, ~
## $ Cards     &lt;int&gt; 2, 3, 4, 3, 2, 4, 2, 2, 5, 3, 4, 3, 1, 1, 2, 3, 3, 3, 1, 2, ~
## $ Age       &lt;int&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49, 75, ~
## $ Education &lt;int&gt; 11, 15, 11, 11, 16, 10, 12, 9, 13, 19, 14, 16, 7, 9, 13, 15,~
## $ Gender    &lt;fct&gt;  Male, Female,  Male, Female,  Male,  Male, Female,  Male, F~
## $ Student   &lt;fct&gt; No, Yes, No, No, No, No, No, No, No, Yes, No, No, No, No, No~
## $ Married   &lt;fct&gt; Yes, Yes, No, No, Yes, No, No, No, No, Yes, Yes, No, Yes, Ye~
## $ Ethnicity &lt;fct&gt; Caucasian, Asian, Asian, Asian, Caucasian, Caucasian, Africa~
## $ Balance   &lt;int&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 1407, 0,~</code></pre>
<p>Notice that <code>ID</code> is being treated as an integer. We could change it to a character since it is a label, but for our work in this chapter we will not bother.</p>
<p>Suppose we suspected that there is a relationship between <code>Balance</code>, the response, and the predictors <code>Income</code> and <code>Student</code>. Note: we actually are using this model for educational purposes and did not go through a model selection process.</p>
<p>The first model simply has these predictors in the model.</p>
<div class="sourceCode" id="cb1018"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1018-1"><a href="#cb1018-1" aria-hidden="true" tabindex="-1"></a>credit_mod1<span class="ot">&lt;-</span><span class="fu">lm</span>(Balance<span class="sc">~</span>Income<span class="sc">+</span>Student,<span class="at">data=</span>Credit)</span></code></pre></div>
<div class="sourceCode" id="cb1019"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1019-1"><a href="#cb1019-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(credit_mod1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Income + Student, data = Credit)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -762.37 -331.38  -45.04  323.60  818.28 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 211.1430    32.4572   6.505 2.34e-10 ***
## Income        5.9843     0.5566  10.751  &lt; 2e-16 ***
## StudentYes  382.6705    65.3108   5.859 9.78e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 391.8 on 397 degrees of freedom
## Multiple R-squared:  0.2775, Adjusted R-squared:  0.2738 
## F-statistic: 76.22 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Let’s plot the data and the regression line. The impact of putting in the categorical variable <code>Student</code> is to just shift the intercept. The slope remains the same, Figure @ref(fig:scat305-fig).</p>
<div class="sourceCode" id="cb1021"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1021-1"><a href="#cb1021-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(credit_mod1) <span class="sc">%&gt;%</span></span>
<span id="cb1021-2"><a href="#cb1021-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(Balance<span class="sc">~</span>Income,<span class="at">color=</span><span class="sc">~</span>Student) <span class="sc">%&gt;%</span></span>
<span id="cb1021-3"><a href="#cb1021-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_line</span>(.fitted<span class="sc">~</span>Income,<span class="at">data=</span><span class="fu">subset</span>(<span class="fu">augment</span>(credit_mod1), Student <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>),<span class="at">color=</span><span class="sc">~</span>Student)<span class="sc">%&gt;%</span></span>
<span id="cb1021-4"><a href="#cb1021-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_line</span>(.fitted<span class="sc">~</span>Income,<span class="at">data=</span><span class="fu">subset</span>(<span class="fu">augment</span>(credit_mod1), Student <span class="sc">==</span> <span class="st">&quot;No&quot;</span>),<span class="at">color=</span><span class="sc">~</span>Student) <span class="sc">%&gt;%</span></span>
<span id="cb1021-5"><a href="#cb1021-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/scat305-fig-1.png" alt="Scatterplot of credit card balance for income and student status." width="672" />
<p class="caption">
(#fig:scat305-fig)Scatterplot of credit card balance for income and student status.
</p>
</div>
<blockquote>
<p><strong>Exercise</strong>:<br />
Write the equation for the regression model.</p>
</blockquote>
<p><span class="math display">\[
\mbox{E}(Balance)=\beta_0 + \beta_1*\text{Income}+ \beta_2*\text{(Student=Yes)}
\]</span></p>
<p>or</p>
<p><span class="math display">\[
\mbox{E}(Balance)=211.14 + 5.98*\text{Income}+ 382.67*\text{(Student=Yes)}
\]</span></p>
<p>If the observation is a student, then the intercept is increased by 382.67.</p>
<p>In this next case, we would want to include an interaction term in the model: an <strong>interaction</strong> term allows the slope to change as well. To include an interaction term when building a model in <code>R</code>, we use <code>*</code>.</p>
<div class="sourceCode" id="cb1022"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1022-1"><a href="#cb1022-1" aria-hidden="true" tabindex="-1"></a>credit_mod2<span class="ot">&lt;-</span><span class="fu">lm</span>(Balance<span class="sc">~</span>Income<span class="sc">*</span>Student,<span class="at">data=</span>Credit)</span></code></pre></div>
<div class="sourceCode" id="cb1023"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1023-1"><a href="#cb1023-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(credit_mod2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Income * Student, data = Credit)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -773.39 -325.70  -41.13  321.65  814.04 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       200.6232    33.6984   5.953 5.79e-09 ***
## Income              6.2182     0.5921  10.502  &lt; 2e-16 ***
## StudentYes        476.6758   104.3512   4.568 6.59e-06 ***
## Income:StudentYes  -1.9992     1.7313  -1.155    0.249    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 391.6 on 396 degrees of freedom
## Multiple R-squared:  0.2799, Adjusted R-squared:  0.2744 
## F-statistic:  51.3 on 3 and 396 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb1025"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1025-1"><a href="#cb1025-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(credit_mod2) <span class="sc">%&gt;%</span></span>
<span id="cb1025-2"><a href="#cb1025-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(Balance<span class="sc">~</span>Income,<span class="at">color=</span><span class="sc">~</span>Student) <span class="sc">%&gt;%</span></span>
<span id="cb1025-3"><a href="#cb1025-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_line</span>(.fitted<span class="sc">~</span>Income,<span class="at">data=</span><span class="fu">subset</span>(<span class="fu">augment</span>(credit_mod2), Student <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>),<span class="at">color=</span><span class="sc">~</span>Student)<span class="sc">%&gt;%</span></span>
<span id="cb1025-4"><a href="#cb1025-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_line</span>(.fitted<span class="sc">~</span>Income,<span class="at">data=</span><span class="fu">subset</span>(<span class="fu">augment</span>(credit_mod2), Student <span class="sc">==</span> <span class="st">&quot;No&quot;</span>),<span class="at">color=</span><span class="sc">~</span>Student) <span class="sc">%&gt;%</span></span>
<span id="cb1025-5"><a href="#cb1025-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/scat306-fig-1.png" alt="Scatterplot of credit card balance for income and student status with an interaction term." width="672" />
<p class="caption">
(#fig:scat306-fig)Scatterplot of credit card balance for income and student status with an interaction term.
</p>
</div>
<p>Now we have a different slope and intercept for each case of the <code>Student</code> variable, Figure @ref(fig:scat306-fig). Thus there is a synergy or interaction between these variables. The student status changes the impact of <code>Income</code> on <code>Balance</code>. If you are a student, then for every increase in income of 1 the balance increase by 4.219 on average. If you are not a student, every increase in income of 1 increases the average balance by 6.2182.</p>
<p>Furthermore, if you suspect that perhaps a curved relationship exists between two variables, we could include a higher order term. As an example, let’s add a quadratic term for <code>Income</code> to our model (without the interaction). To do this in <code>R</code>, we need to wrap the higher order term in <code>I()</code>. If we include a higher order term, we usually want to include the lower order terms as well; a better approach is to make the decision on what to include using predictive performance.</p>
<div class="sourceCode" id="cb1026"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1026-1"><a href="#cb1026-1" aria-hidden="true" tabindex="-1"></a>credit_mod3<span class="ot">&lt;-</span><span class="fu">lm</span>(Balance<span class="sc">~</span>Income<span class="sc">+</span><span class="fu">I</span>(Income<span class="sc">^</span><span class="dv">2</span>),<span class="at">data=</span>Credit)</span></code></pre></div>
<div class="sourceCode" id="cb1027"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1027-1"><a href="#cb1027-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(credit_mod3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Income + I(Income^2), data = Credit)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -782.88 -361.40  -54.98  316.26 1104.39 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 285.3973    54.1720   5.268 2.26e-07 ***
## Income        4.3972     1.9078   2.305   0.0217 *  
## I(Income^2)   0.0109     0.0120   0.908   0.3642    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 408 on 397 degrees of freedom
## Multiple R-squared:  0.2166, Adjusted R-squared:  0.2127 
## F-statistic: 54.88 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb1029"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1029-1"><a href="#cb1029-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(credit_mod3) <span class="sc">%&gt;%</span></span>
<span id="cb1029-2"><a href="#cb1029-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_point</span>(Balance<span class="sc">~</span>Income) <span class="sc">%&gt;%</span></span>
<span id="cb1029-3"><a href="#cb1029-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_line</span>(.fitted<span class="sc">~</span>Income) <span class="sc">%&gt;%</span></span>
<span id="cb1029-4"><a href="#cb1029-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>())</span></code></pre></div>
<div class="figure">
<img src="30-Multiple-Regression_files/figure-html/scat307-fig-1.png" alt="Scatterplot of credit card balance for income with a quadratic fit." width="672" />
<p class="caption">
(#fig:scat307-fig)Scatterplot of credit card balance for income with a quadratic fit.
</p>
</div>
<p>There is not much of a quadratic relationship, Figure @ref(fig:scat307-fig).</p>
<div id="summary-3" class="section level3" number="30.4.1">
<h3><span class="header-section-number">30.4.1</span> Summary</h3>
<p>In this chapter we have extended the linear regression model by allowing multiple predictors. This allows us to account for confounding variables and make more sophisticated models. The interpretation and evaluation of the model changes.</p>
</div>
</div>
<div id="homework-problems-29" class="section level2" number="30.5">
<h2><span class="header-section-number">30.5</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>The <code>mtcars</code> data set contains average mileage (mpg) and other information about specific makes and models of cars. (This data set is built-in to <code>R</code>; for more information about this data set, reference the documentation with <code>?mtcars</code>).</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Build and interpret the coefficients of a model fitting <code>mpg</code> against displacement (<code>disp</code>), horsepower (<code>hp</code>), rear axle ratio (<code>drat</code>), and weight in 1000 lbs (<code>wt</code>).<br />
</li>
<li>Given your model, what is the expected mpg for a vehicle with a displacement of 170, a horsepower of 100, a <code>drat</code> of 3.80 and a wt of 2,900 lbs. Construct a 95% confidence interval and prediction interval for that expected mpg.<br />
</li>
<li>Repeat part (b) with a bootstrap for the confidence interval.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Is that the best model for predicting mpg? Try a variety of different models. You could explore higher order terms or even interactions. One place to start is by using the <code>pairs()</code> function on <code>mtcars</code> to plot a large pairwise scatterplot. How high could you get adjusted <span class="math inline">\(R\)</span>-squared? Keep in mind that is only one measure of fit.</li>
</ol>
<!--chapter:end:30-Multiple-Regression.Rmd-->
</div>
</div>
<div id="LOGREG" class="section level1" number="31">
<h1><span class="header-section-number">31</span> Logistic Regression</h1>
<div id="objectives-29" class="section level2" number="31.1">
<h2><span class="header-section-number">31.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Using <code>R</code>, conduct logistic regression and interpret the output and perform model selection.<br />
</li>
<li>Write the logistic regression model and predict outputs for given inputs.<br />
</li>
<li>Find confidence intervals for parameter estimates and predictions.<br />
</li>
<li>Create and interpret a confusion matrix.</li>
</ol>
</div>
<div id="logistic-regression-introduction" class="section level2" number="31.2">
<h2><span class="header-section-number">31.2</span> Logistic regression introduction</h2>
<p>In this lesson we introduce <strong>logistic regression</strong> as a tool for building models when there is a categorical response variable with two levels. Logistic regression is a type of <strong>generalized linear model</strong> (GLM) for response variables where the assumptions of normally distributed errors is not appropriate. We are prepping you for advanced statistical models and machine learning, where we will explore predictive models of many different types of response variables including ones that don’t assume an underlying functional relationship between inputs and outputs. So cool!</p>
<p>GLMs can be thought of as a two-stage modeling approach. We first model the response variable using a probability distribution, such as the binomial or Poisson distribution. Second, we model the parameter of the distribution using a collection of predictors and a special form of multiple regression.</p>
<p>To explore and explain these ideas, we will again use the Ebay auctions of a video game called <strong>Mario Kart</strong> for the Nintendo Wii. Remember, the data set is in the file <code>mariokart.csv</code> and includes results from 141 auctions.<a href="#fn103" class="footnote-ref" id="fnref103"><sup>103</sup></a></p>
<p>In this chapter, we want the outcome variable of interest to be game condition, <code>cond</code>. In Chapter @ref(LRMULTI) we used the total price of an auction as the response. We are moving from a quantitative response to a binary qualitative variable. If we were only interested in determining if an association exists between the variables <code>cond</code> and <code>total_pr</code>, we could use linear regression with <code>total_pr</code> as the response. However, in this problem we want to predict game condition. We will start by reviewing some of the previous models and then introduce logistic regression. We will finish with a multiple logistic regression model, more than one predictor.</p>
<div id="mario-kart-data" class="section level3" number="31.2.1">
<h3><span class="header-section-number">31.2.1</span> Mario Kart data</h3>
<p>Read the data and summarize.</p>
<div class="sourceCode" id="cb1030"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1030-1"><a href="#cb1030-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="ot">&lt;-</span><span class="fu">read_csv</span>(<span class="st">&quot;data/mariokart.csv&quot;</span>, <span class="at">col_types =</span> <span class="fu">list</span>(<span class="fu">col_character</span>()))</span>
<span id="cb1030-2"><a href="#cb1030-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mariokart,<span class="at">n=</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 12
##    id        duration n_bids cond  start_pr ship_pr total_pr ship_sp seller_rate
##    &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;
##  1 15037742~        3     20 new       0.99    4        51.6 standa~        1580
##  2 26048337~        7     13 used      0.99    3.99     37.0 firstC~         365
##  3 32043234~        3     16 new       0.99    3.5      45.5 firstC~         998
##  4 28040522~        3     18 new       0.99    0        44   standa~           7
##  5 17039222~        1     20 new       0.01    0        71   media           820
##  6 36019515~        3     19 new       0.99    4        45   standa~      270144
##  7 12047772~        1     13 used      0.01    0        37.0 standa~        7284
##  8 30035550~        1     15 new       1       2.99     54.0 upsGro~        4858
##  9 20039206~        3     29 used      0.99    4        47   priori~          27
## 10 33036416~        7      8 used     20.0     4        50   firstC~         201
## # ... with 3 more variables: stock_photo &lt;chr&gt;, wheels &lt;dbl&gt;, title &lt;chr&gt;</code></pre>
<div class="sourceCode" id="cb1032"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1032-1"><a href="#cb1032-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(mariokart)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##          name     class levels   n missing
## 1          id character    143 143       0
## 2        cond character      2 143       0
## 3     ship_sp character      8 143       0
## 4 stock_photo character      2 143       0
## 5       title character     80 142       1
##                                    distribution
## 1 110439174663 (0.7%) ...                      
## 2 used (58.7%), new (41.3%)                    
## 3 standard (23.1%), upsGround (21.7%) ...      
## 4 yes (73.4%), no (26.6%)                      
## 5  (%) ...                                     
## 
## quantitative variables:  
##             name   class   min      Q1 median      Q3       max         mean
## ...1    duration numeric  1.00   1.000    3.0    7.00     10.00     3.769231
## ...2      n_bids numeric  1.00  10.000   14.0   17.00     29.00    13.538462
## ...3    start_pr numeric  0.01   0.990    1.0   10.00     69.95     8.777203
## ...4     ship_pr numeric  0.00   0.000    3.0    4.00     25.51     3.143706
## ...5    total_pr numeric 28.98  41.175   46.5   53.99    326.51    49.880490
## ...6 seller_rate numeric  0.00 109.000  820.0 4858.00 270144.00 15898.419580
## ...7      wheels numeric  0.00   0.000    1.0    2.00      4.00     1.146853
##                sd   n missing
## ...1 2.585693e+00 143       0
## ...2 5.878786e+00 143       0
## ...3 1.506745e+01 143       0
## ...4 3.213179e+00 143       0
## ...5 2.568856e+01 143       0
## ...6 5.184032e+04 143       0
## ...7 8.471829e-01 143       0</code></pre>
<p>We are again only interested in <code>total_pr</code>, <code>cond</code>, <code>stock_photo</code>, <code>duration</code>, and <code>wheels</code>. These variables are described in the following list:</p>
<ol style="list-style-type: decimal">
<li><code>total_pr</code>: final auction price plus shipping costs, in US dollars<br />
</li>
<li><code>cond</code>: a two-level categorical factor variable<br />
</li>
<li><code>stock_photo</code>: a two-level categorical factor variable<br />
</li>
<li><code>duration</code>: the length of the auction, in days, taking values from 1 to 10<br />
</li>
<li><code>wheels</code>: the number of Wii wheels included with the auction (a <strong>Wii wheel</strong> is a plastic racing wheel that holds the Wii controller and is an optional but helpful accessory for playing Mario Kart)</li>
</ol>
<p>Remember that we removed a couple of outlier sales that included multiple items. Before we start let’s clean up the data again to include removing those outliers.</p>
<div class="sourceCode" id="cb1034"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1034-1"><a href="#cb1034-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="ot">&lt;-</span> mariokart <span class="sc">%&gt;%</span></span>
<span id="cb1034-2"><a href="#cb1034-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(total_pr <span class="sc">&lt;=</span> <span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb1034-3"><a href="#cb1034-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">cond=</span><span class="fu">factor</span>(cond),</span>
<span id="cb1034-4"><a href="#cb1034-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">stock_photo=</span><span class="fu">factor</span>(stock_photo)) <span class="sc">%&gt;%</span> </span>
<span id="cb1034-5"><a href="#cb1034-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(cond,stock_photo,total_pr,duration,wheels)</span></code></pre></div>
<p>Next let’s summarize the data.</p>
<div class="sourceCode" id="cb1035"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1035-1"><a href="#cb1035-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(mariokart)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##          name  class levels   n missing
## 1        cond factor      2 141       0
## 2 stock_photo factor      2 141       0
##                                    distribution
## 1 used (58.2%), new (41.8%)                    
## 2 yes (74.5%), no (25.5%)                      
## 
## quantitative variables:  
##          name   class   min Q1 median    Q3 max      mean        sd   n missing
## ...1 total_pr numeric 28.98 41  46.03 53.99  75 47.431915 9.1136514 141       0
## ...2 duration numeric  1.00  1   3.00  7.00  10  3.751773 2.5888663 141       0
## ...3   wheels numeric  0.00  0   1.00  2.00   4  1.148936 0.8446146 141       0</code></pre>
</div>
<div id="analyzing-contingency-table" class="section level3" number="31.2.2">
<h3><span class="header-section-number">31.2.2</span> Analyzing contingency table</h3>
<p>As a review and introduction to logistic regression, let’s analyze the relationship between game condition and stock photo.</p>
<div class="sourceCode" id="cb1037"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1037-1"><a href="#cb1037-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(cond<span class="sc">~</span>stock_photo,<span class="at">data=</span>mariokart</span>
<span id="cb1037-2"><a href="#cb1037-2" aria-hidden="true" tabindex="-1"></a>      ,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format =</span> <span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>##        stock_photo
## cond           no       yes
##   new   0.1111111 0.5238095
##   used  0.8888889 0.4761905
##   Total 1.0000000 1.0000000</code></pre>
<p>We could analyze this by comparing the proportion of new condition games for each stock photo value using both randomization, empirical p-values, and the central limit theorem. We will just use an exact permutation test, <strong>Fisher Exact Test</strong>, which just uses the hypergeometric distribution.</p>
<div class="sourceCode" id="cb1039"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1039-1"><a href="#cb1039-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.test</span>(<span class="fu">tally</span>(<span class="sc">~</span>cond<span class="sc">+</span>stock_photo,<span class="at">data=</span>mariokart))</span></code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  tally(~cond + stock_photo, data = mariokart)
## p-value = 9.875e-06
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.02766882 0.35763723
## sample estimates:
## odds ratio 
##  0.1152058</code></pre>
<p>Clearly, these variables are not independent of each other. This model does not gives us much more information so let’s move to logistic regression.</p>
</div>
<div id="modeling-the-probability-of-an-event" class="section level3" number="31.2.3">
<h3><span class="header-section-number">31.2.3</span> Modeling the probability of an event</h3>
<p>The outcome variable for a GLM is denoted by <span class="math inline">\(Y_i\)</span>, where the index <span class="math inline">\(i\)</span> is used to represent observation <span class="math inline">\(i\)</span>. In the Mario Kart application, <span class="math inline">\(Y_i\)</span> will be used to represent whether the game condition <span class="math inline">\(i\)</span> is new (<span class="math inline">\(Y_i=1\)</span>) or used (<span class="math inline">\(Y_i=0\)</span>).</p>
<p>The predictor variables are represented as follows: <span class="math inline">\(x_{1,i}\)</span> is the value of variable 1 for observation <span class="math inline">\(i\)</span>, <span class="math inline">\(x_{2,i}\)</span> is the value of variable 2 for observation <span class="math inline">\(i\)</span>, and so on.</p>
<p>Logistic regression is a generalized linear model where the outcome is a two-level categorical variable. The outcome, <span class="math inline">\(Y_i\)</span>, takes the value 1 (in our application, this represents a game in new condition but we could easily switch and make the outcome of interest a used game) with probability <span class="math inline">\(p_i\)</span> and the value 0 with probability <span class="math inline">\(1-p_i\)</span>. It is the probability <span class="math inline">\(p_i\)</span> that we model in relation to the predictor variables.</p>
<p>The logistic regression model relates the probability a game is new (<span class="math inline">\(p_i\)</span>) to values of the predictors <span class="math inline">\(x_{1,i}\)</span>, <span class="math inline">\(x_{2,i}\)</span>, …, <span class="math inline">\(x_{k,i}\)</span> through a framework much like that of multiple regression:</p>
<p><span class="math display">\[
\text{transformation}(p_{i}) = \beta_0 + \beta_1x_{1,i} + \beta_2 x_{2,i} + \cdots \beta_k x_{k,i}
\]</span></p>
<p>We want to choose a transformation that makes practical and mathematical sense. For example, we want a transformation that makes the range of possibilities on the left hand side of the above equation equal to the range of possibilities for the right hand side. If there was no transformation for this equation, the left hand side could only take values between 0 and 1, but the right hand side could take values outside of this range. A common transformation for <span class="math inline">\(p_i\)</span> is the <strong>logit transformation</strong>, which may be written as</p>
<p><span class="math display">\[
\text{logit}(p_i) = \log_{e}\left( \frac{p_i}{1-p_i} \right)
\]</span></p>
<p>Below, we expand the equation using the logit transformation of <span class="math inline">\(p_i\)</span>:</p>
<p><span class="math display">\[
\log_{e}\left( \frac{p_i}{1-p_i} \right)
    = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_k x_{k,i}
\]</span></p>
<p>Solving for <span class="math inline">\(p_i\)</span> we get the logistic function:</p>
<p><span class="math display">\[
p_i     = \frac{1}{1+e^{-(\beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_k x_{k,i})}}
\]</span></p>
<p>The logistic function is shown in Figure @ref(fig:logit-fig).</p>
<div class="figure">
<img src="31-Logistic-Regression_files/figure-html/logit-fig-1.png" alt="Logitstic function with some example points plotted." width="672" />
<p class="caption">
(#fig:logit-fig)Logitstic function with some example points plotted.
</p>
</div>
<p>Notice the output of the <code>logistic</code> function restricts the values between 0 and 1. The curve is fairly flat on the edges with a sharp rise in the center. There are other functions that achieve this same result. However, for reasons beyond the scope of this book, the logit function has desirable mathematical properties that relate to making sure all the common GLMs fall within the exponential family of distributions. This topic is at the graduate school level and not needed for our studies.</p>
<p>In our Mario Kart example, there are 4 predictor variables, so <span class="math inline">\(k = 4\)</span>. This nonlinear model isn’t very intuitive, but it still has some resemblance to multiple regression, and we can fit this model using software. In fact, once we look at results from software, it will start to feel like we’re back in multiple regression, even if the interpretation of the coefficients is more complex.</p>
</div>
<div id="first-model---intercept-only" class="section level3" number="31.2.4">
<h3><span class="header-section-number">31.2.4</span> First model - intercept only</h3>
<p>Here we create a model with just an intercept.</p>
<p>In <code>R</code> we use the <code>glm()</code> function to fit a logistic regression model. It has the same formula format as <code>lm</code> but also requires a <code>family</code> argument. Since our response is binary, we use <code>binomial</code>. If we wanted to use <code>glm()</code> for linear regression assuming normally distributed residual, the family argument would be <code>gaussian</code>. This implies that multiple linear regression with the assumption of normally distributed errors is a special case of a generalized linear model. In <code>R</code>, the response is a 0/1 variable, we can control the outcome of interest, the 1, by using a logical argument in the formula.</p>
<p>First to understand the output of logistic regression, let’s just run a model with an intercept term. Notice in the code chunk that the left hand side of the formula has a logical argument, this gives a 0/1 output with 1 being the value we want to predict.</p>
<div class="sourceCode" id="cb1041"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1041-1"><a href="#cb1041-1" aria-hidden="true" tabindex="-1"></a>mario_mod1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>mariokart,</span>
<span id="cb1041-2"><a href="#cb1041-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<p>Let’s get regression output using the <code>summary()</code> function.</p>
<div class="sourceCode" id="cb1042"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1042-1"><a href="#cb1042-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ 1, family = &quot;binomial&quot;, data = mariokart)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.041  -1.041  -1.041   1.320   1.320  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  -0.3292     0.1707  -1.928   0.0538 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.7  on 140  degrees of freedom
## Residual deviance: 191.7  on 140  degrees of freedom
## AIC: 193.7
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>This looks similar to the regression output we saw in previous chapters. However, the model has a different, nonlinear, form. Remember, Equation @ref(eq:logistic) is the general form of the model.</p>
<p><span class="math display">\[\begin{equation}
  \log_{e}\left( \frac{p_i}{1-p_i} \right)
    = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_k x_{k,i}
  (\#eq:logistic)
\end{equation}\]</span></p>
<p>Thus using the output of <code>R</code>, Equation @ref(eq:logistic2) is the estimated model.</p>
<p><span class="math display">\[\begin{equation}
\log\left( \frac{p_i}{1-p_i} \right) = -0.329
  (\#eq:logistic2)
\end{equation}\]</span></p>
<p>Solving Equation @ref(eq:logistic2) for <span class="math inline">\(p_i\)</span>: <span class="math inline">\(\frac{e^{-0.329}}{1 + e^{-0.329}} = 0.418\)</span>. This is the estimated probability of the game condition being new. This point is plotted in Figure @ref(fig:logit-fig). We can also check this result using a summary table.</p>
<div class="sourceCode" id="cb1044"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1044-1"><a href="#cb1044-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>cond,<span class="at">data=</span>mariokart,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>## cond
##       new      used 
## 0.4184397 0.5815603</code></pre>
</div>
<div id="second-model---stock_photo" class="section level3" number="31.2.5">
<h3><span class="header-section-number">31.2.5</span> Second model - stock_photo</h3>
<p>Now that we are starting to understand the logistic regression model. Let’s add a predictor variable, <code>stock_photo</code>. Again, we have many methods to determine if a relationship between two categorical variables exists, logistic regression is another method.</p>
<div class="sourceCode" id="cb1046"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1046-1"><a href="#cb1046-1" aria-hidden="true" tabindex="-1"></a>mario_mod2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo,<span class="at">data=</span>mariokart,</span>
<span id="cb1046-2"><a href="#cb1046-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1047"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1047-1"><a href="#cb1047-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ stock_photo, family = &quot;binomial&quot;, 
##     data = mariokart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.2181  -1.2181  -0.4854   1.1372   2.0963  
## 
## Coefficients:
##                Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -2.0794     0.5303  -3.921 8.81e-05 ***
## stock_photoyes   2.1748     0.5652   3.848 0.000119 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.70  on 140  degrees of freedom
## Residual deviance: 170.44  on 139  degrees of freedom
## AIC: 174.44
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Examining the <strong>p-value</strong> associated with the coefficient for <code>stock_photo</code>, we can see that it is significant. Thus we reject the null hypothesis that the coefficient is zero. There is a relationship between <code>cond</code> and <code>stock_photo</code>, as we found with the Fisher’s test.</p>
<p>We can use the <strong>broom</strong> package to summarize the output and generate model fits.</p>
<div class="sourceCode" id="cb1049"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1049-1"><a href="#cb1049-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod2)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term           estimate std.error statistic   p.value
##   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)       -2.08     0.530     -3.92 0.0000881
## 2 stock_photoyes     2.17     0.565      3.85 0.000119</code></pre>
<p>Let’s convert these coefficients to estimated probabilities using the <code>augment()</code> function. We need to specify the output as the <em>response</em>, this returns a probability, or else we will get the logit of the probability, the link value.</p>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1051-1"><a href="#cb1051-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod2,</span>
<span id="cb1051-2"><a href="#cb1051-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata=</span><span class="fu">tibble</span>(<span class="at">stock_photo=</span><span class="fu">c</span>(<span class="st">&quot;yes&quot;</span>,<span class="st">&quot;no&quot;</span>)),</span>
<span id="cb1051-3"><a href="#cb1051-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   stock_photo .fitted
##   &lt;chr&gt;         &lt;dbl&gt;
## 1 yes           0.524
## 2 no            0.111</code></pre>
<p>These are the conditional probability of a new condition based on status of <code>stock_photo</code>. We can see this using the <code>tally()</code> function.</p>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="#cb1053-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(cond<span class="sc">~</span>stock_photo,<span class="at">data=</span>mariokart,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>##        stock_photo
## cond           no       yes
##   new   0.1111111 0.5238095
##   used  0.8888889 0.4761905
##   Total 1.0000000 1.0000000</code></pre>
<p>Or from the model coefficients.</p>
<div class="sourceCode" id="cb1055"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1055-1"><a href="#cb1055-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">2.079442</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">2.079442</span>))</span></code></pre></div>
<pre><code>## [1] 0.1111111</code></pre>
<div class="sourceCode" id="cb1057"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1057-1"><a href="#cb1057-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">2.079442+2.174752</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">2.079442+2.174752</span>))</span></code></pre></div>
<pre><code>## [1] 0.5238095</code></pre>
<blockquote>
<p><strong>Exercise</strong>:
Fit a logistic regression model with <code>cond</code> as used and <code>stock_photo</code> as a predictor.</p>
</blockquote>
<p>We repeat the code from above.</p>
<div class="sourceCode" id="cb1059"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1059-1"><a href="#cb1059-1" aria-hidden="true" tabindex="-1"></a>mario_mod3 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;used&quot;</span><span class="sc">~</span>stock_photo,<span class="at">data=</span>mariokart,</span>
<span id="cb1059-2"><a href="#cb1059-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1060-1"><a href="#cb1060-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod3)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term           estimate std.error statistic   p.value
##   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)        2.08     0.530      3.92 0.0000881
## 2 stock_photoyes    -2.17     0.565     -3.85 0.000119</code></pre>
<p>Again, let’s convert these coefficients to estimated probabilities using the <code>augment()</code> function.</p>
<div class="sourceCode" id="cb1062"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1062-1"><a href="#cb1062-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod3,</span>
<span id="cb1062-2"><a href="#cb1062-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata=</span><span class="fu">tibble</span>(<span class="at">stock_photo=</span><span class="fu">c</span>(<span class="st">&quot;yes&quot;</span>,<span class="st">&quot;no&quot;</span>)),</span>
<span id="cb1062-3"><a href="#cb1062-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   stock_photo .fitted
##   &lt;chr&gt;         &lt;dbl&gt;
## 1 yes           0.476
## 2 no            0.889</code></pre>
<p>This matches the output from the <code>tally()</code> function we observed above.</p>
<p>Notice that it was not important whether we select new or used condition as the desired outcome. In either case, the logistic regression model returns the conditional probability given the value of the predictor.</p>
</div>
<div id="interpreting-the-coefficients" class="section level3" number="31.2.6">
<h3><span class="header-section-number">31.2.6</span> Interpreting the coefficients</h3>
<p>At this point it seems that we created a great deal of work just to get the same results that we had from other methods. However, the logistic regression model allows us to add other predictors and it also gives us standard errors for the parameter estimates.</p>
<p>Let’s first discuss the interpretation of coefficients. As a reminder, the fitted coefficients are reported from the model summary.</p>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1064-1"><a href="#cb1064-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod2)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term           estimate std.error statistic   p.value
##   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)       -2.08     0.530     -3.92 0.0000881
## 2 stock_photoyes     2.17     0.565      3.85 0.000119</code></pre>
<p>The variable <code>stock_photo</code> takes on the values 0 and 1, the value 1 of indicates the sale had a stock photo. The logistic regression model we are fitting is Equation @ref(eq:logistic4).</p>
<p><span class="math display">\[\begin{equation}
  \log_{e}\left( \frac{p_{new}}{1-p_{new}} \right)
    = \beta_0 + \beta_1 \mbox{stock_photo}  
  (\#eq:logistic4)
\end{equation}\]</span></p>
<p>If the photo is not a stock photo then the model is Equation @ref(eq:logistic5). The left-hand side is the natural logarithm of the odds, where odds are the ratio of the probability of success divided by the probability of failure.<br />
<span class="math display">\[
\log_{e}\left( \frac{p_{\mbox{new|stock photo}}}{1-p_{\mbox{new|stock photo}}} \right)
    = \beta_0 + \beta_1   
\]</span></p>
<p><span class="math display">\[\begin{equation}
  \log_{e}\left( \frac{p_{\mbox{new|no stock photo}}}{1-p_{\mbox{new|no stock photo}}} \right)
    = \beta_0   
  (\#eq:logistic5)
\end{equation}\]</span></p>
<p>If we have a stock photo, the variable <code>stock_photo</code> is 1. Then Equation @ref(eq:logistic6) is the resulting model.</p>
<p><span class="math display">\[\begin{equation}
\log_{e}\left( \frac{p_{\mbox{new|stock photo}}}{1-p_{\mbox{new|stock photo}}} \right)
    = \beta_0 + \beta_1   
  (\#eq:logistic6)
\end{equation}\]</span></p>
<p>Thus the difference of these gives an interpretation of the <span class="math inline">\(\beta_1\)</span> coefficient, it is the log odds ratio as is shown in the derivation that follows.</p>
<p><span class="math display">\[
\log_{e}\left( \frac{p_{\mbox{new|stock photo}}}{1-p_{\mbox{new|stock photo}}} \right)
-
\log_{e}\left( \frac{p_{\mbox{new|no stock photo}}}{1-p_{\mbox{new|no stock photo}}} \right) = \beta_1
\]</span>
<span class="math display">\[
\log_{e}\left(\frac{\frac{p_{\mbox{new|stock photo}}}{1-p_{\mbox{new|stock photo}}}}{\frac{p_{\mbox{new|no stock photo}}}{1-p_{\mbox{new|no stock photo}}}} \right)
= \beta_1
\]</span></p>
<p>For our problem, the log odds more than double if the photo is a stock photo. It is easier to interpret odds ratios, so often analysts use <span class="math inline">\(e^{\beta_1}\)</span> as the odds ratio. Again, for our problem, the odds of a new condition game increase by a factor of 8.8 if a stock photo is used. Note that an odds ratio is not a relative risk. Relative risk is the ratio of the probability of a new game with stock photo to the probability of a new game without a stock photo. Be careful in your interpretation.</p>
<p><span class="math display">\[
\text{Relative Risk} = \left(\frac{p_{\mbox{new|stock photo}}}{p_{\mbox{new|no stock photo}}} \right)
\]</span></p>
</div>
<div id="comparing-models" class="section level3" number="31.2.7">
<h3><span class="header-section-number">31.2.7</span> Comparing models</h3>
<p>Just as is the case for linear regression, we can compare nested models. When we examine the output of model there is a line with the <strong>residual deviance</strong>. This model is not fit using least squares but using maximum likelihood. Deviance is 2 times the negative of the log likelihood. We negate the log likelihood so that maximizing the log likelihood is equivalent to minimizing the negation. This allows the same thought process of minimizing deviance as we had for minimizing residual sum of squares. The multiplication by 2 is because an asymptotic argument shows that 2 times the negative log likelihood is approximately distributed as a Chi-square random variable.</p>
<div class="sourceCode" id="cb1066"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1066-1"><a href="#cb1066-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ stock_photo, family = &quot;binomial&quot;, 
##     data = mariokart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.2181  -1.2181  -0.4854   1.1372   2.0963  
## 
## Coefficients:
##                Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -2.0794     0.5303  -3.921 8.81e-05 ***
## stock_photoyes   2.1748     0.5652   3.848 0.000119 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.70  on 140  degrees of freedom
## Residual deviance: 170.44  on 139  degrees of freedom
## AIC: 174.44
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Similar to linear regression, we can use the <code>anova()</code> function to compare nested models.</p>
<div class="sourceCode" id="cb1068"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1068-1"><a href="#cb1068-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mario_mod1,mario_mod2,<span class="at">test=</span><span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: cond == &quot;new&quot; ~ 1
## Model 2: cond == &quot;new&quot; ~ stock_photo
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)    
## 1       140     191.70                         
## 2       139     170.44  1    21.26 4.01e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Adding, <code>stock_photo</code> is a statistically significant result. The p-value is different from the <code>summary()</code> function, because it assumes the coefficient follows a normal distribution. Different assumptions, but the same conclusion.</p>
<p>The use of p-value to pick a best model uses statistical assumptions to select the features. Another approach is to use a predictive measure. In machine learning contexts, we use many different predictive performance measures for model selection but many are based on a <strong>confusion matrix</strong>.</p>
<p>A confusion matrix generates a 2 by 2 matrix of predicted outcomes versus actual outcomes. For logistic regression, the output is a probability of success. To convert this to 0/1 outcome we pick a threshold. It is common to use 0.5 as the threshold. Probabilities above 0.5 are considered a success, in the context of our problem a new game. Let’s generate the confusion matrix.</p>
<div class="sourceCode" id="cb1070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1070-1"><a href="#cb1070-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod2,<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1070-2"><a href="#cb1070-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">actual=</span><span class="fu">starts_with</span>(<span class="st">&#39;cond&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1070-3"><a href="#cb1070-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">result=</span><span class="fu">as.integer</span>(.fitted<span class="sc">&gt;</span><span class="fl">0.5</span>),</span>
<span id="cb1070-4"><a href="#cb1070-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">actual=</span><span class="fu">as.integer</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb1070-5"><a href="#cb1070-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span></code></pre></div>
<pre><code>##       actual
## result  0  1
##      0 32  4
##      1 50 55</code></pre>
<p>One single number summary metric is accuracy. In this case the model was correct on <span class="math inline">\(32 + 55\)</span> out of the 141 cases, or 61.7% are correct.</p>
<p>This looks like the same table we get comparing <code>cond</code> to <code>stock_photo</code>. This is the case because of the binary nature of the predictor. We only have two probability values in our prediction.</p>
<div class="sourceCode" id="cb1072"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1072-1"><a href="#cb1072-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>cond<span class="sc">+</span>stock_photo,<span class="at">data=</span>mariokart)</span></code></pre></div>
<pre><code>##       stock_photo
## cond   no yes
##   new   4  55
##   used 32  50</code></pre>
<p>If we change the threshold we get a different accuracy. In a machine learning course, we learn about other metrics such as area under the ROC curve. Back to our problem, let’s add another variable to see if we can improve the model.</p>
</div>
</div>
<div id="multiple-logistic-regression" class="section level2" number="31.3">
<h2><span class="header-section-number">31.3</span> Multiple logistic regression</h2>
<p>Let’s add <code>total_pr</code> to the model. This model is something that we could not have done in the previous models we learned about.</p>
<div class="sourceCode" id="cb1074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1074-1"><a href="#cb1074-1" aria-hidden="true" tabindex="-1"></a>mario_mod4 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span>total_pr,</span>
<span id="cb1074-2"><a href="#cb1074-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>mariokart,</span>
<span id="cb1074-3"><a href="#cb1074-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<p>Notice that we use the same formula syntax as we had done with linear regression.</p>
<div class="sourceCode" id="cb1075"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1075-1"><a href="#cb1075-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod4)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ stock_photo + total_pr, family = &quot;binomial&quot;, 
##     data = mariokart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3699  -0.6479  -0.2358   0.6532   2.5794  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    -11.31951    1.88333  -6.010 1.85e-09 ***
## stock_photoyes   2.11633    0.68551   3.087  0.00202 ** 
## total_pr         0.19348    0.03562   5.431 5.60e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.70  on 140  degrees of freedom
## Residual deviance: 119.21  on 138  degrees of freedom
## AIC: 125.21
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>From the summary, both <code>stock_photo</code> and <code>total_pr</code> are statistically significant.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Interpret the coefficient associated with the predictor <code>total_pr</code>.</p>
</blockquote>
<p>For one dollar increase in total price of the auction, the odds ratio increases by <span class="math inline">\(exp(\beta_2)\)</span>, 1.21, for a given condition of the stock photo variable.</p>
<p>This is similar to an interpretation we had for multiple linear regression. We had to specify that the other predictors are held constant and then we increased the variable of interest by one unit.</p>
<p>Besides using individual predictor p-values to assess the model, can also use a confusion matrix.</p>
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="#cb1077-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod4,<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1077-2"><a href="#cb1077-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">actual=</span><span class="fu">starts_with</span>(<span class="st">&#39;cond&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1077-3"><a href="#cb1077-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">result=</span><span class="fu">as.integer</span>(.fitted<span class="sc">&gt;</span><span class="fl">0.5</span>),</span>
<span id="cb1077-4"><a href="#cb1077-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">actual=</span><span class="fu">as.integer</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb1077-5"><a href="#cb1077-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span></code></pre></div>
<pre><code>##       actual
## result  0  1
##      0 71 16
##      1 11 43</code></pre>
<p>For our new model, the accuracy improved to <span class="math inline">\(71 + 43\)</span> out of the 141 cases, or 80.9.7%. Without a measure of variability, we don’t know if this is significant improvement or just the variability in the modeling procedure. On the surface, it appears to be an improvement.</p>
<p>As we experiment to improve the model, let’s use a quadratic term in our model.</p>
<div class="sourceCode" id="cb1079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1079-1"><a href="#cb1079-1" aria-hidden="true" tabindex="-1"></a>mario_mod5 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span><span class="fu">poly</span>(total_pr,<span class="dv">2</span>),</span>
<span id="cb1079-2"><a href="#cb1079-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>mariokart,</span>
<span id="cb1079-3"><a href="#cb1079-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<p>Using the individual p-values, it appears that a quadratic term is significant but it is marginal.</p>
<div class="sourceCode" id="cb1080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1080-1"><a href="#cb1080-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod5)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ stock_photo + poly(total_pr, 2), 
##     family = &quot;binomial&quot;, data = mariokart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1555  -0.6511  -0.1200   0.5987   2.6760  
## 
## Coefficients:
##                    Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)         -2.4407     0.6347  -3.845  0.00012 ***
## stock_photoyes       2.0411     0.6494   3.143  0.00167 ** 
## poly(total_pr, 2)1  23.7534     4.5697   5.198 2.01e-07 ***
## poly(total_pr, 2)2  -9.9724     4.1999  -2.374  0.01758 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.70  on 140  degrees of freedom
## Residual deviance: 114.05  on 137  degrees of freedom
## AIC: 122.05
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>We get a similar result if we use the <code>anova()</code> function.</p>
<div class="sourceCode" id="cb1082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1082-1"><a href="#cb1082-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mario_mod4,mario_mod5,<span class="at">test=</span><span class="st">&quot;Chi&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: cond == &quot;new&quot; ~ stock_photo + total_pr
## Model 2: cond == &quot;new&quot; ~ stock_photo + poly(total_pr, 2)
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)  
## 1       138     119.21                       
## 2       137     114.05  1   5.1687    0.023 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Finally, the confusion matrix results in a slight improvement in accuracy to 82.3%.</p>
<div class="sourceCode" id="cb1084"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1084-1"><a href="#cb1084-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod5,<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1084-2"><a href="#cb1084-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">actual=</span><span class="fu">starts_with</span>(<span class="st">&#39;cond&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1084-3"><a href="#cb1084-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">result=</span><span class="fu">as.integer</span>(.fitted<span class="sc">&gt;</span><span class="fl">0.5</span>),</span>
<span id="cb1084-4"><a href="#cb1084-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">actual=</span><span class="fu">as.integer</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb1084-5"><a href="#cb1084-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span></code></pre></div>
<pre><code>##       actual
## result  0  1
##      0 69 12
##      1 13 47</code></pre>
<p>Almost any classifier will have some error. In the model above, we have decided that it is okay to allow up to 9%, 13 out of 141, of the games for sale to be classified as new when they are really used. If we wanted to make it a little harder to classify an item as new, we could use a cutoff, threshold, of 0.75. This would have two effects. Because it raises the standard for what can be classified as new, it reduces the number of used games that are classified as new. However, it will also fail to correctly classify an increased fraction of new games as new, see the code below. No matter the complexity and the confidence we might have in our model, these practical considerations are absolutely crucial to making a helpful classification model. Without them, we could actually do more harm than good by using our statistical model. This tradeoff is similar to the one we found between Type 1 and Type 2 errors. Notice that the accuracy has also dropped slightly.</p>
<div class="sourceCode" id="cb1086"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1086-1"><a href="#cb1086-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod5,<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1086-2"><a href="#cb1086-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">actual=</span><span class="fu">starts_with</span>(<span class="st">&#39;cond&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1086-3"><a href="#cb1086-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">result=</span><span class="fu">as.integer</span>(.fitted<span class="sc">&gt;</span><span class="fl">0.75</span>),</span>
<span id="cb1086-4"><a href="#cb1086-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">actual=</span><span class="fu">as.integer</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb1086-5"><a href="#cb1086-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span></code></pre></div>
<pre><code>##       actual
## result  0  1
##      0 78 22
##      1  4 37</code></pre>
<p>In a machine learning course, we learn about better methods to assess predictive accuracy as well as more sophisticated methods to transform and adapt our predictor variables.</p>
<blockquote>
<p><strong>Exercise</strong> Find the probability that an auctioned game is new if the total price is 50 and it uses a stock photo.</p>
</blockquote>
<p>It is not clear how to use the coefficients in the regression output since <code>R</code> is performing a transformation on <code>total_pr</code> variable. Let’s approach this in two ways. First we will use the <code>augment()</code> function to do the hard work.</p>
<div class="sourceCode" id="cb1088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1088-1"><a href="#cb1088-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod5,</span>
<span id="cb1088-2"><a href="#cb1088-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">stock_photo=</span><span class="st">&quot;yes&quot;</span>,<span class="at">total_pr=</span><span class="dv">50</span>),</span>
<span id="cb1088-3"><a href="#cb1088-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   stock_photo total_pr .fitted
##   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;
## 1 yes               50   0.693</code></pre>
<p>We predict that the probability of the game being new if it uses a stock photo and the total price is 50 is 69.3%.</p>
<p>If we want to recreate the calculation, we need to use a <strong>raw</strong> polynomial.</p>
<div class="sourceCode" id="cb1090"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1090-1"><a href="#cb1090-1" aria-hidden="true" tabindex="-1"></a>mario_mod6 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span>total_pr<span class="sc">+</span><span class="fu">I</span>(total_pr<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb1090-2"><a href="#cb1090-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>mariokart,</span>
<span id="cb1090-3"><a href="#cb1090-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb1090-4"><a href="#cb1090-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod6)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term            estimate std.error statistic  p.value
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)    -30.7       9.08        -3.38 0.000732
## 2 stock_photoyes   2.04      0.649        3.14 0.00167 
## 3 total_pr         0.969     0.343        2.83 0.00470 
## 4 I(total_pr^2)   -0.00760   0.00320     -2.37 0.0176</code></pre>
<p>We can calculate the link as a linear combination, an inner product of coefficients and values.</p>
<p><span class="math display">\[
-30.67 + 2.04 + 0.969 * 50 -0.007*50^2 = 0.814
\]</span></p>
<div class="sourceCode" id="cb1092"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1092-1"><a href="#cb1092-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod6) <span class="sc">%&gt;%</span></span>
<span id="cb1092-2"><a href="#cb1092-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(estimate) <span class="sc">%&gt;%</span> </span>
<span id="cb1092-3"><a href="#cb1092-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>() <span class="sc">%*%</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">50</span>,<span class="dv">50</span><span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>##           [,1]
## [1,] 0.8140013</code></pre>
<p>Using the inverse transform of the logit function, we find the probability of the game being new given the predictor values.</p>
<p><span class="math display">\[
\frac{\ e^{.814}\ }{\ 1\ +\ e^{.814}\ } = 0.693
\]</span></p>
<div class="sourceCode" id="cb1094"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1094-1"><a href="#cb1094-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(.<span class="dv">814</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(.<span class="dv">814</span>))</span></code></pre></div>
<pre><code>## [1] 0.6929612</code></pre>
<div id="diagnostics-for-logistic-regression" class="section level3" number="31.3.1">
<h3><span class="header-section-number">31.3.1</span> Diagnostics for logistic regression</h3>
<p>The assumptions for logistic regression and the diagnostic tools are similar to what we found for linear regression. However, with the binary nature of the outcome, we often need large data sets to check. We will not devote much time to performing diagnostics for logistic regression because we are interested in using it as a predictive model. The assumptions are:</p>
<ol style="list-style-type: decimal">
<li>Each predictor <span class="math inline">\(x_i\)</span> is linearly related to logit<span class="math inline">\((p_i)\)</span> if all other predictors are held constant. This is similar to our linear fit diagnostic in linear multiple regression.<br />
</li>
<li>Each outcome <span class="math inline">\(Y_i\)</span> is independent of the other outcomes.<br />
</li>
<li>There are no influential data points.<br />
</li>
<li>Multicollinearity is minimal.</li>
</ol>
</div>
</div>
<div id="confidence-intervals-2" class="section level2" number="31.4">
<h2><span class="header-section-number">31.4</span> Confidence intervals</h2>
<p>In this section we will generate confidence intervals. This section is experimental since we are not sure how <code>do()</code> from the <strong>mosaic</strong> package will work with the <code>glm()</code> function, but let’s experiment.</p>
<div id="confidence-intervals-for-a-parameter" class="section level3" number="31.4.1">
<h3><span class="header-section-number">31.4.1</span> Confidence intervals for a parameter</h3>
<p>First, let’s use the <code>R</code> built-in function <code>confint()</code> to find the confidence interval for the simple logistic regression model coefficients.</p>
<div class="sourceCode" id="cb1096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1096-1"><a href="#cb1096-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mario_mod4)</span></code></pre></div>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##                      2.5 %     97.5 %
## (Intercept)    -15.4048022 -7.9648042
## stock_photoyes   0.8888216  3.6268545
## total_pr         0.1297024  0.2705395</code></pre>
<p>These are not symmetric around the estimate because the method is using a profile-likelihood method. We can get symmetric intervals based on the central limit theorem using the function <code>confint.default()</code>.</p>
<div class="sourceCode" id="cb1099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1099-1"><a href="#cb1099-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint.default</span>(mario_mod4)</span></code></pre></div>
<pre><code>##                      2.5 %     97.5 %
## (Intercept)    -15.0107641 -7.6282654
## stock_photoyes   0.7727450  3.4599054
## total_pr         0.1236583  0.2632982</code></pre>
<p>These results are close. We recommend using the profile-likelihood method.</p>
<p>Now, let’s work with the <code>do()</code> function to determine if we can get similar results.</p>
<div class="sourceCode" id="cb1101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1101-1"><a href="#cb1101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">do</span>(<span class="dv">1</span>)<span class="sc">*</span>mario_mod4</span></code></pre></div>
<pre><code>##   Intercept stock_photoyes  total_pr .row .index
## 1 -11.31951       2.116325 0.1934783    1      1</code></pre>
<div class="sourceCode" id="cb1103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1103-1"><a href="#cb1103-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod4)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term           estimate std.error statistic       p.value
##   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;
## 1 (Intercept)     -11.3      1.88       -6.01 0.00000000185
## 2 stock_photoyes    2.12     0.686       3.09 0.00202      
## 3 total_pr          0.193    0.0356      5.43 0.0000000560</code></pre>
<p>It looks like <code>do()</code> is performing as expected. Let’s now perform one resample to see what happens.</p>
<div class="sourceCode" id="cb1105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1105-1"><a href="#cb1105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">do</span>(<span class="dv">1</span>)<span class="sc">*</span><span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span>total_pr,</span>
<span id="cb1105-2"><a href="#cb1105-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span><span class="fu">resample</span>(mariokart),</span>
<span id="cb1105-3"><a href="#cb1105-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<pre><code>##   Intercept stock_photoyes  total_pr .row .index
## 1 -11.05487       1.058763 0.2046713    1      1</code></pre>
<p>Again, it looks like what we expect. Now let’s bootstrap the coefficients and summarize the results.</p>
<div class="sourceCode" id="cb1107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1107-1"><a href="#cb1107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5011</span>)</span>
<span id="cb1107-2"><a href="#cb1107-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span>total_pr,</span>
<span id="cb1107-3"><a href="#cb1107-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span><span class="fu">resample</span>(mariokart),</span>
<span id="cb1107-4"><a href="#cb1107-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode" id="cb1109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1109-1"><a href="#cb1109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##   Intercept stock_photoyes  total_pr .row .index
## 1 -11.22155       1.665492 0.1986654    1      1
## 2 -13.25708       1.889510 0.2371109    1      2
## 3 -11.54544       2.871460 0.1867757    1      3
## 4 -19.25785       5.816050 0.2829247    1      4
## 5 -10.86631       3.255767 0.1672335    1      5
## 6 -13.62425       1.842765 0.2533934    1      6</code></pre>
<p>Now we will plot the bootstrap sampling distribution on the parameter associated with <code>total_pr</code>.</p>
<div class="sourceCode" id="cb1111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1111-1"><a href="#cb1111-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb1111-2"><a href="#cb1111-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>total_pr,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1111-3"><a href="#cb1111-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb1111-4"><a href="#cb1111-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Bootstrap sampling distribtuion&quot;</span>,</span>
<span id="cb1111-5"><a href="#cb1111-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;total price paramater estimate&quot;</span>)</span></code></pre></div>
<p><img src="31-Logistic-Regression_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<p>The printout from the logistic regression model assumes normality for the sampling distribution of the <code>total_pr</code> coefficient, but it appears to be positively skewed, skewed to the right. The 95% confidence interval found using <code>cdata()</code>.</p>
<div class="sourceCode" id="cb1112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1112-1"><a href="#cb1112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>total_pr,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##          lower     upper central.p
## 2.5% 0.1388783 0.3082659      0.95</code></pre>
<p>This result is closer to the result from profile-likelihood. Since the interval does not include the value of zero, we can be 95% confident that it is not zero. This is close to what we found using the <code>R</code> function <code>confint()</code>.</p>
</div>
<div id="confidence-intervals-for-probability-of-success" class="section level3" number="31.4.2">
<h3><span class="header-section-number">31.4.2</span> Confidence intervals for probability of success</h3>
<p>We can use the results from the bootstrap to get a confidence interval on probability of success. We will calculate a confidence for a game with a stock photo and total price of $50. As a reminder, the probability of the game being new is 0.69.</p>
<div class="sourceCode" id="cb1114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1114-1"><a href="#cb1114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod5,</span>
<span id="cb1114-2"><a href="#cb1114-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">stock_photo=</span><span class="st">&quot;yes&quot;</span>,<span class="at">total_pr=</span><span class="dv">50</span>),</span>
<span id="cb1114-3"><a href="#cb1114-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   stock_photo total_pr .fitted
##   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;
## 1 yes               50   0.693</code></pre>
<p>The key is to use the coefficient from each resampled data set to calculate a probability of success.</p>
<div class="sourceCode" id="cb1116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1116-1"><a href="#cb1116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##   Intercept stock_photoyes  total_pr .row .index
## 1 -11.22155       1.665492 0.1986654    1      1
## 2 -13.25708       1.889510 0.2371109    1      2
## 3 -11.54544       2.871460 0.1867757    1      3
## 4 -19.25785       5.816050 0.2829247    1      4
## 5 -10.86631       3.255767 0.1672335    1      5
## 6 -13.62425       1.842765 0.2533934    1      6</code></pre>
<div class="sourceCode" id="cb1118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1118-1"><a href="#cb1118-1" aria-hidden="true" tabindex="-1"></a>results_pred <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span> </span>
<span id="cb1118-2"><a href="#cb1118-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pred=</span><span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">*</span>(Intercept<span class="sc">+</span>stock_photoyes<span class="sc">+</span><span class="dv">50</span><span class="sc">*</span>total_pr))))</span></code></pre></div>
<div class="sourceCode" id="cb1119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1119-1"><a href="#cb1119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>pred,<span class="at">data=</span>results_pred)</span></code></pre></div>
<pre><code>##        lower     upper central.p
## 2.5% 0.50388 0.7445598      0.95</code></pre>
<p>We are 95% confident that expected probability a game with a stock photo and a total price of $50 is between 50.4% and 74.4%.</p>
</div>
</div>
<div id="summary-4" class="section level2" number="31.5">
<h2><span class="header-section-number">31.5</span> Summary</h2>
<p>In this chapter, we learned how to extend linear models to outcomes that are binary. We built and interpreted models. We also used resampling to find confidence intervals.</p>
</div>
<div id="homework-problems-30" class="section level2" number="31.6">
<h2><span class="header-section-number">31.6</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Possum classification</li>
</ol>
<p>Let’s investigate the <code>possum</code> data set again. This time we want to model a binary outcome variable. As a reminder, the common brushtail possum of the Australia region is a bit cuter than its distant cousin, the American opossum. We consider 104 brushtail possums from two regions in Australia, where the possums may be considered a random sample from the population. The first region is Victoria, which is in the eastern half of Australia and traverses the southern coast. The second region consists of New South Wales and Queensland, which make up eastern and northeastern Australia.</p>
<p>We use logistic regression to differentiate between possums in these two regions. The outcome variable, called <code>pop</code>, takes value <code>Vic</code> when a possum is from Victoria and <code>other</code> when it is from New South Wales or Queensland. We consider five predictors: <code>sex</code>, <code>head_l</code>, <code>skull_w</code>, <code>total_l</code>, and <code>tail_l</code>.</p>
<ol style="list-style-type: lower-alpha">
<li>Explore the data by making histograms or boxplots of the quantitative variables, and bar charts of the discrete variables.<br />
Are there any outliers that are likely to have a very large influence on the logistic regression model?<br />
</li>
<li>Build a logistic regression model with all the variables. Report a summary of the model.<br />
</li>
<li>Using the p-values decide if you want to remove a variable(s) and if so build that model.<br />
</li>
<li>For any variable you decide to remove, build a 95% confidence interval for the parameter.<br />
</li>
<li>Explain why the remaining parameter estimates change between the two models.<br />
</li>
<li>Write out the form of the model. Also identify which of the following variables are positively associated (when controlling for other variables) with a possum being from Victoria: <code>head_l</code>, <code>skull_w</code>, <code>total_l</code>, and <code>tail_l</code>.<br />
</li>
<li>Suppose we see a brushtail possum at a zoo in the US, and a sign says the possum had been captured in the wild in Australia, but it doesn’t say which part of Australia. However, the sign does indicate that the possum is male, its skull is about 63 mm wide, its tail is 37 cm long, and its total length is 83 cm. What is the reduced model’s computed probability that this possum is from Victoria? How confident are you in the model’s accuracy of this probability calculation?</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Medical school admission</li>
</ol>
<p>The file <code>MedGPA.csv</code> in the <code>data</code> folder has information on medical school admission status and GPA and standardized test scores gathered on 55 medical school applicants from a liberal arts college in the Midwest.</p>
<p>The variables are:</p>
<p><code>Accept Status</code>: A=accepted to medical school or D=denied admission<br />
<code>Acceptance</code>: Indicator for Accept: 1=accepted or 0=denied<br />
<code>Sex</code>: F=female or M=male<br />
<code>BCPM</code>: Bio/Chem/Physics/Math grade point average<br />
<code>GPA</code>: College grade point average<br />
<code>VR</code>: Verbal reasoning (subscore)<br />
<code>PS</code>: Physical sciences (subscore)<br />
<code>WS</code>: Writing sample (subcore)<br />
<code>BS</code>: Biological sciences (subscore)<br />
<code>MCAT</code>: Score on the MCAT exam (sum of CR+PS+WS+BS)<br />
<code>Apps</code>: Number of medical schools applied to</p>
<ol style="list-style-type: lower-alpha">
<li>Build a logistic regression model to predict if a student where denied admission from <code>GPA</code> and <code>Sex</code>.<br />
</li>
<li>Generate a 95% confidence interval for the coefficient associated with <code>GPA</code>.<br />
</li>
<li>Fit a model with a polynomial of degree 2 in the <code>GPA</code>. Drop <code>Sex</code> from the model. Does a quadratic fit improve the model?<br />
</li>
<li>Fit a model with just <code>GPA</code> and interpret the coefficient.<br />
</li>
<li>Try to add different predictors to come up with your best model.<br />
</li>
<li>Generate a confusion matrix for the best model you have developed.<br />
</li>
<li>Find a 95% confidence interval for the probability a female student with a 3.5 GPA, a <code>BCPM</code> of 3.8, a verbal reasoning score of 10, a physical sciences score of 9, a writing sample score of 8, a biological score of 10, a MCAT score of 40, and who applied to 5 medical schools.</li>
</ol>
<!--chapter:end:31-Logistic-Regression.Rmd-->
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<!--chapter:end:32-Reference.Rmd-->
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-R-rmarkdown" class="csl-entry">
Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2022. <em>Rmarkdown: Dynamic Documents for r</em>. <a href="https://CRAN.R-project.org/package=rmarkdown">https://CRAN.R-project.org/package=rmarkdown</a>.
</div>
<div id="ref-R-infer" class="csl-entry">
Bray, Andrew, Chester Ismay, Evgeni Chasnovski, Simon Couch, Ben Baumer, and Mine Cetinkaya-Rundel. 2021. <em>Infer: Tidy Statistical Inference</em>. <a href="https://CRAN.R-project.org/package=infer">https://CRAN.R-project.org/package=infer</a>.
</div>
<div id="ref-R-openintro" class="csl-entry">
Çetinkaya-Rundel, Mine, David Diez, Andrew Bray, Albert Y. Kim, Ben Baumer, Chester Ismay, Nick Paterno, and Christopher Barr. 2022. <em>Openintro: Data Sets and Supplemental Functions from OpenIntro Textbooks and Labs</em>. <a href="https://CRAN.R-project.org/package=openintro">https://CRAN.R-project.org/package=openintro</a>.
</div>
<div id="ref-ointrorand" class="csl-entry">
Diez, David, Christopher Barr, and Mine Çetinkaya-Rundel. 2014. <em>Introductory Statistics with Randomization and Simulation</em>. 1st ed. Openintro. <a href="https://www.openintro.org/book/isrs/">https://www.openintro.org/book/isrs/</a>.
</div>
<div id="ref-R-ISLR" class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Rob Tibshirani. 2021. <em>ISLR: Data for an Introduction to Statistical Learning with Applications in r</em>. <a href="https://www.statlearning.com">https://www.statlearning.com</a>.
</div>
<div id="ref-R-mosaicCalc" class="csl-entry">
Kaplan, Daniel T., Randall Pruim, and Nicholas J. Horton. 2020. <em>mosaicCalc: Function-Based Numerical and Symbolic Differentiation and Antidifferentiation</em>. <a href="https://github.com/ProjectMOSAIC/mosaicCalc">https://github.com/ProjectMOSAIC/mosaicCalc</a>.
</div>
<div id="ref-ipsur" class="csl-entry">
Kerns, Jay. 2010. <em>Introductory to Probability and Statistics with r</em>. 1st ed. <a href="http://ipsur.r-forge.r-project.org/book/download/IPSUR.pdf">http://ipsur.r-forge.r-project.org/book/download/IPSUR.pdf</a>.
</div>
<div id="ref-R-vcd" class="csl-entry">
Meyer, David, Achim Zeileis, and Kurt Hornik. 2022. <em>Vcd: Visualizing Categorical Data</em>. <a href="https://CRAN.R-project.org/package=vcd">https://CRAN.R-project.org/package=vcd</a>.
</div>
<div id="ref-pruim2011foundations" class="csl-entry">
Pruim, Randall J. 2011. <em>Foundations and Applications of Statistics: An Introduction Using r</em>. Vol. 13. American Mathematical Soc.
</div>
<div id="ref-R-mosaic" class="csl-entry">
Pruim, Randall, Daniel T. Kaplan, and Nicholas J. Horton. 2021. <em>Mosaic: Project MOSAIC Statistics and Mathematics Teaching Utilities</em>. <a href="https://CRAN.R-project.org/package=mosaic">https://CRAN.R-project.org/package=mosaic</a>.
</div>
<div id="ref-R-MASS" class="csl-entry">
Ripley, Brian. 2022. <em>MASS: Support Functions and Datasets for Venables and Ripley’s MASS</em>. <a href="http://www.stats.ox.ac.uk/pub/MASS4/">http://www.stats.ox.ac.uk/pub/MASS4/</a>.
</div>
<div id="ref-R-broom" class="csl-entry">
Robinson, David, Alex Hayes, and Simon Couch. 2022. <em>Broom: Convert Statistical Objects into Tidy Tibbles</em>. <a href="https://CRAN.R-project.org/package=broom">https://CRAN.R-project.org/package=broom</a>.
</div>
<div id="ref-R-tidyverse" class="csl-entry">
Wickham, Hadley. 2021. <em>Tidyverse: Easily Install and Load the Tidyverse</em>. <a href="https://CRAN.R-project.org/package=tidyverse">https://CRAN.R-project.org/package=tidyverse</a>.
</div>
<div id="ref-R-ggplot2" class="csl-entry">
Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2021. <em>Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics</em>. <a href="https://CRAN.R-project.org/package=ggplot2">https://CRAN.R-project.org/package=ggplot2</a>.
</div>
<div id="ref-R-bookdown" class="csl-entry">
Xie, Yihui. 2022a. <em>Bookdown: Authoring Books and Technical Documents with r Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown">https://CRAN.R-project.org/package=bookdown</a>.
</div>
<div id="ref-R-knitr" class="csl-entry">
———. 2022b. <em>Knitr: A General-Purpose Package for Dynamic Report Generation in r</em>. <a href="https://yihui.org/knitr/">https://yihui.org/knitr/</a>.
</div>
<div id="ref-R-DT" class="csl-entry">
Xie, Yihui, Joe Cheng, and Xianying Tan. 2022. <em>DT: A Wrapper of the JavaScript Library DataTables</em>. <a href="https://github.com/rstudio/DT">https://github.com/rstudio/DT</a>.
</div>
<div id="ref-R-kableExtra" class="csl-entry">
Zhu, Hao. 2021. <em>kableExtra: Construct Complex Table with Kable and Pipe Syntax</em>. <a href="https://CRAN.R-project.org/package=kableExtra">https://CRAN.R-project.org/package=kableExtra</a>.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p><a href="http://www.nejm.org/doi/full/10.1056/NEJMoa1105335">Chimowitz MI, Lynn MJ, Derdeyn CP, et al. 2011. Stenting versus Aggressive Medical Therapy for Intracranial Arterial Stenosis. New England Journal of Medicine 365:993-1003.</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><a href="http://www.nytimes.com/2011/09/08/health/research/08stent.html">NY Times article reporting on the study</a><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Formally, a summary statistic is a value computed from the data. Some summary statistics are more useful than others.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a href="https://cran.r-project.org/web/packages/ggformula/vignettes/ggformula-blog.html" class="uri">https://cran.r-project.org/web/packages/ggformula/vignettes/ggformula-blog.html</a><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>G. Allais et al. <a href="http://www.ncbi.nlm.nih.gov/pubmed/21533739">“Ear acupuncture in the treatment of migraine attacks: a randomized trial on the efficacy of appropriate versus inappropriate acupoints”.</a> In: Neurological Sci. 32.1 (2011), pp. 173–175.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>A case is also sometimes called a <strong>unit of observation</strong> or an <strong>observational unit</strong>.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>A tibble is a data frame with attributes for such things as better display and printing.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>For more information on tidy data, see the <a href="https://simplystatistics.org/2016/02/17/non-tidy-data/">blog</a> and the <a href="https://r4ds.had.co.nz/tidy-data.html#pivoting">book</a>.<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p><a href="http://quickfacts.census.gov/qfd/index.html">These data were collected from the US Census website.</a><a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Each county may be viewed as a case, and there are ten pieces of information recorded for each case. A table with 3,142 rows and 10 columns could hold these data, where each row represents a county and each column represents a particular piece of information.<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>Sometimes also called a <strong>nominal</strong> variable.<a href="#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>There are only two possible values for each variable, and in both cases they describe categories. Thus, each is a categorical variable.<a href="#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Two sample questions: (1) Intuition suggests that if there are many line breaks in an email then there would also tend to be many characters: does this hold true? (2) Is there a connection between whether an email format is plain text (versus HTML) and whether it is a spam message?<a href="#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p><a href="https://cran.r-project.org/web/packages/ggformula/vignettes/ggformula-blog.html" class="uri">https://cran.r-project.org/web/packages/ggformula/vignettes/ggformula-blog.html</a><a href="#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>B. Ritz et al. <a href="http://journals.lww.com/epidem/Abstract/2000/09000/Effect_of_Air_Pollution_on_Preterm_Birth_Among.4.aspx">“Effect of air pollution on preterm birth among children born in Southern California
between 1989 and 1993”</a>. In: Epidemiology 11.5 (2000), pp. 502–511.<a href="#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>J. McGowan. “Health Education: Does the Buteyko Institute Method make a difference?” In: Thorax 58 (2003).<a href="#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p> 2) Notice that the first question is only relevant to students who complete their degree; the average cannot be computed using a student who never finished her degree. Thus, only Duke undergraduate students who have graduated in the last five years represent cases in the population under consideration. Each such student would represent an individual case. 3) A person with severe heart disease represents a case. The population includes all people with severe heart disease.<a href="#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Perhaps she would pick a disproportionate number of graduates from health-related fields. Or perhaps her selection would be well-representative of the population. When selecting samples by hand, we run the risk of picking a <em>biased</em> sample, even if that bias is unintentional or difficult to discern.<a href="#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Answers will vary. From our own anecdotal experiences, we believe people tend to rant more about products that fell below expectations than rave about those that perform as expected. For this reason, we suspect there is a negative bias in product ratings on sites like Amazon. However, since our experiences may not be representative, we also keep an open mind.<a href="#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>Sometimes the explanatory variable is called the <strong>independent</strong> variable and the response variable is called the <strong>dependent</strong> variable. However, this becomes confusing since a <em>pair</em> of variables might be independent or dependent, so be careful and consider the context when using or reading these words.<a href="#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>B. Ritz et al. <a href="http://journals.lww.com/epidem/Abstract/2000/09000/Effect_of_Air_Pollution_on_Preterm_Birth_Among.4.aspx">“Effect of air pollution on preterm birth among children born in Southern California
between 1989 and 1993”</a>. In: Epidemiology 11.5 (2000), pp. 502–511.<a href="#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>J. McGowan. “Health Education: Does the Buteyko Institute Method make a difference?” In: Thorax 58 (2003).<a href="#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>No. See the paragraph following the exercise for an explanation.<a href="#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p><a href="http://www.sciencedirect.com/science/article/pii/S0140673698121682" class="uri">http://www.sciencedirect.com/science/article/pii/S0140673698121682</a><br />
<a href="http://archderm.ama-assn.org/cgi/content/abstract/122/5/537" class="uri">http://archderm.ama-assn.org/cgi/content/abstract/122/5/537</a><br />
Study with a similar scenario to that described here:<br />
<a href="http://onlinelibrary.wiley.com/doi/10.1002/ijc.22745/full" class="uri">http://onlinelibrary.wiley.com/doi/10.1002/ijc.22745/full</a><a href="#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>Also called a <strong>lurking variable</strong>, <strong>confounding factor</strong>, or a <strong>confounder</strong>.<a href="#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>It appears that average SAT score declines as expenditures per student increases.<a href="#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>Answers will vary. Population density may be important. If a county is very dense, then a larger fraction of residents may live in multi-unit structures. Additionally, the high density may contribute to increases in property value, making homeownership infeasible for many residents.<a href="#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p><a href="http://www.channing.harvard.edu/nhs/" class="uri">http://www.channing.harvard.edu/nhs/</a><a href="#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>We might get a more stable estimate for the subpopulation in a stratum if the cases are very similar. These improved estimates for each subpopulation will help us build a reliable estimate for the full population.<a href="#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>A simple random sample would likely draw individuals from all 30 villages, which could make data collection extremely expensive. Stratified sampling would be a challenge since it is unclear how we would build strata of similar individuals. However, cluster sampling seems like a very good idea. We might randomly select a small number of villages. This would probably reduce our data collection costs substantially in comparison to a simple random sample and would still give us helpful information.<a href="#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>Anturane Reinfarction Trial Research Group. 1980. Sulfinpyrazone in the prevention of sudden death after myocardial infarction. New England Journal of Medicine 302(5):250-256.<a href="#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>Human subjects are often called <strong>patients</strong>, <strong>volunteers</strong>, or <strong>study participants</strong>.<a href="#fnref32" class="footnote-back">↩︎</a></p></li>
<li id="fn33"><p>There are always some researchers in the study who do know which patients are receiving which treatment. However, they do not interact with the study’s patients and do not tell the blinded health care professionals who is receiving which treatment.<a href="#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>The researchers assigned the patients into their treatment groups, so this study was an experiment. However, the patients could distinguish what treatment they received, so this study was not blind. The study could not be double-blind since it was not blind.<a href="#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>Answers may vary. Scatterplots are helpful in quickly spotting associations between variables, whether those associations represent simple or more complex relationships.<a href="#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p>Subset of data from <a href="http://www.amstat.org/publications/jse/v1n1/datasets.lock.html" class="uri">http://www.amstat.org/publications/jse/v1n1/datasets.lock.html</a><a href="#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>Consider the case where your vertical axis represents something ``good’’ and your horizontal axis represents something that is only good in moderation. Health and water consumption fit this description since water becomes toxic when consumed in excessive quantities.<a href="#fnref37" class="footnote-back">↩︎</a></p></li>
<li id="fn38"><p><span class="math inline">\(x_1\)</span> corresponds to the number of characters in the first email in the sample (21.7, in thousands), <span class="math inline">\(x_2\)</span> to the number of characters in the second email (7.0, in thousands), and <span class="math inline">\(x_i\)</span> corresponds to the number of characters in the <span class="math inline">\(i^{th}\)</span> email in the data set.<a href="#fnref38" class="footnote-back">↩︎</a></p></li>
<li id="fn39"><p>The sample size was <span class="math inline">\(n=50\)</span>.<a href="#fnref39" class="footnote-back">↩︎</a></p></li>
<li id="fn40"><p>Other ways to describe data that are skewed to the right: <strong>skewed to the right</strong>, <strong>skewed to the high end</strong>, or <strong>skewed to the positive end</strong>.<a href="#fnref40" class="footnote-back">↩︎</a></p></li>
<li id="fn41"><p>The skew is visible in all both plots, though the dot plot is the least useful.<a href="#fnref41" class="footnote-back">↩︎</a></p></li>
<li id="fn42"><p>Character counts for individual emails.<a href="#fnref42" class="footnote-back">↩︎</a></p></li>
<li id="fn43"><p>Another definition of mode, which is not typically used in statistics, is the value with the most occurrences. It is common to have <em>no</em> observations with the same value in a data set, which makes this other definition useless for many real data sets.<a href="#fnref43" class="footnote-back">↩︎</a></p></li>
<li id="fn44"><p>There might be two height groups visible in the data set: one of the students and one of the adults. That is, the data are probably bimodal. But it could be multimodal because within each group we may be able to see a difference in males and females.<a href="#fnref44" class="footnote-back">↩︎</a></p></li>
<li id="fn45"><p>The only difference is that the population variance has a division by <span class="math inline">\(n\)</span> instead of <span class="math inline">\(n-1\)</span>.<a href="#fnref45" class="footnote-back">↩︎</a></p></li>
<li id="fn46"><p>Starting with Figure @ref(fig:hist53-fig), the three figures show three distributions that look quite different, but all have the same mean, variance, and standard deviation. Using modality, we can distinguish between the first plot (bimodal) and the last two (unimodal). Using skewness, we can distinguish between the last plot (right skewed) and the first two. While a picture, like a histogram, tells a more complete story, we can use modality and shape (symmetry/skew) to characterize basic information about a distribution.<a href="#fnref46" class="footnote-back">↩︎</a></p></li>
<li id="fn47"><p>The distribution of email character counts is unimodal and very strongly skewed to the high end. Many of the counts fall near the mean at 11,600, and most fall within one standard deviation (13,130) of the mean. There is one exceptionally long email with about 65,000 characters.<a href="#fnref47" class="footnote-back">↩︎</a></p></li>
<li id="fn48"><p>Since <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_3\)</span> capture the middle 50% of the data and the median splits the data in the middle, 25% of the data fall between <span class="math inline">\(Q_1\)</span> and the median, and another 25% falls between the median and <span class="math inline">\(Q_3\)</span>.<a href="#fnref48" class="footnote-back">↩︎</a></p></li>
<li id="fn49"><p>While the choice of exactly 1.5 is arbitrary, it is the most commonly used value for box plots.<a href="#fnref49" class="footnote-back">↩︎</a></p></li>
<li id="fn50"><p>That occasionally there may be very long emails.<a href="#fnref50" class="footnote-back">↩︎</a></p></li>
<li id="fn51"><p>These visual estimates will vary a little from one person to the next: <span class="math inline">\(Q_1\)</span> ~ 3,000, <span class="math inline">\(Q_3\)</span> ~ 15,000, IQR=<span class="math inline">\(Q_3 - Q_1\)</span> ~ 12,000. (The true values: <span class="math inline">\(Q_1=\)</span> 2,536, <span class="math inline">\(Q_3=\)</span> 15,411, IQR = 12,875.)<a href="#fnref51" class="footnote-back">↩︎</a></p></li>
<li id="fn52"><p>(a) Mean is affected more. (b) Standard deviation is affected more.<a href="#fnref52" class="footnote-back">↩︎</a></p></li>
<li id="fn53"><p>The median and IQR are only sensitive to numbers near <span class="math inline">\(Q_1\)</span>, the median, and <span class="math inline">\(Q_3\)</span>. Since values in these regions are relatively stable – there aren’t large jumps between observations – the median and IQR estimates are also quite stable.<a href="#fnref53" class="footnote-back">↩︎</a></p></li>
<li id="fn54"><p>Buyers of a <em>regular car</em> should be concerned about the median price. High-end car sales can drastically inflate the mean price while the median will be more robust to the influence of those sales.<a href="#fnref54" class="footnote-back">↩︎</a></p></li>
<li id="fn55"><p>Most of the data are collected into one bin in the histogram and the data are so strongly skewed that many details in the data are obscured.<a href="#fnref55" class="footnote-back">↩︎</a></p></li>
<li id="fn56"><p>Statisticians often write the natural logarithm as <span class="math inline">\(\log\)</span>. You might be more familiar with it being written as <span class="math inline">\(\ln\)</span>.<a href="#fnref56" class="footnote-back">↩︎</a></p></li>
<li id="fn57"><p>0.748 represents the proportions of emails with no spam that had a small number in it.<a href="#fnref57" class="footnote-back">↩︎</a></p></li>
<li id="fn58"><p>From the help menu on the data HTML is coded as a 1<a href="#fnref58" class="footnote-back">↩︎</a></p></li>
<li id="fn59"><p>The column proportions with <code>number</code> in the columns will probably be most useful, which makes it easier to see that emails with small numbers are spam about 5.9% of the time (relatively rare). We would also see that about 27.1% of emails with no numbers are spam, and 9.2% of emails with big numbers are spam.<a href="#fnref59" class="footnote-back">↩︎</a></p></li>
<li id="fn60"><p>Answers may vary a little. The counties with population gains tend to have higher income (median of about $45,000) versus counties without a gain (median of about $40,000). The variability is also slightly larger for the population gain group. This is evident in the IQR, which is about 50% bigger in the <em>gain</em> group. Both distributions show slight to moderate right skew and are unimodal. There is a secondary small bump at about $60,000 for the <em>no gain</em> group, visible in the density plot, that seems out of place. (Looking into the data set, we would find that 8 of these 15 counties are in Alaska and Texas.) The box plots indicate there are many observations far above the median in each group, though we should anticipate that many observations will fall beyond the whiskers when using such a large data set.<a href="#fnref60" class="footnote-back">↩︎</a></p></li>
<li id="fn61"><p>The side-by-side box plots are especially useful for comparing centers and spreads, while the density plots are more useful for seeing distribution shape, skew, and groups of anomalies.<a href="#fnref61" class="footnote-back">↩︎</a></p></li>
<li id="fn62"><p>The answer is around 34.7%, how close were you?<a href="#fnref62" class="footnote-back">↩︎</a></p></li>
<li id="fn63"><p>Another question may be What does it mean at least two people have matching birthdays?<a href="#fnref63" class="footnote-back">↩︎</a></p></li>
<li id="fn64"><p>It is possible that 3 people all have the same birthday or two sets of 2 people have the same birthday but different from the other pair.<a href="#fnref64" class="footnote-back">↩︎</a></p></li>
<li id="fn65"><p>Multiplication is repeated adding so in a sense we are adding. However in a more serious tone, for this problem for every first number there are 10 possibilities for the second number and for every second number there are 10 possibilities for the third numbers. This is multiplication.<a href="#fnref65" class="footnote-back">↩︎</a></p></li>
<li id="fn66"><p>Because this implies the order selection of the ranks does not matter. In other words, this assumes that for example 3 Kings and 2 fours is the same full house as 3 fours and 2 Kings. This is not true so we break the rank selection about essentially making it a permutation.<a href="#fnref66" class="footnote-back">↩︎</a></p></li>
<li id="fn67"><p>We would be assuming that these two variables are <strong>independent</strong>, meaning they are unrelated.<a href="#fnref67" class="footnote-back">↩︎</a></p></li>
<li id="fn68"><p>Rosen B and Jerdee T. 1974. “Influence of sex role stereotypes on personnel decisions.” Journal of Applied Psychology 59(1):9-14.<a href="#fnref68" class="footnote-back">↩︎</a></p></li>
<li id="fn69"><p>The study is an experiment, as subjects were randomly assigned a male file or a female file. Since this is an experiment, the results can be used to evaluate a causal relationship between gender of a candidate and the promotion decision.<a href="#fnref69" class="footnote-back">↩︎</a></p></li>
<li id="fn70"><p>The test procedure we employ in this section is formally called a <strong>permutation test</strong>.<a href="#fnref70" class="footnote-back">↩︎</a></p></li>
<li id="fn71"><p><span class="math inline">\(18/24 - 17/24=0.042\)</span> or about 4.2% in favor of the men. This difference due to chance is much smaller than the difference observed in the actual groups.<a href="#fnref71" class="footnote-back">↩︎</a></p></li>
<li id="fn72"><p>This reasoning does not generally extend to anecdotal observations. Each of us observes incredibly rare events every day, events we could not possibly hope to predict. However, in the non-rigorous setting of anecdotal evidence, almost anything may appear to be a rare event, so the idea of looking for rare events in day-to-day activities is treacherous. For example, we might look at the lottery: there was only a 1 in 176 million chance that the Mega Millions numbers for the largest jackpot in history (March 30, 2012) would be (2, 4, 23, 38, 46) with a Mega ball of (23), but nonetheless those numbers came up! However, no matter what numbers had turned up, they would have had the same incredibly rare odds. That is, <strong>any set of numbers we could have observed would ultimately be incredibly rare</strong>. This type of situation is typical of our daily lives: each possible event in itself seems incredibly rare, but if we consider every alternative, those outcomes are also incredibly rare. We should be cautious not to misinterpret such anecdotal evidence.<a href="#fnref72" class="footnote-back">↩︎</a></p></li>
<li id="fn73"><p>In our opinion, this is how things developed historically. However, since computational tools prior to machine computers, humans in most cases, were limited and expensive, there was a shift to mathematical solutions. The relatively recent increase and availability in machine computational power has lead to a shift back to computational methods. Thus some people think mathematical methods predate computational but that is not the case.<a href="#fnref73" class="footnote-back">↩︎</a></p></li>
<li id="fn74"><p>Making a Type 1 Error in this context would mean that there is no difference in commercial length between basic and premium channels, despite the strong evidence (the data suggesting otherwise) found in the observational study. Notice that this does <strong>not</strong> necessarily mean something was wrong with the data or that we made a computational mistake. Sometimes data simply point us to the wrong conclusion, which is why scientific studies are often repeated to check initial findings. Replication is part of the scientific method.<a href="#fnref74" class="footnote-back">↩︎</a></p></li>
<li id="fn75"><p>“Efficacy and safety of thrombolytic therapy after initially unsuccessful cardiopulmonary resuscitation: a prospective clinical trial.” The Lancet, 2001.<a href="#fnref75" class="footnote-back">↩︎</a></p></li>
<li id="fn76"><p>Observed control survival rate: <span class="math inline">\(p_c = \frac{11}{50} = 0.22\)</span>. Treatment survival rate: <span class="math inline">\(p_t = \frac{14}{40} = 0.35\)</span>. Observed difference: <span class="math inline">\(\hat{p}_c - \hat{p}_t = 0.22 - 0.35 = - 0.13\)</span>.<a href="#fnref76" class="footnote-back">↩︎</a></p></li>
<li id="fn77"><p>Realistically, we probably are interested in either direction in the past studies as well, and so we should have used the approach we now discuss in this section. However, for simplicity and the sake of not introducing too many concepts at once, we skipped over these details in earlier sections.<a href="#fnref77" class="footnote-back">↩︎</a></p></li>
<li id="fn78"><p>This case study is described in <a href="http://www.openintro.org/redirect.php?go=made-to-stick&amp;redirect=simulation_textbook_pdf_preliminary" class="uri">http://www.openintro.org/redirect.php?go=made-to-stick&amp;redirect=simulation_textbook_pdf_preliminary</a> Made to Stick by Chip and Dan Heath.<a href="#fnref78" class="footnote-back">↩︎</a></p></li>
<li id="fn79"><p>The p-value is the chance of seeing the data summary or something more in favor of the alternative hypothesis given that guessing has a probability of success of 0.5. Since we didn’t observe many even close to just 42 correct, the p-value will be small, around 1-in-1000 or smaller.<a href="#fnref79" class="footnote-back">↩︎</a></p></li>
<li id="fn80"><p>The p-value is less than 0.05, so we reject the null hypothesis. There is statistically significant evidence, and the data provide strong evidence that the chance a listener will guess the correct tune is less than 50%.<a href="#fnref80" class="footnote-back">↩︎</a></p></li>
<li id="fn81"><p>“Efficacy and safety of thrombolytic therapy after initially unsuccessful cardiopulmonary resuscitation: a prospective clinical trial.” The Lancet, 2001.<a href="#fnref81" class="footnote-back">↩︎</a></p></li>
<li id="fn82"><p>L. Shoemaker Allen (1996) What’s Normal? – Temperature, Gender, and Heart Rate, Journal of Statistics Education, 4:2<a href="#fnref82" class="footnote-back">↩︎</a></p></li>
<li id="fn83"><p>Mackowiak, P. A., Wasserman, S. S., and Levine, M. M. (1992), “A Critical Appraisal of 98.6 Degrees F, the Upper Limit of the Normal Body Temperature, and Other Legacies of Carl Reinhold August Wunderlich,” Journal of the American Medical Association, 268, 1578-1580.<a href="#fnref83" class="footnote-back">↩︎</a></p></li>
<li id="fn84"><p>In general, the distribution is reasonably symmetric. It is unimodal and looks like a normal distribution.<a href="#fnref84" class="footnote-back">↩︎</a></p></li>
<li id="fn85"><p>We will only extract the p-value in this exercise<a href="#fnref85" class="footnote-back">↩︎</a></p></li>
<li id="fn86"><p>If we want to be more certain we will capture the fish, we might use a wider net. Likewise, we use a wider confidence interval if we want to be more certain that we capture the parameter. A higher level of confidence implies a wider interval.<a href="#fnref86" class="footnote-back">↩︎</a></p></li>
<li id="fn87"><p>This is equivalent to asking how often a standard normal variable will be larger than -2.58 but less than 2.58. To determine this probability, look up -2.58 and 2.58 in <code>R</code> using <code>pnorm()</code> (0.0049 and 0.9951). Thus, there is a <span class="math inline">\(0.9951-0.0049 \approx 0.99\)</span> probability that the unobserved random variable <span class="math inline">\(X\)</span> will be within 2.58 standard deviations of the mean.<a href="#fnref87" class="footnote-back">↩︎</a></p></li>
<li id="fn88"><p><a href="http://pewinternet.org/Reports/2013/The-Diagnosis-Difference.aspx" class="uri">http://pewinternet.org/Reports/2013/The-Diagnosis-Difference.aspx</a> The Diagnosis Difference. November 26, 2013. Pew Research.<a href="#fnref88" class="footnote-back">↩︎</a></p></li>
<li id="fn89"><p><span class="math inline">\(H_0\)</span>: The average on-base percentage is equal across the four positions. <span class="math inline">\(H_A\)</span>: The average on-base percentage varies across some (or all) groups.<a href="#fnref89" class="footnote-back">↩︎</a></p></li>
<li id="fn90"><p>If you want to do try this again use the <code>plot_ss()</code> from the last lesson.<a href="#fnref90" class="footnote-back">↩︎</a></p></li>
<li id="fn91"><p>There are applications where least absolute deviation may be more useful, and there are plenty of other criteria we might consider. However, this course only applies the least squares criterion. Math 378 will look at other criteria such as a shrinkage method called the lasso.<a href="#fnref91" class="footnote-back">↩︎</a></p></li>
<li id="fn92"><p><a href="http://www.colbertnation.com/the-colbert-report-videos/269929/" class="uri">http://www.colbertnation.com/the-colbert-report-videos/269929/</a><a href="#fnref92" class="footnote-back">↩︎</a></p></li>
<li id="fn93"><p><span class="math inline">\(\hat{\sigma}=\sqrt\frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\text{degrees of freedom}}\)</span><a href="#fnref93" class="footnote-back">↩︎</a></p></li>
<li id="fn94"><p>Formally, we can compute the correlation for observations <span class="math inline">\((x_1, y_1)\)</span>, <span class="math inline">\((x_2, y_2)\)</span>, …, <span class="math inline">\((x_n, y_n)\)</span> using the formula
<span class="math display">\[
R = \frac{1}{n-1}\sum_{i=1}^{n} \frac{x_i-\bar{x}}{s_x}\frac{y_i-\bar{y}}{s_y}
\]</span>
where <span class="math inline">\(\bar{x}\)</span>, <span class="math inline">\(\bar{y}\)</span>, <span class="math inline">\(s_x\)</span>, and <span class="math inline">\(s_y\)</span> are the sample means and standard deviations for each variable.<a href="#fnref94" class="footnote-back">↩︎</a></p></li>
<li id="fn95"><p>About <span class="math inline">\(R^2 = (-0.97)^2 = 0.94\)</span> or 94% of the variation is explained by the linear model.<a href="#fnref95" class="footnote-back">↩︎</a></p></li>
<li id="fn96"><p>Diez DM, Barr CD, and etinkaya-Rundel M. 2012. <code>openintro</code>: OpenIntro data sets and supplemental functions. <a href="http://cran.r-project.org/web/packages/openintro" class="uri">http://cran.r-project.org/web/packages/openintro</a><a href="#fnref96" class="footnote-back">↩︎</a></p></li>
<li id="fn97"><p><span class="math inline">\(\hat{y} = 41.34 + - 5.13x_1 + 1.08x_2 - 0.03x_3 + 7.29x_4\)</span>, and there are <span class="math inline">\(k=4\)</span> predictor variables.<a href="#fnref97" class="footnote-back">↩︎</a></p></li>
<li id="fn98"><p>It is the average difference in auction price for each additional Wii wheel included when holding the other variables constant. The point estimate is <span class="math inline">\(b_4 = 7.29\)</span>.<a href="#fnref98" class="footnote-back">↩︎</a></p></li>
<li id="fn99"><p>Three of the variables (<code>cond</code>, <code>stock_photo</code>, and <code>wheels</code>) do take value 0, but the auction duration is always one or more days. If the auction is not up for any days, then no one can bid on it! That means the total auction price would always be zero for such an auction; the interpretation of the intercept in this setting is not insightful.<a href="#fnref99" class="footnote-back">↩︎</a></p></li>
<li id="fn100"><p><span class="math inline">\(R^2 = 1 - \frac{24.0198}{83.06} = 0.7108\)</span>.<a href="#fnref100" class="footnote-back">↩︎</a></p></li>
<li id="fn101"><p>In multiple regression, the degrees of freedom associated with the variance of the estimate of the residuals is <span class="math inline">\(n-k-1\)</span>, not <span class="math inline">\(n-1\)</span>. For instance, if we were to make predictions for new data using our current model, we would find that the unadjusted <span class="math inline">\(R^2\)</span> is an overly optimistic estimate of the reduction in variance in the response, and using the degrees of freedom in the adjusted <span class="math inline">\(R^2\)</span> formula helps correct this bias.<a href="#fnref101" class="footnote-back">↩︎</a></p></li>
<li id="fn102"><p>The unadjusted <span class="math inline">\(R^2\)</span> would stay the same and the adjusted <span class="math inline">\(R^2\)</span> would go down. Note that unadjusted <span class="math inline">\(R^2\)</span> never decreases by adding another predictor, it can only stay the same or increase. The adjusted <span class="math inline">\(R^2\)</span> increases only if the addition of a predictor reduces the variance of the error larger than add one to <span class="math inline">\(k\)</span> in denominator.<a href="#fnref102" class="footnote-back">↩︎</a></p></li>
<li id="fn103"><p>Diez DM, Barr CD, and etinkaya-Rundel M. 2012. <code>openintro</code>: OpenIntro data sets and supplemental functions. <a href="http://cran.r-project.org/web/packages/openintro" class="uri">http://cran.r-project.org/web/packages/openintro</a><a href="#fnref103" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
  </main>

  <div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Computational Probability and Statistics</strong>" was written by Matthew Davis, Brianna Hitt, Ken Horton, Bradley Warner. It was last built on 2022-06-14.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
<script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>

</html>
