<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Chapter 31 Logistic Regression | Computational Probability and Statistics</title>

    <meta name="author" content="Matthew Davis" />
    <meta name="author" content="Brianna Hitt" />
    <meta name="author" content="Ken Horton" />
    <meta name="author" content="Bradley Warner" />
  
   <meta name="description" content="This is a set of notes used for Math 377 starting in the fall of 2020 that has been compiled into a book." />
   <meta name="generator" content="placeholder" />
  <meta property="og:title" content="Chapter 31 Logistic Regression | Computational Probability and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/figures/Cover.png" />
  <meta property="og:description" content="This is a set of notes used for Math 377 starting in the fall of 2020 that has been compiled into a book." />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 31 Logistic Regression | Computational Probability and Statistics" />
  
  <meta name="twitter:description" content="This is a set of notes used for Math 377 starting in the fall of 2020 that has been compiled into a book." />
  <meta name="twitter:image" content="/figures/Cover.png" />
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
    <script src="libs/bs3compat-0.3.1/transition.js"></script>
    <script src="libs/bs3compat-0.3.1/tabs.js"></script>
    <script src="libs/bs3compat-0.3.1/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script>

  <!-- CSS -->
  <style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
    <style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
      <link rel="stylesheet" href="style.css" />
  
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Computational Probability and Statistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>

      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book source <i class="fab fa-github"></i></a></li></p>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<div id="LOGREG" class="section level1" number="31">
<h1><span class="header-section-number">Chapter 31</span> Logistic Regression</h1>
<div id="objectives-29" class="section level2" number="31.1">
<h2><span class="header-section-number">31.1</span> Objectives</h2>
<ol style="list-style-type: decimal">
<li>Using <code>R</code>, conduct logistic regression and interpret the output and perform model selection.<br />
</li>
<li>Write the logistic regression model and predict outputs for given inputs.<br />
</li>
<li>Find confidence intervals for parameter estimates and predictions.<br />
</li>
<li>Create and interpret a confusion matrix.</li>
</ol>
</div>
<div id="logistic-regression-introduction" class="section level2" number="31.2">
<h2><span class="header-section-number">31.2</span> Logistic regression introduction</h2>
<p>In this lesson we introduce <strong>logistic regression</strong> as a tool for building models when there is a categorical response variable with two levels. Logistic regression is a type of <strong>generalized linear model</strong> (GLM) for response variables where the assumptions of normally distributed errors is not appropriate. We are prepping you for advanced statistical models and machine learning, where we will explore predictive models of many different types of response variables including ones that donâ€™t assume an underlying functional relationship between inputs and outputs. So cool!</p>
<p>GLMs can be thought of as a two-stage modeling approach. We first model the response variable using a probability distribution, such as the binomial or Poisson distribution. Second, we model the parameter of the distribution using a collection of predictors and a special form of multiple regression.</p>
<p>To explore and explain these ideas, we will again use the Ebay auctions of a video game called <strong>Mario Kart</strong> for the Nintendo Wii. Remember, the data set is in the file <code>mariokart.csv</code> and includes results from 141 auctions.<a href="#fn103" class="footnote-ref" id="fnref103"><sup>103</sup></a></p>
<p>In this chapter, we want the outcome variable of interest to be game condition, <code>cond</code>. In Chapter <a href="LRMULTI.html#LRMULTI">30</a> we used the total price of an auction as the response. We are moving from a quantitative response to a binary qualitative variable. If we were only interested in determining if an association exists between the variables <code>cond</code> and <code>total_pr</code>, we could use linear regression with <code>total_pr</code> as the response. However, in this problem we want to predict game condition. We will start by reviewing some of the previous models and then introduce logistic regression. We will finish with a multiple logistic regression model, more than one predictor.</p>
<div id="mario-kart-data" class="section level3" number="31.2.1">
<h3><span class="header-section-number">31.2.1</span> Mario Kart data</h3>
<p>Read the data and summarize.</p>
<div class="sourceCode" id="cb1030"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1030-1"><a href="LOGREG.html#cb1030-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="ot">&lt;-</span><span class="fu">read_csv</span>(<span class="st">&quot;data/mariokart.csv&quot;</span>, <span class="at">col_types =</span> <span class="fu">list</span>(<span class="fu">col_character</span>()))</span>
<span id="cb1030-2"><a href="LOGREG.html#cb1030-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mariokart,<span class="at">n=</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 12
##    id        duration n_bids cond  start_pr ship_pr total_pr ship_sp seller_rate
##    &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;
##  1 15037742~        3     20 new       0.99    4        51.6 standa~        1580
##  2 26048337~        7     13 used      0.99    3.99     37.0 firstC~         365
##  3 32043234~        3     16 new       0.99    3.5      45.5 firstC~         998
##  4 28040522~        3     18 new       0.99    0        44   standa~           7
##  5 17039222~        1     20 new       0.01    0        71   media           820
##  6 36019515~        3     19 new       0.99    4        45   standa~      270144
##  7 12047772~        1     13 used      0.01    0        37.0 standa~        7284
##  8 30035550~        1     15 new       1       2.99     54.0 upsGro~        4858
##  9 20039206~        3     29 used      0.99    4        47   priori~          27
## 10 33036416~        7      8 used     20.0     4        50   firstC~         201
## # ... with 3 more variables: stock_photo &lt;chr&gt;, wheels &lt;dbl&gt;, title &lt;chr&gt;</code></pre>
<div class="sourceCode" id="cb1032"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1032-1"><a href="LOGREG.html#cb1032-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(mariokart)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##          name     class levels   n missing
## 1          id character    143 143       0
## 2        cond character      2 143       0
## 3     ship_sp character      8 143       0
## 4 stock_photo character      2 143       0
## 5       title character     80 142       1
##                                    distribution
## 1 110439174663 (0.7%) ...                      
## 2 used (58.7%), new (41.3%)                    
## 3 standard (23.1%), upsGround (21.7%) ...      
## 4 yes (73.4%), no (26.6%)                      
## 5  (%) ...                                     
## 
## quantitative variables:  
##             name   class   min      Q1 median      Q3       max         mean
## ...1    duration numeric  1.00   1.000    3.0    7.00     10.00     3.769231
## ...2      n_bids numeric  1.00  10.000   14.0   17.00     29.00    13.538462
## ...3    start_pr numeric  0.01   0.990    1.0   10.00     69.95     8.777203
## ...4     ship_pr numeric  0.00   0.000    3.0    4.00     25.51     3.143706
## ...5    total_pr numeric 28.98  41.175   46.5   53.99    326.51    49.880490
## ...6 seller_rate numeric  0.00 109.000  820.0 4858.00 270144.00 15898.419580
## ...7      wheels numeric  0.00   0.000    1.0    2.00      4.00     1.146853
##                sd   n missing
## ...1 2.585693e+00 143       0
## ...2 5.878786e+00 143       0
## ...3 1.506745e+01 143       0
## ...4 3.213179e+00 143       0
## ...5 2.568856e+01 143       0
## ...6 5.184032e+04 143       0
## ...7 8.471829e-01 143       0</code></pre>
<p>We are again only interested in <code>total_pr</code>, <code>cond</code>, <code>stock_photo</code>, <code>duration</code>, and <code>wheels</code>. These variables are described in the following list:</p>
<ol style="list-style-type: decimal">
<li><code>total_pr</code>: final auction price plus shipping costs, in US dollars<br />
</li>
<li><code>cond</code>: a two-level categorical factor variable<br />
</li>
<li><code>stock_photo</code>: a two-level categorical factor variable<br />
</li>
<li><code>duration</code>: the length of the auction, in days, taking values from 1 to 10<br />
</li>
<li><code>wheels</code>: the number of Wii wheels included with the auction (a <strong>Wii wheel</strong> is a plastic racing wheel that holds the Wii controller and is an optional but helpful accessory for playing Mario Kart)</li>
</ol>
<p>Remember that we removed a couple of outlier sales that included multiple items. Before we start letâ€™s clean up the data again to include removing those outliers.</p>
<div class="sourceCode" id="cb1034"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1034-1"><a href="LOGREG.html#cb1034-1" aria-hidden="true" tabindex="-1"></a>mariokart <span class="ot">&lt;-</span> mariokart <span class="sc">%&gt;%</span></span>
<span id="cb1034-2"><a href="LOGREG.html#cb1034-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(total_pr <span class="sc">&lt;=</span> <span class="dv">100</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb1034-3"><a href="LOGREG.html#cb1034-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">cond=</span><span class="fu">factor</span>(cond),</span>
<span id="cb1034-4"><a href="LOGREG.html#cb1034-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">stock_photo=</span><span class="fu">factor</span>(stock_photo)) <span class="sc">%&gt;%</span> </span>
<span id="cb1034-5"><a href="LOGREG.html#cb1034-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(cond,stock_photo,total_pr,duration,wheels)</span></code></pre></div>
<p>Next letâ€™s summarize the data.</p>
<div class="sourceCode" id="cb1035"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1035-1"><a href="LOGREG.html#cb1035-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(mariokart)</span></code></pre></div>
<pre><code>## 
## categorical variables:  
##          name  class levels   n missing
## 1        cond factor      2 141       0
## 2 stock_photo factor      2 141       0
##                                    distribution
## 1 used (58.2%), new (41.8%)                    
## 2 yes (74.5%), no (25.5%)                      
## 
## quantitative variables:  
##          name   class   min Q1 median    Q3 max      mean        sd   n missing
## ...1 total_pr numeric 28.98 41  46.03 53.99  75 47.431915 9.1136514 141       0
## ...2 duration numeric  1.00  1   3.00  7.00  10  3.751773 2.5888663 141       0
## ...3   wheels numeric  0.00  0   1.00  2.00   4  1.148936 0.8446146 141       0</code></pre>
</div>
<div id="analyzing-contingency-table" class="section level3" number="31.2.2">
<h3><span class="header-section-number">31.2.2</span> Analyzing contingency table</h3>
<p>As a review and introduction to logistic regression, letâ€™s analyze the relationship between game condition and stock photo.</p>
<div class="sourceCode" id="cb1037"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1037-1"><a href="LOGREG.html#cb1037-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(cond<span class="sc">~</span>stock_photo,<span class="at">data=</span>mariokart</span>
<span id="cb1037-2"><a href="LOGREG.html#cb1037-2" aria-hidden="true" tabindex="-1"></a>      ,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format =</span> <span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>##        stock_photo
## cond           no       yes
##   new   0.1111111 0.5238095
##   used  0.8888889 0.4761905
##   Total 1.0000000 1.0000000</code></pre>
<p>We could analyze this by comparing the proportion of new condition games for each stock photo value using both randomization, empirical p-values, and the central limit theorem. We will just use an exact permutation test, <strong>Fisher Exact Test</strong>, which just uses the hypergeometric distribution.</p>
<div class="sourceCode" id="cb1039"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1039-1"><a href="LOGREG.html#cb1039-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fisher.test</span>(<span class="fu">tally</span>(<span class="sc">~</span>cond<span class="sc">+</span>stock_photo,<span class="at">data=</span>mariokart))</span></code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  tally(~cond + stock_photo, data = mariokart)
## p-value = 9.875e-06
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.02766882 0.35763723
## sample estimates:
## odds ratio 
##  0.1152058</code></pre>
<p>Clearly, these variables are not independent of each other. This model does not gives us much more information so letâ€™s move to logistic regression.</p>
</div>
<div id="modeling-the-probability-of-an-event" class="section level3" number="31.2.3">
<h3><span class="header-section-number">31.2.3</span> Modeling the probability of an event</h3>
<p>The outcome variable for a GLM is denoted by <span class="math inline">\(Y_i\)</span>, where the index <span class="math inline">\(i\)</span> is used to represent observation <span class="math inline">\(i\)</span>. In the Mario Kart application, <span class="math inline">\(Y_i\)</span> will be used to represent whether the game condition <span class="math inline">\(i\)</span> is new (<span class="math inline">\(Y_i=1\)</span>) or used (<span class="math inline">\(Y_i=0\)</span>).</p>
<p>The predictor variables are represented as follows: <span class="math inline">\(x_{1,i}\)</span> is the value of variable 1 for observation <span class="math inline">\(i\)</span>, <span class="math inline">\(x_{2,i}\)</span> is the value of variable 2 for observation <span class="math inline">\(i\)</span>, and so on.</p>
<p>Logistic regression is a generalized linear model where the outcome is a two-level categorical variable. The outcome, <span class="math inline">\(Y_i\)</span>, takes the value 1 (in our application, this represents a game in new condition but we could easily switch and make the outcome of interest a used game) with probability <span class="math inline">\(p_i\)</span> and the value 0 with probability <span class="math inline">\(1-p_i\)</span>. It is the probability <span class="math inline">\(p_i\)</span> that we model in relation to the predictor variables.</p>
<p>The logistic regression model relates the probability a game is new (<span class="math inline">\(p_i\)</span>) to values of the predictors <span class="math inline">\(x_{1,i}\)</span>, <span class="math inline">\(x_{2,i}\)</span>, â€¦, <span class="math inline">\(x_{k,i}\)</span> through a framework much like that of multiple regression:</p>
<p><span class="math display">\[
\text{transformation}(p_{i}) = \beta_0 + \beta_1x_{1,i} + \beta_2 x_{2,i} + \cdots \beta_k x_{k,i}
\]</span></p>
<p>We want to choose a transformation that makes practical and mathematical sense. For example, we want a transformation that makes the range of possibilities on the left hand side of the above equation equal to the range of possibilities for the right hand side. If there was no transformation for this equation, the left hand side could only take values between 0 and 1, but the right hand side could take values outside of this range. A common transformation for <span class="math inline">\(p_i\)</span> is the <strong>logit transformation</strong>, which may be written as</p>
<p><span class="math display">\[
\text{logit}(p_i) = \log_{e}\left( \frac{p_i}{1-p_i} \right)
\]</span></p>
<p>Below, we expand the equation using the logit transformation of <span class="math inline">\(p_i\)</span>:</p>
<p><span class="math display">\[
\log_{e}\left( \frac{p_i}{1-p_i} \right)
    = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_k x_{k,i}
\]</span></p>
<p>Solving for <span class="math inline">\(p_i\)</span> we get the logistic function:</p>
<p><span class="math display">\[
p_i     = \frac{1}{1+e^{-(\beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_k x_{k,i})}}
\]</span></p>
<p>The logistic function is shown in Figure <a href="LOGREG.html#fig:logit-fig">31.1</a>.</p>
<div class="figure"><span style="display:block;" id="fig:logit-fig"></span>
<img src="31-Logistic-Regression_files/figure-html/logit-fig-1.png" alt="Logitstic function with some example points plotted." width="672" />
<p class="caption">
Figure 31.1: Logitstic function with some example points plotted.
</p>
</div>
<p>Notice the output of the <code>logistic</code> function restricts the values between 0 and 1. The curve is fairly flat on the edges with a sharp rise in the center. There are other functions that achieve this same result. However, for reasons beyond the scope of this book, the logit function has desirable mathematical properties that relate to making sure all the common GLMs fall within the exponential family of distributions. This topic is at the graduate school level and not needed for our studies.</p>
<p>In our Mario Kart example, there are 4 predictor variables, so <span class="math inline">\(k = 4\)</span>. This nonlinear model isnâ€™t very intuitive, but it still has some resemblance to multiple regression, and we can fit this model using software. In fact, once we look at results from software, it will start to feel like weâ€™re back in multiple regression, even if the interpretation of the coefficients is more complex.</p>
</div>
<div id="first-model---intercept-only" class="section level3" number="31.2.4">
<h3><span class="header-section-number">31.2.4</span> First model - intercept only</h3>
<p>Here we create a model with just an intercept.</p>
<p>In <code>R</code> we use the <code>glm()</code> function to fit a logistic regression model. It has the same formula format as <code>lm</code> but also requires a <code>family</code> argument. Since our response is binary, we use <code>binomial</code>. If we wanted to use <code>glm()</code> for linear regression assuming normally distributed residual, the family argument would be <code>gaussian</code>. This implies that multiple linear regression with the assumption of normally distributed errors is a special case of a generalized linear model. In <code>R</code>, the response is a 0/1 variable, we can control the outcome of interest, the 1, by using a logical argument in the formula.</p>
<p>First to understand the output of logistic regression, letâ€™s just run a model with an intercept term. Notice in the code chunk that the left hand side of the formula has a logical argument, this gives a 0/1 output with 1 being the value we want to predict.</p>
<div class="sourceCode" id="cb1041"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1041-1"><a href="LOGREG.html#cb1041-1" aria-hidden="true" tabindex="-1"></a>mario_mod1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span><span class="dv">1</span>,<span class="at">data=</span>mariokart,</span>
<span id="cb1041-2"><a href="LOGREG.html#cb1041-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<p>Letâ€™s get regression output using the <code>summary()</code> function.</p>
<div class="sourceCode" id="cb1042"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1042-1"><a href="LOGREG.html#cb1042-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ 1, family = &quot;binomial&quot;, data = mariokart)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.041  -1.041  -1.041   1.320   1.320  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  -0.3292     0.1707  -1.928   0.0538 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.7  on 140  degrees of freedom
## Residual deviance: 191.7  on 140  degrees of freedom
## AIC: 193.7
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>This looks similar to the regression output we saw in previous chapters. However, the model has a different, nonlinear, form. Remember, Equation <a href="LOGREG.html#eq:logistic">(31.1)</a> is the general form of the model.</p>
<p><span class="math display" id="eq:logistic">\[\begin{equation}
  \log_{e}\left( \frac{p_i}{1-p_i} \right)
    = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_k x_{k,i}
  \tag{31.1}
\end{equation}\]</span></p>
<p>Thus using the output of <code>R</code>, Equation <a href="LOGREG.html#eq:logistic2">(31.2)</a> is the estimated model.</p>
<p><span class="math display" id="eq:logistic2">\[\begin{equation}
\log\left( \frac{p_i}{1-p_i} \right) = -0.329
  \tag{31.2}
\end{equation}\]</span></p>
<p>Solving Equation <a href="LOGREG.html#eq:logistic2">(31.2)</a> for <span class="math inline">\(p_i\)</span>: <span class="math inline">\(\frac{e^{-0.329}}{1 + e^{-0.329}} = 0.418\)</span>. This is the estimated probability of the game condition being new. This point is plotted in Figure <a href="LOGREG.html#fig:logit-fig">31.1</a>. We can also check this result using a summary table.</p>
<div class="sourceCode" id="cb1044"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1044-1"><a href="LOGREG.html#cb1044-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>cond,<span class="at">data=</span>mariokart,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>## cond
##       new      used 
## 0.4184397 0.5815603</code></pre>
</div>
<div id="second-model---stock_photo" class="section level3" number="31.2.5">
<h3><span class="header-section-number">31.2.5</span> Second model - stock_photo</h3>
<p>Now that we are starting to understand the logistic regression model. Letâ€™s add a predictor variable, <code>stock_photo</code>. Again, we have many methods to determine if a relationship between two categorical variables exists, logistic regression is another method.</p>
<div class="sourceCode" id="cb1046"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1046-1"><a href="LOGREG.html#cb1046-1" aria-hidden="true" tabindex="-1"></a>mario_mod2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo,<span class="at">data=</span>mariokart,</span>
<span id="cb1046-2"><a href="LOGREG.html#cb1046-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1047"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1047-1"><a href="LOGREG.html#cb1047-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ stock_photo, family = &quot;binomial&quot;, 
##     data = mariokart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.2181  -1.2181  -0.4854   1.1372   2.0963  
## 
## Coefficients:
##                Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -2.0794     0.5303  -3.921 8.81e-05 ***
## stock_photoyes   2.1748     0.5652   3.848 0.000119 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.70  on 140  degrees of freedom
## Residual deviance: 170.44  on 139  degrees of freedom
## AIC: 174.44
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Examining the <strong>p-value</strong> associated with the coefficient for <code>stock_photo</code>, we can see that it is significant. Thus we reject the null hypothesis that the coefficient is zero. There is a relationship between <code>cond</code> and <code>stock_photo</code>, as we found with the Fisherâ€™s test.</p>
<p>We can use the <strong>broom</strong> package to summarize the output and generate model fits.</p>
<div class="sourceCode" id="cb1049"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1049-1"><a href="LOGREG.html#cb1049-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod2)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term           estimate std.error statistic   p.value
##   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)       -2.08     0.530     -3.92 0.0000881
## 2 stock_photoyes     2.17     0.565      3.85 0.000119</code></pre>
<p>Letâ€™s convert these coefficients to estimated probabilities using the <code>augment()</code> function. We need to specify the output as the <em>response</em>, this returns a probability, or else we will get the logit of the probability, the link value.</p>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1051-1"><a href="LOGREG.html#cb1051-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod2,</span>
<span id="cb1051-2"><a href="LOGREG.html#cb1051-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata=</span><span class="fu">tibble</span>(<span class="at">stock_photo=</span><span class="fu">c</span>(<span class="st">&quot;yes&quot;</span>,<span class="st">&quot;no&quot;</span>)),</span>
<span id="cb1051-3"><a href="LOGREG.html#cb1051-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   stock_photo .fitted
##   &lt;chr&gt;         &lt;dbl&gt;
## 1 yes           0.524
## 2 no            0.111</code></pre>
<p>These are the conditional probability of a new condition based on status of <code>stock_photo</code>. We can see this using the <code>tally()</code> function.</p>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="LOGREG.html#cb1053-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(cond<span class="sc">~</span>stock_photo,<span class="at">data=</span>mariokart,<span class="at">margins =</span> <span class="cn">TRUE</span>,<span class="at">format=</span><span class="st">&quot;proportion&quot;</span>)</span></code></pre></div>
<pre><code>##        stock_photo
## cond           no       yes
##   new   0.1111111 0.5238095
##   used  0.8888889 0.4761905
##   Total 1.0000000 1.0000000</code></pre>
<p>Or from the model coefficients.</p>
<div class="sourceCode" id="cb1055"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1055-1"><a href="LOGREG.html#cb1055-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">2.079442</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">2.079442</span>))</span></code></pre></div>
<pre><code>## [1] 0.1111111</code></pre>
<div class="sourceCode" id="cb1057"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1057-1"><a href="LOGREG.html#cb1057-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">2.079442+2.174752</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">2.079442+2.174752</span>))</span></code></pre></div>
<pre><code>## [1] 0.5238095</code></pre>
<blockquote>
<p><strong>Exercise</strong>:
Fit a logistic regression model with <code>cond</code> as used and <code>stock_photo</code> as a predictor.</p>
</blockquote>
<p>We repeat the code from above.</p>
<div class="sourceCode" id="cb1059"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1059-1"><a href="LOGREG.html#cb1059-1" aria-hidden="true" tabindex="-1"></a>mario_mod3 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;used&quot;</span><span class="sc">~</span>stock_photo,<span class="at">data=</span>mariokart,</span>
<span id="cb1059-2"><a href="LOGREG.html#cb1059-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1060-1"><a href="LOGREG.html#cb1060-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod3)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term           estimate std.error statistic   p.value
##   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)        2.08     0.530      3.92 0.0000881
## 2 stock_photoyes    -2.17     0.565     -3.85 0.000119</code></pre>
<p>Again, letâ€™s convert these coefficients to estimated probabilities using the <code>augment()</code> function.</p>
<div class="sourceCode" id="cb1062"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1062-1"><a href="LOGREG.html#cb1062-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod3,</span>
<span id="cb1062-2"><a href="LOGREG.html#cb1062-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata=</span><span class="fu">tibble</span>(<span class="at">stock_photo=</span><span class="fu">c</span>(<span class="st">&quot;yes&quot;</span>,<span class="st">&quot;no&quot;</span>)),</span>
<span id="cb1062-3"><a href="LOGREG.html#cb1062-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   stock_photo .fitted
##   &lt;chr&gt;         &lt;dbl&gt;
## 1 yes           0.476
## 2 no            0.889</code></pre>
<p>This matches the output from the <code>tally()</code> function we observed above.</p>
<p>Notice that it was not important whether we select new or used condition as the desired outcome. In either case, the logistic regression model returns the conditional probability given the value of the predictor.</p>
</div>
<div id="interpreting-the-coefficients" class="section level3" number="31.2.6">
<h3><span class="header-section-number">31.2.6</span> Interpreting the coefficients</h3>
<p>At this point it seems that we created a great deal of work just to get the same results that we had from other methods. However, the logistic regression model allows us to add other predictors and it also gives us standard errors for the parameter estimates.</p>
<p>Letâ€™s first discuss the interpretation of coefficients. As a reminder, the fitted coefficients are reported from the model summary.</p>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1064-1"><a href="LOGREG.html#cb1064-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod2)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term           estimate std.error statistic   p.value
##   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)       -2.08     0.530     -3.92 0.0000881
## 2 stock_photoyes     2.17     0.565      3.85 0.000119</code></pre>
<p>The variable <code>stock_photo</code> takes on the values 0 and 1, the value 1 of indicates the sale had a stock photo. The logistic regression model we are fitting is Equation <a href="LOGREG.html#eq:logistic4">(31.3)</a>.</p>
<p><span class="math display" id="eq:logistic4">\[\begin{equation}
  \log_{e}\left( \frac{p_{new}}{1-p_{new}} \right)
    = \beta_0 + \beta_1 \mbox{stock_photo}  
  \tag{31.3}
\end{equation}\]</span></p>
<p>If the photo is not a stock photo then the model is Equation <a href="LOGREG.html#eq:logistic5">(31.4)</a>. The left-hand side is the natural logarithm of the odds, where odds are the ratio of the probability of success divided by the probability of failure.<br />
<span class="math display">\[
\log_{e}\left( \frac{p_{\mbox{new|stock photo}}}{1-p_{\mbox{new|stock photo}}} \right)
    = \beta_0 + \beta_1   
\]</span></p>
<p><span class="math display" id="eq:logistic5">\[\begin{equation}
  \log_{e}\left( \frac{p_{\mbox{new|no stock photo}}}{1-p_{\mbox{new|no stock photo}}} \right)
    = \beta_0   
  \tag{31.4}
\end{equation}\]</span></p>
<p>If we have a stock photo, the variable <code>stock_photo</code> is 1. Then Equation <a href="LOGREG.html#eq:logistic6">(31.5)</a> is the resulting model.</p>
<p><span class="math display" id="eq:logistic6">\[\begin{equation}
\log_{e}\left( \frac{p_{\mbox{new|stock photo}}}{1-p_{\mbox{new|stock photo}}} \right)
    = \beta_0 + \beta_1   
  \tag{31.5}
\end{equation}\]</span></p>
<p>Thus the difference of these gives an interpretation of the <span class="math inline">\(\beta_1\)</span> coefficient, it is the log odds ratio as is shown in the derivation that follows.</p>
<p><span class="math display">\[
\log_{e}\left( \frac{p_{\mbox{new|stock photo}}}{1-p_{\mbox{new|stock photo}}} \right)
-
\log_{e}\left( \frac{p_{\mbox{new|no stock photo}}}{1-p_{\mbox{new|no stock photo}}} \right) = \beta_1
\]</span>
<span class="math display">\[
\log_{e}\left(\frac{\frac{p_{\mbox{new|stock photo}}}{1-p_{\mbox{new|stock photo}}}}{\frac{p_{\mbox{new|no stock photo}}}{1-p_{\mbox{new|no stock photo}}}} \right)
= \beta_1
\]</span></p>
<p>For our problem, the log odds more than double if the photo is a stock photo. It is easier to interpret odds ratios, so often analysts use <span class="math inline">\(e^{\beta_1}\)</span> as the odds ratio. Again, for our problem, the odds of a new condition game increase by a factor of 8.8 if a stock photo is used. Note that an odds ratio is not a relative risk. Relative risk is the ratio of the probability of a new game with stock photo to the probability of a new game without a stock photo. Be careful in your interpretation.</p>
<p><span class="math display">\[
\text{Relative Risk} = \left(\frac{p_{\mbox{new|stock photo}}}{p_{\mbox{new|no stock photo}}} \right)
\]</span></p>
</div>
<div id="comparing-models" class="section level3" number="31.2.7">
<h3><span class="header-section-number">31.2.7</span> Comparing models</h3>
<p>Just as is the case for linear regression, we can compare nested models. When we examine the output of model there is a line with the <strong>residual deviance</strong>. This model is not fit using least squares but using maximum likelihood. Deviance is 2 times the negative of the log likelihood. We negate the log likelihood so that maximizing the log likelihood is equivalent to minimizing the negation. This allows the same thought process of minimizing deviance as we had for minimizing residual sum of squares. The multiplication by 2 is because an asymptotic argument shows that 2 times the negative log likelihood is approximately distributed as a Chi-square random variable.</p>
<div class="sourceCode" id="cb1066"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1066-1"><a href="LOGREG.html#cb1066-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ stock_photo, family = &quot;binomial&quot;, 
##     data = mariokart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.2181  -1.2181  -0.4854   1.1372   2.0963  
## 
## Coefficients:
##                Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -2.0794     0.5303  -3.921 8.81e-05 ***
## stock_photoyes   2.1748     0.5652   3.848 0.000119 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.70  on 140  degrees of freedom
## Residual deviance: 170.44  on 139  degrees of freedom
## AIC: 174.44
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Similar to linear regression, we can use the <code>anova()</code> function to compare nested models.</p>
<div class="sourceCode" id="cb1068"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1068-1"><a href="LOGREG.html#cb1068-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mario_mod1,mario_mod2,<span class="at">test=</span><span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: cond == &quot;new&quot; ~ 1
## Model 2: cond == &quot;new&quot; ~ stock_photo
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)    
## 1       140     191.70                         
## 2       139     170.44  1    21.26 4.01e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Adding, <code>stock_photo</code> is a statistically significant result. The p-value is different from the <code>summary()</code> function, because it assumes the coefficient follows a normal distribution. Different assumptions, but the same conclusion.</p>
<p>The use of p-value to pick a best model uses statistical assumptions to select the features. Another approach is to use a predictive measure. In machine learning contexts, we use many different predictive performance measures for model selection but many are based on a <strong>confusion matrix</strong>.</p>
<p>A confusion matrix generates a 2 by 2 matrix of predicted outcomes versus actual outcomes. For logistic regression, the output is a probability of success. To convert this to 0/1 outcome we pick a threshold. It is common to use 0.5 as the threshold. Probabilities above 0.5 are considered a success, in the context of our problem a new game. Letâ€™s generate the confusion matrix.</p>
<div class="sourceCode" id="cb1070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1070-1"><a href="LOGREG.html#cb1070-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod2,<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1070-2"><a href="LOGREG.html#cb1070-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">actual=</span><span class="fu">starts_with</span>(<span class="st">&#39;cond&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1070-3"><a href="LOGREG.html#cb1070-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">result=</span><span class="fu">as.integer</span>(.fitted<span class="sc">&gt;</span><span class="fl">0.5</span>),</span>
<span id="cb1070-4"><a href="LOGREG.html#cb1070-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">actual=</span><span class="fu">as.integer</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb1070-5"><a href="LOGREG.html#cb1070-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span></code></pre></div>
<pre><code>##       actual
## result  0  1
##      0 32  4
##      1 50 55</code></pre>
<p>One single number summary metric is accuracy. In this case the model was correct on <span class="math inline">\(32 + 55\)</span> out of the 141 cases, or 61.7% are correct.</p>
<p>This looks like the same table we get comparing <code>cond</code> to <code>stock_photo</code>. This is the case because of the binary nature of the predictor. We only have two probability values in our prediction.</p>
<div class="sourceCode" id="cb1072"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1072-1"><a href="LOGREG.html#cb1072-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(<span class="sc">~</span>cond<span class="sc">+</span>stock_photo,<span class="at">data=</span>mariokart)</span></code></pre></div>
<pre><code>##       stock_photo
## cond   no yes
##   new   4  55
##   used 32  50</code></pre>
<p>If we change the threshold we get a different accuracy. In a machine learning course, we learn about other metrics such as area under the ROC curve. Back to our problem, letâ€™s add another variable to see if we can improve the model.</p>
</div>
</div>
<div id="multiple-logistic-regression" class="section level2" number="31.3">
<h2><span class="header-section-number">31.3</span> Multiple logistic regression</h2>
<p>Letâ€™s add <code>total_pr</code> to the model. This model is something that we could not have done in the previous models we learned about.</p>
<div class="sourceCode" id="cb1074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1074-1"><a href="LOGREG.html#cb1074-1" aria-hidden="true" tabindex="-1"></a>mario_mod4 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span>total_pr,</span>
<span id="cb1074-2"><a href="LOGREG.html#cb1074-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>mariokart,</span>
<span id="cb1074-3"><a href="LOGREG.html#cb1074-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<p>Notice that we use the same formula syntax as we had done with linear regression.</p>
<div class="sourceCode" id="cb1075"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1075-1"><a href="LOGREG.html#cb1075-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod4)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ stock_photo + total_pr, family = &quot;binomial&quot;, 
##     data = mariokart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3699  -0.6479  -0.2358   0.6532   2.5794  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    -11.31951    1.88333  -6.010 1.85e-09 ***
## stock_photoyes   2.11633    0.68551   3.087  0.00202 ** 
## total_pr         0.19348    0.03562   5.431 5.60e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.70  on 140  degrees of freedom
## Residual deviance: 119.21  on 138  degrees of freedom
## AIC: 125.21
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>From the summary, both <code>stock_photo</code> and <code>total_pr</code> are statistically significant.</p>
<blockquote>
<p><strong>Exercise</strong>:<br />
Interpret the coefficient associated with the predictor <code>total_pr</code>.</p>
</blockquote>
<p>For one dollar increase in total price of the auction, the odds ratio increases by <span class="math inline">\(exp(\beta_2)\)</span>, 1.21, for a given condition of the stock photo variable.</p>
<p>This is similar to an interpretation we had for multiple linear regression. We had to specify that the other predictors are held constant and then we increased the variable of interest by one unit.</p>
<p>Besides using individual predictor p-values to assess the model, can also use a confusion matrix.</p>
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="LOGREG.html#cb1077-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod4,<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1077-2"><a href="LOGREG.html#cb1077-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">actual=</span><span class="fu">starts_with</span>(<span class="st">&#39;cond&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1077-3"><a href="LOGREG.html#cb1077-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">result=</span><span class="fu">as.integer</span>(.fitted<span class="sc">&gt;</span><span class="fl">0.5</span>),</span>
<span id="cb1077-4"><a href="LOGREG.html#cb1077-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">actual=</span><span class="fu">as.integer</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb1077-5"><a href="LOGREG.html#cb1077-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span></code></pre></div>
<pre><code>##       actual
## result  0  1
##      0 71 16
##      1 11 43</code></pre>
<p>For our new model, the accuracy improved to <span class="math inline">\(71 + 43\)</span> out of the 141 cases, or 80.9.7%. Without a measure of variability, we donâ€™t know if this is significant improvement or just the variability in the modeling procedure. On the surface, it appears to be an improvement.</p>
<p>As we experiment to improve the model, letâ€™s use a quadratic term in our model.</p>
<div class="sourceCode" id="cb1079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1079-1"><a href="LOGREG.html#cb1079-1" aria-hidden="true" tabindex="-1"></a>mario_mod5 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span><span class="fu">poly</span>(total_pr,<span class="dv">2</span>),</span>
<span id="cb1079-2"><a href="LOGREG.html#cb1079-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>mariokart,</span>
<span id="cb1079-3"><a href="LOGREG.html#cb1079-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<p>Using the individual p-values, it appears that a quadratic term is significant but it is marginal.</p>
<div class="sourceCode" id="cb1080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1080-1"><a href="LOGREG.html#cb1080-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mario_mod5)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cond == &quot;new&quot; ~ stock_photo + poly(total_pr, 2), 
##     family = &quot;binomial&quot;, data = mariokart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1555  -0.6511  -0.1200   0.5987   2.6760  
## 
## Coefficients:
##                    Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)         -2.4407     0.6347  -3.845  0.00012 ***
## stock_photoyes       2.0411     0.6494   3.143  0.00167 ** 
## poly(total_pr, 2)1  23.7534     4.5697   5.198 2.01e-07 ***
## poly(total_pr, 2)2  -9.9724     4.1999  -2.374  0.01758 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 191.70  on 140  degrees of freedom
## Residual deviance: 114.05  on 137  degrees of freedom
## AIC: 122.05
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>We get a similar result if we use the <code>anova()</code> function.</p>
<div class="sourceCode" id="cb1082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1082-1"><a href="LOGREG.html#cb1082-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mario_mod4,mario_mod5,<span class="at">test=</span><span class="st">&quot;Chi&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: cond == &quot;new&quot; ~ stock_photo + total_pr
## Model 2: cond == &quot;new&quot; ~ stock_photo + poly(total_pr, 2)
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)  
## 1       138     119.21                       
## 2       137     114.05  1   5.1687    0.023 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Finally, the confusion matrix results in a slight improvement in accuracy to 82.3%.</p>
<div class="sourceCode" id="cb1084"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1084-1"><a href="LOGREG.html#cb1084-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod5,<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1084-2"><a href="LOGREG.html#cb1084-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">actual=</span><span class="fu">starts_with</span>(<span class="st">&#39;cond&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1084-3"><a href="LOGREG.html#cb1084-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">result=</span><span class="fu">as.integer</span>(.fitted<span class="sc">&gt;</span><span class="fl">0.5</span>),</span>
<span id="cb1084-4"><a href="LOGREG.html#cb1084-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">actual=</span><span class="fu">as.integer</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb1084-5"><a href="LOGREG.html#cb1084-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span></code></pre></div>
<pre><code>##       actual
## result  0  1
##      0 69 12
##      1 13 47</code></pre>
<p>Almost any classifier will have some error. In the model above, we have decided that it is okay to allow up to 9%, 13 out of 141, of the games for sale to be classified as new when they are really used. If we wanted to make it a little harder to classify an item as new, we could use a cutoff, threshold, of 0.75. This would have two effects. Because it raises the standard for what can be classified as new, it reduces the number of used games that are classified as new. However, it will also fail to correctly classify an increased fraction of new games as new, see the code below. No matter the complexity and the confidence we might have in our model, these practical considerations are absolutely crucial to making a helpful classification model. Without them, we could actually do more harm than good by using our statistical model. This tradeoff is similar to the one we found between Type 1 and Type 2 errors. Notice that the accuracy has also dropped slightly.</p>
<div class="sourceCode" id="cb1086"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1086-1"><a href="LOGREG.html#cb1086-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod5,<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1086-2"><a href="LOGREG.html#cb1086-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">actual=</span><span class="fu">starts_with</span>(<span class="st">&#39;cond&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1086-3"><a href="LOGREG.html#cb1086-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">result=</span><span class="fu">as.integer</span>(.fitted<span class="sc">&gt;</span><span class="fl">0.75</span>),</span>
<span id="cb1086-4"><a href="LOGREG.html#cb1086-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">actual=</span><span class="fu">as.integer</span>(actual)) <span class="sc">%&gt;%</span></span>
<span id="cb1086-5"><a href="LOGREG.html#cb1086-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span></code></pre></div>
<pre><code>##       actual
## result  0  1
##      0 78 22
##      1  4 37</code></pre>
<p>In a machine learning course, we learn about better methods to assess predictive accuracy as well as more sophisticated methods to transform and adapt our predictor variables.</p>
<blockquote>
<p><strong>Exercise</strong> Find the probability that an auctioned game is new if the total price is 50 and it uses a stock photo.</p>
</blockquote>
<p>It is not clear how to use the coefficients in the regression output since <code>R</code> is performing a transformation on <code>total_pr</code> variable. Letâ€™s approach this in two ways. First we will use the <code>augment()</code> function to do the hard work.</p>
<div class="sourceCode" id="cb1088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1088-1"><a href="LOGREG.html#cb1088-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod5,</span>
<span id="cb1088-2"><a href="LOGREG.html#cb1088-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">stock_photo=</span><span class="st">&quot;yes&quot;</span>,<span class="at">total_pr=</span><span class="dv">50</span>),</span>
<span id="cb1088-3"><a href="LOGREG.html#cb1088-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   stock_photo total_pr .fitted
##   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;
## 1 yes               50   0.693</code></pre>
<p>We predict that the probability of the game being new if it uses a stock photo and the total price is 50 is 69.3%.</p>
<p>If we want to recreate the calculation, we need to use a <strong>raw</strong> polynomial.</p>
<div class="sourceCode" id="cb1090"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1090-1"><a href="LOGREG.html#cb1090-1" aria-hidden="true" tabindex="-1"></a>mario_mod6 <span class="ot">&lt;-</span> <span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span>total_pr<span class="sc">+</span><span class="fu">I</span>(total_pr<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb1090-2"><a href="LOGREG.html#cb1090-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>mariokart,</span>
<span id="cb1090-3"><a href="LOGREG.html#cb1090-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb1090-4"><a href="LOGREG.html#cb1090-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod6)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term            estimate std.error statistic  p.value
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)    -30.7       9.08        -3.38 0.000732
## 2 stock_photoyes   2.04      0.649        3.14 0.00167 
## 3 total_pr         0.969     0.343        2.83 0.00470 
## 4 I(total_pr^2)   -0.00760   0.00320     -2.37 0.0176</code></pre>
<p>We can calculate the link as a linear combination, an inner product of coefficients and values.</p>
<p><span class="math display">\[
-30.67 + 2.04 + 0.969 * 50 -0.007*50^2 = 0.814
\]</span></p>
<div class="sourceCode" id="cb1092"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1092-1"><a href="LOGREG.html#cb1092-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod6) <span class="sc">%&gt;%</span></span>
<span id="cb1092-2"><a href="LOGREG.html#cb1092-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(estimate) <span class="sc">%&gt;%</span> </span>
<span id="cb1092-3"><a href="LOGREG.html#cb1092-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>() <span class="sc">%*%</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">50</span>,<span class="dv">50</span><span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>##           [,1]
## [1,] 0.8140013</code></pre>
<p>Using the inverse transform of the logit function, we find the probability of the game being new given the predictor values.</p>
<p><span class="math display">\[
\frac{\ e^{.814}\ }{\ 1\ +\ e^{.814}\ } = 0.693
\]</span></p>
<div class="sourceCode" id="cb1094"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1094-1"><a href="LOGREG.html#cb1094-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(.<span class="dv">814</span>)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(.<span class="dv">814</span>))</span></code></pre></div>
<pre><code>## [1] 0.6929612</code></pre>
<div id="diagnostics-for-logistic-regression" class="section level3" number="31.3.1">
<h3><span class="header-section-number">31.3.1</span> Diagnostics for logistic regression</h3>
<p>The assumptions for logistic regression and the diagnostic tools are similar to what we found for linear regression. However, with the binary nature of the outcome, we often need large data sets to check. We will not devote much time to performing diagnostics for logistic regression because we are interested in using it as a predictive model. The assumptions are:</p>
<ol style="list-style-type: decimal">
<li>Each predictor <span class="math inline">\(x_i\)</span> is linearly related to logit<span class="math inline">\((p_i)\)</span> if all other predictors are held constant. This is similar to our linear fit diagnostic in linear multiple regression.<br />
</li>
<li>Each outcome <span class="math inline">\(Y_i\)</span> is independent of the other outcomes.<br />
</li>
<li>There are no influential data points.<br />
</li>
<li>Multicollinearity is minimal.</li>
</ol>
</div>
</div>
<div id="confidence-intervals-2" class="section level2" number="31.4">
<h2><span class="header-section-number">31.4</span> Confidence intervals</h2>
<p>In this section we will generate confidence intervals. This section is experimental since we are not sure how <code>do()</code> from the <strong>mosaic</strong> package will work with the <code>glm()</code> function, but letâ€™s experiment.</p>
<div id="confidence-intervals-for-a-parameter" class="section level3" number="31.4.1">
<h3><span class="header-section-number">31.4.1</span> Confidence intervals for a parameter</h3>
<p>First, letâ€™s use the <code>R</code> built-in function <code>confint()</code> to find the confidence interval for the simple logistic regression model coefficients.</p>
<div class="sourceCode" id="cb1096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1096-1"><a href="LOGREG.html#cb1096-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mario_mod4)</span></code></pre></div>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##                      2.5 %     97.5 %
## (Intercept)    -15.4048022 -7.9648042
## stock_photoyes   0.8888216  3.6268545
## total_pr         0.1297024  0.2705395</code></pre>
<p>These are not symmetric around the estimate because the method is using a profile-likelihood method. We can get symmetric intervals based on the central limit theorem using the function <code>confint.default()</code>.</p>
<div class="sourceCode" id="cb1099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1099-1"><a href="LOGREG.html#cb1099-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint.default</span>(mario_mod4)</span></code></pre></div>
<pre><code>##                      2.5 %     97.5 %
## (Intercept)    -15.0107641 -7.6282654
## stock_photoyes   0.7727450  3.4599054
## total_pr         0.1236583  0.2632982</code></pre>
<p>These results are close. We recommend using the profile-likelihood method.</p>
<p>Now, letâ€™s work with the <code>do()</code> function to determine if we can get similar results.</p>
<div class="sourceCode" id="cb1101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1101-1"><a href="LOGREG.html#cb1101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">do</span>(<span class="dv">1</span>)<span class="sc">*</span>mario_mod4</span></code></pre></div>
<pre><code>##   Intercept stock_photoyes  total_pr .row .index
## 1 -11.31951       2.116325 0.1934783    1      1</code></pre>
<div class="sourceCode" id="cb1103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1103-1"><a href="LOGREG.html#cb1103-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(mario_mod4)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term           estimate std.error statistic       p.value
##   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;
## 1 (Intercept)     -11.3      1.88       -6.01 0.00000000185
## 2 stock_photoyes    2.12     0.686       3.09 0.00202      
## 3 total_pr          0.193    0.0356      5.43 0.0000000560</code></pre>
<p>It looks like <code>do()</code> is performing as expected. Letâ€™s now perform one resample to see what happens.</p>
<div class="sourceCode" id="cb1105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1105-1"><a href="LOGREG.html#cb1105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">do</span>(<span class="dv">1</span>)<span class="sc">*</span><span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span>total_pr,</span>
<span id="cb1105-2"><a href="LOGREG.html#cb1105-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span><span class="fu">resample</span>(mariokart),</span>
<span id="cb1105-3"><a href="LOGREG.html#cb1105-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<pre><code>##   Intercept stock_photoyes  total_pr .row .index
## 1 -11.05487       1.058763 0.2046713    1      1</code></pre>
<p>Again, it looks like what we expect. Now letâ€™s bootstrap the coefficients and summarize the results.</p>
<div class="sourceCode" id="cb1107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1107-1"><a href="LOGREG.html#cb1107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5011</span>)</span>
<span id="cb1107-2"><a href="LOGREG.html#cb1107-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do</span>(<span class="dv">1000</span>)<span class="sc">*</span><span class="fu">glm</span>(cond<span class="sc">==</span><span class="st">&quot;new&quot;</span><span class="sc">~</span>stock_photo<span class="sc">+</span>total_pr,</span>
<span id="cb1107-3"><a href="LOGREG.html#cb1107-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span><span class="fu">resample</span>(mariokart),</span>
<span id="cb1107-4"><a href="LOGREG.html#cb1107-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode" id="cb1109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1109-1"><a href="LOGREG.html#cb1109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##   Intercept stock_photoyes  total_pr .row .index
## 1 -11.22155       1.665492 0.1986654    1      1
## 2 -13.25708       1.889510 0.2371109    1      2
## 3 -11.54544       2.871460 0.1867757    1      3
## 4 -19.25785       5.816050 0.2829247    1      4
## 5 -10.86631       3.255767 0.1672335    1      5
## 6 -13.62425       1.842765 0.2533934    1      6</code></pre>
<p>Now we will plot the bootstrap sampling distribution on the parameter associated with <code>total_pr</code>.</p>
<div class="sourceCode" id="cb1111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1111-1"><a href="LOGREG.html#cb1111-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb1111-2"><a href="LOGREG.html#cb1111-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_histogram</span>(<span class="sc">~</span>total_pr,<span class="at">fill=</span><span class="st">&quot;cyan&quot;</span>,<span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1111-3"><a href="LOGREG.html#cb1111-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_theme</span>(<span class="fu">theme_bw</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb1111-4"><a href="LOGREG.html#cb1111-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gf_labs</span>(<span class="at">title=</span><span class="st">&quot;Bootstrap sampling distribtuion&quot;</span>,</span>
<span id="cb1111-5"><a href="LOGREG.html#cb1111-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">x=</span><span class="st">&quot;total price paramater estimate&quot;</span>)</span></code></pre></div>
<p><img src="31-Logistic-Regression_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<p>The printout from the logistic regression model assumes normality for the sampling distribution of the <code>total_pr</code> coefficient, but it appears to be positively skewed, skewed to the right. The 95% confidence interval found using <code>cdata()</code>.</p>
<div class="sourceCode" id="cb1112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1112-1"><a href="LOGREG.html#cb1112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>total_pr,<span class="at">data=</span>results)</span></code></pre></div>
<pre><code>##          lower     upper central.p
## 2.5% 0.1388783 0.3082659      0.95</code></pre>
<p>This result is closer to the result from profile-likelihood. Since the interval does not include the value of zero, we can be 95% confident that it is not zero. This is close to what we found using the <code>R</code> function <code>confint()</code>.</p>
</div>
<div id="confidence-intervals-for-probability-of-success" class="section level3" number="31.4.2">
<h3><span class="header-section-number">31.4.2</span> Confidence intervals for probability of success</h3>
<p>We can use the results from the bootstrap to get a confidence interval on probability of success. We will calculate a confidence for a game with a stock photo and total price of $50. As a reminder, the probability of the game being new is 0.69.</p>
<div class="sourceCode" id="cb1114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1114-1"><a href="LOGREG.html#cb1114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(mario_mod5,</span>
<span id="cb1114-2"><a href="LOGREG.html#cb1114-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">stock_photo=</span><span class="st">&quot;yes&quot;</span>,<span class="at">total_pr=</span><span class="dv">50</span>),</span>
<span id="cb1114-3"><a href="LOGREG.html#cb1114-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   stock_photo total_pr .fitted
##   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;
## 1 yes               50   0.693</code></pre>
<p>The key is to use the coefficient from each resampled data set to calculate a probability of success.</p>
<div class="sourceCode" id="cb1116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1116-1"><a href="LOGREG.html#cb1116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>##   Intercept stock_photoyes  total_pr .row .index
## 1 -11.22155       1.665492 0.1986654    1      1
## 2 -13.25708       1.889510 0.2371109    1      2
## 3 -11.54544       2.871460 0.1867757    1      3
## 4 -19.25785       5.816050 0.2829247    1      4
## 5 -10.86631       3.255767 0.1672335    1      5
## 6 -13.62425       1.842765 0.2533934    1      6</code></pre>
<div class="sourceCode" id="cb1118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1118-1"><a href="LOGREG.html#cb1118-1" aria-hidden="true" tabindex="-1"></a>results_pred <span class="ot">&lt;-</span> results <span class="sc">%&gt;%</span> </span>
<span id="cb1118-2"><a href="LOGREG.html#cb1118-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pred=</span><span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">*</span>(Intercept<span class="sc">+</span>stock_photoyes<span class="sc">+</span><span class="dv">50</span><span class="sc">*</span>total_pr))))</span></code></pre></div>
<div class="sourceCode" id="cb1119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1119-1"><a href="LOGREG.html#cb1119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cdata</span>(<span class="sc">~</span>pred,<span class="at">data=</span>results_pred)</span></code></pre></div>
<pre><code>##        lower     upper central.p
## 2.5% 0.50388 0.7445598      0.95</code></pre>
<p>We are 95% confident that expected probability a game with a stock photo and a total price of $50 is between 50.4% and 74.4%.</p>
</div>
</div>
<div id="summary-4" class="section level2" number="31.5">
<h2><span class="header-section-number">31.5</span> Summary</h2>
<p>In this chapter, we learned how to extend linear models to outcomes that are binary. We built and interpreted models. We also used resampling to find confidence intervals.</p>
</div>
<div id="homework-problems-30" class="section level2" number="31.6">
<h2><span class="header-section-number">31.6</span> Homework Problems</h2>
<ol style="list-style-type: decimal">
<li>Possum classification</li>
</ol>
<p>Letâ€™s investigate the <code>possum</code> data set again. This time we want to model a binary outcome variable. As a reminder, the common brushtail possum of the Australia region is a bit cuter than its distant cousin, the American opossum. We consider 104 brushtail possums from two regions in Australia, where the possums may be considered a random sample from the population. The first region is Victoria, which is in the eastern half of Australia and traverses the southern coast. The second region consists of New South Wales and Queensland, which make up eastern and northeastern Australia.</p>
<p>We use logistic regression to differentiate between possums in these two regions. The outcome variable, called <code>pop</code>, takes value <code>Vic</code> when a possum is from Victoria and <code>other</code> when it is from New South Wales or Queensland. We consider five predictors: <code>sex</code>, <code>head_l</code>, <code>skull_w</code>, <code>total_l</code>, and <code>tail_l</code>.</p>
<ol style="list-style-type: lower-alpha">
<li>Explore the data by making histograms or boxplots of the quantitative variables, and bar charts of the discrete variables.<br />
Are there any outliers that are likely to have a very large influence on the logistic regression model?<br />
</li>
<li>Build a logistic regression model with all the variables. Report a summary of the model.<br />
</li>
<li>Using the p-values decide if you want to remove a variable(s) and if so build that model.<br />
</li>
<li>For any variable you decide to remove, build a 95% confidence interval for the parameter.<br />
</li>
<li>Explain why the remaining parameter estimates change between the two models.<br />
</li>
<li>Write out the form of the model. Also identify which of the following variables are positively associated (when controlling for other variables) with a possum being from Victoria: <code>head_l</code>, <code>skull_w</code>, <code>total_l</code>, and <code>tail_l</code>.<br />
</li>
<li>Suppose we see a brushtail possum at a zoo in the US, and a sign says the possum had been captured in the wild in Australia, but it doesnâ€™t say which part of Australia. However, the sign does indicate that the possum is male, its skull is about 63 mm wide, its tail is 37 cm long, and its total length is 83 cm. What is the reduced modelâ€™s computed probability that this possum is from Victoria? How confident are you in the modelâ€™s accuracy of this probability calculation?</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Medical school admission</li>
</ol>
<p>The file <code>MedGPA.csv</code> in the <code>data</code> folder has information on medical school admission status and GPA and standardized test scores gathered on 55 medical school applicants from a liberal arts college in the Midwest.</p>
<p>The variables are:</p>
<p><code>Accept Status</code>: A=accepted to medical school or D=denied admission<br />
<code>Acceptance</code>: Indicator for Accept: 1=accepted or 0=denied<br />
<code>Sex</code>: F=female or M=male<br />
<code>BCPM</code>: Bio/Chem/Physics/Math grade point average<br />
<code>GPA</code>: College grade point average<br />
<code>VR</code>: Verbal reasoning (subscore)<br />
<code>PS</code>: Physical sciences (subscore)<br />
<code>WS</code>: Writing sample (subcore)<br />
<code>BS</code>: Biological sciences (subscore)<br />
<code>MCAT</code>: Score on the MCAT exam (sum of CR+PS+WS+BS)<br />
<code>Apps</code>: Number of medical schools applied to</p>
<ol style="list-style-type: lower-alpha">
<li>Build a logistic regression model to predict if a student where denied admission from <code>GPA</code> and <code>Sex</code>.<br />
</li>
<li>Generate a 95% confidence interval for the coefficient associated with <code>GPA</code>.<br />
</li>
<li>Fit a model with a polynomial of degree 2 in the <code>GPA</code>. Drop <code>Sex</code> from the model. Does a quadratic fit improve the model?<br />
</li>
<li>Fit a model with just <code>GPA</code> and interpret the coefficient.<br />
</li>
<li>Try to add different predictors to come up with your best model.<br />
</li>
<li>Generate a confusion matrix for the best model you have developed.<br />
</li>
<li>Find a 95% confidence interval for the probability a female student with a 3.5 GPA, a <code>BCPM</code> of 3.8, a verbal reasoning score of 10, a physical sciences score of 9, a writing sample score of 8, a biological score of 10, a MCAT score of 40, and who applied to 5 medical schools.</li>
</ol>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="103">
<li id="fn103"><p>Diez DM, Barr CD, and etinkaya-Rundel M. 2012. <code>openintro</code>: OpenIntro data sets and supplemental functions. <a href="http://cran.r-project.org/web/packages/openintro" class="uri">http://cran.r-project.org/web/packages/openintro</a><a href="LOGREG.html#fnref103" class="footnote-back">â†©ï¸Ž</a></p></li>
</ol>
</div>
  </main>

  <div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Computational Probability and Statistics</strong>" was written by Matthew Davis, Brianna Hitt, Ken Horton, Bradley Warner. It was last built on 2022-06-14.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
<script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>

</html>
